======
FILE: /content/artifact_references/_index.md
======
---
menutitle: "Artifact Reference"
title: "Artifact Reference"
date: 2021-06-12T14:03:59Z
draft: false
weight: 160
pre: <i class="fas fa-book"></i>
no_edit: true
disableToc: true
no_children: true
rss_data_file: static/reference/data.json
rss_title: Velociraptor Artifact Reference
noDisqus: true
outputs:
- html
- RSS
---

Velociraptor comes with a large number of built-in artifacts. This
reference provides a copy of the built in artifacts normally shipped
within Velociraptor. This reference is provided for easy searching -
it does not normally need to be imported directly into Velociraptor
since these artifacts are included in the latest binary.

{{% artifact_reference %}}

---END OF FILE---

======
FILE: /content/artifact_references/pages/server.import.deleteartifacts.md
======
---
title: Server.Import.DeleteArtifacts
hidden: true
tags: [Server Artifact]
---

This artifact will remove customized artifacts from the Velociraptor
server based on a regex.

NOTE: It is impossible to remove built in artifacts.


<pre><code class="language-yaml">
name: Server.Import.DeleteArtifacts
description: |
  This artifact will remove customized artifacts from the Velociraptor
  server based on a regex.

  NOTE: It is impossible to remove built in artifacts.

type: SERVER

required_permissions:
- SERVER_ADMIN

parameters:
  - name: ArtifactRegex
    type: regex
    description: A regex to select artifacts to delete.
    default: ^(Exchange|Custom)
  - name: ReallyDoIt
    type: bool

sources:
  - query: |
      SELECT name, description,
         if(condition=ReallyDoIt, then=artifact_delete(name=name)) AS ReallyDoIt
      FROM artifact_definitions()
      WHERE NOT built_in
        AND name =~ ArtifactRegex

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/server.utils.removetimeline.md
======
---
title: Server.Utils.RemoveTimeline
hidden: true
tags: [Server Artifact]
---

Remove a child timeline from a super timeline.


<pre><code class="language-yaml">
name: Server.Utils.RemoveTimeline
description: |
  Remove a child timeline from a super timeline.

type: SERVER

parameters:
  - name: NotebookId
  - name: Timeline
    description: SuperTimeline name
  - name: ChildName
    description: Name of child timeline

sources:
  - query: |
      SELECT if(condition=ChildName AND Timeline AND NotebookId,
                then=timeline_delete(
                     timeline=Timeline,
                     notebook_id=NotebookId,
                     name=ChildName)) AS Removed
      FROM scope()

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.applications.iislogs.md
======
---
title: Windows.Applications.IISLogs
hidden: true
tags: [Client Artifact]
---

This artifact enables grep of IISLogs.
Parameters include SearchRegex and WhitelistRegex as regex terms.


<pre><code class="language-yaml">
name: Windows.Applications.IISLogs
description: |
  This artifact enables grep of IISLogs.
  Parameters include SearchRegex and WhitelistRegex as regex terms.

author: "Matt Green - @mgreen27"

parameters:
  - name: IISLogFiles
    default: '*:/inetpub/logs/**3/*.log'
  - name: SearchRegex
    description: "Regex of strings to search in line."
    default: ' POST '
    type: regex
  - name: WhitelistRegex
    description: "Regex of strings to leave out of output."
    default:
    type: regex

sources:
  - precondition: SELECT OS From info() where OS = 'windows'

    query: |
      LET files = SELECT OSPath FROM glob(globs=IISLogFiles)

      SELECT * FROM foreach(row=files,
          query={
              SELECT Line, OSPath FROM parse_lines(filename=OSPath)
              WHERE
                Line =~ SearchRegex
                AND NOT if(condition= WhitelistRegex,
                    then= Line =~ WhitelistRegex,
                    else= FALSE)
          })

    notebook:
      - type: vql_suggestion
        name: IIS Groks
        template: |
            /*
            ### IIS grok

            Note:  IIS doesn't have a standard logging format so we have added some
            suggestions. Comment in preferred or add / modify your own.
            */

            LET target_grok = "%{TIMESTAMP_ISO8601:LogTimeStamp} %{IPORHOST:Site} %{WORD:Method} %{URIPATH:UriPath} %{NOTSPACE:QueryString} %{NUMBER:Port} %{NOTSPACE:Username} %{IPORHOST:Clienthost} %{NOTSPACE:Useragent} %{NOTSPACE:Referrer} %{NUMBER:Response} %{NUMBER:Subresponse} %{NUMBER:Win32status} %{NUMBER:Timetaken:int}"
            --LET target_grok = "%{TIMESTAMP_ISO8601:log_timestamp} %{IPORHOST:site} %{WORD:method} %{URIPATH:page} %{NOTSPACE:querystring} %{NUMBER:port} %{NOTSPACE:username} %{IPORHOST:clienthost} %{NOTSPACE:useragent} %{NOTSPACE:referer} %{NUMBER:response} %{NUMBER:subresponse} %{NUMBER:scstatus} %{NUMBER:timetaken:int}"
            --LET target_grok = "%{TIMESTAMP_ISO8601:log_timestamp} %{WORD:iisSite} %{NOTSPACE:computername} %{IPORHOST:site} %{WORD:method} %{URIPATH:page} %{NOTSPACE:querystring} %{NUMBER:port} %{NOTSPACE:username} %{IPORHOST:clienthost} %{NOTSPACE:protocol} %{NOTSPACE:useragent} %{NOTSPACE:referer} %{IPORHOST:cshost} %{NUMBER:response} %{NUMBER:subresponse} %{NUMBER:scstatus} %{NUMBER:bytessent:int} %{NUMBER:bytesrecvd:int} %{NUMBER:timetaken:int}"


            LET parsed = SELECT Fqdn, ClientId as _ClientId, Line as _Raw,
                  grok(data=Line,grok=target_grok) as GrokParsed
              FROM source()

            SELECT * FROM foreach(row=parsed,
                  query={ SELECT *, Fqdn, _Raw FROM GrokParsed })

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.kapefiles.extract.md
======
---
title: Windows.KapeFiles.Extract
hidden: true
tags: [Server Artifact]
---

The Windows.KapeFiles.Targets artifact collects files into a Zip
file. Zip files can not generally preserve timestamps since they
only have a single timestamp concept. Velociraptor will only record
the modified time in the zip file header itself but all the times
are present in the metadata file:

"Windows.KapeFiles.Targets/All File Metadata.json"

Sometimes, users wish to extract the contents of a collection to a
directory, and run an external tool over the data. Some such
external tools assume the file timestamps (e.g. prefetch files) are
meaningful. In this case we need to preserve the timestamps.

You can use this artifact to extract the content of a collection
while preserving the timestamps. The artifact will read the metadata
file, unpack the contents of the container and set the timestamps on
the resulting file.

NOTE: Windows allows 3 timestamps to be set (MAC time except for
Btime), while Linux only allows 2 timestamps (Modified and
Accessed).

## Example - command line invocation

```
velociraptor-v0.6.7-linux-amd64 artifacts collect Windows.KapeFiles.Extract --args ContainerPath=Collection-DESKTOP-2OR51GL-2021-07-16_06_56_50_-0700_PDT.zip --args OutputDirectory=/tmp/MyOutput/
```


<pre><code class="language-yaml">
name: Windows.KapeFiles.Extract
description: |
  The Windows.KapeFiles.Targets artifact collects files into a Zip
  file. Zip files can not generally preserve timestamps since they
  only have a single timestamp concept. Velociraptor will only record
  the modified time in the zip file header itself but all the times
  are present in the metadata file:

  "Windows.KapeFiles.Targets/All File Metadata.json"

  Sometimes, users wish to extract the contents of a collection to a
  directory, and run an external tool over the data. Some such
  external tools assume the file timestamps (e.g. prefetch files) are
  meaningful. In this case we need to preserve the timestamps.

  You can use this artifact to extract the content of a collection
  while preserving the timestamps. The artifact will read the metadata
  file, unpack the contents of the container and set the timestamps on
  the resulting file.

  NOTE: Windows allows 3 timestamps to be set (MAC time except for
  Btime), while Linux only allows 2 timestamps (Modified and
  Accessed).

  ## Example - command line invocation

  ```
  velociraptor-v0.6.7-linux-amd64 artifacts collect Windows.KapeFiles.Extract --args ContainerPath=Collection-DESKTOP-2OR51GL-2021-07-16_06_56_50_-0700_PDT.zip --args OutputDirectory=/tmp/MyOutput/
  ```

type: SERVER

parameters:
  - name: OutputDirectory
    description: Directory to write on (must be set).
  - name: ContainerPath
    description: Path to container (zip file) to unpack.

sources:
  - query: |
      LET MetadataFile = ("results", "Windows.KapeFiles.Targets/All File Metadata.json")
      LET UploadsFile = "uploads.json"

      // Path to the root of the container
      LET RootPathSpec = pathspec(DelegateAccessor="auto",
                                  path_type="zip",
                                  DelegatePath=ContainerPath)

      // The pathspec for where to store the file
      LET OutputPathSpec = pathspec()

      // Memoize the metadata stored in the container file so we can
      // quickly extract the file times.
      LET AllFileMetadata &lt;= memoize(
          key="SourceFile",
          query={
            SELECT *
            FROM parse_jsonl(accessor="collector",
                             filename=RootPathSpec + MetadataFile)
          })

      LET ALLUploads = SELECT *, RootPathSpec + _Components AS FileUpload,
                              OutputPathSpec + _Components[2:] AS Dest,
                              get(item=AllFileMetadata,
                                  field=vfs_path) AS Metadata
        FROM parse_jsonl(accessor="collector",
                         filename=RootPathSpec + UploadsFile)
        WHERE Type != "idx"

      SELECT *, upload_directory(
          accessor="collector",
          output=OutputDirectory,
          mtime=Metadata.Modified,
          atime=Metadata.LastAccessed,
          ctime=Metadata.Created,
          name=Dest,
          file=RootPathSpec + _Components) AS UploadedFile
      FROM ALLUploads

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.etw.kernelprocess.md
======
---
title: Windows.ETW.KernelProcess
hidden: true
tags: [Client Event Artifact]
---

This artifact follows the Microsoft-Windows-Kernel-Process provider.

NOTE: We can only attach to this provider when running as
NT_USER/SYSTEM.


<pre><code class="language-yaml">
name: Windows.ETW.KernelProcess
description: |
  This artifact follows the Microsoft-Windows-Kernel-Process provider.

  NOTE: We can only attach to this provider when running as
  NT_USER/SYSTEM.

references:
- "https://github.com/repnz/etw-providers-docs/blob/master/Manifests-Win10-18990/Microsoft-Windows-Kernel-Process.xml"

parameters:
  - name: ProcessRegex
    type: regex
    description: View Processes with Executables matching this regex
    default: .

  - name: IgnoreProcessRegex
    type: regex
    description: Ignore Processes with Executables matching this regex

  - name: Events
    type: multichoice
    description: Events to view
    default: '["ProcessStart", "ImageLoad"]'
    choices:
      - ProcessStart
      - ProcessStop
      - ImageLoad
      - ImageUnload

type: CLIENT_EVENT

sources:
  - query: |
      LET EIDLookup &lt;= dict(
        `1`="ProcessStart", `2`="ProcessStop",
        `5`="ImageLoad", `6`="ImageUnload")

      LET ETW = SELECT *
      FROM watch_etw(guid='{22fb2cd6-0e7b-422b-a0c7-2fad1fd0e716}',
           description="Microsoft-Windows-Kernel-Process", any=0x50)

      SELECT System.ID AS EID,
         get(item=EIDLookup, field=str(str=System.ID)) AS EventType,
         process_tracker_get(id=System.ProcessID).Data AS ParentProcInfo,
         process_tracker_callchain(id=System.ProcessID).Data.Exe AS ParentCallChain,
         EventData
      FROM delay(query=ETW, delay=3)
      WHERE EventType IN Events
        AND EventData.ImageName =~ ProcessRegex
        AND if(condition=IgnoreProcessRegex,
               then=NOT EventData.ImageName =~ IgnoreProcessRegex,
               else=TRUE)

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.applications.teamviewer.incoming.md
======
---
title: Windows.Applications.TeamViewer.Incoming
hidden: true
tags: [Client Artifact]
---

Parses the TeamViewer Connections_incoming.txt log file.

When inbound logging enabled, this file will show all inbound TeamViewer
connections.


<pre><code class="language-yaml">
name: Windows.Applications.TeamViewer.Incoming
description: |
   Parses the TeamViewer Connections_incoming.txt log file.

   When inbound logging enabled, this file will show all inbound TeamViewer
   connections.

author: Matt Green - @mgreen27

reference:
  - https://attack.mitre.org/techniques/T1219/
  - https://www.systoolsgroup.com/forensics/teamviewer/


type: CLIENT
parameters:
  - name: FileGlob
    default: C:\Program Files (x86)\TeamViewer\Connections_incoming.txt
  - name: DateAfter
    description: "search for events after this date. YYYY-MM-DDTmm:hh:ss Z"
    type: timestamp
  - name: DateBefore
    description: "search for events before this date. YYYY-MM-DDTmm:hh:ss Z"
    type: timestamp
  - name: TeamViewerIDRegex
    description: "Regex of TeamViewer ID"
    default: .
    type: regex
  - name: SourceHostRegex
    description: "Regex of source host"
    default: .
    type: regex
  - name: UserRegex
    description: "Regex of user"
    default: .
    type: regex

  - name: VSSAnalysisAge
    type: int
    default: 0
    description: |
      If larger than zero we analyze VSS within this many days
      ago. (e.g 7 will analyze all VSS within the last week).  Note
      that when using VSS analysis we have to use the ntfs accessor
      for everything which will be much slower.

sources:
  - query: |
      LET VSS_MAX_AGE_DAYS &lt;= VSSAnalysisAge
      LET Accessor = if(condition=VSSAnalysisAge &gt; 0, then="ntfs_vss", else="auto")

      -- Build time bounds
      LET DateAfterTime &lt;= if(condition=DateAfter,
        then=DateAfter, else="1600-01-01")
      LET DateBeforeTime &lt;= if(condition=DateBefore,
        then=DateBefore, else="2200-01-01")

      -- expand provided glob into a list of paths on the file system (fs)
      LET fspaths &lt;= SELECT OSPath FROM glob(
         globs=expand(path=FileGlob), accessor=Accessor)

      LET parse_log(OSPath, Accessor) = SELECT OSPath,
          parse_string_with_regex(
            string=Line,
            regex="^(?P&lt;TeamViewerID&gt;^\\d+)\\s+"+
              "(?P&lt;SourceHost&gt;.+)\\s" +
              "(?P&lt;StartTime&gt;\\d{2}-\\d{2}-\\d{4}\\s\\d{2}:\\d{2}:\\d{2})\\s" +
              "(?P&lt;EndTime&gt;\\d{2}-\\d{2}-\\d{4}\\s\\d{2}:\\d{2}:\\d{2})\\s" +
              "(?P&lt;User&gt;.+)\\s+" +
              "(?P&lt;ConnectionType&gt;[^\\s]+)\\s+" +
              "(?P&lt;ConnectionID&gt;.+)$") as Record
        FROM parse_lines(filename=OSPath, accessor=Accessor)
        WHERE Line
          AND Record.TeamViewerID =~ TeamViewerIDRegex
          AND Record.SourceHost =~ SourceHostRegex
          AND Record.User =~ UserRegex

      -- function returning IOC hits
      LET logsearch(PathList) = SELECT * FROM foreach(
            row=PathList,
            query={
               SELECT *, timestamp(epoch=Record.StartTime,
                                format="02-01-2006 15:04:05") AS StartTime,
                      timestamp(epoch=Record.EndTime,
                                format="02-01-2006 15:04:05") AS EndTime
               FROM parse_log(OSPath=OSPath, Accessor=Accessor)
               WHERE StartTime &lt; DateBeforeTime
                    AND StartTime &gt; DateAfterTime
                    AND EndTime &lt; DateBeforeTime
                    AND EndTime &gt; DateAfterTime
            })

      SELECT
        Record.TeamViewerID as TeamViewerID,
        Record.SourceHost as SourceHost,
        StartTime,
        EndTime,
        Record.User as User,
        Record.ConnectionType as ConnectionType,
        Record.ConnectionID as ConnectionID,
        OSPath
      FROM logsearch(PathList=fspaths)

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.ntfs.recover.md
======
---
title: Windows.NTFS.Recover
hidden: true
tags: [Client Artifact]
---

Attempt to recover deleted files.

This artifact uploads all streams from an MFTId. If the MFT entry is
not allocated there is a chance that the cluster that contain the
actual data of the file will be intact still on the disk. Therefore
this artifact can be used to attempt to recover a deleted file.

A common use is to recover deleted directory entries using the
Windows.NTFS.I30 artifact and identify MFT entries of interest. This
is artifact can be used to attempt to recover some data.


<pre><code class="language-yaml">
name: Windows.NTFS.Recover
description: |
  Attempt to recover deleted files.

  This artifact uploads all streams from an MFTId. If the MFT entry is
  not allocated there is a chance that the cluster that contain the
  actual data of the file will be intact still on the disk. Therefore
  this artifact can be used to attempt to recover a deleted file.

  A common use is to recover deleted directory entries using the
  Windows.NTFS.I30 artifact and identify MFT entries of interest. This
  is artifact can be used to attempt to recover some data.

parameters:
 - name: MFTId
   default: "81978"
 - name: Drive
   default: '\\.\C:'

precondition:
  SELECT * FROM info() where OS = 'windows'

sources:
  - name: Upload
    query: |
       LET Parsed &lt;= parse_ntfs(device=Drive, inode=MFTId)

       SELECT *, upload(accessor="mft", file=Drive + Inode,
                        name=Parsed.OSPath + Inode) AS IndexUpload
       FROM foreach(
            row=Parsed.Attributes,
            query={
              SELECT _value.Type AS Type,
                     _value.TypeId AS TypeId,
                     _value.Id AS Id,
                     _value.Inode AS Inode,
                     _value.Size AS Size,
                     _value.Name AS Name
              FROM scope()
            })

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.search.yara.md
======
---
title: Windows.Search.Yara
hidden: true
tags: [Client Artifact]
---

Searches for a specific malicious file or set of files by a Yara rule.


<pre><code class="language-yaml">
name: Windows.Search.Yara
description: |
  Searches for a specific malicious file or set of files by a Yara rule.

parameters:
    - name: nameRegex
      description: Only file names that match this regular expression will be scanned.
      default: "(exe|txt|dll|php)$"
      type: regex
    - name: AlsoUpload
      type: bool
      description: Also upload matching files.
    - name: yaraRule
      type: yara
      description: The Yara Rule to search for.
      default: |
        rule Hit {
            strings:
              $a = "Keyword" nocase wide ascii
            condition:
              any of them
        }

    - name: NTFS_CACHE_TIME
      type: int
      description: How often to flush the NTFS cache. (Default is never).
      default: "1000000"

precondition:
    SELECT * FROM info() WHERE OS =~ "windows"

sources:
  - query: |
        LET Root = pathspec(parse="C:", path_type="ntfs")

        -- Progress logging for newer clients
        LET fileList = SELECT * FROM if(condition=version(function="log") &gt; 1,
        then={
          SELECT Root + OSPath AS OSPath
          FROM parse_mft(accessor="ntfs",filename=Root+"$MFT")
          WHERE InUse
            AND log(message="Processing entry %v", args=EntryNumber, dedup=5)
            AND FileName =~ nameRegex
            AND NOT OSPath =~ "WinSXS"
            AND log(message="Scanning file %v", args=OSPath, dedup=5)

        }, else={
          SELECT Root + OSPath AS OSPath
          FROM parse_mft(accessor="ntfs",filename=Root+"$MFT")
          WHERE InUse
            AND FileName =~ nameRegex
            AND NOT OSPath =~ "WinSXS"
        })

        -- These files are typically short - only report a single hit.
        LET search = SELECT Rule, String.Offset AS HitOffset,
             str(str=String.Data) AS HitContext,
             FileName,
             File.Size AS Size,
             File.ModTime AS ModTime
        FROM yara(
            rules=yaraRule, key="A",
            files= OSPath)
        LIMIT 1

        SELECT *, if(condition=AlsoUpload, then=upload(file=FileName)) AS Upload
        FROM foreach(row=fileList, query=search)

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.forensics.recyclebin.md
======
---
title: Windows.Forensics.RecycleBin
hidden: true
tags: [Client Artifact]
---

This artefact will parse the `$I` files found in the `$Recycle.Bin` folder to
obtain the time of deletion and the original path and file name.

Supports Recycle Bin format found in Vista onwards. This will not parse INFO2
files found in the "Recycler" folder from XP and below.

The layout of the Recycle Bin folder is in the in the form:
```
  C:\$Recycle.Bin\%SID%\
```
Each folder contains the following files:
```
$R###### files; the original data
$I###### files; the "Recycled" file's metadata
```
The first file begins with the value `$R` followed by a random string
– this file contains the actual contents of the recycled file.
The second file begins with `$I` and ends in the same string as the
`$R` file – this file contains the metadata for that specific file

Limitations: This artifact uses the API to read available $I data. There may be additional unallocated but readable $I files referenced in the MFT that may be recoverable.


<pre><code class="language-yaml">
name: Windows.Forensics.RecycleBin
description: |
  This artefact will parse the `$I` files found in the `$Recycle.Bin` folder to
  obtain the time of deletion and the original path and file name.

  Supports Recycle Bin format found in Vista onwards. This will not parse INFO2
  files found in the "Recycler" folder from XP and below.

  The layout of the Recycle Bin folder is in the in the form:
  ```
    C:\$Recycle.Bin\%SID%\
  ```
  Each folder contains the following files:
  ```
  $R###### files; the original data
  $I###### files; the "Recycled" file's metadata
  ```
  The first file begins with the value `$R` followed by a random string
  – this file contains the actual contents of the recycled file.
  The second file begins with `$I` and ends in the same string as the
  `$R` file – this file contains the metadata for that specific file

  Limitations: This artifact uses the API to read available $I data. There may be additional unallocated but readable $I files referenced in the MFT that may be recoverable.

author: "Zach Stanford - @svch0st"

reference:
  - https://forensicswiki.xyz/wiki/index.php?title=Windows#Recycle_Bin
  - https://www.magnetforensics.com/blog/artifact-profile-recycle-bin/


parameters:
    - name: RecycleBinGlobs
      default: C:\$Recycle.Bin\**\$I*

    - name: AlsoUpload
      type: bool
      description: Also upload recovered files.

precondition: SELECT OS From info() where OS = 'windows'

sources:
  - query: |
        SELECT * FROM foreach(
              row={
                 SELECT OSPath FROM glob(globs=RecycleBinGlobs)
              },
              query={
                SELECT
                    timestamp(winfiletime=DeletedTime) as DeletedTimestamp,
                    Name,
                    FilePath as OriginalFilePath,
                    FileSize,
                    OSPath,
                    regex_replace(source=OSPath, re="\\\\\\$I", replace="\\$$R") AS RecyclePath,
                    if(condition=AlsoUpload, then=upload(
                         file=regex_replace(source=OSPath, re="\\\\\\$I", replace="\\$$R"),
                         name=FilePath
                    )) AS Upload
                 FROM parse_recyclebin(filename=OSPath)
              })

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/server.internal.label.md
======
---
title: Server.Internal.Label
hidden: true
tags: [Internal Artifact]
---

An internal artifact used to track new labeling events.


<pre><code class="language-yaml">
name: Server.Internal.Label
description: |
  An internal artifact used to track new labeling events.

type: INTERNAL

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/server.alerts.trackaccount.md
======
---
title: Server.Alerts.Trackaccount
hidden: true
tags: [Server Event Artifact]
---

This artifact alerts when account usage of a monitored account is detected. This is a server-side artifact, please note that it requires the client_event artifact 'Windows.Events.Trackaccount' to be enabled.


<pre><code class="language-yaml">
name: Server.Alerts.Trackaccount
description: |
   This artifact alerts when account usage of a monitored account is detected. This is a server-side artifact, please note that it requires the client_event artifact 'Windows.Events.Trackaccount' to be enabled.

author: Jos Clephas - @DfirJos

type: SERVER_EVENT

parameters:
  - name: SlackToken
    description: The token URL obtained from Slack/Teams/Discord (or basicly any communication-service that supports webhooks). Leave blank to use server metadata. e.g. https://hooks.slack.com/services/XXXX/YYYY/ZZZZ

sources:
  - query: |
        LET token_url = if(
           condition=SlackToken,
           then=SlackToken,
           else=server_metadata().SlackToken)

        LET hits = SELECT * from watch_monitoring(artifact='Windows.Events.Trackaccount')

        SELECT * FROM foreach(row=hits,
        query={
           SELECT EventRecordID, EventID, TargetUserName, TargetWorkstationName, SourceComputer, LogonType, EventTime, ClientId, Url, Content, Response FROM http_client(
            data=serialize(item=dict(
                text=format(format="EventID: %v - Account '%v' authenticated from system '%v' to '%v' with LogonType %v at %v on client %v (EventRecordID: %v)",
                            args=[EventID, TargetUserName, TargetWorkstationName, SourceComputer, LogonType, EventTime, ClientId, EventRecordID])),
                format="json"),
            headers=dict(`Content-Type`="application/json"),
            method="POST",
            url=token_url)
        })

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/admin.client.uninstall.md
======
---
title: Admin.Client.Uninstall
hidden: true
tags: [Client Artifact]
---

Uninstall Velociraptor from the endpoint.

This artifact uninstalls a Velociraptor client (or any other MSI
package) from the endpoint.

Typically the client will be hard terminated during the uninstall
process, so on the server it would appear that the collection is not
completed. This is normal.

NOTE: Be careful with the DisplayNameRegex to ensure you do not
uninstall another package accidentally.


<pre><code class="language-yaml">
name: Admin.Client.Uninstall
description: |
  Uninstall Velociraptor from the endpoint.

  This artifact uninstalls a Velociraptor client (or any other MSI
  package) from the endpoint.

  Typically the client will be hard terminated during the uninstall
  process, so on the server it would appear that the collection is not
  completed. This is normal.

  NOTE: Be careful with the DisplayNameRegex to ensure you do not
  uninstall another package accidentally.

required_permissions:
  - EXECVE

parameters:
  - name: DisplayNameRegex
    type: regex
    default: Velociraptor
    description: A regex that will match the package to uninstall.

  - name: ReallyDoIt
    type: bool

sources:
  - name: Windows
    precondition:
      SELECT OS From info() where OS = 'windows'

    query:  |
      LET packages = SELECT KeyName, DisplayName,UninstallString
      FROM Artifact.Windows.Sys.Programs()
      WHERE DisplayName =~ DisplayNameRegex AND
        log(message="Will uninstall " + DisplayName)

      LET uninstall(UninstallString) = SELECT * FROM execve(
          argv=commandline_split(command=UninstallString) + "/quiet")

      SELECT KeyName, DisplayName, UninstallString,
          if(condition=ReallyDoIt, then=uninstall(Name=UninstallString).Stdout) AS UninstallLog
      FROM packages

  - name: Debian
    precondition: |
      -- Only run if dpkg is installed.
      SELECT OS, {
         SELECT ReturnCode FROM execve(argv=["dpkg", "--help"])
      } AS ReturnCode
      FROM info()
      WHERE OS = 'linux' AND ReturnCode = 0

    query:  |
      SELECT * FROM if(condition=ReallyDoIt,
      then={
        SELECT * FROM execve(argv=["dpkg", "--remove", "velociraptor-client"])
      })

  - name: RPMBased
    precondition: |
      -- Only run if rpm is installed.
      SELECT OS, {
         SELECT ReturnCode FROM execve(argv=["rpm", "--help"])
      } AS ReturnCode
      FROM info()
      WHERE OS = 'linux' AND ReturnCode = 0

    query:  |
      SELECT * FROM if(condition=ReallyDoIt,
      then={
        SELECT * FROM execve(argv=["rpm", "--erase", "velociraptor-client"])
      })

  - name: MacOS
    precondition: |
      SELECT OS
      FROM info()
      WHERE OS = 'darwin'

    query:  |
      LET me &lt;= SELECT Exe FROM info()

      SELECT * FROM if(condition=ReallyDoIt,
      then={
        SELECT * FROM execve(argv=[me[0].Exe, "service", "remove"])
      })

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.forensics.localhashes.usn.md
======
---
title: Windows.Forensics.LocalHashes.Usn
hidden: true
tags: [Client Event Artifact]
---

This artifact maintains a local (client side) database of file
hashes. It is then possible to query this database using the
Generic.Forensic.LocalHashes.Query artifact


<pre><code class="language-yaml">
name: Windows.Forensics.LocalHashes.Usn
description: |
  This artifact maintains a local (client side) database of file
  hashes. It is then possible to query this database using the
  Generic.Forensic.LocalHashes.Query artifact

type: CLIENT_EVENT

parameters:
  - name: PathRegex
    description: A regex to match the entire path (you can watch a directory or a file type).
    default: .
    type: regex

  - name: Device
    description: The NTFS drive to watch
    default: C:\\

  - name: HashDb
    description: Name of the local hash database
    default: hashdb.sqlite

  - name: SuppressOutput
    description: If this is set, the artifact does not return any rows to the server but will still update the local database.
    type: bool

  - name: UsnCheckPeriod
    type: int
    description: Dedup all file operations that occur within this period
    default: "10"

precondition: SELECT OS from info() where OS = "windows"

sources:
  - query: |
      -- Dont be too aggressive on the USN watching to conserve CPU usage
      LET NTFS_CACHE_TIME = 30
      LET USN_FREQUENCY = 60

      LET hash_db &lt;= SELECT OSPath
      FROM Artifact.Generic.Forensic.LocalHashes.Init(HashDb=HashDb)

      LET path &lt;= hash_db[0].OSPath

      LET _ &lt;= log(message="Will use local hash database " + path)

      LET file_modifications = SELECT Device + OSPath AS OSPath
      FROM watch_usn(device=Device)
      WHERE OSPath =~ PathRegex

      -- The USN journal may contain multiple entries for the same
      -- file modification (e.g. TRUNCATE followed by APPEND and
      -- CLOSE). We therefore dedup all entries that happen within the
      -- period as a single modification.
      LET deduped = SELECT * FROM foreach(row={
         SELECT * FROM clock(period=UsnCheckPeriod, start=0)
      },
      query={
         -- Each time the fifo is accessed we pull all the rows and
         -- dedup the path, then clear the cache.
         SELECT * FROM fifo(
             query=file_modifications,
             max_rows=5000,
             max_age=6000, flush=TRUE)
         GROUP BY OSPath
      })

      -- Stat each file that was changed to get its size and hash
      LET files = SELECT * FROM foreach(row=deduped,
      query={
         SELECT OSPath, Size, hash(path=OSPath).MD5 AS Hash, now() AS Time
         FROM stat(filename=OSPath)
         WHERE Mode.IsRegular
      })

      -- For each file hashed, insert to the local database
      LET insertion = SELECT OSPath, Hash, Size, Time, {
         SELECT * FROM sqlite(file=path,
            query="INSERT into hashes (path, md5, timestamp, size) values (?,?,?,?)",
            args=[OSPath.String, Hash, Time, Size])
      } AS Insert
      FROM files
      WHERE Insert OR TRUE

      // If output is suppressed do not emit a row, but still update the local database.
      SELECT OSPath, Hash, Size, Time
      FROM insertion
      WHERE NOT SuppressOutput

column_types:
  - name: Time
    type: timestamp

  - name: Hash
    type: hash

  - name: ClientId
    type: client_id

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/generic.forensic.timeline.md
======
---
title: Generic.Forensic.Timeline
hidden: true
tags: [Client Artifact]
---

This artifact generates a timeline of a file glob in bodyfile
format. We currently do not calculate the md5 because it is quite
expensive.


<pre><code class="language-yaml">
name: Generic.Forensic.Timeline
description: |
  This artifact generates a timeline of a file glob in bodyfile
  format. We currently do not calculate the md5 because it is quite
  expensive.

parameters:
  - name: timelineGlob
    default: C:\Users\**
  - name: timelineAccessor
    default: file

sources:
  # For NTFS accessors we write the MFT id as the inode. On windows
  # the file accessor does not give the inode at all.
  - precondition:
      SELECT OS From info() where OS = 'windows' AND timelineAccessor = 'ntfs'
    query: |
        SELECT 0 AS Md5, OSPath,
               Sys.mft as Inode,
               Mode.String AS Mode, 0 as Uid, 0 as Gid, Size,
               Atime, Mtime, Ctime
        FROM glob(globs=timelineGlob, accessor=timelineAccessor)

  # For linux we can get the Inode from Sys.Ino
  - precondition:
      SELECT * From scope() where timelineAccessor = 'file'
    query: |
        SELECT 0 AS Md5, OSPath,
               Sys.Ino as Inode,
               Mode.String AS Mode, Sys.Uid AS Uid, Sys.Gid AS Gid, Size,
               Atime, Mtime, Ctime
        FROM glob(globs=timelineGlob, accessor=timelineAccessor)

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/elastic.events.clients.md
======
---
title: Elastic.Events.Clients
hidden: true
tags: [Server Event Artifact]
---

This server monitoring artifact will watch a selection of client or
server monitoring artifacts for new events and push those to an
elastic index.

NOTE: You must ensure you are collecting these artifacts from the
clients by adding them to the "Client Events" GUI, or for server
artifacts, the "Server Events" GUI.


<pre><code class="language-yaml">
name: Elastic.Events.Upload
aliases:
- Elastic.Events.Clients

description: |
  This server monitoring artifact will watch a selection of client or
  server monitoring artifacts for new events and push those to an
  elastic index.

  NOTE: You must ensure you are collecting these artifacts from the
  clients by adding them to the "Client Events" GUI, or for server
  artifacts, the "Server Events" GUI.

type: SERVER_EVENT

parameters:
  - name: ElasticAddresses
    default: http://127.0.0.1:9200/
  - name: Username
  - name: Password
  - name: APIKey
  - name: ClientArtifactsToWatch
    type: artifactset
    artifact_type: CLIENT_EVENT
    default: |
      Artifact
      Windows.Detection.PsexecService
      Windows.Events.ProcessCreation
      Windows.Events.ServiceCreation
  - name: ServerArtifactsToWatch
    type: artifactset
    artifact_type: SERVER_EVENT
    default: |
      Artifact
      Server.Audit.Logs
  - name: DisableSSLSecurity
    type: bool
    description: Disable SSL certificate verification
  - name: Threads
    type: int
    description: Number of threads to upload with
  - name: ChunkSize
    type: int
    description: Batch this many rows for each upload.
  - name: CloudID
    description: The cloud id if needed
  - name: RootCA
    description: |
      A root CA certificate in PEM for trusting TLS protected Elastic
      servers.

sources:
  - query: |
      LET artifacts_to_watch = SELECT * FROM chain(
        a={SELECT Artifact FROM ClientArtifactsToWatch},
        b={SELECT Artifact FROM ServerArtifactsToWatch})
      WHERE NOT Artifact =~ "Elastic.Events.Upload"
        AND log(message="Uploading artifact " + Artifact + " to Elastic")

      LET s = scope()

      LET events = SELECT * FROM foreach(
          row=artifacts_to_watch,
          async=TRUE,   // Required for event queries in foreach()
          query={
             SELECT *, "Artifact_" + Artifact as _index,
                    Artifact,
                    client_info(client_id=s.ClientId || "server").os_info.hostname AS Hostname,
                    timestamp(epoch=now()) AS timestamp
             FROM watch_monitoring(artifact=Artifact)
          })

      SELECT * FROM elastic_upload(
          query=events,
          threads=Threads,
          chunk_size=ChunkSize,
          addresses=split(string=ElasticAddresses, sep=","),
          index="velociraptor",
          password=Password,
          username=Username,
          cloud_id=CloudID,
          api_key=APIKey,
          root_ca=RootCA,
          disable_ssl_security=DisableSSLSecurity,
          type="ClientEvents")

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.registry.puttyhostkeys.md
======
---
title: Windows.Registry.PuttyHostKeys
hidden: true
tags: [Client Artifact]
---

This artifact extracts PuTTY SSH host keys.

As a security measure PuTTY and its companion utilities PSCP, PSFTP, and Plink 
records the host key for each server connected to, in the Windows Registry.

- Output KeyName: ssh-ed12345@22:27.27.27.27
- To search for a specific IP: TargetKeyName =~ ':\<IP\>$'
- To search for a specific PORT: TargetKeyName =~ '@\<PORT\>:.+$'


<pre><code class="language-yaml">
name: Windows.Registry.PuttyHostKeys
author: Matt Green - @mgreen27
description: |
   This artifact extracts PuTTY SSH host keys.
   
   As a security measure PuTTY and its companion utilities PSCP, PSFTP, and Plink 
   records the host key for each server connected to, in the Windows Registry.
   
   - Output KeyName: ssh-ed12345@22:27.27.27.27
   - To search for a specific IP: TargetKeyName =~ ':\&lt;IP\&gt;$'
   - To search for a specific PORT: TargetKeyName =~ '@\&lt;PORT\&gt;:.+$'
   
   
type: CLIENT

parameters:
   - name: KeyGlob
     default: Software\SimonTatham\Putty\SshHostKeys\**
   - name: TargetUser
     default: .
   - name: TargetKeyName
     default: .
   - name: TargetKeyValue
     default: .

sources:
  - precondition:
      SELECT OS From info() where OS = 'windows' 

    query: |
      LET HKEY_USERS &lt;= pathspec(path_type="registry", Path="HKEY_USERS")

      SELECT 
        Mtime,
        Username,
        OSPath.Basename AS KeyName,
        Data.value AS KeyValue,
        HKEY_USERS + UUID + OSPath.Dirname AS Key,
        OSPath.DelegatePath AS SourcePath
      FROM Artifact.Windows.Registry.NTUser(KeyGlob=KeyGlob,userRegex=TargetUser)
      WHERE KeyName =~ TargetKeyName
        AND KeyValue =~ TargetKeyValue


</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.network.interfaceaddresses.md
======
---
title: Windows.Network.InterfaceAddresses
hidden: true
tags: [Client Artifact]
---

Network interfaces and relevant metadata. This artifact works on all
supported OSs.


<pre><code class="language-yaml">
name: Generic.Network.InterfaceAddresses
description: |
  Network interfaces and relevant metadata. This artifact works on all
  supported OSs.

aliases:
  - Windows.Network.InterfaceAddresses

sources:
  - query: |
        LET interface_address =
           SELECT Index, MTU, Name,
                  HardwareAddr.String AS HardwareAddr,
                  Flags, Addrs
           from interfaces()

        SELECT Index, MTU, Name, HardwareAddr,
           Flags, Addrs.IP as IP, Addrs.Mask.String as Mask
        FROM flatten(query=interface_address)

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/elastic.eventlogs.sysmon.md
======
---
title: Elastic.EventLogs.Sysmon
hidden: true
tags: [Client Artifact]
---

Ship the the Sysmon event log in ECS schema.

The Elastic Common Schema (ECS) is an open source specification,
developed with support from the Elastic user community. ECS defines
a common set of fields to be used when storing event data in
Elasticsearch, such as logs and metrics.

NOTE: ECS is poorly documented. There is no clear documentation of
where each field in the ECS record comes from other than the actual
source code of the winlogbeats client. This artifact implements the
winlogbeat transformation as described in
https://github.com/elastic/beats/blob/master/x-pack/winlogbeat/module/sysmon/ingest/sysmon.yml

There may be slight variations between the data produced by this
artifact and the official winlogbeat client. If you find such
variation, please file an issue on Velociraptor's GitHub issue
board.


<pre><code class="language-yaml">
name: Elastic.EventLogs.Sysmon
description: |
  Ship the the Sysmon event log in ECS schema.

  The Elastic Common Schema (ECS) is an open source specification,
  developed with support from the Elastic user community. ECS defines
  a common set of fields to be used when storing event data in
  Elasticsearch, such as logs and metrics.

  NOTE: ECS is poorly documented. There is no clear documentation of
  where each field in the ECS record comes from other than the actual
  source code of the winlogbeats client. This artifact implements the
  winlogbeat transformation as described in
  https://github.com/elastic/beats/blob/master/x-pack/winlogbeat/module/sysmon/ingest/sysmon.yml

  There may be slight variations between the data produced by this
  artifact and the official winlogbeat client. If you find such
  variation, please file an issue on Velociraptor's GitHub issue
  board.

reference:
  - https://www.elastic.co/guide/en/ecs/current/ecs-reference.html

parameters:
  - name: LogFileGlob
    default: C:/Windows/System32/WinEvt/Logs/Microsoft-Windows-Sysmon%4Operational.evtx

export: |
  -- ECS clears many fields from EventData but we preserve them all,
  -- although to ensure that Elastic does not reject the fields we
  -- convert them all to strings.
  LET NormalizeEventData(EventData) = to_dict(item={
    SELECT _key, str(str=_value) AS _value FROM items(item=EventData)
  })

  LET OpcodesLookup &lt;= dict(
    `0`= "Info",
    `1`= "Start",
    `2`= "Stop",
    `3`= "DCStart",
    `4`= "DCStop",
    `5`= "Extension",
    `6`= "Reply",
    `7`= "Resume",
    `8`= "Suspend",
    `9`= "Send")

  LET LevelLookup &lt;= dict(
    `0`= "Information",
    `1`= "Critical",
    `2`= "Error",
    `3`= "Warning",
    `4`= "Information",
    `5`= "Verbose")

  LET CategoryLookup &lt;= dict(
     `1`=["process",],
     `2`=["file",],
     `3`=["network",],
     `4`=["process",],
     `5`=["process",],
     `6`=["driver",],
     `7`=["process",],
     `8`=["process",],
     `9`=["process",],
     `10`=["process",],
     `11`=["file",],
     `12`=["configuration","registry"],
     `13`=["configuration","registry"],
     `14`=["configuration","registry"],
     `15`=["file",],
     `16`=["configuration",],
     `17`=["file",],
     `18`=["file",],
     `19`=["process",],
     `20`=["process",],
     `21`=["network",],
     `22`=["network",],
     `23`=["file",],
     `24`=["",],
     `25`=["process",],
     `26`=["file",],
     `27`=["file",],
     `28`=["file",],
     `255`=["process",])

  LET TypeLookup &lt;= dict(
     `1`=["start",],
     `2`=["change",],
     `3`=["start", "connection", "protocol"],
     `4`=["change",],
     `5`=["end",],
     `6`=["start",],
     `7`=["change",],
     `8`=["change",],
     `9`=["access",],
     `10`=["access",],
     `11`=["creation",],
     `12`=["change",],
     `13`=["change",],
     `14`=["change",],
     `15`=["access",],
     `16`=["change",],
     `17`=["creation",],
     `18`=["access",],
     `19`=["creation",],
     `20`=["creation",],
     `21`=["access",],
     `22`=["connection", "protocol", "info"],
     `23`=["deletion",],
     `24`=["change",],
     `25`=["change",],
     `26`=["deletion",],
     `27`=["creation", "denied"],
     `28`=["deletion", "denied"],
     `255`=["error",])

  LET DNSLookup &lt;= dict(
        `1`= "A",
        `2`= "NS",
        `3`= "MD",
        `4`= "MF",
        `5`= "CNAME",
        `6`= "SOA",
        `7`= "MB",
        `8`= "MG",
        `9`= "MR",
        `10`= "NULL",
        `11`= "WKS",
        `12`= "PTR",
        `13`= "HINFO",
        `14`= "MINFO",
        `15`= "MX",
        `16`= "TXT",
        `17`= "RP",
        `18`= "AFSDB",
        `19`= "X25",
        `20`= "ISDN",
        `21`= "RT",
        `22`= "NSAP",
        `23`= "NSAPPTR",
        `24`= "SIG",
        `25`= "KEY",
        `26`= "PX",
        `27`= "GPOS",
        `28`= "AAAA",
        `29`= "LOC",
        `30`= "NXT",
        `31`= "EID",
        `32`= "NIMLOC",
        `33`= "SRV",
        `34`= "ATMA",
        `35`= "NAPTR",
        `36`= "KX",
        `37`= "CERT",
        `38`= "A6",
        `39`= "DNAME",
        `40`= "SINK",
        `41`= "OPT",
        `43`= "DS",
        `46`= "RRSIG",
        `47`= "NSEC",
        `48`= "DNSKEY",
        `49`= "DHCID",
        `100`= "UINFO",
        `101`= "UID",
        `102`= "GID",
        `103`= "UNSPEC",
        `248`= "ADDRS",
        `249`= "TKEY",
        `250`= "TSIG",
        `251`= "IXFR",
        `252`= "AXFR",
        `253`= "MAILB",
        `254`= "MAILA",
        `255`= "ANY",
        `65281`= "WINS",
        `65282`= "WINSR"
  )

  LET DnsStatusLookup &lt;= dict(
    `5`= "ERROR_ACCESS_DENIED",
    `0`= "SUCCESS",
    `8`= "ERROR_NOT_ENOUGH_MEMORY",
    `13`= "ERROR_INVALID_DATA",
    `14`= "ERROR_OUTOFMEMORY",
    `123`= "ERROR_INVALID_NAME",
    `1214`= "ERROR_INVALID_NETNAME",
    `1223`= "ERROR_CANCELLED",
    `1460`= "ERROR_TIMEOUT",
    `4312`= "ERROR_OBJECT_NOT_FOUND",
    `9001`= "DNS_ERROR_RCODE_FORMAT_ERROR",
    `9002`= "DNS_ERROR_RCODE_SERVER_FAILURE",
    `9003`= "DNS_ERROR_RCODE_NAME_ERROR",
    `9004`= "DNS_ERROR_RCODE_NOT_IMPLEMENTED",
    `9005`= "DNS_ERROR_RCODE_REFUSED",
    `9006`= "DNS_ERROR_RCODE_YXDOMAIN",
    `9007`= "DNS_ERROR_RCODE_YXRRSET",
    `9008`= "DNS_ERROR_RCODE_NXRRSET",
    `9009`= "DNS_ERROR_RCODE_NOTAUTH",
    `9010`= "DNS_ERROR_RCODE_NOTZONE",
    `9016`= "DNS_ERROR_RCODE_BADSIG",
    `9017`= "DNS_ERROR_RCODE_BADKEY",
    `9018`= "DNS_ERROR_RCODE_BADTIME",
    `9101`= "DNS_ERROR_KEYMASTER_REQUIRED",
    `9102`= "DNS_ERROR_NOT_ALLOWED_ON_SIGNED_ZONE",
    `9103`= "DNS_ERROR_NSEC3_INCOMPATIBLE_WITH_RSA_SHA1",
    `9104`= "DNS_ERROR_NOT_ENOUGH_SIGNING_KEY_DESCRIPTORS",
    `9105`= "DNS_ERROR_UNSUPPORTED_ALGORITHM",
    `9106`= "DNS_ERROR_INVALID_KEY_SIZE",
    `9107`= "DNS_ERROR_SIGNING_KEY_NOT_ACCESSIBLE",
    `9108`= "DNS_ERROR_KSP_DOES_NOT_SUPPORT_PROTECTION",
    `9109`= "DNS_ERROR_UNEXPECTED_DATA_PROTECTION_ERROR",
    `9110`= "DNS_ERROR_UNEXPECTED_CNG_ERROR",
    `9111`= "DNS_ERROR_UNKNOWN_SIGNING_PARAMETER_VERSION",
    `9112`= "DNS_ERROR_KSP_NOT_ACCESSIBLE",
    `9113`= "DNS_ERROR_TOO_MANY_SKDS",
    `9114`= "DNS_ERROR_INVALID_ROLLOVER_PERIOD",
    `9115`= "DNS_ERROR_INVALID_INITIAL_ROLLOVER_OFFSET",
    `9116`= "DNS_ERROR_ROLLOVER_IN_PROGRESS",
    `9117`= "DNS_ERROR_STANDBY_KEY_NOT_PRESENT",
    `9118`= "DNS_ERROR_NOT_ALLOWED_ON_ZSK",
    `9119`= "DNS_ERROR_NOT_ALLOWED_ON_ACTIVE_SKD",
    `9120`= "DNS_ERROR_ROLLOVER_ALREADY_QUEUED",
    `9121`= "DNS_ERROR_NOT_ALLOWED_ON_UNSIGNED_ZONE",
    `9122`= "DNS_ERROR_BAD_KEYMASTER",
    `9123`= "DNS_ERROR_INVALID_SIGNATURE_VALIDITY_PERIOD",
    `9124`= "DNS_ERROR_INVALID_NSEC3_ITERATION_COUNT",
    `9125`= "DNS_ERROR_DNSSEC_IS_DISABLED",
    `9126`= "DNS_ERROR_INVALID_XML",
    `9127`= "DNS_ERROR_NO_VALID_TRUST_ANCHORS",
    `9128`= "DNS_ERROR_ROLLOVER_NOT_POKEABLE",
    `9129`= "DNS_ERROR_NSEC3_NAME_COLLISION",
    `9130`= "DNS_ERROR_NSEC_INCOMPATIBLE_WITH_NSEC3_RSA_SHA1",
    `9501`= "DNS_INFO_NO_RECORDS",
    `9502`= "DNS_ERROR_BAD_PACKET",
    `9503`= "DNS_ERROR_NO_PACKET",
    `9504`= "DNS_ERROR_RCODE",
    `9505`= "DNS_ERROR_UNSECURE_PACKET",
    `9506`= "DNS_REQUEST_PENDING",
    `9551`= "DNS_ERROR_INVALID_TYPE",
    `9552`= "DNS_ERROR_INVALID_IP_ADDRESS",
    `9553`= "DNS_ERROR_INVALID_PROPERTY",
    `9554`= "DNS_ERROR_TRY_AGAIN_LATER",
    `9555`= "DNS_ERROR_NOT_UNIQUE",
    `9556`= "DNS_ERROR_NON_RFC_NAME",
    `9557`= "DNS_STATUS_FQDN",
    `9558`= "DNS_STATUS_DOTTED_NAME",
    `9559`= "DNS_STATUS_SINGLE_PART_NAME",
    `9560`= "DNS_ERROR_INVALID_NAME_CHAR",
    `9561`= "DNS_ERROR_NUMERIC_NAME",
    `9562`= "DNS_ERROR_NOT_ALLOWED_ON_ROOT_SERVER",
    `9563`= "DNS_ERROR_NOT_ALLOWED_UNDER_DELEGATION",
    `9564`= "DNS_ERROR_CANNOT_FIND_ROOT_HINTS",
    `9565`= "DNS_ERROR_INCONSISTENT_ROOT_HINTS",
    `9566`= "DNS_ERROR_DWORD_VALUE_TOO_SMALL",
    `9567`= "DNS_ERROR_DWORD_VALUE_TOO_LARGE",
    `9568`= "DNS_ERROR_BACKGROUND_LOADING",
    `9569`= "DNS_ERROR_NOT_ALLOWED_ON_RODC",
    `9570`= "DNS_ERROR_NOT_ALLOWED_UNDER_DNAME",
    `9571`= "DNS_ERROR_DELEGATION_REQUIRED",
    `9572`= "DNS_ERROR_INVALID_POLICY_TABLE",
    `9573`= "DNS_ERROR_ADDRESS_REQUIRED",
    `9601`= "DNS_ERROR_ZONE_DOES_NOT_EXIST",
    `9602`= "DNS_ERROR_NO_ZONE_INFO",
    `9603`= "DNS_ERROR_INVALID_ZONE_OPERATION",
    `9604`= "DNS_ERROR_ZONE_CONFIGURATION_ERROR",
    `9605`= "DNS_ERROR_ZONE_HAS_NO_SOA_RECORD",
    `9606`= "DNS_ERROR_ZONE_HAS_NO_NS_RECORDS",
    `9607`= "DNS_ERROR_ZONE_LOCKED",
    `9608`= "DNS_ERROR_ZONE_CREATION_FAILED",
    `9609`= "DNS_ERROR_ZONE_ALREADY_EXISTS",
    `9610`= "DNS_ERROR_AUTOZONE_ALREADY_EXISTS",
    `9611`= "DNS_ERROR_INVALID_ZONE_TYPE",
    `9612`= "DNS_ERROR_SECONDARY_REQUIRES_MASTER_IP",
    `9613`= "DNS_ERROR_ZONE_NOT_SECONDARY",
    `9614`= "DNS_ERROR_NEED_SECONDARY_ADDRESSES",
    `9615`= "DNS_ERROR_WINS_INIT_FAILED",
    `9616`= "DNS_ERROR_NEED_WINS_SERVERS",
    `9617`= "DNS_ERROR_NBSTAT_INIT_FAILED",
    `9618`= "DNS_ERROR_SOA_DELETE_INVALID",
    `9619`= "DNS_ERROR_FORWARDER_ALREADY_EXISTS",
    `9620`= "DNS_ERROR_ZONE_REQUIRES_MASTER_IP",
    `9621`= "DNS_ERROR_ZONE_IS_SHUTDOWN",
    `9622`= "DNS_ERROR_ZONE_LOCKED_FOR_SIGNING",
    `9651`= "DNS_ERROR_PRIMARY_REQUIRES_DATAFILE",
    `9652`= "DNS_ERROR_INVALID_DATAFILE_NAME",
    `9653`= "DNS_ERROR_DATAFILE_OPEN_FAILURE",
    `9654`= "DNS_ERROR_FILE_WRITEBACK_FAILED",
    `9655`= "DNS_ERROR_DATAFILE_PARSING",
    `9701`= "DNS_ERROR_RECORD_DOES_NOT_EXIST",
    `9702`= "DNS_ERROR_RECORD_FORMAT",
    `9703`= "DNS_ERROR_NODE_CREATION_FAILED",
    `9704`= "DNS_ERROR_UNKNOWN_RECORD_TYPE",
    `9705`= "DNS_ERROR_RECORD_TIMED_OUT",
    `9706`= "DNS_ERROR_NAME_NOT_IN_ZONE",
    `9707`= "DNS_ERROR_CNAME_LOOP",
    `9708`= "DNS_ERROR_NODE_IS_CNAME",
    `9709`= "DNS_ERROR_CNAME_COLLISION",
    `9710`= "DNS_ERROR_RECORD_ONLY_AT_ZONE_ROOT",
    `9711`= "DNS_ERROR_RECORD_ALREADY_EXISTS",
    `9712`= "DNS_ERROR_SECONDARY_DATA",
    `9713`= "DNS_ERROR_NO_CREATE_CACHE_DATA",
    `9714`= "DNS_ERROR_NAME_DOES_NOT_EXIST",
    `9715`= "DNS_WARNING_PTR_CREATE_FAILED",
    `9716`= "DNS_WARNING_DOMAIN_UNDELETED",
    `9717`= "DNS_ERROR_DS_UNAVAILABLE",
    `9718`= "DNS_ERROR_DS_ZONE_ALREADY_EXISTS",
    `9719`= "DNS_ERROR_NO_BOOTFILE_IF_DS_ZONE",
    `9720`= "DNS_ERROR_NODE_IS_DNAME",
    `9721`= "DNS_ERROR_DNAME_COLLISION",
    `9722`= "DNS_ERROR_ALIAS_LOOP",
    `9751`= "DNS_INFO_AXFR_COMPLETE",
    `9752`= "DNS_ERROR_AXFR",
    `9753`= "DNS_INFO_ADDED_LOCAL_WINS",
    `9801`= "DNS_STATUS_CONTINUE_NEEDED",
    `9851`= "DNS_ERROR_NO_TCPIP",
    `9852`= "DNS_ERROR_NO_DNS_SERVERS",
    `9901`= "DNS_ERROR_DP_DOES_NOT_EXIST",
    `9902`= "DNS_ERROR_DP_ALREADY_EXISTS",
    `9903`= "DNS_ERROR_DP_NOT_ENLISTED",
    `9904`= "DNS_ERROR_DP_ALREADY_ENLISTED",
    `9905`= "DNS_ERROR_DP_NOT_AVAILABLE",
    `9906`= "DNS_ERROR_DP_FSMO_ERROR",
    `9911`= "DNS_ERROR_RRL_NOT_ENABLED",
    `9912`= "DNS_ERROR_RRL_INVALID_WINDOW_SIZE",
    `9913`= "DNS_ERROR_RRL_INVALID_IPV4_PREFIX",
    `9914`= "DNS_ERROR_RRL_INVALID_IPV6_PREFIX",
    `9915`= "DNS_ERROR_RRL_INVALID_TC_RATE",
    `9916`= "DNS_ERROR_RRL_INVALID_LEAK_RATE",
    `9917`= "DNS_ERROR_RRL_LEAK_RATE_LESSTHAN_TC_RATE",
    `9921`= "DNS_ERROR_VIRTUALIZATION_INSTANCE_ALREADY_EXISTS",
    `9922`= "DNS_ERROR_VIRTUALIZATION_INSTANCE_DOES_NOT_EXIST",
    `9923`= "DNS_ERROR_VIRTUALIZATION_TREE_LOCKED",
    `9924`= "DNS_ERROR_INVAILD_VIRTUALIZATION_INSTANCE_NAME",
    `9925`= "DNS_ERROR_DEFAULT_VIRTUALIZATION_INSTANCE",
    `9951`= "DNS_ERROR_ZONESCOPE_ALREADY_EXISTS",
    `9952`= "DNS_ERROR_ZONESCOPE_DOES_NOT_EXIST",
    `9953`= "DNS_ERROR_DEFAULT_ZONESCOPE",
    `9954`= "DNS_ERROR_INVALID_ZONESCOPE_NAME",
    `9955`= "DNS_ERROR_NOT_ALLOWED_WITH_ZONESCOPES",
    `9956`= "DNS_ERROR_LOAD_ZONESCOPE_FAILED",
    `9957`= "DNS_ERROR_ZONESCOPE_FILE_WRITEBACK_FAILED",
    `9958`= "DNS_ERROR_INVALID_SCOPE_NAME",
    `9959`= "DNS_ERROR_SCOPE_DOES_NOT_EXIST",
    `9960`= "DNS_ERROR_DEFAULT_SCOPE",
    `9961`= "DNS_ERROR_INVALID_SCOPE_OPERATION",
    `9962`= "DNS_ERROR_SCOPE_LOCKED",
    `9963`= "DNS_ERROR_SCOPE_ALREADY_EXISTS",
    `9971`= "DNS_ERROR_POLICY_ALREADY_EXISTS",
    `9972`= "DNS_ERROR_POLICY_DOES_NOT_EXIST",
    `9973`= "DNS_ERROR_POLICY_INVALID_CRITERIA",
    `9974`= "DNS_ERROR_POLICY_INVALID_SETTINGS",
    `9975`= "DNS_ERROR_CLIENT_SUBNET_IS_ACCESSED",
    `9976`= "DNS_ERROR_CLIENT_SUBNET_DOES_NOT_EXIST",
    `9977`= "DNS_ERROR_CLIENT_SUBNET_ALREADY_EXISTS",
    `9978`= "DNS_ERROR_SUBNET_DOES_NOT_EXIST",
    `9979`= "DNS_ERROR_SUBNET_ALREADY_EXISTS",
    `9980`= "DNS_ERROR_POLICY_LOCKED",
    `9981`= "DNS_ERROR_POLICY_INVALID_WEIGHT",
    `9982`= "DNS_ERROR_POLICY_INVALID_NAME",
    `9983`= "DNS_ERROR_POLICY_MISSING_CRITERIA",
    `9984`= "DNS_ERROR_INVALID_CLIENT_SUBNET_NAME",
    `9985`= "DNS_ERROR_POLICY_PROCESSING_ORDER_INVALID",
    `9986`= "DNS_ERROR_POLICY_SCOPE_MISSING",
    `9987`= "DNS_ERROR_POLICY_SCOPE_NOT_ALLOWED",
    `9988`= "DNS_ERROR_SERVERSCOPE_IS_REFERENCED",
    `9989`= "DNS_ERROR_ZONESCOPE_IS_REFERENCED",
    `9990`= "DNS_ERROR_POLICY_INVALID_CRITERIA_CLIENT_SUBNET",
    `9991`= "DNS_ERROR_POLICY_INVALID_CRITERIA_TRANSPORT_PROTOCOL",
    `9992`= "DNS_ERROR_POLICY_INVALID_CRITERIA_NETWORK_PROTOCOL",
    `9993`= "DNS_ERROR_POLICY_INVALID_CRITERIA_INTERFACE",
    `9994`= "DNS_ERROR_POLICY_INVALID_CRITERIA_FQDN",
    `9995`= "DNS_ERROR_POLICY_INVALID_CRITERIA_QUERY_TYPE",
    `9996`= "DNS_ERROR_POLICY_INVALID_CRITERIA_TIME_OF_DAY",
    `10054`= "WSAECONNRESET",
    `10055`= "WSAENOBUFS",
    `10060`= "WSAETIMEDOUT"
  )

  LET ParseDNSAnswers(X) = SELECT if(condition=_value =~ "^type",
  then=dict(
     data=parse_string_with_regex(
        string=regex_replace(source=_value, replace="", re="::ffff:"),
        regex="(?P&lt;Data&gt;[^\\s]+)$").Data,
     type=get(item=DNSLookup,
       field=parse_string_with_regex(
         string=_value, regex="type:\\s+([0-9]+)").g1)),
  else=dict(
     data=regex_replace(source=_value, replace="", re="::ffff:"),
     type=if(condition=regex_replace(source=_value, replace="", re="::ffff:") =~ ":",
             then="AAAA", else="A")
  )) AS Field
  FROM foreach(row=split(string=X, sep=";"))
  WHERE _value

  LET ParseHashes(Hashes) = to_dict(item={
     SELECT split(string=_value, sep="=")[0] AS _key,
            split(string=_value, sep="=")[1] AS _value
     FROM foreach(row=split(string=Hashes, sep=","))
  })

  LET _EventToECSBase(System, EventData) = dict(
     ecs=dict(version="1.12.0"),
     log=dict(level=System.Level),
     event=dict(
        module="sysmon",
        kind="event",
        code=System.EventID.Value,
        category=get(item=CategoryLookup, field=str(str=System.EventID.Value)),
        type=get(item=TypeLookup, field=str(str=System.EventID.Value)),
        created=timestamp(epoch=System.TimeCreated.SystemTime)
     ),
     error=dict(
       code=if(condition=System.EventID.Value = 255, then=EventData.ID, else=0)
     ),
     rule=dict(
       name=EventData.RuleName
     ),
     message=if(condition=System.EventID.Value = 255, then=EventData.Type, else=""),
     winlog=dict(
        api="wineventlog",
        channel=System.Channel,
        computer_name=System.Computer,
        event_data=NormalizeEventData(EventData=EventData),
        event_id=System.EventID.Value ,
        opcode=get(item=OpcodesLookup, field=str(str=System.Opcode)),
        process=dict(
           pid=System.Execution.ProcessID,
           thread=dict(
             id=System.Execution.ThreadID
           )
        ),
        provider_guid=System.Provider.Guid,
        provider_name=System.Provider.Name,
        record_id=str(str=System.EventRecordID),
        user=dict(
          identifier=System.Security.UserID
        )
     )
  )

  LET _EventToECSProcess(System, EventData) = dict(
     process=dict(
       hash=ParseHashes(Hashes=EventData.Hashes),
       entity_id=EventData.ProcessGuid || EventData.SourceProcessGuid || EventData.SourceProcessGUID,
       pid=EventData.ProcessId || EventData.SourceProcessId,
       executable=EventData.Image || EventData.SourceImage || EventData.Destination,
       command_line=EventData.CommandLine,
       working_directory=EventData.CurrentDirectory,
       parent=dict(
          pid=EventData.ParentProcessId,
          entity_id= EventData.ParentProcessGuid,
          executable=EventData.ParentImage,
          command_line=EventData.ParentCommandLine,
          args=commandline_split(command=EventData.ParentCommandLine),
          args_count=len(list=commandline_split(command=EventData.ParentCommandLine)),
          name=pathspec(parse=EventData.ParentImage, path_type="windows").Basename
       ),
       thread=dict(
          id= EventData.SourceThreadId || 0
       ),
       pe=if(condition=System.EventID.Value != 7, then=dict(
         original_file_name=EventData.OriginalFileName || "",
         company=EventData.Company || "",
         description=EventData.Description || "",
         file_version=EventData.FileVersion || "",
         product= EventData.Product || ""
       )),
       args=commandline_split(command=EventData.CommandLine),
       args_count=len(list=commandline_split(command=EventData.CommandLine)),
       name=pathspec(parse=EventData.Image, path_type="windows").Basename
    )
  )

  LET _EventToECSNetwork(System, EventData) = dict(
    network=dict(
      transport=EventData.Protocol,
      protocol=if(condition=System.EventID.Value = 22, then="dns", else=EventData.DestinationPortName || EventData.SourcePortName),
      direction=if(condition= EventData.Initiated, then="egress", else="ingress"),
      type=if(condition= EventData.SourceIsIpv6, then="ipv6", else="ipv4")
    ),
    source=dict(
      ip=EventData.SourceIp,
      domain=EventData.SourceHostname,
      port=EventData.SourcePort
    ),
    destination=dict(
      ip=EventData.DestinationIp,
      domain=EventData.DestinationHostname,
      port=EventData.DestinationPort
    ),
    dns=dict(
      answers=ParseDNSAnswers(X=EventData.QueryResults).Field,
      question=dict(
         name=EventData.QueryName
      ),
      status=get(item=DnsStatusLookup, field=str(str=EventData.QueryStatus))
    )
  )

  LET _ParseRegData(X) = if(condition=X =~ "^DWORD",
     then=dict(
        strings=[str(str=int(int= parse_string_with_regex(string=X, regex="\\((.+?)\\)").g1)),],
        type="DWORD"),
     else=if(condition=X =~ "^Binary Data",
             then=dict(
               strings=["Binary Data",],
               type="REG_BINARY"),
             else=if(condition=X =~ "^QWORD",
                     then=dict(
                         strings=[str(str=int(int= regex_replace(re="-0x", replace="",
                                  source=parse_string_with_regex(string=X, regex="\\((.+?)\\)").g1))),],
                         type="QWORD"),
                     else=dict(strings=X, type=parse_string_with_regex(string=X, regex="(^[^\\S]+)").g1)
            )
     ))

  LET _EventToECSRegistry(System, EventData) = dict(
     process=dict(
       entity_id=EventData.ProcessGuid || EventData.SourceProcessGuid || EventData.SourceProcessGUID,
       pid=EventData.ProcessId || EventData.SourceProcessId,
       executable=EventData.Image || EventData.SourceImage || EventData.Destination,
       name=pathspec(parse=EventData.Image, path_type="windows").Basename
     ),
     registry=dict(
        hive=pathspec(parse=EventData.TargetObject, path_type="registry")[0],
        key=pathspec(parse=EventData.TargetObject, path_type="registry")[1:],
        path=EventData.TargetObject,
        value=pathspec(parse=EventData.TargetObject, path_type="registry").Basename,
        data= _ParseRegData(X=EventData.Details)
     )
  )

  LET _EventToECSFile(System, EventData) = dict(
    file=dict(
      path=EventData.TargetFilename || EventData.Device || EventData.ImageLoaded,
      directory=pathspec(parse=EventData.TargetFilename || EventData.Device || EventData.ImageLoaded, path_type="windows").Dirname,
      name=EventData.PipeName || pathspec(parse=EventData.TargetFilename || EventData.Device || EventData.ImageLoaded, path_type="windows").Basename,
      code_signature=dict(
        subject_name= EventData.Signature || "",
        status = EventData.SignatureStatus || "",
        signed=if(condition=EventData.Signed, then=TRUE, else=FALSE),
        valid=EventData.SignatureStatus = "Valid"
      ),
      process=dict(
        entity_id=EventData.ProcessGuid || EventData.SourceProcessGuid || EventData.SourceProcessGUID,
        pid=EventData.ProcessId || EventData.SourceProcessId,
        executable=EventData.Image || EventData.SourceImage || EventData.Destination,
        name=pathspec(parse=EventData.Image, path_type="windows").Basename,
        hash=ParseHashes(Hashes=EventData.Hash)
      ),
      pe=dict(
        original_file_name=EventData.OriginalFileName || "",
        company=EventData.Company || "",
        description=EventData.Description || "",
        file_version=EventData.FileVersion || "",
        product=EventData.Product || ""
      ),
      sysmon=dict(
        file=dict(
          archived=if(condition=EventData.Archived =~ "true", then=TRUE, else=FALSE),
          is_executable=if(condition=EventData.is_executable, then=TRUE, else=FALSE)
        )
      )
    )
  )

  LET SysmonEventToECS(System, EventData) = _EventToECSBase(System=System, EventData=EventData) + if(
        condition=get(item=CategoryLookup, field=str(str=System.EventID.Value)) =~ "process",
        then=_EventToECSProcess(System=System, EventData=EventData),
      else=if(
        condition=get(item=CategoryLookup, field=str(str=System.EventID.Value)) =~ "network",
        then=_EventToECSNetwork(System=System, EventData=EventData),
      else=if(
        condition=get(item=CategoryLookup, field=str(str=System.EventID.Value)) =~ "registry",
        then=_EventToECSRegistry(System=System, EventData=EventData),
      else=if(
        condition=get(item=CategoryLookup, field=str(str=System.EventID.Value)) =~ "file",
        then=_EventToECSFile(System=System, EventData=EventData),
      else=dict()))))

sources:
  - query: |
      SELECT * FROM foreach(row={
        SELECT * FROM foreach(row={
           SELECT OSPath FROM glob(globs=LogFileGlob)
        }, query={
           SELECT SysmonEventToECS(System=System, EventData=EventData) AS ECS
           FROM parse_evtx(filename=OSPath)
        })
      }, column="ECS")

    notebook:
      - type: vql_suggestion
        name: "Upload to Elastic"
        template: |
          /*
             * Modify the Elastic parameters to upload this dataset.
             * You might need to add authentication to Elastic.
          */
          LET ElasicAddress = "http://localhost:9200"

          // Uncomment this when you are ready to upload the data
          LET X = SELECT *
          FROM elastic_upload(
            addresses=ElasicAddress,
            index="winlogbeat-velo",
            action="create",
            query={
               SELECT timestamp(epoch=now()) AS `@timestamp`,
                      ClientId,
                      client_info(client_id=ClientId).Hostname AS Hostname,
                      *
               FROM source(artifact="Elastic.EventLogs.Sysmon")
               LIMIT 10
            })

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.forensics.bulkextractor.md
======
---
title: Windows.Forensics.BulkExtractor
hidden: true
tags: [Client Artifact]
---

This content will execute bulk_extractor with record carving plugins from
4n6ist. Initially developed to carve EventLogs from physical disk and
unallocated space, this content may also be leveraged for other
bulk extractor capability. Best use case is for remote targeted machine
collection to remove the need for a disk image.

**Settings**
Target - Can be \\\\.\\PhysicalDrive[X], \\\\?\\HarddiskVolumeShadowCopy[Y]
or C:\\Folder\\Path"
TargetAllPhysical - boolean option to include all attached physical disks
TargetVSS - boolean option to target all VSC
CarveEvtx - boolean option to include evtx carving
FindRegex - regex to include for BulkExtractor find plugins

FreeCommand - supersedes evtx or find options and allows free form switch
generation for adlib use cases.
e.g '-E evtx, -e zip -S unzip_carve_mode=2'"
Will add:
command prefix: "-q 99999999999 -R'" and
postfix: "-o [Outfolder] [Target]".
To make: bulk_extractor q 99999999999 -R -E evtx, -e zip -S unzip_carve_mode=2 -o [outfolder] [Target]

If FindRegex or "-f" has been used in FreeCommand the artifact will attempt
to parse find.txt output.

**Note**
1. Currently only supported for x64 bit machines.
2. This artifact usually takes a long time. Ensure default timeout is high
enough for completion.
3. This content is NOT recommended for hunting without great consideration as
bulk_extractor is a multithreaded tool and utilises all CPU available on the
endpoint.
4. The artifact copies carved data to the local disk prior to upload which
is not ideal from a forensic viewpoint.


<pre><code class="language-yaml">
name: Windows.Forensics.BulkExtractor
description: |
    This content will execute bulk_extractor with record carving plugins from
    4n6ist. Initially developed to carve EventLogs from physical disk and
    unallocated space, this content may also be leveraged for other
    bulk extractor capability. Best use case is for remote targeted machine
    collection to remove the need for a disk image.

    **Settings**
    Target - Can be \\\\.\\PhysicalDrive[X], \\\\?\\HarddiskVolumeShadowCopy[Y]
    or C:\\Folder\\Path"
    TargetAllPhysical - boolean option to include all attached physical disks
    TargetVSS - boolean option to target all VSC
    CarveEvtx - boolean option to include evtx carving
    FindRegex - regex to include for BulkExtractor find plugins

    FreeCommand - supersedes evtx or find options and allows free form switch
    generation for adlib use cases.
    e.g '-E evtx, -e zip -S unzip_carve_mode=2'"
    Will add:
    command prefix: "-q 99999999999 -R'" and
    postfix: "-o [Outfolder] [Target]".
    To make: bulk_extractor q 99999999999 -R -E evtx, -e zip -S unzip_carve_mode=2 -o [outfolder] [Target]

    If FindRegex or "-f" has been used in FreeCommand the artifact will attempt
    to parse find.txt output.

    **Note**
    1. Currently only supported for x64 bit machines.
    2. This artifact usually takes a long time. Ensure default timeout is high
    enough for completion.
    3. This content is NOT recommended for hunting without great consideration as
    bulk_extractor is a multithreaded tool and utilises all CPU available on the
    endpoint.
    4. The artifact copies carved data to the local disk prior to upload which
    is not ideal from a forensic viewpoint.

reference:
  - http://www.kazamiya.net/en/bulk_extractor-rec
  - http://downloads.digitalcorpora.org/downloads/bulk_extractor/BEUsersManual.pdf
  - https://simson.net/clips/academic/2013.COSE.bulk_extractor.pdf

author: Matt Green - @mgreen27

required_permissions:
  - EXECVE

tools:
  - name: Bulk_Extractor_Binary
    url: https://github.com/Velocidex/Tools/raw/main/BulkExtractor/bulk_extractor.exe
    serve_locally: true

precondition: SELECT OS From info() where OS = 'windows'

parameters:
  - name: Target
    description: "Target. Can by physical drive, \\\\?\\HarddiskVolumeShadowCopy1 or C:\\Folder\\Path"
    default: \\.\PhysicalDrive0
  - name: TargetAllPhysical
    description: "Target all attached physical drives"
    type: bool
  - name: TargetVSS
    description: "Target all VSC. Note: Not targeted to folder. Velociraptor CAN collect from the Volume Shadow direct targeted to folder with ntfs accessor so there may be a better way."
    type: bool
  - name: CarveEvtx
    description: "Carve EVTX files"
    type: bool
  - name: FindRegex
    description: "Regex for Bulk_extractor find plugin"
  - name: FreeCommand
    description: "Bulk_extractor custom commands. .e.g '-E evtx, -e zip -S unzip_carve_mode=2'"

sources:
  - query: |
      LET bin &lt;= SELECT *
        FROM Artifact.Generic.Utils.FetchBinary(ToolName="Bulk_Extractor_Binary")
      LET tempfolder &lt;= tempdir()
      LET ExePath &lt;= tempfile(extension=".exe")

      LET target = SELECT
            DeviceID,
            if(condition=DeviceID=~"^\\\\\\\\.\\\\",
                then=split(string=split(string=DeviceID,sep='\\\\\\\\.\\\\')[1],
                    sep='\\\\')[0],
                else="bulk_out") as base,
            _DeviceID
      FROM chain(
            a={
                SELECT
                    DeviceID,
                    upcase(string=DeviceID) as _DeviceID
                FROM Artifact.Windows.Sys.DiskInfo()
                WHERE TargetAllPhysical
            },
            b={
                SELECT
                    Target as DeviceID,
                    upcase(string=Target) as _DeviceID
                FROM scope()
                WHERE Target =~ '.'
            },
            c={
                SELECT
                    regex_replace(source=OSPath,
                        re="GLOBALROOT\\\\Device\\\\",replace="")AS DeviceID,
                    Data.ID AS ShadowCopyID,
                    upcase(string=regex_replace(source=OSPath,
                        re="GLOBALROOT\\\\Device\\\\",replace="")) as _DeviceID
                FROM glob(globs='/*', accessor='ntfs')
                WHERE ShadowCopyID AND TargetVSS
                ORDER by OSPath
            })
            GROUP BY _DeviceID

      LET cmdline = SELECT (bin[0].OSPath, '-q', '99999999999', '-R') +
                           CMD + '-o' as CMD FROM switch(
            a= {
                SELECT commandline_split(command=FreeCommand) AS CMD
                FROM scope()
                WHERE FreeCommand
            },
            b= {
                SELECT
                    ('-E','evtx','-e','find','-f',FindRegex) AS CMD
                FROM scope()
                WHERE CarveEvtx AND FindRegex
            },
            c= {
                SELECT ('-E','evtx') AS CMD
                FROM scope()
                WHERE CarveEvtx
            },
            d= {
                SELECT ('-E','find','-f',FindRegex) AS CMD
                FROM scope()
                WHERE FindRegex
            },
            e= {
                SELECT ('-h') AS CMD FROM scope()
            })

      SELECT * FROM foreach(
        row=target,
        query= {
            SELECT *
            FROM execve(
             argv=cmdline[0].CMD + (
                tempfolder + '\\' +
                  regex_replace(source=base, re='[^a-zA-Z]', replace='_'),
                  DeviceID),
             length=10000000, sep='\n')})

  - name: FindResults
    query: |
      SELECT * FROM foreach(
        row={  SELECT *
               FROM glob(globs='/*/find.txt', root=tempfolder)
        },
        query={
            SELECT *
            FROM split_records(filenames=OSPath,first_row_is_headers=false,
                columns=['Location','Match','Data'],regex='\t')
            WHERE NOT Location =~ '#'
        })
        WHERE FindRegex OR FreeCommand =~ '-f'

  - name: Upload
    query: |
      SELECT upload(file=OSPath,
                    name=strip(string=OSPath,prefix=tempfolder)) AS Upload
      FROM glob(globs="/**", root=tempfolder)
      WHERE Upload

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/server.enrichment.geoip.md
======
---
title: Server.Enrichment.GeoIP
hidden: true
tags: [Client Artifact]
---

This artifact can use the MaxMind database to Geo resolve an IP
address. You will need to provide a valid GeoIP database.

You can obtain a free to use (gratis but not libre) database from
https://www.maxmind.com/ or you can pay for a more accurate option.

After storing the database somewhere on your server, you should the
location in the server metadata screen to it under the key "GeoIPDB"
(for example `/usr/shared/GeoLite2-City_20210803/GeoLite2-City.mmdb`)

Alternatively you can import this artifact to gain access to the
utility functions (or just copy them into your own artifact).


<pre><code class="language-yaml">
name: Server.Enrichment.GeoIP
description: |
  This artifact can use the MaxMind database to Geo resolve an IP
  address. You will need to provide a valid GeoIP database.

  You can obtain a free to use (gratis but not libre) database from
  https://www.maxmind.com/ or you can pay for a more accurate option.

  After storing the database somewhere on your server, you should the
  location in the server metadata screen to it under the key "GeoIPDB"
  (for example `/usr/shared/GeoLite2-City_20210803/GeoLite2-City.mmdb`)

  Alternatively you can import this artifact to gain access to the
  utility functions (or just copy them into your own artifact).

export: |
  LET DB = server_metadata().GeoIPDB
  LET Country(IP) = geoip(db=DB, ip=IP).country.names.en
  LET State(IP) = geoip(db=DB, ip=IP).subdivisions[0].names.en
  LET City(IP) = geoip(db=DB, ip=IP).city.names.en

parameters:
  - name: IP
    description: An IP to lookup

sources:
  - query: |
      SELECT Country(IP=_value) AS Country,
             State(IP=_value) AS State,
             City(IP=_value) AS City
      FROM foreach(row=IP)

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.events.failedlogbeforesuccess.md
======
---
title: Windows.Events.FailedLogBeforeSuccess
hidden: true
tags: [Client Event Artifact]
---

Sometimes attackers will brute force an local user's account's
password. If the account password is strong, brute force attacks are
not effective and might not represent a high value event in
themselves.

However, if the brute force attempt succeeds, then it is a very high
value event (since brute forcing a password is typically a
suspicious activity).

On the endpoint this looks like a bunch of failed logon attempts in
quick succession followed by a successful login.

NOTE: In order for this artifact to work we need Windows to be
logging failed account login. This is not on by default and should
be enabled via group policy.

https://docs.microsoft.com/en-us/windows/security/threat-protection/auditing/basic-audit-logon-events

You can set the policy in group policy management console (gpmc):
Computer Configuration\Windows Settings\Security Settings\Local Policies\Audit Policy.


<pre><code class="language-yaml">
name: Windows.Events.FailedLogBeforeSuccess
description: |
  Sometimes attackers will brute force an local user's account's
  password. If the account password is strong, brute force attacks are
  not effective and might not represent a high value event in
  themselves.

  However, if the brute force attempt succeeds, then it is a very high
  value event (since brute forcing a password is typically a
  suspicious activity).

  On the endpoint this looks like a bunch of failed logon attempts in
  quick succession followed by a successful login.

  NOTE: In order for this artifact to work we need Windows to be
  logging failed account login. This is not on by default and should
  be enabled via group policy.

  https://docs.microsoft.com/en-us/windows/security/threat-protection/auditing/basic-audit-logon-events

  You can set the policy in group policy management console (gpmc):
  Computer Configuration\Windows Settings\Security Settings\Local Policies\Audit Policy.
type: CLIENT_EVENT

parameters:
  - name: securityLogFile
    default: &gt;-
      C:/Windows/System32/Winevt/Logs/Security.evtx

  - name: failureCount
    description: Alert if there are this many failures before the successful logon.
    default: 3

  - name: failedLogonTimeWindow
    default: 3600

sources:
  - precondition:
      SELECT OS FROM info() where OS = 'windows'
    query: |
      LET failed_logon = SELECT EventData as FailedEventData,
           System as FailedSystem
      FROM watch_evtx(filename=securityLogFile)
      WHERE System.EventID.Value = 4625


      LET last_5_events = SELECT FailedEventData, FailedSystem
        FROM fifo(query=failed_logon,
                      max_rows=500,
                      max_age=atoi(string=failedLogonTimeWindow))

      // Force the fifo to materialize.
      LET foo &lt;= SELECT * FROM last_5_events

      LET success_logon = SELECT EventData as SuccessEventData,
           System as SuccessSystem
        FROM watch_evtx(filename=securityLogFile)
        WHERE System.EventID.Value = 4624

      SELECT * FROM foreach(
          row=success_logon,
          query={
           SELECT SuccessSystem.TimeCreated.SystemTime AS LogonTime,
                  SuccessSystem, SuccessEventData,
                  enumerate(items=FailedEventData) as FailedEventData,
                  FailedSystem, count(items=SuccessSystem) as Count
           FROM last_5_events
           WHERE FailedEventData.SubjectUserName = SuccessEventData.SubjectUserName
           GROUP BY LogonTime
          })  WHERE Count &gt; atoi(string=failureCount)

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/server.enrichment.cortexanalyzer.md
======
---
title: Server.Enrichment.CortexAnalyzer
hidden: true
tags: [Server Artifact]
---

Run Cortex analyzer jobs across all enabled and applicable analyzers (based on supported analyzer data types), then retrieve the results.

This artifact can be called from within another artifact (such as one looking for files) to enrich the data made available by that artifact.

Ex.

  `SELECT * from Artifact.Server.Enrichment.CortexAnalyzer(Observable=$YOURHASH, ObservableType='hash')`


<pre><code class="language-yaml">
name: Server.Enrichment.CortexAnalyzer
description: |
  Run Cortex analyzer jobs across all enabled and applicable analyzers (based on supported analyzer data types), then retrieve the results.

  This artifact can be called from within another artifact (such as one looking for files) to enrich the data made available by that artifact.

  Ex.

    `SELECT * from Artifact.Server.Enrichment.CortexAnalyzer(Observable=$YOURHASH, ObservableType='hash')`

reference:
  - https://github.com/TheHive-Project/Cortex

author: Wes Lambert - @therealwlambert

type: SERVER

parameters:
   - name: Observable
     description: Data to be analyzed by Cortex 
     default: 
   - name: ObservableType
     description: Type of observable to be submitted to Cortex. Ex. `hash`, `domain`, `ip`
     default:
   - name: TLP
     description: TLP for the job submitted to Cortex
     default: 0
   - name: CortexURL
     description: URL used for Cortex job submission. It is recommended to use the &lt;a href="#/host/server"&gt;server metadata store&lt;/a&gt; for this.
     default: ''
   - name: CortexKey
     description: API key used for authentication to Cortex. It is recommended to use the &lt;a href="#/host/server"&gt;server metadata store&lt;/a&gt; for this.
     default: ''
   - name: DisableSSLVerify
     type: bool
     description: Disable SSL Verification
     default: True
   - name: JobMessage
     description: Message to be used when running analyzer job
     default: Job submmitted by Velociraptor
   - name: JobWaitTime
     description: Amount of time to wait for a report from Cortex.
     default: 10minute

sources:
  - query: |
        LET OBSERVABLE &lt;= Observable
        LET OBSERVABLE_DATATYPE &lt;= ObservableType
        LET URL &lt;= if(
                condition=CortexURL,
            then=CortexURL,
            else=server_metadata().CortexURL)
        LET cortex_key = 
            if(
                condition=CortexKey,
            then=CortexKey,
            else=server_metadata().CortexKey)
        LET ENABLED_ANALYZERS = SELECT Content FROM 
            http_client(
                url=URL + '/analyzer', 
                method='GET', 
                disable_ssl_security=DisableSSLVerify, 
                headers=dict(
                    `Authorization`=format(format="Bearer %v", args=[cortex_key])))
        LET ANALYZERS_SUPPORTED = SELECT name AS AnalyzerName, id AS ID, dataTypeList AS DList FROM parse_json_array(data=ENABLED_ANALYZERS.Content)
        LET ANALYZERS_MATCH_TYPE = SELECT ID  FROM foreach(row=ANALYZERS_SUPPORTED, query={ SELECT AnalyzerName, ID, _value AS Match FROM 
            if(
                condition= filter(list=DList, regex=OBSERVABLE_DATATYPE),
            then="yes",
            else="no")}) WHERE Match = "yes"
        LET ANALYZER_RUN = SELECT parse_json(data=Content) AS Resp FROM 
            http_client(
                url=URL + '/analyzer/'+ ID + '/run' , 
                method='POST', 
                disable_ssl_security=DisableSSLVerify, 
                headers=dict(
                    `Content-Type`="application/json", 
                    `Authorization`=format(format="Bearer %v", 
                    args=[cortex_key])),
                    data=serialize(item=dict(
                        data=OBSERVABLE, dataType=OBSERVABLE_DATATYPE, tlp=TLP, message=JobMessage
                    ))
            )
        LET JOBID = SELECT Resp.id AS JobID from foreach(row=ANALYZER_RUN)
        LET GETREPORT = SELECT Content AS Resp FROM 
            http_client(
                url=format(format="%v/job/%v/waitreport?atMost=%v", args=[URL,JOBID.JobID[0], JobWaitTime]),
                method='GET', 
                disable_ssl_security=DisableSSLVerify, 
                headers=dict(
                    `Content-Type`="application/json", 
                    `Authorization`=format(format="Bearer %v", 
                    args=[cortex_key])
                )
            )
        LET REPORT = SELECT parse_json(data=Resp) AS Details FROM GETREPORT
        SELECT Observable, Details.workerName as AnalyzerName, Details as _Details, Details.report AS Report FROM foreach(row=ANALYZERS_MATCH_TYPE, query={SELECT * FROM REPORT})

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/macos.detection.installhistory.md
======
---
title: MacOS.Detection.InstallHistory
hidden: true
tags: [Client Artifact]
---

This artifact collects entries from the InstallHistory .plist file


<pre><code class="language-yaml">
name: MacOS.Detection.InstallHistory
description: |
  This artifact collects entries from the InstallHistory .plist file

type: CLIENT

author: Wes Lambert - @therealwlambert

precondition: SELECT OS FROM info() WHERE OS =~ 'darwin'

parameters:
- name: InstallHistoryGlob
  default: /Library/Receipts/InstallHistory.plist

sources:
- name: Install History
  query: |
    LET SWplist = SELECT OSPath FROM glob(globs=InstallHistoryGlob)

    LET SoftwareDetails =
            SELECT * FROM foreach(
                row=plist(file=OSPath),
                query={
                    SELECT
                        get(member="displayName", default="") AS DisplayName,
                        get(member="displayVersion", default="") AS DisplayVersion,
                        get(member="processName", default="") AS ProcessName,
                        get(member="date", default="") AS InstallDate,
                        get(member="contentType", default="") AS ContentType,
                        get(member="packageIdentifiers", default="") AS PackageIdentifiers
                    FROM scope()
            })
    SELECT * FROM foreach(row=SWplist, query=SoftwareDetails)

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/server.information.users.md
======
---
title: Server.Information.Users
hidden: true
tags: [Server Artifact]
---

List the user names and SIDs on each machine. We get this
information from the last time we collected Windows.Sys.Users. If we
never collected it for this machine, there will be no results.


<pre><code class="language-yaml">
name: Server.Information.Users
description: |
  List the user names and SIDs on each machine. We get this
  information from the last time we collected Windows.Sys.Users. If we
  never collected it for this machine, there will be no results.

type: SERVER

parameters:
  - name: StandardUserAccounts
    description: Well known SIDs to hide from the output.
    default: "(-5..$|S-1-5-18|S-1-5-19|S-1-5-20)"
    type: regex

sources:
  - query: |
        LET clients = SELECT client_id, os_info.fqdn AS Fqdn FROM clients()

        // Get the most recent collection of our user listing.
        LET last_user_listing = SELECT
               session_id AS flow_id,
               active_time, client_id, Fqdn
           FROM flows(client_id=client_id)
           WHERE artifacts_with_results =~'Windows.Sys.Users'
           ORDER BY active_time
           DESC LIMIT 1

        /* For each Windows.Sys.Users collection, extract the user
           names, but hide standard SIDs.
        */
        LET users = SELECT * FROM foreach(
            row=last_user_listing,
            query={
              SELECT Name, UUID, client_id, Fqdn from source(
                 flow_id=flow_id,
                 artifact='Windows.Sys.Users',
                 client_id=client_id)
              WHERE NOT UUID =~ StandardUserAccounts
            })

        SELECT * FROM foreach(row=clients, query=users)

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.sys.allusers.md
======
---
title: Windows.Sys.AllUsers
hidden: true
tags: [Client Artifact]
---

List User accounts. We combine two data sources - the output from
the `NetUserEnum` API (termed `local` users) and the list of SIDs in
the registry (termed `remote` users).

In this artifact, 'remote' means that user profile was cached in the
registry, but the user does not appear in the output of the
`NetUserEnum` API - this normally happens for users remotely logging
into the system using domain credentials.

On Domain Controllers the `NetUserEnum` API will return the contents
of the entire ActiveDirectory as a list of 'local' users, however
this does not mean that the users have logged into the DC
locally. In this artifact we limit the number of users to 1000. If
you need to obtain the full list from the AD, customize this
artifact.


<pre><code class="language-yaml">
name: Windows.Sys.AllUsers
description: |
  List User accounts. We combine two data sources - the output from
  the `NetUserEnum` API (termed `local` users) and the list of SIDs in
  the registry (termed `remote` users).

  In this artifact, 'remote' means that user profile was cached in the
  registry, but the user does not appear in the output of the
  `NetUserEnum` API - this normally happens for users remotely logging
  into the system using domain credentials.

  On Domain Controllers the `NetUserEnum` API will return the contents
  of the entire ActiveDirectory as a list of 'local' users, however
  this does not mean that the users have logged into the DC
  locally. In this artifact we limit the number of users to 1000. If
  you need to obtain the full list from the AD, customize this
  artifact.

parameters:
  - name: remoteRegKey
    default: HKEY_LOCAL_MACHINE\SOFTWARE\Microsoft\Windows NT\CurrentVersion\ProfileList\*

export: |
  -- Cache function for lookupSID
  LET LookupSIDCache(SID) = cache(name="SID", key=SID,
     func=lookupSID(sid=SID) ||

     -- resolve usernames via registry if lookupSID is not available
     -- or yields no results

          pathspec(parse=stat(accessor="registry",
               filename="HKEY_LOCAL_MACHINE/Software/Microsoft/Windows NT/CurrentVersion/ProfileList/" +
                      SID + "/ProfileImagePath").Data.value).Basename || "")

sources:
  - precondition:
      SELECT OS From info() where OS = 'windows'
    query: |
        LET GetTimestamp(High, Low) = if(condition=High,
                then=timestamp(winfiletime=High * 4294967296 + Low))

        -- lookupSID() may not be available on deaddisk analysis
        LET roaming_users &lt;=
          SELECT
             split(string=Key.OSPath.Basename, sep="-")[-1] as Uid,
             "" AS Gid,
             LookupSIDCache(SID=Key.OSPath.Basename || "") AS Name,
             Key.OSPath as Description,
             ProfileImagePath as Directory,
             Key.OSPath.Basename as UUID,
             Key.Mtime as Mtime,
             {
                SELECT Mtime
                FROM stat(filename=expand(path=ProfileImagePath))
             } AS HomedirMtime,
             dict(ProfileLoadTime=GetTimestamp(
                  High=LocalProfileLoadTimeHigh, Low=LocalProfileLoadTimeLow),
                  ProfileUnloadTime=GetTimestamp(
                  High=LocalProfileUnloadTimeHigh, Low=LocalProfileUnloadTimeLow),
                  ProfileImagePath=ProfileImagePath,
                  ProfileKey=Key.OSPath
             ) AS Data
           FROM read_reg_key(globs=remoteRegKey, accessor="registry")


        LET roaming_users_lookup &lt;= memoize(query=roaming_users, key="UUID")

        -- On a DC the NetUserEnum API will return the entire domain!
        LET local_users &lt;= select User_id as Uid,
           Primary_group_id as Gid, Name,
           Comment as Description,
           get(item=roaming_users_lookup, field=User_sid) AS  RoamingData,
           User_sid as UUID
        FROM users()
        LIMIT 1000

        LET local_users_lookup &lt;= memoize(query={
            SELECT UUID FROM local_users
        }, key="UUID")

        -- Populate the mtime from the user's home directory.
        LET local_users_with_mtime = SELECT Uid, Gid, Name, Description,
            RoamingData.Directory AS Directory,
            UUID,
            RoamingData.Mtime As Mtime,
            RoamingData.HomedirMtime AS HomedirMtime,
            RoamingData.Data || dict() AS Data
        FROM local_users

        SELECT * from chain(
           q1=local_users_with_mtime,
           q2={
             SELECT * FROM roaming_users
             -- Only show records who were not shown before
             WHERE NOT get(item=local_users_lookup, field=UUID)
           })
         --ORDER BY Gid DESC
    notebook:
      - type: VQL
        template: |
          /*
          # Users Hunt

          Enumerating all the users on all endpoints can reveal machines
          which had an unexpected login activity. For example, if a user
          from an unrelated department is logging into an endpoint by
          virtue of domain credentials, this could mean their account is
          compromised and the attackers are laterally moving through the
          network.
          */
          LET s = scope()
          SELECT Name, UUID, s.Fqdn AS Fqdn, HomedirMtime as LastMod, Data FROM source()
          WHERE NOT UUID =~ "(-5..$|S-1-5-18|S-1-5-19|S-1-5-20)"

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/server.import.rapid7labs.md
======
---
title: Server.Import.Rapid7Labs
hidden: true
tags: [Server Artifact]
---

This artifact will import curated artifacts by Rapid7 Labs.


<pre><code class="language-yaml">
name: Server.Import.Rapid7Labs
description: |
   This artifact will import curated artifacts by Rapid7 Labs.

type: SERVER

required_permissions:
- SERVER_ADMIN

parameters:
   - name: Rapid7LabsURL
     default: https://github.com/rapid7/Rapid7-Labs/raw/main/Vql/release/Rapid7LabsVQL.zip
   - name: Prefix
     description: Add artifacts with this prefix
     default: Rapid7Labs.

sources:
  - query: |
        LET X = SELECT artifact_set(prefix=Prefix, definition=Definition) AS Definition
        FROM foreach(row={
          SELECT Content FROM http_client(
             remove_last=TRUE,
             tempfile_extension=".zip", url=Rapid7LabsURL)
        }, query={
          SELECT read_file(accessor="zip", filename=OSPath) AS Definition
          FROM glob(
             globs='/**/*.yaml',
             root=pathspec(
                DelegateAccessor="auto",
                DelegatePath=Content),
             accessor="zip")
        })

        SELECT Definition.name AS Name,
               Definition.description AS Description,
               Definition.author AS Author
        FROM X

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/generic.forensic.sqlitehunter.md
======
---
title: Generic.Forensic.SQLiteHunter
hidden: true
tags: [Client Artifact]
---

Hunt for SQLite files.

SQLite has become the de-facto standard for storing application data,
in many types of applications:

- Web Browsers
- Operating Systems
- Various applications, such as iMessage, TCC etc

This artifact can hunt for these artifacts in a mostly automated way.
More info at https://github.com/Velocidex/SQLiteHunter

NOTE: If you want to use this artifact on just a bunch of files already
collected (for example the files collected using the
Windows.KapeFiles.Targets artifact) you can use the CustomGlob parameter
(for example set it to "/tmp/unpacked/**" to consider all files in the
unpacked directory).


<pre><code class="language-yaml">

name: Generic.Forensic.SQLiteHunter
description: |
    Hunt for SQLite files.
    
    SQLite has become the de-facto standard for storing application data,
    in many types of applications:
    
    - Web Browsers
    - Operating Systems
    - Various applications, such as iMessage, TCC etc
    
    This artifact can hunt for these artifacts in a mostly automated way.
    More info at https://github.com/Velocidex/SQLiteHunter
    
    NOTE: If you want to use this artifact on just a bunch of files already
    collected (for example the files collected using the
    Windows.KapeFiles.Targets artifact) you can use the CustomGlob parameter
    (for example set it to "/tmp/unpacked/**" to consider all files in the
    unpacked directory).
    
    

column_types:
- name: Image
  type: preview_upload

export: |
  LET SPEC &lt;= "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"
  LET Specs &lt;= parse_json(data=gunzip(string=base64decode(string=SPEC)))
  LET CheckHeader(OSPath) = read_file(filename=OSPath, length=12) = "SQLite forma"
  LET Bool(Value) = if(condition=Value, then="Yes", else="No")

  -- In fast mode we check the filename, then the header then run the sqlite precondition
  LET matchFilename(SourceName, OSPath) = OSPath =~ get(item=Specs.sources, field=SourceName).filename
    AND CheckHeader(OSPath=OSPath)
    AND Identify(SourceName= SourceName, OSPath= OSPath)
    AND log(message=format(format="%v matched by filename %v",
            args=[OSPath, get(item=Specs.sources, field=SourceName).filename]))

  -- If the user wanted to also upload the file, do so now
  LET MaybeUpload(OSPath) = if(condition=AlsoUpload, then=upload(file=OSPath)) OR TRUE

  LET Identify(SourceName, OSPath) = SELECT if(
    condition=CheckHeader(OSPath=OSPath),
    then={
      SELECT *
      FROM sqlite(file=OSPath, query=get(item=Specs.sources, field=SourceName).id_query)
    }) AS Hits
  FROM scope()
  WHERE if(condition=Hits[0].Check = get(item=Specs.sources, field=SourceName).id_value,
    then= log(message="%v was identified as %v",
            args=[OSPath, get(item=Specs.sources, field=SourceName).Name]),
    else=log(message="%v was not identified as %v (got %v, wanted %v)",
             args=[OSPath, get(item=Specs.sources, field=SourceName).Name, str(str=Hits),
                   get(item=Specs.sources, field=SourceName).id_value]) AND FALSE)

  LET ApplyFile(SourceName) = SELECT * FROM foreach(row={
     SELECT OSPath FROM AllFiles
     WHERE if(condition=MatchFilename,  then=matchFilename(SourceName=SourceName, OSPath=OSPath),
      else=Identify(SourceName= SourceName, OSPath= OSPath))

  }, query={
     SELECT *, OSPath FROM sqlite(
        file=OSPath, query=get(item=Specs.sources, field=SourceName).SQL)
  })

  -- Filter for matching files without sqlite checks.
  LET FilterFile(SourceName) =
     SELECT OSPath FROM AllFiles
     WHERE if(condition=MatchFilename,
              then=OSPath =~ get(item=Specs.sources, field=SourceName).filename)

  -- Build a regex for all enabled categories.
  LET all_categories = SELECT _value FROM foreach(row=["All","MacOS","Chrome","Browser","Edge","Firefox","InternetExplorer","Windows"]) WHERE get(field=_value)
  LET category_regex &lt;= join(sep="|", array=all_categories._value)
  LET AllGlobs &lt;= filter(list=Specs.globs, condition="x=&gt; x.tags =~ category_regex")
  LET _ &lt;= log(message="Globs for category %v is %v", args=[category_regex, CustomGlob || AllGlobs.glob])
  LET AllFiles &lt;= SELECT OSPath FROM glob(globs=CustomGlob || AllGlobs.glob)
    WHERE NOT IsDir AND MaybeUpload(OSPath=OSPath)

parameters:
- name: MatchFilename
  description: |
    If set we use the filename to detect the type of sqlite file.
    When unset we use heristics (slower)
  type: bool
  default: Y

- name: CustomGlob
  description: Specify this glob to select other files

- name: DateAfter
  description: Timebox output to rows after this time.
  type: timestamp
  default: "1970-01-01T00:00:00Z"

- name: DateBefore
  description: Timebox output to rows after this time.
  type: timestamp
  default: "2100-01-01T00:00:00Z"

- name: FilterRegex
  description: Filter critical rows by this regex
  type: regex
  default: .


- name: All
  description: Select targets with category All
  type: bool
  default: Y


- name: MacOS
  description: Select targets with category MacOS
  type: bool
  default: N


- name: Chrome
  description: Select targets with category Chrome
  type: bool
  default: N


- name: Browser
  description: Select targets with category Browser
  type: bool
  default: N


- name: Edge
  description: Select targets with category Edge
  type: bool
  default: N


- name: Firefox
  description: Select targets with category Firefox
  type: bool
  default: N


- name: InternetExplorer
  description: Select targets with category InternetExplorer
  type: bool
  default: N


- name: Windows
  description: Select targets with category Windows
  type: bool
  default: N


- name: SQLITE_ALWAYS_MAKE_TEMPFILE
  type: bool
  default: Y

- name: AlsoUpload
  description: If specified we also upload the identified file.
  type: bool

sources:
- name: AllFiles
  query: |
    SELECT * FROM AllFiles


- name: iMessage_Profiles
  query: |
    LET Rows = SELECT * FROM ApplyFile(SourceName="iMessage_Profiles")
    SELECT timestamp(epoch=date / 1000000000 + 978307200) AS Timestamp, *
    FROM Rows
    WHERE Timestamp &gt; DateAfter AND Timestamp &lt; DateBefore
      AND (MessageText, RoomName) =~ FilterRegex
    


- name: Chromium Browser Autofill_Profiles
  query: |
    LET Rows = SELECT * FROM ApplyFile(SourceName="Chromium Browser Autofill_Profiles")
    SELECT GUID,
      timestamp(epoch= date_modified) AS DateModified,
      timestamp(epoch= use_date) AS UseDate,
      FirstName, MiddleName, LastName, EmailAddress,
      PhoneNumber, CompanyName, StreetAddress,
      City, State, ZipCode, UseCount, OSPath
    FROM Rows
    WHERE UseDate &gt; DateAfter AND UseDate &lt; DateBefore
      AND (FirstName, MiddleName, LastName, EmailAddress, CompanyName, StreetAddress) =~ FilterRegex
    


- name: Chromium Browser Autofill_Masked Credit Cards
  query: |
    LET Rows = SELECT * FROM ApplyFile(SourceName="Chromium Browser Autofill_Masked Credit Cards")
    SELECT * FROM Rows


- name: Chromium Browser Bookmarks
  query: |
    LET Rows = SELECT * FROM FilterFile(SourceName="Chromium Browser Bookmarks")
    -- Recursive function to report the details of a folder
    LET ReportFolder(Data, BaseName) = SELECT * FROM chain(a={
      -- First row emit the data about the actual folder
      SELECT BaseName + " | " + Data.name AS Name,
             timestamp(winfiletime=int(int=Data.date_added) * 10) AS DateAdded,
             timestamp(winfiletime=int(int=Data.date_last_used) * 10) AS DateLastUsed,
             Data.type AS Type,
             Data.url || ""  AS URL
      FROM scope()
    },
    b={
       -- If this folder has children recurse into it
       SELECT * FROM foreach(row={
          SELECT _value FROM items(item=Data.children)
       },  query={
          SELECT * FROM ReportFolder(Data=_value, BaseName=BaseName + " | " + Data.name)
       })
    })
    
    LET MatchingFiles = SELECT OSPath, parse_json(data=read_file(filename=OSPath)) AS Data
    FROM Rows
    
    SELECT * FROM foreach(row=MatchingFiles, query={
      SELECT * FROM chain(
      a={
        SELECT OSPath, *, "bookmark_bar" AS Type
        FROM ReportFolder(Data=Data.roots.bookmark_bar, BaseName="")
      },
      b={
        SELECT OSPath, *, "other" AS Type
        FROM ReportFolder(Data=Data.roots.other, BaseName="")
      },
      c={
        SELECT OSPath, *, "synced" AS Type
        FROM ReportFolder(Data=Data.roots.synced, BaseName="")
      })
    })
    


- name: Chromium Browser_Cookies
  query: |
    LET Rows = SELECT * FROM ApplyFile(SourceName="Chromium Browser_Cookies")
    SELECT timestamp(winfiletime=(creation_utc * 10) || 0) AS CreationUTC,
           timestamp(winfiletime=(expires_utc * 10) || 0) AS ExpiresUTC,
           timestamp(winfiletime=(last_access_utc * 10) || 0) AS LastAccessUTC,
           HostKey, Name, Path,
           Bool(Value=is_secure) AS IsSecure,
           Bool(Value=is_httponly) AS IsHttpOnly,
           Bool(Value=has_expires) AS HasExpiration,
           Bool(Value=is_persistent) AS IsPersistent,
           Priority, SourcePort, OSPath
    FROM Rows
    WHERE LastAccessUTC &gt; DateAfter AND LastAccessUTC &lt; DateBefore
      AND (Name, Path) =~ FilterRegex
    


- name: Chromium Browser Extensions
  query: |
    LET Rows = SELECT * FROM FilterFile(SourceName="Chromium Browser Extensions")
    -- Resolve the message string against the Locale dict
    LET ResolveName(Message, Locale) = get(item=Locale,
          field=lowcase(string=parse_string_with_regex(regex="^__MSG_(.+)__$", string=Message).g1),
          default=Message).message || Message
    
    -- Read the manifest files
    LET ManifestData = SELECT OSPath, parse_json(data=read_file(filename=OSPath)) AS Manifest
    FROM Rows
    
    -- Find the Locale file to help with.
    LET LocaleData = SELECT *, if(condition=Manifest.default_locale, else=dict(),
         then=parse_json(data=read_file(
            filename=OSPath.Dirname + "_locales" + Manifest.default_locale + "messages.json"))) AS Locale
    FROM ManifestData
    
    LET GetIcon(Manifest) = Manifest.icons.`128` || Manifest.icons.`64` || Manifest.icons.`32` || Manifest.icons.`16`
    
    SELECT OSPath, Manifest.author.email AS Email,
      ResolveName(Message = Manifest.name, Locale=Locale) AS name,
      ResolveName(Message = Manifest.description, Locale=Locale) AS description,
      Manifest.oauth2.scopes as Scopes,
      Manifest.permissions as Permissions,
      Manifest.key as Key, if(condition=GetIcon(Manifest=Manifest),
                then=upload(file=OSPath.Dirname + GetIcon(Manifest=Manifest))) AS Image,
      Manifest AS _Manifest
    FROM LocaleData
    WHERE (name, description) =~ FilterRegex
    


- name: Chromium Browser Favicons
  query: |
    LET Rows = SELECT * FROM ApplyFile(SourceName="Chromium Browser Favicons")
    SELECT ID, IconID,
      timestamp(winfiletime= (LastUpdated * 10) || 0) AS LastUpdated,
      PageURL, FaviconURL,
      upload(accessor="data",
         file=_image,
         name=format(format="Image%v.png", args=ID)) AS Image,
      OSPath as _OSPath
    FROM Rows
    WHERE LastUpdated &gt; DateAfter AND LastUpdated &lt; DateBefore
    


- name: Chromium Browser History_Visits
  query: |
    LET Rows = SELECT * FROM ApplyFile(SourceName="Chromium Browser History_Visits")
    SELECT ID,
       timestamp(winfiletime=(visit_time * 10) || 0) AS VisitTime,
       timestamp(winfiletime=(last_visit_time * 10) || 0) AS LastVisitedTime,
       URLTitle, URL, VisitCount, TypedCount,
       if(condition=hidden =~ '1', then="Yes", else="No") AS Hidden,
       VisitID, FromVisitID,
       visit_duration / 1000000 AS VisitDurationInSeconds,
       OSPath
    FROM Rows
    WHERE VisitTime &gt; DateAfter
      AND VisitTime &lt; DateBefore
      AND (URLTitle, URL) =~ FilterRegex
    


- name: Chromium Browser History_Downloads
  query: |
    LET Rows = SELECT * FROM ApplyFile(SourceName="Chromium Browser History_Downloads")
    LET StateLookup &lt;= dict(`0`='In Progress', `1`='Complete', `2`="Cancelled", `3`="Interrupted", `4`="Interrupted")
    LET DangerType &lt;= dict(`0`='Not Dangerous', `1`="Dangerous", `2`='Dangerous URL', `3`='Dangerous Content',
        `4`='Content May Be Malicious', `5`='Uncommon Content', `6`='Dangerous But User Validated',
        `7`='Dangerous Host', `8`='Potentially Unwanted', `9`='Whitelisted by Policy')
    LET InterruptReason &lt;= dict(`0`= 'No Interrupt', `1`= 'File Error', `2`='Access Denied', `3`='Disk Full',
      `5`='Path Too Long',`6`='File Too Large', `7`='Virus', `10`='Temporary Problem', `11`='Blocked',
      `12`='Security Check Failed', `13`='Resume Error', `20`='Network Error', `21`='Operation Timed Out',
      `22`='Connection Lost', `23`='Server Down', `30`='Server Error', `31`='Range Request Error',
      `32`='Server Precondition Error', `33`='Unable to get file', `34`='Server Unauthorized',
      `35`='Server Certificate Problem', `36`='Server Access Forbidden', `37`='Server Unreachable',
      `38`='Content Length Mismatch', `39`='Cross Origin Redirect', `40`='Cancelled', `41`='Browser Shutdown',
      `50`='Browser Crashed')
    
    SELECT ID, GUID, CurrentPath, TargetPath, OriginalMIMEType, ReceivedBytes, TotalBytes,
      timestamp(winfiletime=(start_time * 10) || 0) AS StartTime,
      timestamp(winfiletime=(end_time * 10) || 0) AS EndTime,
      timestamp(winfiletime=(opened * 10) || 0) AS Opened,
      timestamp(winfiletime=(last_access_time * 10) || 0) AS LastAccessTime,
      timestamp(epoch=last_modified) AS LastModified,
      get(item=StateLookup, field=str(str=state), default="Unknown") AS State,
      get(item=DangerType, field=str(str=danger_type), default="Unknown") AS DangerType,
      get(item=InterruptReason, field=str(str=interrupt_reason), default="Unknown") AS InterruptReason,
      ReferrerURL, SiteURL, TabURL, TabReferrerURL, DownloadURL, OSPath
    FROM Rows
    WHERE LastAccessTime &gt; DateAfter AND LastAccessTime &lt; DateBefore
      AND (SiteURL, DownloadURL, TabURL, TabReferrerURL, ReferrerURL, DownloadURL) =~ FilterRegex
    


- name: Chromium Browser History_Keywords
  query: |
    LET Rows = SELECT * FROM ApplyFile(SourceName="Chromium Browser History_Keywords")
    SELECT KeywordID, URLID,
       timestamp(winfiletime=(last_visit_time * 10) || 0) AS LastVisitedTime,
       KeywordSearchTerm, Title, URL, OSPath
    FROM Rows
    WHERE LastVisitedTime &gt; DateAfter AND LastVisitedTime &lt; DateBefore
      AND (Title, KeywordSearchTerm, URL) =~ FilterRegex
    


- name: Chromium Browser Media_History
  query: |
    LET Rows = SELECT * FROM ApplyFile(SourceName="Chromium Browser Media_History")
    SELECT ID, URL, WatchTimeSeconds,
       Bool(Value=has_video) AS HasVideo,
       Bool(Value=has_audio) AS HasAudio,
       timestamp(winfiletime=last_updated_time_s || 0) AS LastUpdated,
       OriginID, OSPath
    FROM Rows
    WHERE LastUpdated &gt; DateAfter AND LastUpdated &lt; DateBefore
      AND URL =~ FilterRegex
    


- name: Chromium Browser Media_Playback Session
  query: |
    LET Rows = SELECT * FROM ApplyFile(SourceName="Chromium Browser Media_Playback Session")
    SELECT ID,
      timestamp(winfiletime=last_updated_time_s || 0) AS LastUpdated, URL,
      duration_ms / 1000 AS DurationInSeconds,
      position_ms / 1000 AS PositionInSeconds,
      Title, Artist, Album, SourceTitle, OriginID, OSPath
    FROM Rows
    WHERE LastUpdated &gt; DateAfter AND LastUpdated &lt; DateBefore
      AND URL =~ FilterRegex
    


- name: Chromium Browser Network_Predictor
  query: |
    LET Rows = SELECT * FROM ApplyFile(SourceName="Chromium Browser Network_Predictor")
    SELECT * FROM Rows
    WHERE UserText =~ FilterRegex
    


- name: Chromium Browser Notifications_Site Engagements
  query: |
    LET Rows = SELECT * FROM FilterFile(SourceName="Chromium Browser Notifications_Site Engagements")
    LET JSON = SELECT parse_json(data=read_file(filename=OSPath)) AS Data, OSPath FROM Rows
    
    SELECT * FROM foreach(row={
      SELECT OSPath, Data.profile.content_settings.exceptions AS exceptions FROM JSON
    },  query={
      SELECT _key AS Site,
         timestamp(winfiletime=int(int=_value.last_modified) * 10 || 0) AS LastModified,
         timestamp(winfiletime=int(int=_value.setting.lastEngagementTime) * 10 || 0) AS LastEngagementTime,
         OSPath
      FROM items(item=exceptions.site_engagement)
    })
    


- name: Chromium Browser Notifications_App Banners
  query: |
    LET Rows = SELECT * FROM FilterFile(SourceName="Chromium Browser Notifications_App Banners")
    LET JSON = SELECT parse_json(data=read_file(filename=OSPath)) AS Data, OSPath FROM Rows
    
    SELECT * FROM foreach(row={
      SELECT OSPath, Data.profile.content_settings.exceptions AS exceptions FROM JSON
    },  query={
      SELECT _key AS Site,
         timestamp(winfiletime=int(int=_value.last_modified) * 10 || 0) AS LastModified,
         {
           SELECT _key AS Site,
              timestamp(winfiletime=int(int=_value.couldShowBannerEvents) * 10 || 0) AS CouldShowBannerEvents,
              timestamp(winfiletime=int(int=_value.next_install_text_animation.last_shown) * 10 || 0) AS LastShown
           FROM items(item=_value.setting)
         } AS Setting,
         OSPath
      FROM items(item=exceptions.app_banner)
    })
    


- name: Chromium Browser Notifications_Notification Preferences
  query: |
    LET Rows = SELECT * FROM FilterFile(SourceName="Chromium Browser Notifications_Notification Preferences")
    LET ContentSettings &lt;= array(`0`="Default",`1`="Allow",`2`="Block",`3`="Ask",`4`="Session Only",`5`="Detect Important Content")
    
    LET JSON = SELECT parse_json(data=read_file(filename=OSPath)) AS Data, OSPath FROM Rows
    
    SELECT * FROM foreach(row={
      SELECT OSPath, Data.profile.content_settings.exceptions AS exceptions FROM JSON
    },  query={
      SELECT _key AS Site,
        timestamp(winfiletime=int(int=_value.last_modified) * 10 || 0) AS LastModified,
        ContentSettings[_value.setting] AS Setting,
        OSPath
      FROM items(item=exceptions.notifications)
    })
    


- name: Chromium Browser Notifications_Notification Interactions
  query: |
    LET Rows = SELECT * FROM FilterFile(SourceName="Chromium Browser Notifications_Notification Interactions")
    LET JSON = SELECT parse_json(data=read_file(filename=OSPath)) AS Data, OSPath FROM Rows
    LET S = scope()
    
    SELECT * FROM foreach(row={
      SELECT OSPath, Data.profile.content_settings.exceptions AS exceptions FROM JSON
    },  query={
      SELECT _key AS URL,
        timestamp(winfiletime=int(int=_value.last_modified) * 10 || 0) AS LastModified,
        _value.display_count as DisplayCount,
        _value.click_count as ClickCount,
        OSPath
      FROM items(item=S.notification_interactions || dict())
    })
    


- name: Chromium Browser Shortcuts
  query: |
    LET Rows = SELECT * FROM ApplyFile(SourceName="Chromium Browser Shortcuts")
    SELECT ID,
      timestamp(winfiletime= (last_access_time * 10) || 0) AS LastAccessTime,
      TextTyped, FillIntoEdit, URL, Contents,
      Description, Type, Keyword, TimesSelectedByUser, OSPath
    FROM Rows
    WHERE LastAccessTime &gt; DateAfter AND LastAccessTime &lt; DateBefore
      AND (Contents, Description) =~ FilterRegex
    


- name: Chromium Sessions_Sessions
  query: |
    LET Rows = SELECT * FROM ApplyFile(SourceName="Chromium Sessions_Sessions")
    SELECT timestamp(winfiletime=(creation_utc * 10) || 0) AS CreationUTC,
           timestamp(winfiletime=(expires_utc * 10) || 0) AS ExpiresUTC,
           timestamp(winfiletime=(last_access_utc * 10) || 0) AS LastAccessUTC,
           HostKey, Name, Path,
           Bool(Value=is_secure) AS IsSecure,
           Bool(Value=is_httponly) AS IsHttpOnly,
           Bool(Value=has_expires) AS HasExpiration,
           Bool(Value=is_persistent) AS IsPersistent,
           Priority, SourcePort, OSPath
    FROM Rows
    WHERE LastAccessUTC &gt; DateAfter AND LastAccessUTC &lt; DateBefore
      AND (Name, Path) =~ FilterRegex
    


- name: Chromium Browser Top Sites
  query: |
    LET Rows = SELECT * FROM ApplyFile(SourceName="Chromium Browser Top Sites")
    SELECT * FROM Rows
    WHERE ( URL =~ FilterRegex OR Title =~ FilterRegex )
    


- name: Edge Browser Autofill_CombinedAutofill
  query: |
    LET Rows = SELECT * FROM ApplyFile(SourceName="Edge Browser Autofill_CombinedAutofill")
    SELECT timestamp(epoch=date_last_used) AS DateLastUsed
    FROM Rows
    WHERE DateLastUsed &gt; DateAfter AND DateLastUsed &lt; DateBefore
    


- name: Edge Browser Navigation History_Navigation History
  query: |
    LET Rows = SELECT * FROM ApplyFile(SourceName="Edge Browser Navigation History_Navigation History")
    SELECT ID,
       timestamp(epoch=`Last Visited Time`) AS `Last Visited Time`,
       Title, URL, VisitCount, OSPath
    FROM Rows
    WHERE `Last Visited Time` &gt; DateAfter
      AND `Last Visited Time` &lt; DateBefore
      AND (Title, URL) =~ FilterRegex
    


- name: Firefox Places
  query: |
    LET Rows = SELECT * FROM ApplyFile(SourceName="Firefox Places")
    LET BookmarkTypes &lt;= dict(`1`="URL", `2`="Folder", `3`="Separator")
    SELECT ID, ParentID,
       get(item= BookmarkTypes, field=str(str=type), default="Unknown") AS Type,
       timestamp(epoch=dateAdded) AS DateAdded,
       timestamp(epoch=lastModified) AS LastModified,
       Position, Title, URL, ForeignKey, OSPath
    FROM Rows
    WHERE LastModified &gt; DateAfter AND LastModified &lt; DateBefore
      AND (Title, URL) =~ FilterRegex
    


- name: Firefox Places_Downloads
  query: |
    LET Rows = SELECT * FROM ApplyFile(SourceName="Firefox Places_Downloads")
    SELECT PlaceID, Content,
       timestamp(epoch=dateAdded) AS DateAdded,
       timestamp(epoch=lastModified) AS LastModified,
       OSPath
    FROM Rows
    WHERE LastModified &gt; DateAfter AND LastModified &lt; DateBefore
      AND Content =~ FilterRegex
    


- name: Firefox Places_History
  query: |
    LET Rows = SELECT * FROM ApplyFile(SourceName="Firefox Places_History")
    LET VisitType &lt;= dict(`1`='TRANSITION_LINK', `2`='TRANSITION_TYPED', `3`='TRANSITION_BOOKMARK',
      `4`='TRANSITION_EMBED', `5`= 'TRANSITION_REDIRECT_PERMANENT', `6`='TRANSITION_REDIRECT_TEMPORARY',
      `7`='TRANSITION_DOWNLOAD', `8`='TRANSITION_FRAMED_LINK', `9`='TRANSITION_RELOAD')
    
    SELECT VisitID, FromVisitID,
       timestamp(epoch= last_visit_date) AS LastVisitDate,
       VisitCount, URL, Title, Description,
       get(item= VisitType, field=str(str=visit_type), default="Unknown") AS VisitType,
       Bool(Value=hidden) AS Hidden,
       Bool(Value=typed) AS Typed,
       Frecency, PreviewImageURL, OSPath
    FROM Rows
    WHERE LastVisitDate &gt; DateAfter AND LastVisitDate &lt; DateBefore
      AND (Title, URL, Description) =~ FilterRegex
    


- name: Firefox Cookies
  query: |
    LET Rows = SELECT * FROM ApplyFile(SourceName="Firefox Cookies")
    SELECT ID, Host, Name, Value,
       timestamp(epoch= creationTime) AS CreationTime,
       timestamp(epoch= lastAccessed) AS LastAccessedTime,
       timestamp(epoch= expiry) AS Expiration,
       Bool(Value= isSecure) AS IsSecure,
       Bool(Value= isHttpOnly) AS IsHTTPOnly, OSPath
    FROM Rows
    WHERE LastAccessedTime &gt; DateAfter
      AND LastAccessedTime &lt; DateBefore
      AND ( Name =~ FilterRegex OR Value =~ FilterRegex )
    


- name: Firefox Downloads
  query: |
    LET Rows = SELECT * FROM ApplyFile(SourceName="Firefox Downloads")
    SELECT ID, Name, MIMEType, Source, Target,
       timestamp(epoch= startTime) AS StartTime,
       timestamp(epoch= endTime) AS EndTime,
       timestamp(epoch= expiry) AS Expiration,
       CurrentBytes, MaxBytes, OSPath
    FROM Rows
    WHERE StartTime &gt; DateAfter
      AND StartTime &lt; DateBefore
      AND Name =~ FilterRegex
    


- name: Firefox Favicons
  query: |
    LET Rows = SELECT * FROM ApplyFile(SourceName="Firefox Favicons")
    SELECT ID, PageURL, FaviconURL,
       timestamp(epoch= expire_ms) AS Expiration,
       OSPath
    FROM Rows
    


- name: Firefox Form History
  query: |
    LET Rows = SELECT * FROM ApplyFile(SourceName="Firefox Form History")
    SELECT ID, FieldName, Value, TimesUsed,
       timestamp(epoch= firstUsed) AS FirstUsed,
       timestamp(epoch= lastUsed) AS LastUsed,
       GUID, OSPath
    FROM Rows
    WHERE LastUsed &gt; DateAfter AND LastUsed &lt; DateBefore
      AND ( FieldName =~ FilterRegex OR Value =~ FilterRegex )
    


- name: IE or Edge WebCacheV01_All Data
  query: |
    LET Rows = SELECT * FROM FilterFile(SourceName="IE or Edge WebCacheV01_All Data")
    LET MatchingFiles = SELECT OSPath FROM Rows
    LET S = scope()
    
    LET Containers(OSPath) = SELECT Table
    FROM parse_ese_catalog(file=OSPath)
    WHERE Table =~ "Container_"
    GROUP BY Table
    
    LET AllHits(OSPath) = SELECT * FROM foreach(row={
        SELECT * FROM Containers(OSPath=OSPath)
    }, query={
       SELECT timestamp(winfiletime=ExpiryTime) AS ExpiryTime,
          timestamp(winfiletime=ModifiedTime) AS ModifiedTime,
          timestamp(winfiletime=AccessedTime) AS AccessedTime,
          S.Url AS Url, *
       FROM parse_ese(file=OSPath, table=Table)
    })
    
    SELECT * FROM foreach(row=MatchingFiles, query={
      SELECT * FROM AllHits(OSPath=OSPath)
    })
    WHERE AccessedTime &gt; DateAfter AND AccessedTime &lt; DateBefore
      AND Url =~ FilterRegex
    


- name: IE or Edge WebCacheV01_Highlights
  query: |
    LET Rows = SELECT * FROM FilterFile(SourceName="IE or Edge WebCacheV01_Highlights")
    SELECT * FROM foreach(row=MatchingFiles, query={
      SELECT AccessedTime, ModifiedTime, ExpiryTime, Url
      FROM AllHits(OSPath=OSPath)
    })
    WHERE AccessedTime &gt; DateAfter AND AccessedTime &lt; DateBefore
      AND Url =~ FilterRegex
    


- name: MacOS Applications Cache
  query: |
    LET Rows = SELECT * FROM ApplyFile(SourceName="MacOS Applications Cache")
    SELECT
       time_stamp AS Timestamp,
       OSPath.Base AS Application,
       entry_ID AS EntryID,
       version AS Version,
       hash_value AS Hash,
       storage_policy AS StoragePolicy,
       request_key AS URL,
       plist(file=request_object, accessor="data") AS Request,
       plist(file=response_object, accessor="data") AS Response,
       partition AS Partition,
       OSPath
    FROM Rows
    WHERE Timestamp &gt; DateAfter AND Timestamp &lt; DateBefore
      AND Application =~ FilterRegex
    


- name: MacOS NetworkUsage
  query: |
    LET Rows = SELECT * FROM ApplyFile(SourceName="MacOS NetworkUsage")
    SELECT timestamp(epoch= ZTIMESTAMP + 978307200) AS Timestamp,
      timestamp(epoch= ZFIRSTTIMESTAMP + 978307200) AS FirstTimestamp,
      timestamp(epoch= LIVE_USAGE_TIMESTAMP + 978307200) AS LiveUsageTimestamp,
      ZBUNDLENAME AS BundleID,
      ZPROCNAME AS ProcessName,
      ZWIFIIN AS WifiIn,
      ZWIFIOUT AS WifiOut,
      ZWWANIN AS WanIn,
      ZWWANOUT AS WandOut,
      ZWIREDIN AS WiredIn,
      ZWIREDOUT AS WiredOut,
      ZXIN AS _XIn,
      ZXOUT AS _XOut,
      Z_PK AS LiveUsageTableID
    FROM Rows
    


- name: MacOS Notes
  query: |
    LET Rows = SELECT * FROM ApplyFile(SourceName="MacOS Notes")
    SELECT Key AS _Key,
     OSPath[1] AS User,
     Note,
     Title,
     Snippet,
     NoteID AS _NoteID,
     timestamp(cocoatime=CreatedTS) AS CreatedTime,
     timestamp(cocoatime=LastOpenedDate) AS LastOpenedTime,
     timestamp(cocoatime=DirModificationDate) AS LastDirModifcation,
     Account AS _Account,
     Directory,
     DirectoryID,
     AttachmentName,
     AttachmentSize,
     AttachmentUUID,
     if(condition=AttachmentUUID,
        then=OSPath[:2] + '/Library/Group Containers/group.com.apple.notes/Accounts/LocalAccount/Media/' + AttachmentUUID + '/' + AttachmentName) AS AttachmentLocation,
     AccountName AS _AccountName,
     AccountID AS _AccountID,
     AccountType AS _AccountType,
     gunzip(string=Data) AS Data,
     OSPath
    FROM Rows
    WHERE LastOpenedTime &gt; DateAfter AND LastOpenedTime &lt; DateBefore
      AND ( Title =~ FilterRegex OR Data =~ FilterRegex )
    


- name: MacOS XProtect Detections
  query: |
    LET Rows = SELECT * FROM ApplyFile(SourceName="MacOS XProtect Detections")
    SELECT *
    FROM Rows
    WHERE dt &gt; DateAfter
      AND dt &lt; DateBefore
      AND (violated_rule, exec_path, responsible_path, responsible_signing_id,
        exec_cdhash, exec_sha256, responsible_cdhash, responsible_sha256 ) =~ FilterRegex
    


- name: Windows Activities Cache_ActivityPackageId
  query: |
    LET Rows = SELECT * FROM ApplyFile(SourceName="Windows Activities Cache_ActivityPackageId")
    SELECT format(format="%0X-%0X-%0X-%0X-%0X", args=[
      ActivityId[0:4], ActivityId[4:6], ActivityId[6:8],
      ActivityId[8:10], ActivityId[10:] ]) AS ActivityId,
      Platform, PackageName, ExpirationTime, OSPath
    FROM Rows
    


- name: Windows Activities Cache_Clipboard
  query: |
    LET Rows = SELECT * FROM ApplyFile(SourceName="Windows Activities Cache_Clipboard")
    SELECT
      CreatedTime,
      timestamp(epoch=LastModifiedTime) AS LastModifiedTime,
      timestamp(epoch=LastModifiedOnClient) AS LastModifiedOnClient,
      StartTime,
      EndTime,
      Payload,
      OSPath[1] AS User,
      base64decode(string=parse_json_array(data=ClipboardPayload)[0].content) AS ClipboardPayload,
      OSPath AS Path,
      Mtime
    FROM Rows
    WHERE StartTime &gt; DateAfter
      AND StartTime &lt; DateBefore
      AND ClipboardPayload =~ FilterRegex
    


- name: Windows Search Service_SystemIndex_Gthr
  query: |
    LET Rows = SELECT * FROM FilterFile(SourceName="Windows Search Service_SystemIndex_Gthr")
    LET MatchingFiles = SELECT OSPath FROM Rows
    
    LET FormatTimeB(T) = timestamp(winfiletime=parse_binary(
       filename=T, accessor="data", struct="uint64b"))
    
    LET FormatTime(T) = timestamp(winfiletime=parse_binary(
       filename=T, accessor="data", struct="uint64"))
    
    LET FormatSize(T) = parse_binary(
       filename=T, accessor="data", struct="uint64")
    
    SELECT * FROM foreach(row=MatchingFiles, query={
       SELECT ScopeID, DocumentID, SDID,
          FormatTimeB(T=LastModified) AS LastModified,
          FileName
       FROM parse_ese(file=OSPath, table= "SystemIndex_Gthr")
    })
    WHERE LastModified &gt; DateAfter AND LastModified &lt; DateBefore
      AND FileName =~ FilterRegex
    


- name: Windows Search Service_SystemIndex_GthrPth
  query: |
    LET Rows = SELECT * FROM FilterFile(SourceName="Windows Search Service_SystemIndex_GthrPth")
    SELECT * FROM foreach(row=MatchingFiles, query={
       SELECT Scope, Parent, Name
       FROM parse_ese(file=OSPath, table= "SystemIndex_GthrPth")
    })
    WHERE Name =~ FilterRegex
    


- name: Windows Search Service_SystemIndex_PropertyStore
  query: |
    LET Rows = SELECT * FROM FilterFile(SourceName="Windows Search Service_SystemIndex_PropertyStore")
    LET X = scope()
    
    -- The PropertyStore columns look like
    -- &lt;random&gt;-ProperName so we strip the
    -- random part off to display it properly.
    LET FilterDict(Dict) = to_dict(item={
      SELECT split(sep_string="-", string=_key)[1] || _key AS _key, _value
      FROM items(item=Dict)
    })
    
    LET PropStore(OSPath) = SELECT *,
       FormatTime(T=X.System_Search_GatherTime) AS System_Search_GatherTime,
       FormatSize(T=X.System_Size) AS System_Size,
       FormatTime(T=X.System_DateModified) AS System_DateModified,
       FormatTime(T=X.System_DateAccessed) AS System_DateAccessed,
       FormatTime(T=X.System_DateCreated) AS System_DateCreated
    FROM foreach(row={
       SELECT *, FilterDict(Dict=_value) AS _value
       FROM items(item={
         SELECT * FROM parse_ese(file=OSPath, table="SystemIndex_PropertyStore")
      })
    }, column="_value")
    
    SELECT * FROM foreach(row=MatchingFiles, query={
       SELECT *
       FROM PropStore(OSPath=OSPath)
    })
    WHERE System_DateAccessed &gt; DateAfter AND System_DateAccessed &lt; DateBefore
    


- name: Windows Search Service_SystemIndex_PropertyStore_Highlights
  query: |
    LET Rows = SELECT * FROM FilterFile(SourceName="Windows Search Service_SystemIndex_PropertyStore_Highlights")
    SELECT * FROM foreach(row=MatchingFiles, query={
       SELECT WorkID,
          System_Search_GatherTime,
          System_Size,
          System_DateModified,
          System_DateCreated,
          X.System_FileOwner AS System_FileOwner,
          X.System_ItemPathDisplay AS System_ItemPathDisplay,
          X.System_ItemType AS System_ItemType,
          X.System_FileAttributes AS System_FileAttributes,
          X.System_Search_AutoSummary AS System_Search_AutoSummary
       FROM PropStore(OSPath=OSPath)
    })
    WHERE System_DateAccessed &gt; DateAfter AND System_DateAccessed &lt; DateBefore
    


- name: Windows Search Service_BrowsingActivity
  query: |
    LET Rows = SELECT * FROM FilterFile(SourceName="Windows Search Service_BrowsingActivity")
    SELECT * FROM foreach(row=MatchingFiles, query={
       SELECT X.ItemPathDisplay AS ItemPathDisplay,
          X.Activity_ContentUri AS Activity_ContentUri,
          X.Activity_Description AS Activity_Description
       FROM PropStore(OSPath=OSPath)
       WHERE Activity_ContentUri
    })
    


- name: Windows Search Service_UserActivityLogging
  query: |
    LET Rows = SELECT * FROM FilterFile(SourceName="Windows Search Service_UserActivityLogging")
    SELECT * FROM foreach(row=MatchingFiles, query={
       SELECT X.System_ItemPathDisplay AS System_ItemPathDisplay,
           FormatTime(T=X.ActivityHistory_StartTime) AS ActivityHistory_StartTime,
           FormatTime(T=X.ActivityHistory_EndTime) AS ActivityHistory_EndTime,
           X.ActivityHistory_AppId AS ActivityHistory_AppId
       FROM PropStore(OSPath=OSPath)
       WHERE ActivityHistory_AppId
    })
    WHERE ActivityHistory_StartTime &gt; DateAfter
      AND ActivityHistory_StartTime &lt; DateBefore
    




</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.carving.usn.md
======
---
title: Windows.Carving.USN
hidden: true
tags: [Client Artifact]
---

Carve URN Journal records from the disk.

The USN journal is a very important source of information about when
and how files were manipulated on the filesystem. However, typically
the journal is rotated within a few days.

This artifact carves out USN journal entries from the raw disk. This
might recover older entries which have since been rotated from the
journal file.

## Notes

1. Like all carving, USN carving is not very reliable. You
   would tend to use it to corroborate an existing theory or to
   discover new leads.

2. This artifact takes a long time to complete - you should
   probably increase the collection timeout past 10 minutes (usually
   more than an hour).

3. The reassembled OSPath is derived from the MFTId referenced in
   the USN record. Bear in mind that this might be out of date and
   inaccurate.

4. If you need to carve from a standalone file (e.g. collection from
   `Windows.KapeFiles.Targets`) you should use the
   Windows.Carving.USNFiles artifact instead.


<pre><code class="language-yaml">
name: Windows.Carving.USN
description: |
  Carve URN Journal records from the disk.

  The USN journal is a very important source of information about when
  and how files were manipulated on the filesystem. However, typically
  the journal is rotated within a few days.

  This artifact carves out USN journal entries from the raw disk. This
  might recover older entries which have since been rotated from the
  journal file.

  ## Notes

  1. Like all carving, USN carving is not very reliable. You
     would tend to use it to corroborate an existing theory or to
     discover new leads.

  2. This artifact takes a long time to complete - you should
     probably increase the collection timeout past 10 minutes (usually
     more than an hour).

  3. The reassembled OSPath is derived from the MFTId referenced in
     the USN record. Bear in mind that this might be out of date and
     inaccurate.

  4. If you need to carve from a standalone file (e.g. collection from
     `Windows.KapeFiles.Targets`) you should use the
     Windows.Carving.USNFiles artifact instead.

parameters:
  - name: Device
    default: "C:"
    description: The NTFS drive to carve
  - name: MFTFile
    description: Alternatively provide an MFTFile to use for resolving paths.
  - name: USNFile
    description: Alternatively provide a previously extracted USN file to carve or an image file.
  - name: Accessor
    description: The accessor to use.
  - name: FileNameRegex
    description: "Regex search over File Name"
    default: "."
    type: regex
  - name: DateAfter
    type: timestamp
    description: "search for events after this date. YYYY-MM-DDTmm:hh:ssZ"
  - name: DateBefore
    type: timestamp
    description: "search for events before this date. YYYY-MM-DDTmm:hh:ssZ"

sources:
  - precondition:
      SELECT OS From info() where OS = 'windows'

    query: |
        -- firstly set timebounds for performance
        LET DateAfterTime &lt;= if(condition=DateAfter,
             then=DateAfter, else="1600-01-01")
        LET DateBeforeTime &lt;= if(condition=DateBefore,
            then=DateBefore, else="2200-01-01")

        -- If the user specified an MFTFile then ignore the device
        LET Device &lt;= if(condition=MFTFile OR USNFile, then=NULL,
          else=if(condition=Device,
          then=pathspec(parse=Device, path_type="ntfs")))

        LET Parse(MFT, USN, Accessor) = SELECT *
              FROM carve_usn(accessor=Accessor,
                             mft_filename=MFT, usn_filename=USN)
              WHERE Filename =~ FileNameRegex
                AND Timestamp &lt; DateBeforeTime
                AND Timestamp &gt; DateAfterTime

        SELECT *
        FROM if(condition=Device, then={
          SELECT Timestamp,
            Filename,
            Device + OSPath AS OSPath,
            _Links,
            Reason,
            _FileMFTID as MFTId,
            _FileMFTSequence as Sequence,
            _ParentMFTID as ParentMFTId,
            _ParentMFTSequence as ParentSequence,
            FileAttributes,
            SourceInfo,
            Usn
          FROM Parse(Accessor="ntfs",
              MFT=Device + "$MFT",
              USN=Device)
        }, else={
          SELECT Timestamp,
            Filename,
            OSPath,
            _Links,
            Reason,
            _FileMFTID as MFTId,
            _FileMFTSequence as Sequence,
            _ParentMFTID as ParentMFTId,
            _ParentMFTSequence as ParentSequence,
            FileAttributes,
            SourceInfo,
            Usn
          FROM Parse(Accessor=Accessor,
              MFT=MFTFile, USN=USNFile)
        })

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/macos.system.plist.md
======
---
title: MacOS.System.Plist
hidden: true
tags: [Client Artifact]
---

This artifact collects and/or parses MacOS .plist files.  While simple,
this artifact allows users to specify a .plist glob, and have those plist files
returned for quick review.  If more advanced parsing is desired, the artifact can be copied
and modified.


<pre><code class="language-yaml">
name: MacOS.System.Plist
description: |
  This artifact collects and/or parses MacOS .plist files.  While simple,
  this artifact allows users to specify a .plist glob, and have those plist files
  returned for quick review.  If more advanced parsing is desired, the artifact can be copied
  and modified.

type: CLIENT

author: Wes Lambert - @therealwlambert

precondition: SELECT OS FROM info() WHERE OS =~ 'darwin'

parameters:
  - name: PlistGlob
    default: /Library/Preferences/*.plist

  - name: Upload_File
    default: N
    type: bool

sources:
  - query: |
      SELECT
        OSPath,
        Mtime,
        plist(file=OSPath) AS Content,
        if(condition=Upload_File,
           then=upload(file=OSPath,
                       mtime=Mtime,
                       atime=Atime,
                       ctime=Ctime,
                       btime=Btime)) AS Upload
      FROM glob(globs=PlistGlob)

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.remediation.sinkhole.md
======
---
title: Windows.Remediation.Sinkhole
hidden: true
tags: [Client Artifact]
---

**Apply a Sinkhole via Windows hosts file modification**
This content will modify the Windows hosts file by a configurable
lookup table.

On application, the original configuration is backed up.
When reapplying a sinkhole, the original configuration is restored then
changes applied to maintain integrity of the restore process.
If RestoreBackup is selected the artifact will restore the backup
configuration, then delete the backup with no further processing.

NOTE:
Modifying the hosts file may cause network communication issues. I have
disabled any sinkhole settings on the Velociraptor agent configuration
but there are no rail guards on other domains. Use with caution.


<pre><code class="language-yaml">
name: Windows.Remediation.Sinkhole
description: |
   **Apply a Sinkhole via Windows hosts file modification**
   This content will modify the Windows hosts file by a configurable
   lookup table.

   On application, the original configuration is backed up.
   When reapplying a sinkhole, the original configuration is restored then
   changes applied to maintain integrity of the restore process.
   If RestoreBackup is selected the artifact will restore the backup
   configuration, then delete the backup with no further processing.

   NOTE:
   Modifying the hosts file may cause network communication issues. I have
   disabled any sinkhole settings on the Velociraptor agent configuration
   but there are no rail guards on other domains. Use with caution.

author: Matt Green - @mgreen27

required_permissions:
  - EXECVE

type: CLIENT

parameters:
  - name: HostsFile
    description: Path to hosts file
    default: C:\Windows\System32\drivers\etc\hosts
  - name: HostsFileBackup
    description: Name to backup original hosts file. If reapplying the artifact this file is used as the base.
    default: C:\Windows\System32\drivers\etc\hosts.velociraptor.backup
  - name: CommentPrefix
    description: Prefix to add to description in hosts file comments.
    default: "Velociraptor sinkhole"
  - name: RestoreBackup
    description: "Restore hosts file backup"
    type: bool
  - name: SinkholeTable
    description: Table of Domains to add to or modify in hosts file.
    type: csv
    default: |
        Domain,Sinkhole,Description
        evil.com,127.0.0.1,Evilcorp C2 domain


sources:
  - precondition:
      SELECT OS From info() where OS = 'windows'

    query: |
      -- Extract sink hole requirements from table
      LET changes &lt;= SELECT
                Domain,
                Sinkhole,
                if(condition=Description,
                  then= CommentPrefix + ': ' + Description,
                  else= CommentPrefix) as Description
            FROM SinkholeTable

      -- Check for backup to determine if sinkhole applied
      LET check_backup = SELECT OSPath FROM stat(filename=HostsFileBackup)
      WHERE log(message="Found backup at " + OSPath)

      -- Backup old config
      LET backup = copy(filename=HostsFile,dest=HostsFileBackup)

      -- Restore old config
      LET restore = SELECT * FROM chain(
            z=log(message="Will restore from backup"),
            a=copy(filename=HostsFileBackup,dest=HostsFile),
            b={
                SELECT *
                FROM if(condition=RestoreBackup,
                    then={
                        SELECT *
                        FROM execve(argv=['cmd.exe', '/c',
                            'del','/F',HostsFileBackup])
                    })
            })

      -- Write hosts file
      LET write(DataBlob) = copy(filename=DataBlob,dest=HostsFile,accessor='data')

      -- FlushDNS
      LET flushdns = SELECT *
        FROM execve(argv=['cmd.exe', '/c','ipconfig','/flushdns'])

      -- Find existing entries to modify
      LET existing &lt;= SELECT
            parse_string_with_regex(
            string=Line,
            regex=[
                "^\\s+(?P&lt;Resolution&gt;[^\\s]+)\\s+" +
                "(?P&lt;Hostname&gt;[^\\s]+)\\s*\\S*$"
            ]) as Record,
            Line
        FROM parse_lines(filename=HostsFile)
        WHERE
            Record AND Line
            AND NOT Line =~ '^#'

      -- Parse a URL to get domain name.
      LET get_domain(URL) = parse_string_with_regex(
           string=URL, regex='^https?://(?P&lt;Domain&gt;[^:/]+)').Domain

      -- extract Velociraptor config for policy
      LET extracted_config &lt;= SELECT * FROM foreach(
          row=config.server_urls,
            query={
                SELECT get_domain(URL=_value) AS Domain
                FROM scope()
            })

      -- Set existing entries to sinkholed values
      LET find_modline &lt;= SELECT * FROM foreach(row=changes,
            query={
                SELECT
                    format(format='\t%v\t\t%v\t\t# %v',
                    args=[Sinkhole,Domain,Description]) as Line,
                    Domain,
                    'modification' as Type
                FROM existing
                WHERE
                    Record.Hostname = Domain
                    AND NOT Domain in extracted_config.Domain
                GROUP BY Line
            })

      -- Add new hostsfile entries
      LET find_newline &lt;= SELECT * FROM foreach(row=changes,
            query={
                SELECT
                    format(format='\t%v\t\t%v\t\t# %v',
                        args=[Sinkhole,Domain,Description]) as Line,
                    Domain,
                    'new entry' as Type
                FROM scope()
                WHERE
                    NOT Domain in find_modline.Domain
                    AND NOT Domain in extracted_config.Domain
            })

      -- Determine which lines should stay the same
      LET find_line &lt;= SELECT
                Line,
                Record.Hostname as Domain,
                'old entry' as Type
            FROM existing
            WHERE
                NOT Domain in find_modline.Domain
                AND NOT Domain in find_newline.Domain

      -- Add all lines to staging object
      LET build_lines &lt;= SELECT Line FROM chain(
            a=find_modline,
            b=find_newline,
            c=find_line
      )

      -- Join lines from staging object
      LET HostsData = join(array=build_lines.Line,sep='\r\n')

      -- Force start of backup or restore if applicable
      LET backup_restore &lt;= if(
         condition= RestoreBackup AND log(message="Will attempt to restore backup"),
         then= if(
            condition= check_backup,
            then= restore,
            -- then= { SELECT * FROM restore },
            else= log(message='Can not restore hosts file as backup does not exist.')),

         else= if(
           condition= check_backup,
           then={
              SELECT * FROM chain(
                 a= log(message='Backup hosts file already exists.'),
                 b= restore)
              },
          else= backup)
        )

      -- Do kick off logic
      LET do_it &lt;= SELECT * FROM if(condition= NOT RestoreBackup,
            then= {
                SELECT * FROM chain(
                    a= log(message='Adding hosts entries.'),
                    b= write(DataBlob=HostsData),
                    c= flushdns
                )})

      -- Finally show resultant HostsFile
      SELECT * FROM Artifact.Windows.System.HostsFile(HostsFile=HostsFile)

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.events.kerberoasting.md
======
---
title: Windows.Events.Kerberoasting
hidden: true
tags: [Client Event Artifact]
---

**Description**:
This Artifact will monitor all successful Kerberos TGS Ticket events for
Service Accounts (SPN attribute) implemented with weak encryption. These
tickets are vulnerable to brute force attack and this event is an indicator
of a Kerberoasting attack.

**ATT&CK**: [T1208 - Kerberoasting](https://attack.mitre.org/techniques/T1208/)
Typical attacker methodology is to firstly request accounts in the domain
with SPN attributes, then request an insecure TGS ticket for brute forcing.
This attack is particularly effective as any domain credentials can be used
to implement the attack and service accounts often have elevated privileges.
Kerberoasting can be used for privilege escalation or persistence by adding a
SPN attribute to an unexpected account.

**Reference**: [The Art of Detecting Kerberoast Attacks](https://www.trustedsec.com/2018/05/art_of_kerberoast/)
**Log Source**: Windows Security Event Log (Domain Controllers)
**Event ID**: 4769
**Status**: 0x0 (Audit Success)
**Ticket Encryption**: 0x17 (RC4)
**Service Name**: NOT krbtgt or NOT a system account (account name ends in $)
**TargetUserName**: NOT a system account (*$@*)


Monitor and alert on unusual events from an unexpected IP.
Note: There are potential false positives so whitelist normal source IPs and
manage risk of insecure ticket generation.


<pre><code class="language-yaml">
name: Windows.Events.Kerberoasting
description: |
  **Description**:
  This Artifact will monitor all successful Kerberos TGS Ticket events for
  Service Accounts (SPN attribute) implemented with weak encryption. These
  tickets are vulnerable to brute force attack and this event is an indicator
  of a Kerberoasting attack.

  **ATT&amp;CK**: [T1208 - Kerberoasting](https://attack.mitre.org/techniques/T1208/)
  Typical attacker methodology is to firstly request accounts in the domain
  with SPN attributes, then request an insecure TGS ticket for brute forcing.
  This attack is particularly effective as any domain credentials can be used
  to implement the attack and service accounts often have elevated privileges.
  Kerberoasting can be used for privilege escalation or persistence by adding a
  SPN attribute to an unexpected account.

  **Reference**: [The Art of Detecting Kerberoast Attacks](https://www.trustedsec.com/2018/05/art_of_kerberoast/)
  **Log Source**: Windows Security Event Log (Domain Controllers)
  **Event ID**: 4769
  **Status**: 0x0 (Audit Success)
  **Ticket Encryption**: 0x17 (RC4)
  **Service Name**: NOT krbtgt or NOT a system account (account name ends in $)
  **TargetUserName**: NOT a system account (*$@*)


  Monitor and alert on unusual events from an unexpected IP.
  Note: There are potential false positives so whitelist normal source IPs and
  manage risk of insecure ticket generation.


author: Matt Green - @mgreen27

type: CLIENT_EVENT

parameters:
  - name: eventLog
    default: C:\Windows\system32\winevt\logs\Security.evtx

sources:
  - name: Kerberoasting
    query: |
      LET files = SELECT * FROM glob(globs=eventLog)

      SELECT timestamp(epoch=System.TimeCreated.SystemTime) As EventTime,
              System.EventID.Value as EventID,
              System.Computer as Computer,
              EventData.ServiceName as ServiceName,
              EventData.ServiceSid as ServiceSid,
              EventData.TargetUserName as TargetUserName,
              "0x" + format(format="%x", args=EventData.Status) as Status,
              EventData.TargetDomainName as TargetDomainName,
              "0x" + format(format="%x", args=EventData.TicketEncryptionType) as TicketEncryptionType,
              "0x" + format(format="%x", args=EventData.TicketOptions) as TicketOptions,
              EventData.TransmittedServices as TransmittedServices,
              EventData.IpAddress as IpAddress,
              EventData.IpPort as IpPort
        FROM foreach(
          row=files,
          async=TRUE,
          query={
            SELECT *
            FROM watch_evtx(filename=OSPath)
            WHERE System.EventID.Value = 4769
                AND EventData.TicketEncryptionType = 23
                AND EventData.Status = 0
                AND NOT EventData.ServiceName =~ "krbtgt|\\$$"
                AND NOT EventData.TargetUserName =~ "\\$@"
        })

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.system.svchost.md
======
---
title: Windows.System.SVCHost
hidden: true
tags: [Client Artifact]
---

Typically a windows system will have many svchost.exe
processes. Sometimes attackers name their processes svchost.exe to
try to hide. Typically svchost.exe is spawned by services.exe.

This artifact lists all the processes named svchost.exe and their
parents if the parent is not also named services.exe.


<pre><code class="language-yaml">
name: Windows.System.SVCHost
description: |
  Typically a windows system will have many svchost.exe
  processes. Sometimes attackers name their processes svchost.exe to
  try to hide. Typically svchost.exe is spawned by services.exe.

  This artifact lists all the processes named svchost.exe and their
  parents if the parent is not also named services.exe.

sources:
  - precondition: |
      SELECT OS From info() where OS = 'windows'

    query: |
        // Cache the pslist output in memory.
        LET processes &lt;= SELECT Pid, Ppid, Name, Exe FROM pslist()

        // Get the pids of all procecesses named services.exe
        LET services &lt;= SELECT Pid FROM processes where Name =~ "services.exe"

        // The interesting processes are those which are not spawned by services.exe
        LET suspicious = SELECT Pid As SVCHostPid,
            Ppid As SVCHostPpid,
            Exe as SVCHostExe,
            CommandLine as SVCHostCommandLine
        FROM processes
        WHERE Name =~ "svchost" AND NOT Ppid in services.Pid

        // Now for each such process we display its actual parent.
        SELECT * from foreach(
           row=suspicious,
           query={
              SELECT SVCHostPid, SVCHostPpid, SVCHostExe,
                     SVCHostCommandLine, Name as ParentName,
                     Exe As ParentExe
              FROM processes
              WHERE Pid=SVCHostPpid
          })

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.applications.firefox.history.md
======
---
title: Windows.Applications.Firefox.History
hidden: true
tags: [Client Artifact]
---

Enumerate the users Firefox history.

## NOTES:

This artifact is deprecated in favor of
Generic.Forensic.SQLiteHunter and will be removed in future


<pre><code class="language-yaml">
name: Windows.Applications.Firefox.History
description: |
  Enumerate the users Firefox history.

  ## NOTES:

  This artifact is deprecated in favor of
  Generic.Forensic.SQLiteHunter and will be removed in future


author: Zach Stanford @svch0st, Modified by @angry-bender
parameters:
  - name: placesGlobs
    default: \AppData\Roaming\Mozilla\Firefox\Profiles\*\places.sqlite
  - name: urlSQLQuery
    default: |
        SELECT *,url as url_visited FROM moz_historyvisits, moz_places WHERE moz_historyvisits.place_id=moz_places.id
  - name: userRegex
    default: .
    type: regex
  - name: URLRegex
    default: .
    type: regex

precondition: SELECT OS From info() where OS = 'windows'

sources:
  - query: |
        LET places_files = SELECT * from foreach(
          row={
             SELECT Uid, Name AS User,
                    expand(path=Directory) AS HomeDirectory
             FROM Artifact.Windows.Sys.Users()
             WHERE Name =~ userRegex
          },
          query={
             SELECT User, OSPath, Mtime
             FROM glob(root=HomeDirectory, globs=placesGlobs)
          })

        SELECT * FROM foreach(row=places_files,
          query={
            SELECT User, OSPath,
                   timestamp(epoch=visit_date/1000000) as visit_time,
                   place_id,url_visited,title,rev_host,visit_count,hidden,typed,description
            FROM sqlite(
              file=OSPath,
              query=urlSQLQuery)
          })
          WHERE url_visited =~ URLRegex

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.system.criticalservices.md
======
---
title: Windows.System.CriticalServices
hidden: true
tags: [Client Artifact]
---

This artifact returns information about any services which are
considered critical.

The default list contains virus scanners. If the software is not
installed at all, it will not be shown.


<pre><code class="language-yaml">
name: Windows.System.CriticalServices
description: |
  This artifact returns information about any services which are
  considered critical.

  The default list contains virus scanners. If the software is not
  installed at all, it will not be shown.

reference:
  - "ATT&amp;CK: T1089"
  - https://github.com/teoseller/osquery-attck/blob/master/windows_critical_service_status.conf

precondition: SELECT OS From info() where OS = 'windows'

parameters:
  - name: lookupTable
    type: csv
    default: |
       ServiceName
       WinDefend
       MpsSvc
       SepMasterService
       SAVAdminService
       SavService
       wscsvc
       wuauserv

sources:
     - query: |
         SELECT Name, DisplayName, Created, State, {
            SELECT * FROM lookupTable WHERE Name =~ ServiceName
         } AS Critical
         FROM Artifact.Windows.System.Services()
         WHERE Critical AND State != "Running"

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.sys.startupitems.md
======
---
title: Windows.Sys.StartupItems
hidden: true
tags: [Client Artifact]
---

Applications that will be started up from the various run key
locations.


<pre><code class="language-yaml">
name: Windows.Sys.StartupItems
description: |
    Applications that will be started up from the various run key
    locations.

reference:
  - https://docs.microsoft.com/en-us/windows/desktop/setupapi/run-and-runonce-registry-keys

parameters:
  - name: AlsoUpload
    type: bool
    description: If set we also upload the files in the startup folders

  - name: runKeyGlobs
    type: csv
    default: |
      KeyGlobs
      HKEY_LOCAL_MACHINE\SOFTWARE\Microsoft\Windows\CurrentVersion\Run*\*
      HKEY_LOCAL_MACHINE\SOFTWARE\WOW6432Node\Microsoft\Windows\CurrentVersion\Run*\*
      HKEY_LOCAL_MACHINE\SOFTWARE\Microsoft\Windows\CurrentVersion\Policies\Explorer\Run*\*
      HKEY_USERS\*\SOFTWARE\Microsoft\Windows\CurrentVersion\Run*\*
      HKEY_USERS\*\SOFTWARE\WOW6432Node\Microsoft\Windows\CurrentVersion\Run*\*
      HKEY_USERS\*\SOFTWARE\Microsoft\Windows\CurrentVersion\Policies\Explorer\Run*\*

  - name: startupApprovedGlobs
    type: csv
    default: |
      KeyGlobs
      HKEY_LOCAL_MACHINE\SOFTWARE\Microsoft\Windows\CurrentVersion\Explorer\StartupApproved\**
      HKEY_USERS\*\SOFTWARE\Microsoft\Windows\CurrentVersion\Explorer\StartupApproved\**

  - name: startupFolderDirectories
    type: csv
    default: |
      FileGlobs
      C:/ProgramData/Microsoft/Windows/Start Menu/Programs/Startup/**
      C:/Users/*/AppData/Roaming/Microsoft/Windows/Start Menu/Programs/Startup/**

sources:
  - precondition:
      SELECT OS From info() where OS = 'windows'

    query: |
        LET approved &lt;=
           SELECT Name as ApprovedName,
                  encode(string=Data, type="hex") as Enabled
           FROM glob(globs=startupApprovedGlobs.KeyGlobs,
                     accessor="registry")
           WHERE Enabled =~ "^0[0-9]0+$"

        LET registry_runners = SELECT Name,
          OSPath, Data.value as Details,
          if(
           condition={
                SELECT Enabled from approved
                WHERE Name = ApprovedName
           },
           then="enabled", else="disabled") as Enabled,
           "" AS Upload
          FROM glob(
           globs=runKeyGlobs.KeyGlobs,
           accessor="registry")

        LET enrich_file(OSPath) = SELECT * FROM switch(
        ini={
            SELECT regex_replace(re="[^0-9a-z_]", replace=".",
                 source=read_file(filename=OSPath, length=1024)) AS Details
            FROM scope()
            WHERE OSPath.Basename =~ ".(bat|ini|ps1)$"
        }, lnk={
            SELECT { 
                  SELECT SourceFile, ShellLinkHeader, LinkInfo, LinkTarget, StringData, ExtraData 
                  FROM Artifact.Windows.Forensics.Lnk(TargetGlob=OSPath)
                } as Details
            FROM scope()
        }, default={
            SELECT hash(path=OSPath) AS Details
            FROM scope()
        })

        LET file_runners =
          SELECT Name, OSPath,
                 enrich_file(OSPath=OSPath)[0].Details AS Details,
                 "enable" as Enabled,
                 if(condition=AlsoUpload, then=upload(file=OSPath)) AS Upload
          FROM glob(globs=startupFolderDirectories.FileGlobs)

        SELECT *
        FROM chain(
           first=registry_runners,
           second=file_runners)

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/generic.client.info.md
======
---
title: Generic.Client.Info
hidden: true
tags: [Client Artifact]
---

Collect basic information about the client.

This artifact is collected when any new client is enrolled into the
system. Velociraptor will watch for this artifact and populate its
internal indexes from this artifact as well.

You can edit this artifact to enhance the client's interrogation
information as required, by adding new sources.

NOTE: Do not modify the BasicInformation source since it is used to
interrogate the clients.


<pre><code class="language-yaml">
name: Generic.Client.Info
description: |
  Collect basic information about the client.

  This artifact is collected when any new client is enrolled into the
  system. Velociraptor will watch for this artifact and populate its
  internal indexes from this artifact as well.

  You can edit this artifact to enhance the client's interrogation
  information as required, by adding new sources.

  NOTE: Do not modify the BasicInformation source since it is used to
  interrogate the clients.

sources:
  - name: BasicInformation
    description: |
      This source is used internally to populate agent info. Do not
      modify or remove this query.
    query: |
        LET Interfaces = SELECT HardwareAddrString AS MAC
        FROM interfaces()
        WHERE HardwareAddr

        SELECT config.Version.Name AS Name,
               config.Version.BuildTime as BuildTime,
               config.Version.Version as Version,
               config.Version.ci_build_url AS build_url,
               config.Version.install_time as install_time,
               config.Labels AS Labels,
               Hostname, OS, Architecture,
               Platform, PlatformVersion, KernelVersion, Fqdn,
               Interfaces.MAC AS MACAddresses
        FROM info()

  - name: DetailedInfo
    query: |
      LET Info = SELECT * FROM info()
      SELECT _key AS Param, _value AS Value FROM items(item=Info[0])

  - name: LinuxInfo
    description: Linux specific information about the host
    precondition: SELECT OS From info() where OS = 'linux'
    query: |
      SELECT if(condition=version(function='sysinfo') != NULL, then=sysinfo()) AS `Computer Info`,
      { SELECT Name, HardwareAddrString AS MACAddress,
               Up, PointToPoint,
               AddrsString AS IPAddresses
        FROM interfaces() WHERE HardwareAddr} AS `Network Info`
      FROM scope()

  - name: WindowsInfo
    description: Windows specific information about the host
    precondition: SELECT OS From info() where OS = 'windows'
    query: |
      LET DomainLookup &lt;= dict(
         `0`='Standalone Workstation',
         `1`='Member Workstation',
         `2`='Standalone Server',
         `3`='Member Server',
         `4`='Backup Domain Controller',
         `5`='Primary Domain Controller')

      SELECT
          {
            SELECT DNSHostName, Name, Domain, TotalPhysicalMemory,
                   get(item=DomainLookup,
                       field=str(str=DomainRole), default="Unknown") AS DomainRole
            FROM wmi(
               query='SELECT * FROM win32_computersystem')
          } AS `Computer Info`,
          {
            SELECT Caption,
               join(array=IPAddress, sep=", ") AS IPAddresses,
               join(array=IPSubnet, sep=", ") AS IPSubnet,
               MACAddress,
               join(array=DefaultIPGateway, sep=", ") AS DefaultIPGateway,
               DNSHostName,
               join(array=DNSServerSearchOrder, sep=", ") AS DNSServerSearchOrder
            FROM wmi(
               query="SELECT * from Win32_NetworkAdapterConfiguration" )
            WHERE IPAddress
          } AS `Network Info`
      FROM scope()

    notebook:
      - type: vql_suggestion
        name: "Enumerate Domain Roles"
        template: |
          /*
          # Enumerate Domain Roles

          Search all clients' enrollment information for their domain roles.
          */
          --
          -- Remove the below comments to label Domain Controllers
          SELECT *--, label(client_id=client_id, labels="DomainController", op="set") AS Label
          FROM foreach(row={
             SELECT * FROM clients()
          }, query={
              SELECT
                `Computer Info`.Name AS Name, client_id,
                `Computer Info`.DomainRole AS DomainRole
              FROM source(client_id=client_id,
                  flow_id=last_interrogate_flow_id,
                  source="WindowsInfo")
          })
          -- WHERE DomainRole =~ "Controller"

  - name: Users
    precondition: SELECT OS From info() where OS = 'windows'
    query: |
      SELECT Name, Description, Mtime AS LastLogin
      FROM Artifact.Windows.Sys.Users()

reports:
  - type: CLIENT
    template: |
      {{ $client_info := Query "SELECT * FROM clients(client_id=ClientId) LIMIT 1" | Expand }}

      {{ $flow_id := Query "SELECT timestamp(epoch=active_time / 1000000) AS Timestamp FROM flows(client_id=ClientId, flow_id=FlowId)" | Expand }}

      # {{ Get $client_info "0.os_info.fqdn" }} ( {{ Get $client_info "0.client_id" }} ) @ {{ Get $flow_id "0.Timestamp" }}

      {{ Query "SELECT * FROM source(source='BasicInformation')" | Table }}

      # Memory and CPU footprint over the past 24 hours

      {{ define "resources" }}
       SELECT * FROM sample(
         n=4,
         query={
           SELECT Timestamp, rate(x=CPU, y=Timestamp) * 100 As CPUPercent,
                  RSS / 1000000 AS MemoryUse
           FROM source(artifact="Generic.Client.Stats",
                       client_id=ClientId,
                       start_time=now() - 86400)
           WHERE CPUPercent &gt;= 0
         })
      {{ end }}

      {{ define "computerinfo" }}
      LET X &lt;= SELECT *
        FROM source(source="LinuxInfo')
        LIMIT 1

      SELECT humanize(bytes=TotalPhysicalMemory) AS  TotalPhysicalMemory,
             humanize(bytes=TotalFreeMemory) AS  TotalFreeMemory,
             humanize(bytes=TotalSharedMemory) AS  TotalSharedMemory,
             humanize(bytes=TotalSwap) AS  TotalSwap,
             humanize(bytes=FreeSwap) AS  FreeSwap
      FROM foreach(row=X[0].`Computer Info`)
      {{ end }}

      &lt;div&gt;
      {{ Query "resources" | LineChart "xaxis_mode" "time" "RSS.yaxis" 2 }}
      &lt;/div&gt;

      {{ $windows_info := Query "SELECT * FROM source(source='WindowsInfo')" }}
      {{ if $windows_info | Expand }}
      # Windows agent information
        {{ $windows_info | Table }}
      {{ end }}

      {{ $linux_info := Query "LET X &lt;= SELECT * FROM source(source='LinuxInfo') LIMIT 1 SELECT * FROM X" }}
      {{ if Query "SELECT * FROM source(source='LinuxInfo')" | Expand }}
      # Linux agent information

      ### Network Info
        {{ Query "SELECT * FROM foreach(row=X[0].`Network Info`)" | Table }}

      ### Computer Info
        {{ Query "computerinfo" | Table }}

      {{ end }}

      # Active Users
      {{ Query "SELECT * FROM source(source='Users')" | Table }}


column_types:
  - name: BuildTime
    type: timestamp
  - name: LastLogin
    type: timestamp

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.detection.usn.md
======
---
title: Windows.Detection.Usn
hidden: true
tags: [Client Event Artifact]
---

NTFS is a journal filesystem. This means that it maintains a journal
file where intended filesystem changes are written first, then the
filesystem is changed. This journal is called the USN journal in NTFS.

Velociraptor can watch the USN journal for new filesystem
events. This allows Velociraptor to detect when new files are
created or modified.

A common use case is to determine when a new prefetch file is
modified (this indicates a binary was executed). Note: It seems
prefetch files are not updated immediately - there could be a small
delay between the execution and the prefetch being modified.


<pre><code class="language-yaml">
name: Windows.Detection.Usn
description: |
  NTFS is a journal filesystem. This means that it maintains a journal
  file where intended filesystem changes are written first, then the
  filesystem is changed. This journal is called the USN journal in NTFS.

  Velociraptor can watch the USN journal for new filesystem
  events. This allows Velociraptor to detect when new files are
  created or modified.

  A common use case is to determine when a new prefetch file is
  modified (this indicates a binary was executed). Note: It seems
  prefetch files are not updated immediately - there could be a small
  delay between the execution and the prefetch being modified.

type: CLIENT_EVENT

parameters:
  - name: PathRegex
    description: A regex to match the entire path (you can watch a directory or a file type).
    default: \.pf$
    type: regex
  - name: Device
    description: The NTFS drive to watch
    default: C:\\
  - name: USN_FREQUENCY
    type: int
    description: How many seconds before rechecking the USN journal.
    default: "30"
  - name: NTFS_CACHE_TIME
    type: int
    description: How often to flush the NTFS cache.
    default: "30"

precondition: SELECT OS from info() where OS = "windows"

sources:
  - query: |
      SELECT * FROM watch_usn(device=Device)
      WHERE OSPath =~ PathRegex

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/system.hunt.participation.md
======
---
title: System.Hunt.Participation
hidden: true
tags: [Internal Artifact]
---

Endpoints may participate in hunts. This artifact collects which
hunt each system participated in.


<pre><code class="language-yaml">
name: System.Hunt.Participation
description: |
     Endpoints may participate in hunts. This artifact collects which
     hunt each system participated in.

# Will not be written but will be relayed between minions and server.
type: INTERNAL

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.sysinternals.sysmonlogforward.md
======
---
title: Windows.Sysinternals.SysmonLogForward
hidden: true
tags: [Client Event Artifact]
---

A client side event forwarder to forward sysmon events to the server.


<pre><code class="language-yaml">
name: Windows.Sysinternals.SysmonLogForward
description: |
  A client side event forwarder to forward sysmon events to the server.

type: CLIENT_EVENT

precondition: SELECT OS From info() where OS = 'windows'

tools:
  - name: SysmonBinary
    url: https://live.sysinternals.com/tools/sysmon64.exe
    serve_locally: true

  - name: SysmonConfig
    url: https://raw.githubusercontent.com/SwiftOnSecurity/sysmon-config/master/sysmonconfig-export.xml
    serve_locally: true

parameters:
  - name: SysmonFileLocation
    description: If set, we check this location first for sysmon installed.
    default: C:/Windows/sysmon64.exe

sources:
- query: |
    // First ensure that sysmon is actually installed.
    LET _ &lt;= SELECT * FROM Artifact.Windows.Sysinternals.SysmonInstall(
        SysmonFileLocation=SysmonFileLocation)

    // Just parse and forward events. Use ETW rather than watch_evtx()
    // because it is a little bit faster.
    SELECT System.ID AS ID,
           System.TimeStamp AS Timestamp,
           get(member='EventData') AS EventData
    FROM watch_etw(
       description='Microsoft-Windows-Sysmon/Operational',
       guid='{5770385f-c22a-43e0-bf4c-06f5698ffbd9}')

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.etw.dnsqueriesserver.md
======
---
title: Windows.ETW.DNSQueriesServer
hidden: true
tags: [Client Event Artifact]
---

Logs dns queries on DNS servers. This is handy for identifying the true source system that is initiating malicious dns requests that you observed. Note that this can be resource intensive for the CPU on busy DNS servers - from 5% to 70% CPU load of one core, but memory consumption is very low. This is still a lot less then enabling DNS debug logging.


<pre><code class="language-yaml">
name: Windows.ETW.DNSQueriesServer
type: CLIENT_EVENT

description: |
   Logs dns queries on DNS servers. This is handy for identifying the true source system that is initiating malicious dns requests that you observed. Note that this can be resource intensive for the CPU on busy DNS servers - from 5% to 70% CPU load of one core, but memory consumption is very low. This is still a lot less then enabling DNS debug logging.

author: "Jos Clephas - jos-ir"

parameters:
  - name: QueryNameRegex
    default: .
    type: regex
  - name: SourceIPRegex
    default: .
    type: regex

sources:
  - precondition:
      SELECT OS From info() where OS = 'windows'

    query: |
        SELECT System.TimeStamp as TimeStamp,
               System.ID as ID,
               EventData.BufferSize as BufferSize,
               EventData.Flags as Flags,
               EventData.InterfaceIP as InterfaceIP,
               EventData.Port as Port,
               EventData.QNAME as QNAME,
               EventData.QTYPE as QTYPE,
               EventData.RD as RD,
               EventData.Source as Source,
               EventData.TCP as TCP,
               EventData.XID as XID
        FROM watch_etw(
          description="EventLog-Microsoft-Windows-DNSServer-Analytical",
          guid="{EB79061A-A566-4698-9119-3ED2807060E7}")
        WHERE EventData AND
              QNAME =~ QueryNameRegex AND
              Source =~ SourceIPRegex

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/logscale.events.clients.md
======
---
title: LogScale.Events.Clients
hidden: true
tags: [Server Event Artifact]
---

This server side event monitoring artifact will watch a selection of client
monitoring artifacts for new events and push those to a LogScale (formerly
Humio) ingestion endpoint

NOTE: You must ensure you are collecting these artifacts from the
clients by adding them to the "Client Events" GUI.


<pre><code class="language-yaml">
name: LogScale.Events.Clients
description: |
  This server side event monitoring artifact will watch a selection of client
  monitoring artifacts for new events and push those to a LogScale (formerly
  Humio) ingestion endpoint

  NOTE: You must ensure you are collecting these artifacts from the
  clients by adding them to the "Client Events" GUI.

type: SERVER_EVENT

parameters:
  - name: ingestApiBase
    description: API Base Url for LogScale server
    type: string
    default: https://cloud.community.humio.com/api
  - name: ingestToken
    description: Ingest token for API
    type: string
  - name: tagFields
    description: Comma-separated list of field names to use as tags in the message; Can be renamed with &lt;oldname&gt;=&lt;newname&gt;.
    default:
    type: string
  - name: numThreads
    description: Number of threads to start up to post events
    type: int
    default: 1
  - name: httpTimeout
    description: Timeout (in seconds) for http connection attempts
    type: int
    default: 10
  - name: batchingTimeoutMs
    description: Timeout (in ms) to batch events prior to sending
    type: int
    default: 30000
  - name: eventBatchSize
    description: Count of events to batch prior to sending
    type: int
    default: 2000
  - name: statsInterval
    description: Interval to post statistics to log (in seconds, 0 to disable)
    type: int
    default: 600
  - name: debug
    description: Enable verbose logging
    type: bool
    default: false
  - name: Artifacts
    type: artifactset
    artifact_type: CLIENT_EVENT
    description: Client artifacts to monitor

sources:
  - query: |
      LET artifacts_to_watch = SELECT Artifact FROM Artifacts
        WHERE log(message="Uploading artifact " + Artifact + " to LogScale")

      LET events = SELECT * FROM foreach(
          row=artifacts_to_watch,
          async=TRUE,   // Required for event queries in foreach()
          query={
             SELECT *, Artifact, timestamp(epoch=now()) AS timestamp
             FROM watch_monitoring(artifact=Artifact)
          })

      SELECT * FROM logscale_upload(
          query=events,
          apibaseurl=ingestApiBase,
          ingest_token=ingestToken,
          threads=numThreads,
          tag_fields=split(string=tagFields, sep=","),
          batching_timeout_ms=batchingTimeoutMs,
          event_batch_size=eventBatchSize,
          http_timeout=httpTimeout,
          debug=debug,
          stats_interval=statsInterval)

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.eventlogs.symantec.md
======
---
title: Windows.EventLogs.Symantec
hidden: true
tags: [Client Artifact]
---

Query the Symantec Endpoint Protection Event Logs. The default artifact will
return EventId 51 and high value strings with goals bubble up some events for
triage.

Note:
EventID selection is controlled by regex to allow multiple EID selections.
If running a hunt, consider also hunting EventId 45 - Tamper Protection
Detection (this will be noisy so whitelist is required).
IgnoreRegex allows filtering out events relevant to the target environment.


<pre><code class="language-yaml">
name: Windows.EventLogs.Symantec
description: |
  Query the Symantec Endpoint Protection Event Logs. The default artifact will
  return EventId 51 and high value strings with goals bubble up some events for
  triage.

  Note:
  EventID selection is controlled by regex to allow multiple EID selections.
  If running a hunt, consider also hunting EventId 45 - Tamper Protection
  Detection (this will be noisy so whitelist is required).
  IgnoreRegex allows filtering out events relevant to the target environment.

reference:
    - https://www.nextron-systems.com/wp-content/uploads/2019/10/Antivirus_Event_Analysis_CheatSheet_1.7.2.pdf

author: Matt Green - @mgreen27

parameters:
  - name: SymantecEventLog
    default: C:\Windows\system32\winevt\logs\Symantec Endpoint Protection Client.evtx
  - name: RegexEventIds
    description: "Regex of Event IDs to hunt for. Consider EID 45 for Tamper Protection Detection"
    type: regex
    default: ^51$
  - name: TargetRegex
    description: "Regex to hunt for - default is high value SEP detections"
    default: "Infostealer|Hacktool|Mimi|SecurityRisk|WinCredEd|NetCat|Backdoor|Pwdump|SuperScan|XScan|PasswordRevealer|Trojan|Malscript|Agent|Malware|Exploit|webshell|cobalt|Mpreter|sploit|Meterpreter|RAR|7z|encrypted|tsclient|PerfLogs"
    type: regex
  - name: IgnoreRegex
    description: "Regex to ignore events with EventData strings matching."
    type: regex
  - name: DateAfter
    type: timestamp
    description: "search for events after this date. YYYY-MM-DDTmm:hh:ssZ"
  - name: DateBefore
    type: timestamp
    description: "search for events before this date. YYYY-MM-DDTmm:hh:ssZ"

sources:
    - query: |
       LET DateAfterTime &lt;= if(condition=DateAfter,
            then=timestamp(epoch=DateAfter), else=timestamp(epoch="1600-01-01"))
       LET DateBeforeTime &lt;= if(condition=DateBefore,
            then=timestamp(epoch=DateBefore), else=timestamp(epoch="2200-01-01"))
       SELECT timestamp(epoch=System.TimeCreated.SystemTime) As EventTime,
              System.EventID.Value as EventId,
              System.Computer as Computer,
              EventData.Data[0] as EventData
       FROM parse_evtx(filename=SymantecEventLog)
       WHERE
            EventTime &lt; DateBeforeTime AND
            EventTime &gt; DateAfterTime AND
            format(format="%v",args=System.EventID.Value) =~ RegexEventIds AND
            EventData =~ TargetRegex AND
            if(condition=IgnoreRegex,
                then= NOT EventData=~IgnoreRegex,
                else= True)

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/generic.detection.hashhunter.md
======
---
title: Generic.Detection.HashHunter
hidden: true
tags: [Client Artifact]
---

This artifact enables searching for hashes.

The artifact takes a glob targetting input, then generates a hash for each 
file in scope to compare to several types of hash lists provided by the user.

Note: this artifacts filters are cumulative so a hash based hit will return 
no results if the file is filtered out by other filters.  
For most performant searches leverage path, size and and date filters. By default 
the artifact leverages the 'auto' data accessor but can also be changed as desired.  


<pre><code class="language-yaml">
name: Generic.Detection.HashHunter
author: "Matt Green - @mgreen27"
description: |
    This artifact enables searching for hashes.
    
    The artifact takes a glob targetting input, then generates a hash for each 
    file in scope to compare to several types of hash lists provided by the user.
    
    Note: this artifacts filters are cumulative so a hash based hit will return 
    no results if the file is filtered out by other filters.  
    For most performant searches leverage path, size and and date filters. By default 
    the artifact leverages the 'auto' data accessor but can also be changed as desired.  

parameters:
  - name: TargetGlob
    description: Glob to target.
    default: "C:/Users/**/*"
  - name: Accessor
    description: Velociraptor accessor to use. Changing to ntfs will increase scan time.
    default: auto
  - name: DateAfter
    description: Search for binaries with timestamps after this date. YYYY-MM-DDTmm:hh:ssZ
    type: timestamp
  - name: DateBefore
    description: Search for binaries with timestamps before this date. YYYY-MM-DDTmm:hh:ssZ
    type: timestamp
  - name: SizeMax
    description: Return binaries only under this size in bytes.
    type: int64
    default: 4294967296
  - name: SizeMin
    description: Return binaries only over this size in bytes.
    type: int64
    default: 0
  - name: MD5List
    description: MD5 hash list to hunt for. New MD5 hash on each line
    default:
  - name: SHA1List
    description: SHA1 hash list to hunt for. New SHA1 hash on each line
    default:
  - name: SHA256List
    description: SHA256 hash list to hunt for. New SHA256 hash on each line
    default:

sources:
  - query: |
      -- setup hash lists
      LET MD5List &lt;= if(condition= MD5List,
                        then= split(sep='\\s+',string=MD5List), else=Null)
      LET SHA1List &lt;= if(condition= SHA1List,
                        then= split(sep='\\s+',string=SHA1List), else=Null)
      LET SHA256List &lt;= if(condition= SHA256List,
                        then= split(sep='\\s+',string=SHA256List), else=Null)
      
      -- set hash selector for optimised hash calculation
      LET HashSelector &lt;= SELECT * FROM chain(
          a={ SELECT "MD5" AS Hash FROM scope() WHERE MD5List },
          b={ SELECT "SHA1" AS Hash FROM scope() WHERE SHA1List },
          c={ SELECT "SHA256" AS Hash FROM scope() WHERE SHA256List })
      
      -- firstly find files in scope with performance
      LET find_files = SELECT * FROM if(condition=DateBefore AND DateAfter,
            then={
                SELECT OSPath, Name, Size,Mtime,Atime,Ctime,Btime
                FROM glob(globs=TargetGlob,accessor=Accessor,nosymlink='True')
                WHERE NOT IsDir AND NOT IsLink
                    AND Size &gt; SizeMin AND Size &lt; SizeMax
                    AND ( Mtime &lt; DateBefore OR Ctime &lt; DateBefore OR Btime &lt; DateBefore )
                    AND ( Mtime &gt; DateAfter OR Ctime &gt; DateAfter OR Btime &gt; DateAfter )
            }, 
            else={ SELECT * FROM  if(condition=DateBefore,
                then={
                    SELECT OSPath, Name, Size,Mtime,Atime,Ctime,Btime
                    FROM glob(globs=OSPath,accessor=Accessor)
                    WHERE NOT IsDir AND NOT IsLink
                        AND Size &gt; SizeMin AND Size &lt; SizeMax
                        AND ( Mtime &lt; DateBefore OR Ctime &lt; DateBefore OR Btime &lt; DateBefore )
                },
                else={ SELECT * FROM  if(condition=DateAfter,
                then={
                    SELECT OSPath, Name, Size,Mtime,Atime,Ctime,Btime
                    FROM glob(globs=TargetGlob,accessor=Accessor)
                    WHERE NOT IsDir AND NOT IsLink
                        AND Size &gt; SizeMin AND Size &lt; SizeMax
                        AND ( Mtime &gt; DateAfter OR Ctime &gt; DateAfter OR Btime &gt; DateAfter )
                },
                else={
                    SELECT OSPath, Name, Size,Mtime,Atime,Ctime,Btime
                    FROM glob(globs=TargetGlob,accessor=Accessor)
                    WHERE NOT IsDir AND NOT IsLink
                        AND Size &gt; SizeMin AND Size &lt; SizeMax
                })})})
      
      
      -- lookup hash and run finl filters
      SELECT OSPath,Name,Size,
            dict(Mtime=Mtime,Atime=Atime,Ctime=Ctime,Btime=Btime) as Timestamps,
            hash(path=OSPath,hashselect=HashSelector.Hash) as Hash
        FROM if(condition= HashSelector.Hash, then= find_files)
        WHERE 
            ( Hash.MD5 in MD5List OR Hash.SHA1 in SHA1List OR Hash.SHA256 in SHA256List )
</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.attack.parentprocess.md
======
---
title: Windows.Attack.ParentProcess
hidden: true
tags: [Client Artifact]
---

Maps the Mitre Att&ck framework process executions into artifacts.

NOTE: This artifact uses the process tracker. If you also enable the
Windows.Events.TrackProcesses or Windows.Events.TrackProcessesBasic
artifacts, this will be able to retrieve information about exited
processes.


<pre><code class="language-yaml">
name: Windows.Attack.ParentProcess
description: |
  Maps the Mitre Att&amp;ck framework process executions into artifacts.

  NOTE: This artifact uses the process tracker. If you also enable the
  Windows.Events.TrackProcesses or Windows.Events.TrackProcessesBasic
  artifacts, this will be able to retrieve information about exited
  processes.

reference:
  - https://www.sans.org/security-resources/posters/hunt-evil/165/download
  - https://github.com/teoseller/osquery-attck/blob/master/windows-incorrect_parent_process.conf

precondition: SELECT OS From info() where OS = 'windows'

parameters:
  - name: lookupTable
    type: csv
    description: |
      A table mapping a process name to its expected parents. Both
      columns are regular expressions. The ProcessName must appear
      only once - you can specify multiple possible parents using
      regular expressions patterns.

    default: |
       ProcessName,ParentRegex
       smss.exe,System
       runtimebroker.exe,svchost.exe
       taskhostw.exe,svchost.exe
       services.exe,wininit.exe
       lsass.exe,wininit.exe
       svchost.exe,services.exe
       cmd.exe,explorer.exe
       powershell.exe,explorer.exe
       iexplore.exe,explorer.exe
       firefox.exe,(firefox|explorer).exe
       chrome.exe,(chrome|explorer).exe

sources:
     - query: |
         SELECT * FROM foreach(row=lookupTable,
         query={
           SELECT Name AS ActualProcessName,
                  process_tracker_get(id=Ppid).Data.Name AS ActualParentName,
                  Pid, Ppid,
                  CommandLine,
                  StartTime,
                  EndTime,
                  Exe,
                  ParentRegex as ExpectedParentName,
                  Username,
                  join(array=process_tracker_callchain(id=Pid).Data.Name,
                       sep=" -&gt; ") AS CallChain
           FROM process_tracker_pslist()
           WHERE ActualProcessName =~ ProcessName
             AND ActualParentName
             AND NOT ActualParentName =~ ParentRegex
         })

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.eventlogs.alternatelogon.md
======
---
title: Windows.EventLogs.AlternateLogon
hidden: true
tags: [Client Artifact]
---

Logon specifying alternate credentials - if NLA enabled on
destination Current logged-on User Name Alternate User Name
Destination Host Name/IP Process Name


<pre><code class="language-yaml">
name: Windows.EventLogs.AlternateLogon
description: |
  Logon specifying alternate credentials - if NLA enabled on
  destination Current logged-on User Name Alternate User Name
  Destination Host Name/IP Process Name

reference:
  - https://digital-forensics.sans.org/media/SANS_Poster_2018_Hunt_Evil_FINAL.pdf

precondition: SELECT OS From info() where OS = 'windows'

parameters:
  - name: securityLogFile
    default: C:/Windows/System32/Winevt/Logs/Security.evtx

sources:
  - query: |
      SELECT
        timestamp(epoch=System.TimeCreated.SystemTime) AS EventTime,
        EventData.IpAddress AS IpAddress,
        EventData.IpPort AS Port,
        EventData.ProcessName AS ProcessName,
        EventData.SubjectUserSid AS SubjectUserSid,
        EventData.SubjectUserName AS SubjectUserName,
        EventData.TargetUserName AS TargetUserName,
        EventData.TargetServerName AS TargetServerName,
        System.TimeCreated.SystemTime AS LogonTime
      FROM parse_evtx(filename=securityLogFile)
      WHERE System.EventID.Value = 4648
        AND EventData

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.system.services.md
======
---
title: Windows.System.Services
hidden: true
tags: [Client Artifact]
---

List Service details.


<pre><code class="language-yaml">
name: Windows.System.Services
description: |
  List Service details.

parameters:
  - name: servicesKeyGlob
    default: HKEY_LOCAL_MACHINE\SYSTEM\CurrentControlSet\Services\
  - name: Calculate_hashes
    default: N
    type: bool
  - name: CertificateInfo
    default: N
    type: bool
  - name: NameRegex
    default: .
    type: regex
  - name: DisplayNameRegex
    default: .
    type: regex
  - name: PathNameRegex
    default: .
    type: regex
  - name: ServiceDllRegex
    default: .
    type: regex
  - name: FailureCommandRegex
    default: .
    type: regex
  - name: DISABLE_DANGEROUS_API_CALLS
    type: bool
    description: |
      Enable this to disable potentially flakey APIs which may cause
      crashes.

export: |
    LET Profile = '''
        [
        ["ServiceFailureActions", 0, [
          ["ResetPeriod", 0, "uint32"],
          ["__ActionsCount", 12, "uint32"],
          ["__lpsaActionsHeader", 16, "uint32"],
          ["FailureAction", "x=&gt;x.__lpsaActionsHeader", "Array", {
              "type": "ServiceAction",
              "count": "x=&gt;x.__ActionsCount"
          }]
        ]],
        ["ServiceAction", 8, [
            ["Type", 0, "Enumeration", {
                "type": "uint32",
                "map": {
                    "SC_ACTION_NONE": 0,
                    "SC_ACTION_RESTART": 1,
                    "SC_ACTION_REBOOT": 2,
                    "SC_ACTION_RUN_COMMAND": 3,
                }}],
            ["__DelayMsec", 4, "uint32"],
            ["Delay", 4,"Value",{ "value": "x=&gt;x.__DelayMsec/1000" }],
        ]],
      ]
      '''

sources:
  - precondition:
      SELECT OS From info() where OS = 'windows'

    query: |
      LET service &lt;= SELECT State, Name, DisplayName, Status,
            ProcessId as Pid, ExitCode, StartMode,
            PathName, ServiceType, StartName as UserAccount,
            {
                SELECT Mtime as Created
                FROM stat(filename=servicesKeyGlob + Name, accessor='registry')
            } AS Created,
            {
                SELECT expand(path=ServiceDll) AS ServiceDll
                FROM read_reg_key(globs=servicesKeyGlob + Name + "\\Parameters")
                LIMIT 1
            } AS ServiceDll,
            {
                SELECT FailureCommand FROM read_reg_key(globs=servicesKeyGlob + Name)
                LIMIT 1
            } AS FailureCommand,
            {
                SELECT if(condition=FailureActions,
                   then=parse_binary(accessor='data',
                                     filename= FailureActions || " ",
                                     profile=Profile,
                                     struct='ServiceFailureActions')) as FailureActions
                FROM read_reg_key(globs=servicesKeyGlob + Name)
            } AS FailureActions,
            expand(path=parse_string_with_regex(regex=
                ['^"(?P&lt;AbsoluteExePath&gt;[^"]+)','(?P&lt;AbsoluteExePath&gt;^[^ "]+)'],
                string=PathName).AbsoluteExePath) as AbsoluteExePath
        FROM wmi(query="SELECT * From Win32_service", namespace="root/CIMV2")
        WHERE Name =~ NameRegex
            AND DisplayName =~ DisplayNameRegex
            AND PathName =~ PathNameRegex
            AND if(condition=ServiceDll, then=ServiceDll =~ ServiceDllRegex, else=TRUE)
            AND if(condition=FailureCommand, then=FailureCommand =~ FailureCommandRegex, else=TRUE)

      SELECT *,
        if(condition=Calculate_hashes,
            then=hash(path=AbsoluteExePath, accessor="auto")) AS HashServiceExe,
                 if(condition=CertificateInfo,
                    then=authenticode(filename=AbsoluteExePath || " ")) AS CertinfoServiceExe,
                 if(condition=Calculate_hashes,
                    then=hash(path=ServiceDll || " ",accessor="auto")) AS HashServiceDll,
                 if(condition=CertificateInfo,
                    then=authenticode(filename=ServiceDll || " ")) AS CertinfoServiceDll
      FROM service

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.carving.cobaltstrike.md
======
---
title: Windows.Carving.CobaltStrike
hidden: true
tags: [Client Artifact]
---

This artifact extracts cobalt strike configuration from a byte stream, process
or file on disk such as a process dump. Best used as a triage step against a
detection of a cobalt strike beacon via a yara process scan.

The User can define bytes, file glob, process name or pid regex as a target. The
content will search for a configuration pattern, extract a defined byte size,
xor with discovered key, then attempt configuration extraction.

- Cobalt Strike beacon configuration is typically XORed with 0x69 or 0x2e
(depending on version) but trivial to change.
- Configuration is built in a typical index / type / length / value structure
with either big endian values or zero terminated strings.
- If no beacon is found, parser will fallback to CobaltStrike Shellcode analysis.

This content simply carves the configuration and does not unpack files on
disk. That means pointing this artifact as a packed or obfuscated file may not
obtain the expected results.

Unpacking later version.


<pre><code class="language-yaml">
name: Windows.Carving.CobaltStrike
author: Matt Green - @mgreen27
description: |
  This artifact extracts cobalt strike configuration from a byte stream, process
  or file on disk such as a process dump. Best used as a triage step against a
  detection of a cobalt strike beacon via a yara process scan.

  The User can define bytes, file glob, process name or pid regex as a target. The
  content will search for a configuration pattern, extract a defined byte size,
  xor with discovered key, then attempt configuration extraction.

  - Cobalt Strike beacon configuration is typically XORed with 0x69 or 0x2e
  (depending on version) but trivial to change.
  - Configuration is built in a typical index / type / length / value structure
  with either big endian values or zero terminated strings.
  - If no beacon is found, parser will fallback to CobaltStrike Shellcode analysis.

  This content simply carves the configuration and does not unpack files on
  disk. That means pointing this artifact as a packed or obfuscated file may not
  obtain the expected results.

  Unpacking later version.

reference:
  - https://attack.mitre.org/software/S0154/
  - https://blog.didierstevens.com/2020/11/07/1768-k/

parameters:
  - name: TargetBytes
    default:
  - name: TargetFileGlob
    default:
  - name: PidRegex
    default: .
    type: regex
  - name: ProcessRegex
    default: .
    type: regex
  - name: ExtractBytes
    type: int
    default: 10000
  - name: BruteXor
    type: bool
    description: Select to attempt brute forcing Xor byte in config. Default is 0x2e or 0x69.
  - name: IncludeDecodedData
    type: bool
    description: Select to include decoded data in output.
  - name: FindConfigTemplate
    type: hidden
    default: |
        rule cobalt_strike_beacon {
            strings:
                $REPLACEME

            condition:
                any of them
        }
  - name: FindShellcode
    type: hidden
    default: |
        rule cobalt_strike_shellcode {
            strings:
                $header = { FC }
                $s1 = "hwini"
                $s2 = "hws2_"
                $s3 = "wininet"

            condition:
                ( $header at 0 and filesize &lt; 4096 )
                or any of ($s*) // we enact offset limits in VQL ( 0..4096 )
        }
  - name: FindSleepFunction
    type: hidden
    default: |
        rule cobalt_strike_sleepfunction {
            strings:
                $x64 = { 4C 8B 53 08 45 8B 0A 45 8B 5A 04 4D 8D 52 08 45 85 C9 75 05 45 85 DB 74 33 45 3B CB 73 E6 49 8B F9 4C 8B 03 }
                $x86 = { 8B 46 04 8B 08 8B 50 04 83 C0 08 89 55 08 89 45 0C 85 C9 75 04 85 D2 74 23 3B CA 73 E6 8B 06 8D 3C 08 33 D2 }

            condition:
                any of them
        }

export: |
  LET PROFILE = '''[
    [CobaltConfig, 0, [
        # 0x0001:BeaconType, 0x0001:Type, 0x0002:Length
        ["BeaconType", 6, "Enumeration", {
            "type": "uint16b",
            "choices": {
                 "0": "windows-beacon_http-reverse_http",
                 "1": "windows-beacon_dns-reverse_http",
                 "2": "windows-beacon_smb-bind_pipe",
                 "8": "windows-beacon_https-reverse_https",
                 "16": "windows-beacon_tcp-bind_tcp"
            }
        }],

        # 0x0002:Port, 0x0001:Type, 0x0002:Length
        ["__port_prefix", 0, "String",{"term_hex": "000200010002", length: 10000, max_length: 10000}],
        ["Port", "x=&gt;len(list=x.__port_prefix) + 6", "uint16b"],

        # 0x0003:Sleeptime,0x0002:Type, 0x0004:Length
        ["__sleeptime_prefix", 0, "String", {"term_hex": "000300020004", length: 10000, max_length: 10000}],
        ["Sleeptime", "x=&gt;len(list=x.__sleeptime_prefix) + 6", "uint32b"],

        # 0x0004:Maxgetsize, 0x0002:Type, 0x0004:Length
        ["__maxgetsize_prefix", 0, "String",{"term_hex": "000400020004", length: 10000, max_length: 10000}],
        ["Maxgetsize", "x=&gt;len(list=x.__maxgetsize_prefix) + 6", "uint32b"],

        # 0x0005:Jitter, 0x0001:Type, 0x0002:Length
        ["__jitter_prefix", 0, "String",{"term_hex": "000500010002", length: 10000, max_length: 10000}],
        ["Jitter", "x=&gt;len(list=x.__jitter_prefix) + 6", "uint16b"],

        # 0x0006:MaxDns, 0x0001:Type, 0x0002:Length
        ["__maxdns_prefix", 0, "String",{"term_hex": "000600010002", length: 10000, max_length: 10000}],
        ["MaxDns", "x=&gt;len(list=x.__maxdns_prefix) + 6", "uint16b"],

        # 0x0007:Publickey,0x0003:Type,
        ["__publickey_prefix", 0, "String",{"term_hex": "000700030100", length: 10000, max_length: 10000}],
        ["__publickey_raw", "x=&gt;len(list=x.__publickey_prefix) + 6", "String",{"term_hex":"00000008"}],
        ["PublicKey", "x=&gt;len(list=x.__publickey_prefix) + 6", "Value",{"value":"x=&gt;format(format='% x',args=x.__publickey_raw)"}],

        # 0x0008:server/get-uri,0x0003:Type,
        ["__c2server_prefix", 0, "String",{"term_hex": "00080003", length: 10000, max_length: 10000}],
        ["C2Server", "x=&gt;len(list=x.__c2server_prefix) + 6", "String"],

        # 0x0009:useragent,0x0003:Type,
        ["__useragent_prefix", 0, "String",{"term_hex": "00090003", length: 10000, max_length: 10000}],
        ["UserAgent", "x=&gt;len(list=x.__useragent_prefix) + 6", "String"],

        # 0x000a:PostUri,0x0003:Type,
        ["__PostUri_prefix", 0, "String", {"term_hex": "000a0003", length: 10000, max_length: 10000}],
        ["PostURI", "x=&gt;len(list=x.__PostUri_prefix) + 6", "String"],

        # 0x000b:Malleable_C2_Instructions,0x0003:Type, adding length check as not sure if we can rely on termination
        ["__Malleable_C2_Instructions_prefix", 0, "String",{"term_hex": "000b0003", length: 10000, max_length: 10000}],
        ["__Malleable_C2_Instructions_length","x=&gt;len(list=x.__Malleable_C2_Instructions_prefix) + 4","uint16b"],
        ["__Malleable_C2_Instructions", "x=&gt;len(list=x.__Malleable_C2_Instructions_prefix) + 6", "String",{"term":"***NOTERM***", "length": "x=&gt; x.__Malleable_C2_Instructions_length"}],
        ["MalleableC2Instructions",0,"Value",{ "value": "x=&gt;format(format='%s', args=[regex_replace(source=x.__Malleable_C2_Instructions, re='[^ -~\\r\\n]', replace='')])" }],
        #["Malleable_C2_Instructions",0,"Value",{ "value": "x=&gt;'base64:' + base64encode(string=x.__Malleable_C2_Instructions)" }], #uncomment to return base64 encoded raw Malleable_C2_Instructions

        # 0x000c:HttpGetHeader,0x0003:Type, adding length check as we can not rely on termination
        ["__HttpGetHeader_prefix", 0, "String",{"term_hex": "000c0003", length: 10000, max_length: 10000}],
        ["__HttpGetHeader_length","x=&gt;len(list=x.__HttpGetHeader_prefix) + 4","uint16b"],
        ["__HttpGetHeader","x=&gt;len(list=x.__HttpGetHeader_prefix) + 6","String",{"term":"***NOTERM***", "length": "x=&gt; x.__HttpGetHeader_length"}],
        ["HttpGetHeader",0,"Value",{ "value": "x=&gt;format(format='%s', args=[regex_replace(source=x.__HttpGetHeader, re='[^ -~\\r\\n]', replace='')])" }],
        #["HttpGetHeader",0,"Value",{ "value": "x=&gt;'base64:' + base64encode(string=x.__HttpGetHeader)" }], #uncomment to return base64 encoded raw HttpGetHeader

        # 0x000d:HttpPostHeader,0x0003:Type, adding length check as we can not rely on termination
        ["__http_post_header_prefix", 0, "String",{"term_hex": "000d0003", length: 10000, max_length: 10000}],
        ["__HttpPostHeader_length","x=&gt;len(list=x.__http_post_header_prefix) + 4","uint16b"],
        ["__HttpPostHeader","x=&gt;len(list=x.__http_post_header_prefix) + 6","String",{"term":"***NOTERM***", "length": "x=&gt; x.__HttpPostHeader_length"}],
        ["HttpPostHeader",0,"Value",{ "value": "x=&gt;format(format='%s', args=[regex_replace(source=x.__HttpPostHeader, re='[^ -~\\r\\n]', replace='')])" }],
        #["HttpPostHeader",0,"Value",{ "value": "x=&gt;'base64:' + base64encode(string=x.__HttpPostHeader)" }], #uncomment to return base64 encoded raw HttpPostHeader

        # 0x000e:SpawnTo,0x0003:Type # Adding length check as we can not rely on termination
        ["__SpawnTo_header_prefix", 0, "String",{"term_hex": "000e0003", length: 10000, max_length: 10000}],
        ["__SpawnTo_header_length","x=&gt;len(list=x.__SpawnTo_header_prefix) + 4","uint16b"],
        ["__SpawnTo", "x=&gt;len(list=x.__SpawnTo_header_prefix) + 6", "String",{"term":"***NOTERM***", "length": "x=&gt; x.__SpawnTo_header_length"}],
        ["SpawnTo",0,"Value",{ "value": "x=&gt;format(format='%s', args=[regex_replace(source=x.__SpawnTo, re='[^ -~\\r\\n]', replace='')])" }],
        #["SpawnTo",0,"Value",{ "value": "x=&gt;'base64:' + base64encode(string=x.__SpawnTo)" }], #uncomment to return base64 encoded raw SpawnTo

        # 0x000f:PipeName,0x0003:Type
        ["__pipename_prefix", 0, "String",{"term_hex": "000f0003", length: 10000, max_length: 10000}],
        ["Pipename", "x=&gt;len(list=x.__pipename_prefix) + 6", "String",{"term_hex":"0000"}],

        # 0x0010:KillDateYear, 0x0001:Type, 0x0002:Length
        ["__KillDateYear_prefix", 0, "String",{"term_hex": "001000010002", length: 10000, max_length: 10000}],
        ["KillDateYear", "x=&gt;len(list=x.__KillDateYear_prefix) + 6", "uint16b"],

        # 0x0011:KillDateMonth, 0x0001:Type, 0x0002:Length
        ["__KillDateMonth_prefix", 0, "String",{"term_hex": "001200010002", length: 10000, max_length: 10000}],
        ["KillDateMonth", "x=&gt;len(list=x.__KillDateMonth_prefix) + 6", "uint16b"],

        # 0x0012:KillDateDay, 0x0001:Type, 0x0002:Length
        ["__KillDateDay_prefix", 0, "String",{"term_hex": "001200010002", length: 10000, max_length: 10000}],
        ["KillDateDay", "x=&gt;len(list=x.__KillDateDay_prefix) + 6", "uint16b"],

        # 0x0013:DNSIdle, 0x0002:Type, 0x0004:Length
        ["__DNSIdle_prefix", 0, "String",{"term_hex": "001300020004", length: 10000, max_length: 10000}],
        ["__DNSIdle1", "x=&gt;len(list=x.__DNSIdle_prefix) + 6", "uint8"],
        ["__DNSIdle2", "x=&gt;len(list=x.__DNSIdle_prefix) + 7", "uint8"],
        ["__DNSIdle3", "x=&gt;len(list=x.__DNSIdle_prefix) + 8", "uint8"],
        ["__DNSIdle4", "x=&gt;len(list=x.__DNSIdle_prefix) + 9", "uint8"],
        ["DNSIdle", 0, "Value", {
            "value": "x=&gt; str(str=x.__DNSIdle1) + '.' + str(str=x.__DNSIdle2) + '.' + str(str=x.__DNSIdle3) + '.' + str(str=x.__DNSIdle4)"
        }],

        # 0x0014:DNSSleep', 0x0002:Type, 0x0004:Length
        ["__DNSSleep_prefix", 0, "String",{"term_hex": "001400020004", length: 10000, max_length: 10000}],
        ["DNSSleep", "x=&gt;len(list=x.__DNSSleep_prefix) + 6", "uint32b"],

        # 0x0015:SSH_1, to complete - didnt find any examples assuming zero terminated
        ["__SSH_1_prefix", 0, "String",{"term_hex": "00150003", length: 10000, max_length: 10000}],
        ["SSH_1", "x=&gt;len(list=x.__SSH_1_prefix) + 6", "String"],

        # 0x0016:SSH_2, to complete - didnt find any examples assuming zero terminated
        ["__SSH_2_prefix", 0, "String",{"term_hex": "00160003", length: 10000, max_length: 10000}],
        ["SSH_2", "x=&gt;len(list=x.__SSH_2_prefix) + 6", "String"],

        # 0x0017:SSH_3, to complete - didnt find any examples assuming zero terminated
        ["__SSH_3_prefix", 0, "String",{"term_hex": "00170003", length: 10000, max_length: 10000}],
        ["SSH_3", "x=&gt;len(list=x.__SSH_3_prefix) + 6", "String"],

        # 0x0018:SSH_4, to complete - didnt find any examples assuming zero terminated
        ["__SSH_4_prefix", 0, "String",{"term_hex": "00180003", length: 10000, max_length: 10000}],
        ["SSH_4", "x=&gt;len(list=x.__SSH_4_prefix) + 6", "String"],

        # 0x0019:SSH_5, to complete - didnt find any examples assuming zero terminated
        ["__SSH_5_prefix", 0, "String",{"term_hex": "00190003", length: 10000, max_length: 10000}],
        ["SSH_5", "x=&gt;len(list=x.__SSH_5_prefix) + 6", "String"],

        # 0x001a:GetVerb,0x0003:Type
        ["__GetVerb_prefix", 0, "String",{"term_hex": "001a0003"}],
        ["GetVerb", "x=&gt;len(list=x.__GetVerb_prefix) + 6", "String",{"term_hex":"0000"}],

        # 0x001b: PostVerb, 0x0003:Type
        ["__PostVerb_prefix", 0, "String",{"term_hex": "001b0003"}],
        ["PostVerb", "x=&gt;len(list=x.__PostVerb_prefix) + 6", "String",{"term_hex":"0000"}],

        # 0x001c:HttpPostChunk,0x0002:Type, 0x0004:Length
        ["__HttpPostChunk_prefix", 0, "String", {"term_hex": "001c00020004"}],
        ["HttpPostChunk", "x=&gt;len(list=x.__HttpPostChunk_prefix) + 6", "uint32b"],

        # 0x001d:spawnto_x86,0x0003:Type
        ["__spawnx86_prefix", 0, "String",{"term_hex": "001d0003", length: 10000, max_length: 10000}],
        ["SpawnTox86", "x=&gt;len(list=x.__spawnx86_prefix) + 6", "String",{"term_hex":"0000"}],

        # 0x001e:spawn_to_x64,0x0003:Type
        ["__spawnx64_prefix", 0, "String",{"term_hex": "001e0003", length: 10000, max_length: 10000}],
        ["SpawnTox64", "x=&gt;len(list=x.__spawnx64_prefix) + 6", "String",{"term_hex":"0000"}],

        # 0x001f:CryptoScheme, 0x0001:Type, 0x0002:Length
        ["__CryptoScheme_prefix", 0, "String",{"term_hex": "001f00010002", length: 10000, max_length: 10000}],
        ["CryptoScheme", "x=&gt;len(list=x.__CryptoScheme_prefix) + 6", "uint16b"],

        # 0x0020:Proxy, 0x0003:Type
        ["__Proxy_prefix", 0, "String",{"term_hex": "000e0003", length: 10000, max_length: 10000}],
        #["__Proxy_length","x=&gt;len(list=x.__Proxy_prefix) + 4","uint16b"],
        ["Proxy", "x=&gt;len(list=x.__Proxy_prefix) + 6", "String"],

        # 0x0021:ProxyUsername, 0x0003:Type
        ["__ProxyUsername_prefix", 0, "String",{"term_hex": "000e0003", length: 10000, max_length: 10000}],
        ["__ProxyUsername_length","x=&gt;len(list=x.__ProxyUsername_prefix) + 4","uint16b"],
        ["ProxyUsername", "x=&gt;len(list=x.__ProxyUsername_prefix) + 6", "String"],

        # 0x0022:ProxyPassword, 0x0003:Type
        ["__ProxyPassword_prefix", 0, "String",{"term_hex": "000e0003", length: 10000, max_length: 10000}],
        ["__ProxyPassword_length","x=&gt;len(list=x.__ProxyPassword_prefix) + 4","uint16b"],
        ["ProxyPassword", "x=&gt;len(list=x.__ProxyPassword_prefix) + 6", "String"],

        # 0x0023:ProxyType, 0x0001:Type, 0x0002:Length
        ["__ProxyType", 0, "String",{"term_hex": "002300010002", length: 10000, max_length: 10000}],
        ["ProxyType", "x=&gt;len(list=x.__ProxyType) + 6", "Enumeration", {
            "type": "uint16b",
            "choices": {
                 "1": "No proxy",
                 "2": "IE settings",
                 "4": "Hardcoded proxy"}
        }],

        # 0x0024:Deprecated, 0x0001:Type, 0x0002:Length
        ["__Deprecated_prefix", 0, "String",{"term_hex": "002400010002", length: 10000, max_length: 10000}],
        ["Deprecated", "x=&gt;len(list=x.__Deprecated_prefix) + 6", "uint16b"],

        # 0x0025:LicenseId,0x0002:Type, 0x0004:Length
        ["__LicenseId_prefix", 0, "String", {"term_hex": "002500020004", length: 10000, max_length: 10000}],
        ["LicenseId", "x=&gt;len(list=x.__LicenseId_prefix) + 6", "uint32b"],

        # 0x0026:bStageCleanup, 0x0001:Type, 0x0002:Length
        ["__bStageCleanup_prefix", 0, "String",{"term_hex": "002600010002", length: 10000, max_length: 10000}],
        ["bStageCleanup", "x=&gt;len(list=x.__bStageCleanup_prefix) + 6", "uint16b"],

        # 0x0027:bCFGCaution, 0x0001:Type, 0x0002:Length
        ["__bCFGCaution_prefix", 0, "String",{"term_hex": "002700010002", length: 10000, max_length: 10000}],
        ["bCFGCaution", "x=&gt;len(list=x.__bCFGCaution_prefix) + 6", "uint16b"],

        # 0x0028:KillDate,0x0002:Type, 0x0004:Length
        ["__KillDate_prefix", 0, "String", {"term_hex": "002800020004", length: 10000, max_length: 10000}],
        ["KillDate", "x=&gt;len(list=x.__KillDate_prefix) + 6", "uint32b"],

        # 0x0029:TextSectionEnd,0x0002:Type, 0x0004:Length
        ["__TextSectionEnd_prefix", 0, "String", {"term_hex": "002900020004", length: 10000, max_length: 10000}],
        ["TextSectionEnd", "x=&gt;len(list=x.__TextSectionEnd_prefix) + 6", "uint32b"],

        # 0x002a:ObfuscateSectionsInfo,0x0003:Type # Adding length check as we can not rely on termination
        ["__ObfuscateSectionsInfo_prefix", 0, "String",{"term_hex": "002a0003", length: 10000, max_length: 10000}],
        ["__ObfuscateSectionsInfo_length","x=&gt;len(list=x.__ObfuscateSectionsInfo_prefix) + 4","uint16b"],
        ["__ObfuscateSectionsInfo", "x=&gt;len(list=x.__ObfuscateSectionsInfo_prefix) + 6", "String",{"term":"***NOTERM***", "length": "x=&gt; x.__ObfuscateSectionsInfo_length"}],
        ["ObfuscateSectionsInfo",0,"Value",{ "value": "x=&gt;format(format='%s', args=[regex_replace(source=x.__ObfuscateSectionsInfo, re='[^ -~\\r\\n]', replace='')])" }],
        #["ObfuscateSectionsInfo",0,"Value",{ "value": "x=&gt;'base64:' + base64encode(string=x.__ObfuscateSectionsInfo)" }], #uncomment to return base64 encoded raw ObfuscateSectionsInfo

        #0x002b:ProcessInjectStartRWX, 0x0001:Type, 0x0002:Length
        ["__ProcessInjectStartRWX", 0, "String",{"term_hex": "002b00010002", length: 10000, max_length: 10000}],
        ["ProcessInjectStartRWX", "x=&gt;len(list=x.__ProcessInjectStartRWX) + 6", "Enumeration", {
            "type": "uint16b",
            "choices": {
                 "0x1": "PAGE_NOACCESS",
                 "0x2": "PAGE_READONLY",
                 "0x4": "PAGE_READWRITE",
                 "0x8": "PAGE_WRITECOPY",
                "0x10": "PAGE_EXECUTE",
                "0x20": "PAGE_EXECUTE_READ",
                "0x40": "PAGE_EXECUTE_READWRITE",
                "0x80": "PAGE_EXECUTE_WRITECOPY"}
        }],

        #0x002c:ProcessInjectUseRWX, 0x0001:Type, 0x0002:Length
        ["__ProcessInjectUseRWX", 0, "String",{"term_hex": "002c00010002", length: 10000, max_length: 10000}],
        ["ProcessInjectUseRWX", "x=&gt;len(list=x.__ProcessInjectUseRWX) + 6", "Enumeration", {
            "type": "uint16b",
            "choices": {
                 "0x1": "PAGE_NOACCESS",
                 "0x2": "PAGE_READONLY",
                 "0x4": "PAGE_READWRITE",
                 "0x8": "PAGE_WRITECOPY",
                "0x10": "PAGE_EXECUTE",
                "0x20": "PAGE_EXECUTE_READ",
                "0x40": "PAGE_EXECUTE_READWRITE",
                "0x80": "PAGE_EXECUTE_WRITECOPY"}
        }],

        # 0x002d:ProcessInjectMinAlloc,0x0002:Type, 0x0004:Length
        ["__ProcessInjectMinAlloc_prefix", 0, "String", {"term_hex": "002d00020004", length: 10000, max_length: 10000}],
        ["ProcessInjectMinAlloc", "x=&gt;len(list=x.__ProcessInjectMinAlloc_prefix) + 6", "uint32b"],

        # 0x002e:ProcessInjectTransformx86, 0x0003:Type, # Adding length check as we can not rely on termination
        ["__ProcessInjectTransformx86_prefix", 0, "String",{"term_hex": "002e0003", length: 10000, max_length: 10000}],
        ["__ProcessInjectTransformx86_length","x=&gt;len(list=x.__ProcessInjectTransformx86_prefix) + 4","uint16b"],
        ["__ProcessInjectTransformx86", "x=&gt;len(list=x.__ProcessInjectTransformx86_prefix) + 6", "String",{"term":"***NOTERM***", "length": "x=&gt; x.__ProcessInjectTransformx86_length"}],
        ["ProcessInjectTransformx86",0,"Value",{ "value": "x=&gt;format(format='%s', args=[regex_replace(source=x.__ProcessInjectTransformx86, re='[^ -~\\r\\n]', replace='')])" }],
        #["ProcessInjectTransformx86",0,"Value",{ "value": "x=&gt;'base64:' + base64encode(string=x.__ProcessInjectTransformx86)" }],#uncomment to return base64 encoded raw ProcessInjectTransformx86


        # 0x002f:ProcessInjectTransformx64, 0x0003:Type, # Adding length check as we can not rely on termination
        ["__ProcessInjectTransformx64_prefix", 0, "String",{"term_hex": "002f0003", length: 10000, max_length: 10000}],
        ["__ProcessInjectTransformx64_length","x=&gt;len(list=x.__ProcessInjectTransformx64_prefix) + 4","uint16b"],
        ["__ProcessInjectTransformx64", "x=&gt;len(list=x.__ProcessInjectTransformx64_prefix) + 6", "String",{"term":"***NOTERM***", "length": "x=&gt; x.__ProcessInjectTransformx64_length"}],
        ["ProcessInjectTransformx64",0,"Value",{ "value": "x=&gt;format(format='%s', args=[regex_replace(source=x.__ProcessInjectTransformx64, re='[^ -~\\r\\n]', replace='')])" }],
        #["ProcessInjectTransformx64",0,"Value",{ "value": "x=&gt;'base64:' + base64encode(string=x.__ProcessInjectTransformx64)" }],#uncomment to return base64 encoded raw ProcessInjectTransformx64

        # 0x0032:UsesCookies, 0x0001:Type, 0x0002:Length
        ["__UsesCookies_prefix", 0, "String",{"term_hex": "003200010002", length: 10000, max_length: 10000}],
        ["UsesCookies", "x=&gt;len(list=x.__UsesCookies_prefix) + 6", "uint16b"],

        # 0x0033:ProcessInjectExecute, 0x0003:Type # Adding length check as we can not rely on termination
        ["__ProcessInjectExecute_prefix", 0, "String",{"term_hex": "00330003", length: 10000, max_length: 10000}],
        ["__ProcessInjectExecute_length","x=&gt;len(list=x.__ProcessInjectExecute_prefix) + 4","uint16b"],
        ["__ProcessInjectExecute", "x=&gt;len(list=x.__ProcessInjectExecute_prefix) + 6", "String",{"term":"***NOTERM***", "length": "x=&gt; x.__ProcessInjectExecute_length"}],
        ["ProcessInjectExecute",0,"Value",{ "value": "x=&gt;format(format='%s', args=[regex_replace(source=x.__ProcessInjectExecute, re='[^ -~\\r\\n]', replace='')])" }],
        #["ProcessInjectExecute",0,"Value",{ "value": "x=&gt;'base64:' + base64encode(string=x.__ProcessInjectExecute)" }], #uncomment to return base64 encoded raw ProcessInjectExecute

        # 0x0034:ProcessInjectAllocationMethod, 0x0001:Type, 0x0002:Length
        ["__ProcessInjectAllocationMethod_prefix", 0, "String",{"term_hex": "003400010002", length: 10000, max_length: 10000}],
        ["ProcessInjectAllocationMethod", "x=&gt;len(list=x.__ProcessInjectAllocationMethod_prefix) + 6", "uint16b"],

        # 0x0035:ProcessInjectStub, 0x0003:Type # Adding length check as we can not rely on termination
        ["__ProcessInjectStub_prefix", 0, "String",{"term_hex": "00350003", length: 10000, max_length: 10000}],
        ["__ProcessInjectStub_length","x=&gt;len(list=x.__ProcessInjectStub_prefix) + 4","uint16b"],
        ["__ProcessInjectStub", "x=&gt;len(list=x.__ProcessInjectStub_prefix) + 6", "String",{"term_hex":"00000000", "length": "x=&gt; x.__ProcessInjectStub_length"}],
        ["ProcessInjectStub",0,"Value",{ "value": "x=&gt;format(format='% x', args=x.__ProcessInjectStub)" }],

        # 0x0036:HostHeader, 0x0003:Type # Adding length check as we can not rely on termination
        ["__HostHeader_prefix", 0, "String",{"term_hex": "00360003", length: 10000, max_length: 10000}],
        ["__HostHeader_length","x=&gt;len(list=x.__HostHeader_prefix) + 4","uint16b"],
        ["HostHeader", "x=&gt;len(list=x.__HostHeader_prefix) + 6", "String",{"term_hex":"00000000", "length": "x=&gt; x.__HostHeader_length"}],

    ]],
    [Shellcode, 0, [
        ["__Position", 0, "Value",{"value":"x=&gt;unhex(string=position(data=_Data))"}],
        ["Server", 0, "Value",{"value":"x=&gt;regex_replace(source=regex_replace(source=x.__Position,re='\\x{00}.{4}[^$]*$',replace=''),re='\u0000',replace='')"}],
        ["TargetUri", 0, "Value",{"value":"x=&gt;find_strings(data=_Data,length=5,filter='^/').Strings[0]"}],
        ["__LicenseBytes", 0, "Value",{"value":"x=&gt;read_file(accessor='data',filename=x.__Position || '', offset=len(list=x.Server) + 1 ,length=4)"}],
        ["License", 0, "Value",{"value":"x=&gt;parse_binary(accessor='data', filename=x.__LicenseBytes,struct='uint32b')"}],
        ["Strings", 0, "Value",{"value":"x=&gt;find_strings(data=_Data,length=5,filter='.').Strings"}],
    ]],

    ["EmbeddedPE", 0, [
        ["__PayloadType", 0, "uint32"],
        ["PayloadType", 0, "Value",{"value":"x=&gt;format(format='0x%08x',args=x.__PayloadType)"}],
        ["__PayloadSize", 4, "uint32"],
        #["PayloadSize", 4, "Value",{"value":"x=&gt;format(format='0x%08x',args=x.__PayloadSize)"}],
        ["__XorKey", 8, "uint32b"],
        ["XorKey", 8, "Value",{"value":"x=&gt;format(format='0x%08x',args=x.__XorKey)"}],
        ["__Id2", 12, "uint32"],
        ["Id2", 12, "Value",{"value":"x=&gt;format(format='0x%08x',args=x.__Id2)"}],
        ["__Payload", 16, "Value",{"value":"x=&gt;read_file(accessor='data',filename=embedded_section(path=TargetBytes || OSPath,
                type=if(condition=TargetBytes,then='data',else='auto'))[0].Data || '', offset=16,length=x.__PayloadSize)"}],
        #["__Payload", 16, "String",{"term_hex":"",length=x.__PayloadSize)"}],
        ["DecodedPayload", 16, "Value",{"value":"x=&gt;xor(string=x.__Payload,key=unhex(string=x.XorKey))"}],
        ["PayloadHash", 16, "Value",{"value":"x=&gt;hash(path=xor(string=x.__Payload,key=unhex(string=x.XorKey)),accessor='data')"}],
        ["OriginalFileHash", 16, "Value",{"value":"x=&gt;hash(path=OSPath)"}],
    ]]]'''


sources:
  - query: |
      -- unique function to groupby value for enumerate
      LET unique(values) = SELECT _value as value FROM foreach(row=values) GROUP BY _value

      -- section to dynamically generate Xor configuration yara hunt strings
      LET a &lt;= unhex(string='01')
      LET b &lt;= unhex(string='02')
      LET c &lt;= unhex(string='03')

      LET XorChars &lt;=
        SELECT format(format="%#02x", args=_value) AS H,
            unhex(string=format(format="%02x", args=_value)) as X
        FROM range(start=0, end=256, step=1)
        WHERE if(condition=BruteXor,
                    then=True,
                    else= H=~ '0x2e|0x69')

      Let XorCharsStep2 =
        SELECT H, X,
            xor(string=a, key=X) as aXor,
            xor(string=b, key=X) as bXor,
            xor(string=c, key=X) as cXor,
            len(list=X)
        FROM XorChars

      LET YaraStrings =
        SELECT -- { 00 01 00 01 00 02 ?? ?? 00 02 00 01 00 02 ?? ?? 00 03 }
            X,H,
            H + ' = { ' + format(format='% x', args=X + aXor + X + aXor + X + bXor) +
            ' ?? ?? ' + format(format='% x', args=X + bXor + X + aXor + X + bXor) +
            ' ?? ?? ' + format(format='% x', args=X + cXor) + ' }'  as Line
        FROM XorCharsStep2

      LET FindConfig =
            regex_replace(
                source=FindConfigTemplate,
                re='REPLACEME',
                replace=join(array=YaraStrings.Line, sep=" $$"))


      -- function to extract potential additional encoded PE in data section
      LET embedded_section(path,type) = SELECT
            path as OriginalFileName,
            _value.Name as Name,
            _value.Size as Size,
            _value.FileOffset as FileOffset,
            _value.VMA as VMA,
            _value.RVA as RVA,
            _value.Perm as Perm,
            read_file(filename=path,
                      accessor=type,
                      offset=_value.FileOffset,
                      length=_value.Size) as Data
        FROM foreach(row= parse_pe(file=path,accessor=type).Sections)
        WHERE Name = '.data' AND Size &gt; 15


      -- scan DataBytes for CobaltStrike config
      LET ByteConfiguration = SELECT Rule,
                len(list=TargetBytes) as Size,
                hash(path=TargetBytes,accessor='data') as Hash,
                format(format="%v_%v.bin", args=[Rule,String.Offset]) as _DecodedDataName,
                Xor,_Data,
                Rule  as _Group
            FROM switch( -- switchcase will find beacon as priority, then search for shellcode
                beacon = {
                    SELECT *,
                        substr(start=0, end=1, str=String.Data) as Xor,
                        read_file(accessor='data',
                                  filename=TargetBytes,
                                  offset= String.Offset,
                                  length=ExtractBytes) as _Data
                    FROM yara(accessor='data',files=TargetBytes || "",
                              rules=FindConfig, number=99)
                },
                shellcode = {
                    SELECT *, '' as Xor,
                        read_file(accessor='data',
                                  filename=TargetBytes,
                                  offset=String.Offset,length=4096) as _Data
                    FROM yara(accessor='data',
                              files=TargetBytes,
                              rules=FindShellcode, number=99)
                },
                section_encoded_pe = {
                    SELECT *,
                        'Embedded data section: ' + Rule as Rule,
                        substr(start=0,end=1,str=String.Data) as Xor,
                        read_file(accessor='data',
                                  filename=File.OSPath,
                                  offset=String.Offset,
                                  length=ExtractBytes) as _Data
                    FROM yara(files=parse_binary(
                                accessor='data',
                                filename= embedded_section(
                                     path=TargetBytes, type='data')[0].Data || "",
                                profile=PROFILE,
                                struct="EmbeddedPE").DecodedPayload,
                              accessor='data', rules=FindConfig, number=99)
                },
                    section_encoded_stager = {
                        SELECT *,
                            '' as Xor,
                            'Embedded data section: ' + Rule as Rule,
                            read_file(accessor='data',
                                      filename=File.OSPath) as _Data
                        FROM yara(files=parse_binary(
                                     accessor='data',
                                     filename= embedded_section(
                                          path=TargetBytes,type='data')[0].Data || "",
                                     profile=PROFILE,
                                     struct="EmbeddedPE").DecodedPayload,
                                  accessor='data', rules=FindShellcode, number=99)
                    },
                sleepfunction = {
                    SELECT *, '' as Xor,
                    if(condition= String.Name= '$x86',
                            then= 'Sleep mask 32-bit 4.2 deobfuscation routine found.',
                            else= 'Sleep mask 64-bit 4.2 deobfuscation routine found.') as _Data
                    FROM yara(accessor='data',files=TargetBytes, rules=FindSleepFunction, number=1)
                })

      -- find target files
      LET TargetFiles = SELECT OSPath AS OSPath,Size
        FROM glob(globs=TargetFileGlob) WHERE NOT IsDir


      -- scan files in scope with our rule
      LET FileConfiguration = SELECT * FROM foreach(row=TargetFiles,
            query={
                SELECT
                    Rule,
                    OSPath, Size,
                    hash(path=OSPath) as Hash,
                    Xor,_Data,
                    Rule + '|' + OSPath.String as _Group,
                    format(format="%v_%v_%v.bin", args=[Rule,OSPath,String.Offset]) as _DecodedDataName
                FROM switch( -- switchcase will find beacon as priority, then search for shellcode
                    beacon = {
                        SELECT *,
                            substr(start=0,end=1,str=String.Data) as Xor,
                            read_file(
                               filename=OSPath,
                               offset= String.Offset,
                               length=ExtractBytes) as _Data
                        FROM yara(files=OSPath, rules=FindConfig, number=99)
                    },

                    shellcode = {
                        SELECT *, '' as Xor,
                            read_file(filename=OSPath,length=4096) as _Data
                        FROM yara(files=OSPath, rules=FindShellcode, number=99)
                    },

                    section_encoded_pe = {
                        SELECT *,
                            'Embedded data section: ' + Rule as Rule,
                            substr(start=0,end=1,str=String.Data) as Xor,
                            read_file(accessor='data',filename=File.OSPath,
                                      offset=String.Offset,length=ExtractBytes) as _Data
                        FROM yara(files=parse_binary(
                                      accessor='data',
                                      filename= embedded_section(path=OSPath,type='auto')[0].Data || "",
                                      profile=PROFILE,
                                      struct="EmbeddedPE").DecodedPayload,
                                  accessor='data', rules=FindConfig, number=99)
                    },
                    section_encoded_stager = {
                        SELECT *,
                            '' as Xor,
                            'Embedded data section: ' + Rule as Rule,
                            read_file(accessor='data',
                                      filename=File.OSPath,
                                      length=ExtractBytes) as _Data
                        FROM yara(files=parse_binary(
                                      accessor='data',
                                      filename= embedded_section(path=OSPath,type='auto')[0].Data || "",
                                      profile=PROFILE,
                                      struct="EmbeddedPE").DecodedPayload,
                                  accessor='data', rules=FindShellcode, number=99)
                    },
                    sleepfunction = {
                        SELECT *, '' as Xor,
                            if(condition= String.Name= '$x86',
                                then= 'Sleep mask 32-bit 4.2 deobfuscation routine found.',
                                else= 'Sleep mask 64-bit 4.2 deobfuscation routine found.') as _Data
                        FROM yara(files=OSPath, rules=FindSleepFunction, number=1)
                    })
            })


      -- find velociraptor process
      LET me &lt;= SELECT * FROM if(condition= NOT ( TargetFileGlob OR TargetBytes ),
                    then = { SELECT Pid FROM pslist(pid=getpid()) })


      -- find all processes and add filters
      LET processes = SELECT Name as ProcessName, CommandLine, Pid
        FROM pslist()
        WHERE
            Name =~ ProcessRegex
            AND format(format="%d", args=Pid) =~ PidRegex
            AND NOT Pid in me.Pid

      -- scan processes in scope with our rule
      LET ProcessConfiguration = SELECT * FROM foreach(
        row=processes,
        query={
            SELECT Rule,
                Pid, ProcessName, CommandLine,
                format(format="%v_%v_%v_%v.bin", args=[Rule,ProcessName,Pid,String.Offset]) as _DecodedDataName,
                Xor,_Data,_Group
            FROM switch( -- switchcase will find beacon as priority, then search for shellcode
                beacon = {
                    SELECT *,
                        substr(start=0,end=1,str=String.Data) as Xor,
                        read_file(accessor='process',
                                  filename=str(str=Pid),
                                  offset= String.Offset,
                                  length=ExtractBytes) as _Data,
                        Rule +'|'+ str(str=Pid) +'|'+ ProcessName +'|'+ CommandLine as _Group
                    FROM yara(accessor='process',files=str(str=Pid), rules=FindConfig, number=99)
                },
                shellcode = {
                    SELECT *, '' as Xor,
                        read_file(accessor='process',
                                  filename=str(str=Pid),
                                  offset=String.Offset,length=4096) as _Data,
                        Rule +'|'+ str(str=Pid) +'|'+ ProcessName +'|'+ CommandLine as _Group
                    FROM yara(accessor='process',files=str(str=Pid), rules=FindShellcode, number=99)
                },
                sleepfunction = {
                    SELECT *, '' as Xor,
                        if(condition= String.Name= '$x86',
                            then= 'Sleep mask 32-bit 4.2 deobfuscation routine found.',
                            else= 'Sleep mask 64-bit 4.2 deobfuscation routine found.') as _Data,
                        '' as _Group
                    FROM yara(accessor='process',files=str(str=Pid), rules=FindSleepFunction, number=1)
                })
        })


      -- Add dynamic functions for shellcode parsing
      LET position(data) = if(condition= len(list=split(string=format(format='%x',args=data),sep='ffff')) &gt; 1,
            then= split(string=format(format='%x',args=data),sep='ffff')[-1],
            else= False )
      LET find_strings(data,length,filter) = SELECT Strings
        FROM parse_records_with_regex(file=data,accessor='data',regex='(?P&lt;Strings&gt;[ -~]+)')
        WHERE len(list=Strings) &gt; length - 1
            AND Strings =~ filter
            AND NOT Strings =~ '^\\s+$'
        LIMIT 150


      -- generate results remove any FPs
      LET results &lt;= SELECT *,
            if(condition= Rule=~'cobalt_strike_beacon$',
                then= format(format='0x%x',args=Xor),else='0x00') as Xor,
            if(condition= Rule=~'cobalt_strike_beacon',
                then= parse_binary(accessor='data',
                    filename= xor(string=_Data || "" ,key=Xor),
                    profile = PROFILE,struct  = "CobaltConfig"),
                else= if(condition= Rule=~'cobalt_strike_shellcode',
                    then= parse_binary(accessor='data',
                        filename= _Data || "",
                        profile = PROFILE,struct="Shellcode"),
                    else= _Data )) AS DecodedConfig
        FROM if(condition=TargetBytes,
            then=ByteConfiguration,
            else= if(condition=TargetFileGlob,
                then= FileConfiguration,
                else= ProcessConfiguration))
        WHERE _Data
            AND
              (( DecodedConfig.C2Server =~ '^[ -~]+$' AND DecodedConfig.BeaconType )
            OR ( DecodedConfig.Pipename =~ '^[ -~]+$' AND DecodedConfig.BeaconType )
            OR DecodedConfig.Server =~ '^[ -~]+' -- AND DecodedConfig.TargetUri )
            OR Rule='cobalt_strike_sleepfunction' )

      -- add decoded data seperate to keep pretty output
      LET output_decoded_data = SELECT *,
            upload(accessor = 'data',
                file = if(condition = Rule='cobalt_strike_beacon',
                            then = xor(string=_Data,key=unhex(string=Xor)),
                            else = _Data),
                name = _DecodedDataName) as DecodedData
        FROM results

      LET cleanup(config) = to_dict(item=
            {
                SELECT _key, _value
                FROM items(item=config)
                WHERE NOT _key =~ '^__'  AND ( _value  OR _key =~ '^license' )
            })

      -- output rows, standard config priority, exclude _Data
      SELECT *,
        if(condition= format(format='%T',args=DecodedConfig)='string',
            then= DecodedConfig,
            else= cleanup(config=DecodedConfig)) as DecodedConfig
      FROM column_filter(
        query={
            SELECT * ,
                 -- NOTE: some junk strings for shellcode _Group are removed in GROUP BY
                if(condition= Rule='cobalt_strike_beacon',
                    then= _Group +'|'+ str(str=DecodedConfig),
                    else= _Group +'|'+ str(str=DecodedConfig.Server) +'|'+ str(str=DecodedConfig.TargetUri) +'|'+ str(str=DecodedConfig.Licence) ) as _Group
            FROM if(condition=IncludeDecodedData,
                then= output_decoded_data,
                else= results)
            GROUP BY _Group
        }, exclude=["_Data","_Group"])

column_types:
  - name: DecodedData
    type: preview_upload

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.attack.prefetch.md
======
---
title: Windows.Attack.Prefetch
hidden: true
tags: [Client Artifact]
---

Maps the Mitre Att&ck framework process executions into
artifacts. This pack was generated from
https://github.com/teoseller/osquery-attck


<pre><code class="language-yaml">
name: Windows.Attack.Prefetch
description: |
   Maps the Mitre Att&amp;ck framework process executions into
   artifacts. This pack was generated from
   https://github.com/teoseller/osquery-attck

precondition: SELECT OS From info() where OS = 'windows'

sources:
     - query: |
         SELECT Name, ModTime, Mtime AS modified
         FROM glob(globs="C:/Windows/Prefetch/*")

# Reports can be MONITORING_DAILY, CLIENT, SERVER_EVENT
reports:
  - type: CLIENT
    parameters:
      - name: lookupTable
        type: csv
        default: |
           signature,description
           attrib,Attrib Execute is usually used to modify file attributes - ATT&amp;CK T1158
           schtasks.exe,Schtasks Execute: usaullay used to create a scheduled task - ATT&amp;CK T1053:S0111
           taskeng.exe,taskeng Execute: usaullay used to create a scheduled task - ATT&amp;CK T1053
           tscon.exe,tscon.exe Execute: usaullay used to Terminal Services Console - ATT&amp;CK T1076
           mstsc.exe,mstsc.exe Execute: usaullay used to perform a RDP Session  - ATT&amp;CK T1076
           at.exe,Schtasks Execute: usaullay used to create a scheduled task - ATT&amp;CK T1053:S0110
           tasklist.exe,Tasklist Execute: usaullay used to list task - ATT&amp;CK T1057:T1063:T1007:S0057
           taskkill.exe,Taskkill Execute: usaullay used to kill task
           mshta.exe,Mshta Execute: is a utility that executes Microsoft HTML Applications (HTA) - ATT&amp;CK T1170
           whoami.exe,Whoami Execute: used to prints the effective username of the current user
           xcopy.exe,Xcopy Execute: is used for copying multiple files or entire directory trees from one directory to another and for copying files across a network.
           esentutl.exe,Esentutl Execute: is a legitimate built-in command-line program it could be used to create a exe from dump raw source.
           net.exe,Net Execute: is used in command-line operations for control of users: groups: services: and network connections - ATT&amp;CK T1126:T1087:T1201:T1069:S0039:T1018:T1007:T1124
           vssadmin.exe,Vssadmin Execute: usaullay used to execute activity on Volume Shadow copy
           InstallUtil.exe,InstallUtil Execute: InstallUtil is a command-line utility that allows for installation and uninstallation of resources by executing specific installer components specified in .NET binaries - ATT&amp;CK T1118
           cmstp.exe,CMSTP Execute: The Microsoft Connection Manager Profile Installer (CMSTP.exe) is a command-line program used to install Connection Manager service profiles. - ATT&amp;CK T1191
           cmd.exe,Command-Line Interface Execute: CMD execution - ATT&amp;CK T1059
           cscript.exe,Command-Line Interface Execute: Cscript execution starts a script so that it runs in a command-line environment. - ATT&amp;CK T1216
           powershell.exe,POWERSHELL Execute: is a powerful interactive command-line interface and scripting environment included in the Windows operating system - ATT&amp;CK T1086
           regsvr32.exe,POWERSHELL Execute: is a powerful interactive command-line interface and scripting environment included in the Windows operating system - ATT&amp;CK T1117
           PsExec.exe,PsExec Execute: is a free Microsoft tool that can be used to execute a program on another computer. - ATT&amp;CK T1035:S0029
           runas.exe,Runas Execute: Allows a user to run specific tools and programs with different permissions than the user's current logon provides. - ATT&amp;CK T1134
           bitsadmin.exe,Bitsadmin Execute: Windows Background Intelligent Transfer Service (BITS) is a low-bandwidth: asynchronous file transfer mechanism exposed through Component Object Model (COM) - ATT&amp;CK T1197:S0190
           certutil.exe,Certutil Execute: Certutil.exe is a legitimate built-in command-line program to manage certificates in Windows - ATT&amp;CK T1105:T1140:T1130:S0160
           netsh.exe,Netsh Execute: Netsh.exe (also referred to as Netshell) is a command-line scripting utility used to interact with the network configuration of a system - ATT&amp;CK T1128:T1063:S0108
           netstat.exe,Netstat Execute:  is an operating system utility that displays active TCP connections: listening ports: and network statistics. - ATT&amp;CK T1049:S0104
           reg.exe,Reg Execute: Reg is a Windows utility used to interact with the Windows Registry.  - ATT&amp;CK T1214:T1012:T1063:S0075
           regedit.exe,Regedit Execute: is a Windows utility used to interact with the Windows Registry. - ATT&amp;CK T1214
           systeminfo.exe,Systeminfo Execute: Systeminfo is a Windows utility that can be used to gather detailed information about a computer. - ATT&amp;CK T1082:S0096
           sc.exe,SC.exe Execute: Service Control - Create: Start: Stop: Query or Delete any Windows SERVICE. . - ATT&amp;CK T1007


    template: |
      {{ .Description }}

      The below shows any prefetch files of interest and what they
      could potentially mean.

      {{ define "query" }}
         LET lookup &lt;= SELECT * FROM lookupTable
      {{ end }}

      {{ define "data"}}
        LET data &lt;= SELECT * FROM source()
      {{ end }}

      {{ range (Query "data" "query" "SELECT * FROM lookup") }}
          {{ $rows := Query (printf "SELECT * FROM source() WHERE Name =~ '%v'" (Get . "signature") ) }}
          {{ if $rows }}

      ## {{ Get $rows "0.Name" }}
      Modified on {{ Get $rows "0.ModTime" }}.

      {{ Get . "description" }}

          {{ end }}
      {{ end }}

      # Timeline

      {{ Query "SELECT modified * 1000, Name FROM foreach(row=lookup, query={ SELECT * FROM data WHERE Name =~ signature})" | Timeline }}

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/server.monitor.clientconflict.md
======
---
title: Server.Monitor.ClientConflict
hidden: true
tags: [Server Event Artifact]
---

Sometimes the Velociraptor client is installed into a VM template
image with an existing write back file. In this case each VM
instance will start the client with the same client id.

When clients connect to the server multiple times, the server will
reject one with the HTTP 409 Conflict response.

This artifact will also force conflicting clients to rekey
themselves. Clients will generate a new client id and reconnect with
the server, saving their new keys into their write back files.


<pre><code class="language-yaml">
name: Server.Monitor.ClientConflict
type: SERVER_EVENT
description: |
  Sometimes the Velociraptor client is installed into a VM template
  image with an existing write back file. In this case each VM
  instance will start the client with the same client id.

  When clients connect to the server multiple times, the server will
  reject one with the HTTP 409 Conflict response.

  This artifact will also force conflicting clients to rekey
  themselves. Clients will generate a new client id and reconnect with
  the server, saving their new keys into their write back files.

sources:
  - query: |
      SELECT
        collect_client(client_id=ClientId,
            artifacts="Generic.Client.Rekey", env=dict())
      AS NewCollection
      FROM watch_monitoring(artifact="Server.Internal.ClientConflict")

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.network.netstatenriched.md
======
---
title: Windows.Network.NetstatEnriched
hidden: true
tags: [Client Artifact]
---

NetstatEnhanced adds additional data points to the Netstat artifact and
enables verbose search options.

Examples include: Process name and path, authenticode information or
network connection details.

WARNING:
KillProcess - attempts to use Taskill to kill the processes returned.
DumpProcess - dumps the process as a sparse file for post processing.

Please only use these switches after scoping as there are no guardrails on
shooting yourself in the foot.


<pre><code class="language-yaml">
name: Windows.Network.NetstatEnriched
author: "Matt Green - @mgreen27"
description: |
  NetstatEnhanced adds additional data points to the Netstat artifact and
  enables verbose search options.

  Examples include: Process name and path, authenticode information or
  network connection details.

  WARNING:
  KillProcess - attempts to use Taskill to kill the processes returned.
  DumpProcess - dumps the process as a sparse file for post processing.

  Please only use these switches after scoping as there are no guardrails on
  shooting yourself in the foot.

required_permissions:
  - EXECVE

precondition: SELECT OS From info() where OS = 'windows'

parameters:
  - name: IPRegex
    description: "regex search over IP address fields."
    default:  .
    type: regex
  - name: PortRegex
    description: "regex search over port fields."
    default: .
    type: regex
  - name: Family
    description: "IP version family selection"
    type: choices
    default: ALL
    choices:
       - ALL
       - IPv4
       - IPv6
  - name: FamilyMap
    type: hidden
    default: |
      Choice,Regex
      ALL,"."
      IPv4,"^IPv4$"
      IPv6,"^IPv6$"

  - name: Type
    description: "Transport protocol type selection"
    type: choices
    default: ALL
    choices:
       - ALL
       - TCP
       - UDP
  - name: TypeMap
    type: hidden
    default: |
      Choice,Regex
      ALL,"."
      TCP,"^TCP$"
      UDP,"^UDP$"

  - name: Status
    description: "TCP status selection"
    type: choices
    default: ALL
    choices:
       - ALL
       - ESTABLISHED
       - LISTENING
       - OTHER
  - name: StatusMap
    type: hidden
    default: |
      Choice,Regex
      ALL,"."
      ESTABLISHED,"^ESTAB$"
      LISTENING,"^LISTEN$"
      OTHER,"CLOS|SENT|RCVD|LAST|WAIT|DELETE"

  - name: ProcessNameRegex
    description: "regex search over source process name"
    default: ^(malware\.exe|.*)$
    type: regex
  - name: ProcessPathRegex
    description: "regex search over source process path"
    default: .
    type: regex
  - name: CommandLineRegex
    description: "regex search over source process commandline"
    default: .
    type: regex
  - name: HashRegex
    description: "regex search over source process hash"
    default: .
    type: regex
  - name: UsernameRegex
    description: "regex search over source process user context"
    default: .
    type: regex
  - name: AuthenticodeSubjectRegex
    description: "regex search over source Authenticode Subject"
    default: .
    type: regex
  - name: AuthenticodeIssuerRegex
    description: "regex search over source Authenticode Issuer"
    default: .
    type: regex
  - name: AuthenticodeVerified
    description: "Authenticode signiture selection"
    type: choices
    default: ALL
    choices:
       - ALL
       - TRUSTED
       - UNSIGNED
       - NOT TRUSTED
  - name: AuthenticodeVerifiedMap
    type: hidden
    default: |
      Choice,Regex
      ALL,"."
      TRUSTED,"^trusted$"
      UNSIGNED,"^unsigned$"
      NOT TRUSTED,"unsigned|disallowed|untrusted|error"
  - name: DumpProcess
    description: "WARNING: If selected will attempt to dump process from all results."
    type: bool
  - name: KillProcess
    description: "WARNING: If selected will attempt to kill process from all results."
    type: bool
  - name: DISABLE_DANGEROUS_API_CALLS
    type: bool
    description: |
      Enable this to disable potentially flakey APIs which may cause
      crashes.

sources:
  - name: Netstat
    query: |
      LET VerifiedRegex &lt;= SELECT Regex
            FROM parse_csv(filename=AuthenticodeVerifiedMap, accessor="data")
            WHERE Choice=AuthenticodeVerified LIMIT 1
      LET StatusRegex &lt;= SELECT Regex
            FROM parse_csv(filename=StatusMap, accessor="data")
            WHERE Choice=Status LIMIT 1
      LET FamilyRegex &lt;= SELECT Regex
            FROM parse_csv(filename=FamilyMap, accessor="data")
            WHERE Choice=Family LIMIT 1
      LET TypeRegex &lt;= SELECT Regex
            FROM parse_csv(filename=TypeMap, accessor="data")
            WHERE Choice=Type LIMIT 1

      LET process &lt;= SELECT Pid as PsId,
            Ppid,
            Name,
            CommandLine,
            Exe,
            Hash,
            Authenticode,
            Username
        FROM Artifact.Windows.System.Pslist(
            DISABLE_DANGEROUS_API_CALLS=DISABLE_DANGEROUS_API_CALLS)
        WHERE Name =~ ProcessNameRegex
            AND Exe =~ ProcessPathRegex
            AND CommandLine =~ CommandLineRegex

      LET results = SELECT Pid,
                { SELECT Ppid FROM process WHERE PsId = Pid } as Ppid,
                { SELECT Name FROM process WHERE PsId = Pid } as Name,
                { SELECT Exe FROM process WHERE PsId = Pid } as Path,
                { SELECT CommandLine FROM process WHERE PsId = Pid } as CommandLine,
                { SELECT Hash FROM process WHERE PsId = Pid } as Hash,
                { SELECT Username FROM process WHERE PsId = Pid } as Username,
                { SELECT Authenticode FROM process WHERE PsId = Pid } as Authenticode,
                FamilyString as Family,
                TypeString as Type,
                Status,
                Laddr.IP as Laddr,
                Laddr.Port as Lport,
                Raddr.IP as Raddr,
                Raddr.Port as Rport,
                Timestamp
            FROM netstat()
            WHERE
                Name =~ ProcessNameRegex
                AND Path =~ ProcessPathRegex
                and CommandLine =~ CommandLineRegex
                and Username =~ UsernameRegex
                and ( Hash.MD5 =~ HashRegex
                  or Hash.SHA1 =~ HashRegex
                  or Hash.SHA256 =~ HashRegex
                  or not Hash )
                and ( Authenticode.IssuerName =~ AuthenticodeIssuerRegex or not Authenticode )
                and ( Authenticode.SubjectName =~ AuthenticodeSubjectRegex or not Authenticode )
                and ( Authenticode.Trusted =~ VerifiedRegex.Regex[0] or not Authenticode )
                and Status =~ StatusRegex.Regex[0]
                and Family =~ FamilyRegex.Regex[0]
                and Type =~ TypeRegex.Regex[0]
                and ( format(format="%v", args=Laddr) =~ IPRegex
                    or format(format="%v", args=Raddr) =~ IPRegex )
                and ( format(format="%v", args=Lport) =~ PortRegex
                    or format(format="%v", args=Rport) =~ PortRegex )

      LET Regions(Pid) = SELECT dict(Offset=Address, Length=Size) AS Sparse
        FROM vad(pid=Pid)
        WHERE Protection =~ "r"
      LET dump = SELECT *,
            upload(accessor="sparse",
                    file=pathspec(
                    Path=serialize(item=Regions(Pid=Pid).Sparse),
                    DelegateAccessor="process",
                    DelegatePath=format(format="/%d", args=Pid)),
                     name=pathspec(Path=format(format="%d.dd", args=Pid))) AS ProcessMemory
        FROM results
      LET kill = SELECT *, pskill(pid=Pid) AS KillProcess
        FROM results
      LET dumpandkill = SELECT *, pskill(pid=Pid) AS KillProcess
        FROM dump

      SELECT * FROM switch(
            a = {
                SELECT *, if(condition= KillProcess=Null,then='Success',else=KillProcess) AS KillProcess
                FROM if(condition= DumpProcess AND KillProcess, then= dumpandkill )},
            b = { SELECT * FROM if(condition= DumpProcess, then= dump )},
            c = {
                SELECT *, if(condition= KillProcess=Null,then='Success',else=KillProcess) AS KillProcess
                FROM if(condition= KillProcess, then= kill)
            },
            catch = results
        )

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.registry.sysinternals.eulacheck.md
======
---
title: Windows.Registry.Sysinternals.Eulacheck
hidden: true
tags: [Client Artifact]
---

Checks for the Accepted Sysinternals EULA from the registry key
"HKCU\Software\Sysinternals\[TOOL]\".  When a Sysinternals tool is
first run on a system, the EULA must be accepted. This writes a
value called EulaAccepted under that key.

Note: This artifact uses HKEY_USERS and therefore will not detect
users that are not currently logged on.


<pre><code class="language-yaml">
name: Windows.Registry.Sysinternals.Eulacheck
description: |
  Checks for the Accepted Sysinternals EULA from the registry key
  "HKCU\Software\Sysinternals\[TOOL]\".  When a Sysinternals tool is
  first run on a system, the EULA must be accepted. This writes a
  value called EulaAccepted under that key.

  Note: This artifact uses HKEY_USERS and therefore will not detect
  users that are not currently logged on.

parameters:
   - name: Sysinternals_Reg_Key
     default: HKEY_USERS\*\Software\Sysinternals\*
   - name: userRegex
     default: .
     type: regex

imports:
   - Windows.Registry.NTUser

sources:
  - precondition:
      SELECT OS From info() where OS = 'windows'
    name: RegistryAPI
    query: |
      LET users &lt;= SELECT Name, UUID
          FROM Artifact.Windows.Sys.Users()
      WHERE Name =~ userRegex

      SELECT Key.Name as ProgramName,
             Key.OSPath as Key,
             Key.Mtime AS TimeAccepted,
             {
                SELECT Name FROM users WHERE UUID=regex_replace(
                   source=Key.OSPath, re=".+\\\\(S-[^\\\\]+)\\\\.+", replace="$1")
             } as User,
             EulaAccepted
      FROM read_reg_key(globs=split(string=Sysinternals_Reg_Key, sep=',[\\s]*'))

  - name: RawRegistry
    description: Detect keys using Raw Registry Analysis
    query: |
      -- Apply Raw Registry Mappings
      LET _ &lt;= MapRawRegistryHives

      -- Make sure to call the other sources otherwise we get recursion errors!
      SELECT *
      FROM Artifact.Windows.Registry.Sysinternals.Eulacheck(source="RegistryAPI")

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/macos.osquery.generic.md
======
---
title: MacOS.OSQuery.Generic
hidden: true
tags: [Client Artifact]
---

OSQuery is an excellent tool for querying system state across the
three supported Velociraptor platform (Windows/Linux/MacOS).

You can read more about OSQuery on https://osquery.io/


<pre><code class="language-yaml">
name: MacOS.OSQuery.Generic
description: |
  OSQuery is an excellent tool for querying system state across the
  three supported Velociraptor platform (Windows/Linux/MacOS).

  You can read more about OSQuery on https://osquery.io/

reference:
  - https://osquery.io/
  - https://github.com/osquery/osquery

# I am not actually sure if OSQuery allows arbitrary command execution via SQL?
required_permissions:
  - EXECVE

precondition: SELECT OS From info() where OS = 'darwin'

tools:
  - name: OSQueryDarwin
    github_project: Velocidex/OSQuery-Releases
    github_asset_regex: darwin-amd64

parameters:
  - name: Query
    default: "SELECT * FROM osquery_info"

sources:
  - query: |
      LET binary &lt;= SELECT OSPath
      FROM Artifact.Generic.Utils.FetchBinary(ToolName="OSQueryDarwin")

      LET result = SELECT * FROM execve(
         argv=[binary[0].OSPath, "--json", Query],
         length=1000000)

      SELECT * FROM foreach(row=result,
      query={
         SELECT * FROM parse_json_array(data=Stdout)
      })

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.memory.pedump.md
======
---
title: Windows.Memory.PEDump
hidden: true
tags: [Client Artifact]
---

This artifact dumps a PE file from memory and uploads the file to
the server.

NOTE: The output is not exactly the same as the original binary:
1. Relocations are not fixed
2. Due to ASLR the base address of the binary will not be the same as the original.

The result is usully much better than the binaries dumped from a
physical memory image (using e.g. Volatility) because reading
process memory will page in any mmaped pages as we copy them
out. Therefore we do not expect to have holes in the produced binary
as is often the case in memory analysis.


<pre><code class="language-yaml">
name: Windows.Memory.PEDump
description: |
  This artifact dumps a PE file from memory and uploads the file to
  the server.

  NOTE: The output is not exactly the same as the original binary:
  1. Relocations are not fixed
  2. Due to ASLR the base address of the binary will not be the same as the original.

  The result is usully much better than the binaries dumped from a
  physical memory image (using e.g. Volatility) because reading
  process memory will page in any mmaped pages as we copy them
  out. Therefore we do not expect to have holes in the produced binary
  as is often the case in memory analysis.

parameters:
  - name: Pid
    type: int
    description: The pid to dump
  - name: BaseOffset
    type: int
    description: |
      The base offset to dump from memory. If not provided, we dump
      all pe files from the PID.
  - name: FilenameRegex
    default: .+exe$
    description: Applies to the PE mapping filename to upload

sources:
  - query: |
     LET GetFilename(MappingName, BaseOffset) = if(
         condition=MappingName,
         then=format(format="dump_%#x_%s", args=[BaseOffset, basename(path=MappingName)]),
         else=format(format="dump_%#x", args=BaseOffset))

     SELECT format(format="%#x", args=Address) AS Address, Size, MappingName,
            State, Type, Protection, ProtectionMsg, read_file(
              accessor="process",
              filename=format(format="/%d", args=Pid),
              offset=Address,
              length=10) AS Header,
            upload(file=pe_dump(pid=Pid, base_offset=Address),
                   name=GetFilename(MappingName=MappingName, BaseOffset=Address)) AS Upload
     FROM vad(pid=9604)
     WHERE Header =~ "^MZ" AND MappingName =~ FilenameRegex

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.eventlogs.kerbroasting.md
======
---
title: Windows.EventLogs.Kerbroasting
hidden: true
tags: [Client Artifact]
---

This Artifact will return all successful Kerberos TGS Ticket events for
Service Accounts (SPN attribute) implemented with weak encryption. These
tickets are vulnerable to brute force attack and this event is an indicator
of a Kerbroasting attack.

Typical attacker methodology is to firstly request accounts in the domain
with SPN attributes, then request an insecure TGS ticket for brute forcing.
This attack is particularly effective as any domain credentials can be used
to implement the attack and service accounts often have elevated privileges.
Kerbroasting can be used for privilege escalation or persistence by adding a
SPN attribute to an unexpected account.

Log Source: Windows Security Event Log (Domain Controllers).
Event ID: 4769
Status: 0x0 (Audit Success)
Ticket Encryption: 0x17 (RC4)
Service Name: NOT krbtgt or NOT a system account (account name ends in $)
TargetUserName: NOT a system account (*$@*)

Monitor and alert on unusual events with these conditions from an unexpected
IP.
Note: There are potential false positives so whitelist normal source IPs and
manage risk of insecure ticket generation.


<pre><code class="language-yaml">
name: Windows.EventLogs.Kerbroasting
author: Matt Green - @mgreen27

description: |
  This Artifact will return all successful Kerberos TGS Ticket events for
  Service Accounts (SPN attribute) implemented with weak encryption. These
  tickets are vulnerable to brute force attack and this event is an indicator
  of a Kerbroasting attack.

  Typical attacker methodology is to firstly request accounts in the domain
  with SPN attributes, then request an insecure TGS ticket for brute forcing.
  This attack is particularly effective as any domain credentials can be used
  to implement the attack and service accounts often have elevated privileges.
  Kerbroasting can be used for privilege escalation or persistence by adding a
  SPN attribute to an unexpected account.

  Log Source: Windows Security Event Log (Domain Controllers).
  Event ID: 4769
  Status: 0x0 (Audit Success)
  Ticket Encryption: 0x17 (RC4)
  Service Name: NOT krbtgt or NOT a system account (account name ends in $)
  TargetUserName: NOT a system account (*$@*)

  Monitor and alert on unusual events with these conditions from an unexpected
  IP.
  Note: There are potential false positives so whitelist normal source IPs and
  manage risk of insecure ticket generation.

reference:
  - https://attack.mitre.org/techniques/T1208/
  - https://www.trustedsec.com/blog/art_of_kerberoast/

parameters:
  - name: EvtxGlob
    default: '%SystemRoot%\System32\winevt\logs\Security.evtx'
  - name: VSSAnalysisAge
    type: int
    default: 0
    description: |
      If larger than zero we analyze VSS within this many days
      ago. (e.g 7 will analyze all VSS within the last week).  Note
      that when using VSS analysis we have to use the ntfs accessor
      for everything which will be much slower.

sources:
  - query: |
      LET VSS_MAX_AGE_DAYS &lt;= VSSAnalysisAge
      LET Accessor = if(condition=VSSAnalysisAge &gt; 0, then="ntfs_vss", else="auto")

      -- expand provided glob into a list of paths on the file system (fs)
      LET fspaths = SELECT OSPath
        FROM glob(globs=expand(path=EvtxGlob))

      -- function returning IOC hits
      LET evtxsearch(PathList) = SELECT * FROM foreach(
            row=PathList,
            query={
                SELECT
                    timestamp(epoch=int(int=System.TimeCreated.SystemTime)) AS EventTime,
                    System.EventID.Value as EventID,
                    System.Computer as Computer,
                    EventData.ServiceName as ServiceName,
                    EventData.ServiceSid as ServiceSid,
                    EventData.TargetUserName as TargetUserName,
                    format(format="0x%x", args=EventData.Status) as Status,
                    EventData.TargetDomainName as TargetDomainName,
                    format(format="0x%x", args=EventData.TicketEncryptionType) as TicketEncryptionType,
                    format(format="0x%x", args=EventData.TicketOptions) as TicketOptions,
                    EventData.TransmittedServices as TransmittedServices,
                    EventData.IpAddress as IpAddress,
                    EventData.IpPort as IpPort,
                    OSPath
                FROM parse_evtx(filename=OSPath, accessor=Accessor)
                WHERE
                    System.EventID.Value = 4769
                    AND EventData.TicketEncryptionType = 23
                    AND EventData.Status = 0
                    AND NOT EventData.ServiceName =~ "krbtgt|\\$$"
                    AND NOT EventData.TargetUserName =~ "\\$@"
          })


        SELECT * FROM evtxsearch(PathList=fspaths)

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/server.alerts.winpmem.md
======
---
title: Server.Alerts.WinPmem
hidden: true
tags: [Server Event Artifact]
---

Send an email if the pmem service has been installed on any of the
endpoints.

Note this requires that the Windows.Event.ServiceCreation
monitoring artifact be collected from clients.


<pre><code class="language-yaml">
name: Server.Alerts.WinPmem
description: |
   Send an email if the pmem service has been installed on any of the
   endpoints.

   Note this requires that the Windows.Event.ServiceCreation
   monitoring artifact be collected from clients.

type: SERVER_EVENT

parameters:
  - name: EmailAddress
    default: admin@example.com
  - name: SkipVerify
    type: bool
    description: If set we skip TLS verification.

sources:
  - query: |
        SELECT * FROM foreach(
          row={
            SELECT * from watch_monitoring(
              artifact='Windows.Events.ServiceCreation')
            WHERE ServiceName =~ 'pmem'
          },
          query={
            SELECT * FROM mail(
              to=EmailAddress,
              subject='Pmem launched on host',
              period=60,
              skip_verify=SkipVerify,
              body=format(
                 format="WinPmem execution detected at %s for client %v",
                 args=[Timestamp, ClientId]
              )
          )
        })

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.forensics.partitiontable.md
======
---
title: Windows.Forensics.PartitionTable
hidden: true
tags: [Client Artifact]
---

Parses the raw disk for partition tables.

This artifact also applies magic() check to indicate the type of
partition stored. If a partition contains NTFS filesystems, the
artifact will also list the top level directory. This allows a quick
overview of what type of partition this is (e.g. System OS or data
drive).

Currently handles only GPT (Most common) and Primary Dos partition
tables


<pre><code class="language-yaml">
name: Windows.Forensics.PartitionTable
description: |
  Parses the raw disk for partition tables.

  This artifact also applies magic() check to indicate the type of
  partition stored. If a partition contains NTFS filesystems, the
  artifact will also list the top level directory. This allows a quick
  overview of what type of partition this is (e.g. System OS or data
  drive).

  Currently handles only GPT (Most common) and Primary Dos partition
  tables

parameters:
  - name: ImagePath
    default: "\\\\?\\GLOBALROOT\\Device\\Harddisk0\\DR0"
    description: Raw Device for main disk containing partition table to parse.
  - name: Accessor
    default: "raw_file"
  - name: SectorSize
    type: int
    default: 512
  - name: MagicRegex
    type: regex
    description: Filter partitions by their magic
    default: .
  - name: NameRegex
    type: regex
    description: Filter partitions by their magic
    default: .

export: |
    LET MBRProfile = '''[
        ["MBRHeader", 0, [
         ["Magic", 0x1FE, "uint16"],
         ["PrimaryPartitions", 0x1BE, Array, {
            type: "PrimaryPartition",
            count: 4,
         }],
        ]],
        ["PrimaryPartition", 16, [
         ["boot", 0, "uint8"],
         ["ptype", 4, "Enumeration", {
             type: "uint8",
             map: {
                 "Unused": 0,
                 "Dos Extended": 0x05,
                 "Win95 Extended": 0x0f,
                 "GPT Safety Partition": 0xee,
                 "NTFS / exFAT": 7,
                 "Hibernation": 0x12,
                 "Linux": 0x83,
                 "Linux Swap": 0x82,
                 "Linux Extended": 0x85,
             }}],
         ["start_sec", 8, "uint32"],
         ["size_sec", 12, "uint32"],
        ]],
        ["GPTHeader", 0, [
         ["signature", 0, "String", {
             length: 8,
         }],
         ["version", 4, "uint32"],
         ["tab_start_lba", 72, "uint64"],
         ["tab_num", 80, "uint32"],
         ["tab_size", 84, "uint32"],
         ["entries", 0, "Profile", {
            type: "Array",
            offset: "x=&gt;x.tab_start_lba * 512",
            type_options: {
             type: "GPTEntry",
             count: "x=&gt;x.tab_num",
            }}]
        ]],
        ["GPTEntry", 128, [
          ["Offset", 0, "Value", {
              value: "x=&gt;x.StartOf",
          }],
          ["type_guid", 0, GUID],
          ["id_guid", 16, GUID],
          ["start_lba", 32, "uint64"],
          ["end_lba", 40, "uint64"],
          ["flag", 48, "uint64"],
          ["name", 56, "String", {
              encoding: "utf16"
          }]
        ]],
        ["GUID", 16, [
          ["__D1", 0, "uint32"],
          ["__D2", 2, "uint16"],
          ["__D3", 4, "uint16"],
          ["__D4", 6, "String", {"term": "", "length": 2}],
          ["__D5", 8, "String", {"term": "", "length": 6}],
          ["Value", 0, "Value", {
            "value": "x=&gt;format(format='{%08x-%04x-%04x-%02x-%02x}', args=[x.__D1, x.__D2, x.__D3, x.__D4, x.__D5])"
          }]
        ]]
        ]
        '''

sources:
  - query: |
        LET GPTHeader &lt;= parse_binary(filename=ImagePath,
           accessor=Accessor,
           profile=MBRProfile,
           struct="GPTHeader",
           offset=SectorSize)

        LET PrimaryPartitions &lt;= parse_binary(filename=ImagePath,
           accessor=Accessor,
           profile=MBRProfile,
           struct="MBRHeader",
           offset=0)

        -- Display GPT - this is by far the most common one on modern
        -- systems.
        LET GPT = SELECT * FROM if(condition=GPTHeader.signature =~ "EFI",
        then={
          SELECT start_lba * SectorSize AS StartOffset,
                 end_lba * SectorSize AS EndOffset,
                 humanize(bytes=(end_lba - start_lba) * SectorSize) AS Size,
                 name
          FROM foreach(row=GPTHeader.entries)
          WHERE start_lba &gt; 0
        })

        -- Display primary partitions
        LET PARTS = SELECT start_sec * SectorSize AS StartOffset,
           ( start_sec + size_sec ) * SectorSize AS EndOffset,
            humanize(bytes=size_sec * SectorSize) AS Size,
            ptype AS name
        FROM foreach(row=PrimaryPartitions.PrimaryPartitions)
        WHERE start_sec &gt; 0

        -- Handle the correct partition types
        LET GetAccessor(Magic) =
        if(condition=Magic =~ "NTFS", then="raw_ntfs",
           else=if(condition=Magic =~ "FAT", then="fat"))

        LET ListTopDirectory(PartitionPath, Magic) =
        SELECT * FROM if(condition=GetAccessor(Magic=Magic), then={
            SELECT OSPath.Path AS OSPath
            FROM glob(globs="/*",
                      accessor=GetAccessor(Magic=Magic),
                      root=PartitionPath)
        })

        LET PartitionList = SELECT StartOffset, EndOffset, Size, name,
            magic(accessor="data", path=read_file(
              accessor=Accessor,
              filename=ImagePath,
              offset=StartOffset, length=10240)) AS Magic,

            -- The OSPath to access the partition
            pathspec(
              DelegateAccessor="offset",
              DelegatePath=pathspec(
                 DelegateAccessor=Accessor,
                 DelegatePath=ImagePath,
                 Path=format(format="%d", args=StartOffset))) AS _PartitionPath
        FROM chain(a=PARTS, b=GPT)
        WHERE name =~ NameRegex
          AND Magic =~ MagicRegex

        SELECT StartOffset, EndOffset, Size, name,
            ListTopDirectory(Magic=Magic,
              PartitionPath= _PartitionPath).OSPath AS TopLevelDirectory,
            Magic, _PartitionPath
        FROM PartitionList

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/generic.client.vql.md
======
---
title: Generic.Client.VQL
hidden: true
tags: [Client Artifact]
---

Run arbitrary VQL on the endpoint.


<pre><code class="language-yaml">
name: Generic.Client.VQL
description: |
  Run arbitrary VQL on the endpoint.

required_permissions:
  - EXECVE

parameters:
  - name: Command
    default: SELECT * FROM info()

sources:
  - query: |
      SELECT * FROM query(query=Command, env=dict(config=config))

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/linux.sys.suid.md
======
---
title: Linux.Sys.SUID
hidden: true
tags: [Client Artifact]
---

When the setuid or setgid bits are set on Linux or macOS for an
application, this means that the application will run with the
privileges of the owning user or group respectively [1]. Normally an
application is run in the current user’s context, regardless of
which user or group owns the application. There are instances where
programs need to be executed in an elevated context to function
properly, but the user running them doesn’t need the elevated
privileges. Instead of creating an entry in the sudoers file, which
must be done by root, any user can specify the setuid or setgid flag
to be set for their own applications. These bits are indicated with
an "s" instead of an "x" when viewing a file's attributes via ls
-l. The chmod program can set these bits with via bitmasking, chmod
4777 [file] or via shorthand naming, chmod u+s [file].

An adversary can take advantage of this to either do a shell escape
or exploit a vulnerability in an application with the setsuid or
setgid bits to get code running in a different user’s
context. Additionally, adversaries can use this mechanism on their
own malware to make sure they're able to execute in elevated
contexts in the future [2].


<pre><code class="language-yaml">
name: Linux.Sys.SUID
description: |
  When the setuid or setgid bits are set on Linux or macOS for an
  application, this means that the application will run with the
  privileges of the owning user or group respectively [1]. Normally an
  application is run in the current user’s context, regardless of
  which user or group owns the application. There are instances where
  programs need to be executed in an elevated context to function
  properly, but the user running them doesn’t need the elevated
  privileges. Instead of creating an entry in the sudoers file, which
  must be done by root, any user can specify the setuid or setgid flag
  to be set for their own applications. These bits are indicated with
  an "s" instead of an "x" when viewing a file's attributes via ls
  -l. The chmod program can set these bits with via bitmasking, chmod
  4777 [file] or via shorthand naming, chmod u+s [file].

  An adversary can take advantage of this to either do a shell escape
  or exploit a vulnerability in an application with the setsuid or
  setgid bits to get code running in a different user’s
  context. Additionally, adversaries can use this mechanism on their
  own malware to make sure they're able to execute in elevated
  contexts in the future [2].

reference:
  - https://attack.mitre.org/techniques/T1166/

parameters:
  - name: GlobExpression
    default: /usr/**

sources:
  - query: |
      SELECT Mode.String AS Mode,
               OSPath, Size,
               Mtime,
               Sys.Uid AS OwnerID,
               Sys.Gid AS GroupID
      FROM glob(globs=GlobExpression) WHERE Mode =~ '^g|u'

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.etw.filecreation.md
======
---
title: Windows.ETW.FileCreation
hidden: true
tags: [Client Event Artifact]
---

This artifact follows the Microsoft-Windows-Kernel-File provider.

NOTE: We can only attach to this provider when running as
NT_USER/SYSTEM.


<pre><code class="language-yaml">
name: Windows.ETW.KernelFile
description: |
  This artifact follows the Microsoft-Windows-Kernel-File provider.

  NOTE: We can only attach to this provider when running as
  NT_USER/SYSTEM.

aliases:
  - Windows.ETW.FileCreation

type: CLIENT_EVENT

references:
  - https://github.com/repnz/etw-providers-docs/blob/master/Manifests-Win10-18990/Microsoft-Windows-Kernel-File.xml

parameters:
  - name: ProcessRegex
    type: regex
    description: View Processes with Executables matching this regex
    default: .

  - name: IgnoreProcessRegex
    type: regex
    description: Ignore Processes with Executables matching this regex

  - name: Events
    type: multichoice
    description: Events to view
    default: '["NameCreate", "NameDelete", "FileOpen", "Rename", "RenamePath", "CreateNewFile"]'
    choices:
      - NameCreate
      - NameDelete
      - FileOpen
      - Rename
      - RenamePath
      - CreateNewFile

sources:
  - query: |
      -- KERNEL_FILE_KEYWORD_FILENAME | KERNEL_FILE_KEYWORD_CREATE | KERNEL_FILE_KEYWORD_DELETE_PATH
      LET Keyword &lt;= 0x1490
      LET EIDLookup &lt;= dict(
        `10`="NameCreate", `11`="NameDelete", `12`="FileOpen",
        `19`="Rename", `27`="RenamePath",`30`="CreateNewFile")

      LET ETW = SELECT *
      FROM watch_etw(guid='{edd08927-9cc4-4e65-b970-c2560fb5c289}',
           description="Microsoft-Windows-Kernel-File", any=Keyword)

      SELECT System.ID AS EID,
         get(item=EIDLookup, field=str(str=System.ID)) AS EventType,
         process_tracker_get(id=System.ProcessID).Data AS ProcInfo,
         process_tracker_callchain(id=System.ProcessID).Data.Exe AS CallChain,
         EventData
      FROM delay(query=ETW, delay=3)
      WHERE EventType IN Events
        AND ProcInfo.Exe =~ ProcessRegex
        AND if(condition=IgnoreProcessRegex,
               then=NOT ProcInfo.Exe =~ IgnoreProcessRegex,
               else=TRUE)

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.memory.processinfo.md
======
---
title: Windows.Memory.ProcessInfo
hidden: true
tags: [Client Artifact]
---

This artifact returns process information obtained by parsing the PEB directly.

Renamed Windows.Forensics.ProcessInfo


<pre><code class="language-yaml">
name: Windows.Memory.ProcessInfo
description: |
   This artifact returns process information obtained by parsing the PEB directly.

   Renamed Windows.Forensics.ProcessInfo

parameters:
  - name: ProcessNameRegex
    default: .
    type: regex
  - name: PidRegex
    default: .
    type: regex
  - name: ImagePathRegex
    default: .
    type: regex
  - name: CommandLineRegex
    default: .
    type: regex

sources:
- query: |
       LET profile = '''[
       ["PEB",0 , [
           # https://docs.microsoft.com/en-us/windows/win32/api/winternl/ns-winternl-peb
           ["ProcessParameters", 32, "Pointer", {
                "type": "ProcessParameters",
           }],
       ]],
       ["ProcessParameters", 0, [
          ["ImagePathName", 96, "UNICODE_STRING"],
          ["CommandLine", 112, "UNICODE_STRING"],
          ["CurrentDirectory", 56, "CURDIR"],
          ["EnvironmentSize", 1008, "uint64"],
          ["Environment", 128, "Pointer", {
              "type": "String",
              "type_options": {
                 "length": "x=&gt;x.EnvironmentSize",
                 "encoding": "utf16",
                 "max_length": 10000,
                 "term": "",
              }}]
       ]],
       ["CURDIR", 0, [
         ["DosPath", 0, "UNICODE_STRING"],
       ]],
       ["UNICODE_STRING", 16, [
          ["Length", 0, "uint16"],
          ["Buffer", 8, "Pointer", {
              "type": "String",
              "type_options": {
                "encoding": "utf16",
                "length": "x=&gt;x.Length",
                "term": "",
              }}],
       ]]
       ]'''

       LET ParsePeb(PID) = SELECT Name,
           format(format="%0#x", args=PebBaseAddress) AS PebBaseAddress, Pid,
           parse_binary(accessor="process",
                        filename=format(format="/%v", args=PID),
                        profile=profile,
                        struct="PEB",
                        offset=PebBaseAddress) AS Data
       FROM pslist(pid=PID)

       -- The Environment string consists of null terminated
       -- lines. Each line contains the variable name followed by an =
       -- sign and then the variable value.
       LET SplitEnv(EnvString) =  SELECT parse_string_with_regex(
          string=_value, regex="^(?P&lt;Name&gt;[^=]*)=(?P&lt;Value&gt;.+)") AS Line
       FROM foreach(row=split(string=EnvString, sep="\x00"))
       WHERE Line

       -- Massage the parsed data into a structured table
       LET Calculate(PID) = SELECT Name, PebBaseAddress, Pid,
              Data.ProcessParameters.ImagePathName.Buffer AS ImagePathName,
              Data.ProcessParameters.CommandLine.Buffer AS CommandLine,
              Data.ProcessParameters.CurrentDirectory.DosPath.Buffer AS CurrentDirectory,
              -- Build an Env dict out of the parsed string.
              to_dict(item={
                 SELECT Line.Name AS _key, Line.Value AS _value
                 FROM SplitEnv(EnvString=Data.ProcessParameters.Environment)
              }) AS Env
        FROM ParsePeb(PID=PID)

        SELECT * FROM foreach(row={
            SELECT Pid FROM pslist()
            WHERE Name =~ ProcessNameRegex
              AND str(str=Pid) =~ PidRegex
              AND str(str=ImagePathName) =~ ImagePathRegex
              AND str(str=CommandLine) =~ CommandLineRegex
        }, query={
            SELECT * FROM Calculate(PID=Pid)
        })

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/linux.syslog.sshlogin.md
======
---
title: Linux.Syslog.SSHLogin
hidden: true
tags: [Client Artifact]
---

Parses the auth logs to determine all SSH login attempts.


<pre><code class="language-yaml">
name: Linux.Syslog.SSHLogin
description: |
  Parses the auth logs to determine all SSH login attempts.

reference:
  - https://www.elastic.co/blog/grokking-the-linux-authorization-logs

type: CLIENT

parameters:
  - name: syslogAuthLogPath
    default: /var/log/{auth.log,secure}*

  - name: SSHGrok
    description: A Grok expression for parsing SSH auth lines.
    default: &gt;-
      %{SYSLOGTIMESTAMP:Timestamp} (?:%{SYSLOGFACILITY} )?%{SYSLOGHOST:logsource} %{SYSLOGPROG}: %{DATA:event} %{DATA:method} for (invalid user )?%{DATA:user} from %{IPORHOST:ip} port %{NUMBER:port} ssh2(: %{GREEDYDATA:system.auth.ssh.signature})?

sources:
  - query: |
      // Basic syslog parsing via GROK expressions.
      SELECT timestamp(string=Event.Timestamp) AS Time,
               Event.ip AS IP,
               Event.event AS Result,
               Event.method AS Method,
               Event.user AS AttemptedUser,
               OSPath
        FROM foreach(
          row={
              SELECT OSPath FROM glob(globs=syslogAuthLogPath)
          }, query={
              SELECT grok(grok=SSHGrok, data=Line) AS Event, OSPath
              FROM parse_lines(filename=OSPath)
              WHERE Event.program = "sshd"
          })

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/macos.system.users.md
======
---
title: MacOS.System.Users
hidden: true
tags: [Client Artifact]
---

This artifact collects information about the local users on the
system. The information is stored in plist files.


<pre><code class="language-yaml">
name: MacOS.System.Users
description: |
  This artifact collects information about the local users on the
  system. The information is stored in plist files.

parameters:
  - name: UserPlistGlob
    default: /private/var/db/dslocal/nodes/Default/users/*.plist
  - name: OnlyShowRealUsers
    type: bool
    default: Y

sources:
  - query: |
      LET user_plist = SELECT OSPath FROM glob(globs=UserPlistGlob)
      LET UserDetails(OSPath) =
              SELECT get(member="name.0", default="") AS Name,
                     get(member="realname.0", default="") AS RealName,
                     get(member="uid.0", default="") AS Uid,
                     get(member="gid.0", default="") AS Gid,
                     get(member="shell.0", default="") AS UserShell,
                     get(member="home.0", default="") AS HomeDir,
                     get(member="generateduid.0", default="") AS UUid,
                     if(condition=LinkedIdentity,
                        then=plist(file=LinkedIdentity[0],
                                   accessor='data')) as AppleId,
                     if(condition=accountPolicyData,
                        then=plist(file=accountPolicyData[0],
                                   accessor='data')) AS AccountPolicyData
              FROM plist(file=OSPath)

      SELECT Name, RealName, Uid, Gid, UUid, UserShell, HomeDir,
               get(item=AppleId, field="appleid.apple.com") AS AppleId,
               timestamp(epoch=AccountPolicyData.creationTime) AS CreationTime,
               AccountPolicyData.failedLoginCount AS FailedLoginCount,
               timestamp(epoch=AccountPolicyData.failedLoginTimestamp) AS FailedLoginTimestamp,
               timestamp(epoch=AccountPolicyData.passwordLastSetTime) AS PasswordLastSetTime
      FROM foreach(row=user_plist, query={
         SELECT * FROM UserDetails(OSPath= OSPath)
      })
      WHERE NOT OnlyShowRealUsers OR NOT UserShell =~ 'false'

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/generic.client.cleanuptemp.md
======
---
title: Generic.Client.CleanupTemp
hidden: true
tags: [Client Artifact]
---

This artifact cleans up the temp folder in the Velociraptor client.


<pre><code class="language-yaml">
name: Generic.Client.CleanupTemp
description: |
  This artifact cleans up the temp folder in the Velociraptor client.

parameters:
  - name: TempGlob
    default: "%TEMP%/**"
    description: Glob to find all the files in the temp folder.
  - name: AgeSeconds
    default: 600
    type: int
    description: Any files older than this many seconds will be removed.
  - name: ReadllyDoIt
    type: bool


sources:
  - query: |
      LET Threshold &lt;= timestamp(epoch=now() - AgeSeconds )
      SELECT OSPath, Size, Mtime,
         if(condition=ReadllyDoIt, then=rm(filename=OSPath)) AS Removed
      FROM glob(globs=expand(path=TempGlob))
      WHERE NOT IsDir AND Mtime &lt; Threshold

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/linux.events.sshlogin.md
======
---
title: Linux.Events.SSHLogin
hidden: true
tags: [Client Event Artifact]
---

This monitoring artifact watches the auth.log file for new
successful SSH login events and relays them back to the server.


<pre><code class="language-yaml">
name: Linux.Events.SSHLogin
description: |
  This monitoring artifact watches the auth.log file for new
  successful SSH login events and relays them back to the server.

reference:
  - https://www.elastic.co/blog/grokking-the-linux-authorization-logs

type: CLIENT_EVENT

parameters:
  - name: syslogAuthLogPath
    default: /var/log/auth.log

  - name: SSHGrok
    description: A Grok expression for parsing SSH auth lines.
    default: &gt;-
      %{SYSLOGTIMESTAMP:timestamp} (?:%{SYSLOGFACILITY} )?%{SYSLOGHOST:logsource} %{SYSLOGPROG}: %{DATA:event} %{DATA:method} for (invalid user )?%{DATA:user} from %{IPORHOST:ip} port %{NUMBER:port} ssh2(: %{GREEDYDATA:system.auth.ssh.signature})?

sources:
  - query: |
      -- Basic syslog parsing via GROK expressions.
      LET success_login = SELECT grok(grok=SSHGrok, data=Line) AS Event, Line
        FROM watch_syslog(filename=syslogAuthLogPath)
        WHERE Event.program = "sshd" AND Event.event = "Accepted"

      SELECT timestamp(string=Event.timestamp) AS Time,
              Event.user AS User,
              Event.method AS Method,
              Event.IP AS SourceIP,
              Event.pid AS Pid
        FROM success_login

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/linux.sys.bashshell.md
======
---
title: Linux.Sys.BashShell
hidden: true
tags: [Client Artifact]
---

This artifact allows running arbitrary commands through the system
shell.

Since Velociraptor typically runs as root, the commands will also
run as root.

This is a very powerful artifact since it allows for arbitrary
command execution on the endpoints. Therefore this artifact requires
elevated permissions (specifically the `EXECVE`
permission). Typically it is only available with the `administrator`
role.


<pre><code class="language-yaml">
name: Linux.Sys.BashShell
description: |
  This artifact allows running arbitrary commands through the system
  shell.

  Since Velociraptor typically runs as root, the commands will also
  run as root.

  This is a very powerful artifact since it allows for arbitrary
  command execution on the endpoints. Therefore this artifact requires
  elevated permissions (specifically the `EXECVE`
  permission). Typically it is only available with the `administrator`
  role.

required_permissions:
  - EXECVE

parameters:
  - name: Command
    default: "ls -l /"

sources:
  - query: |
      SELECT * FROM execve(argv=["/bin/bash", "-c", Command])

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.detection.wmiprocesscreation.md
======
---
title: Windows.Detection.WMIProcessCreation
hidden: true
tags: [Client Event Artifact]
---

WMI Process creation is a common lateral movement technique. The
attacker simply uses WMI to call the Create() method on the
Win32_Process WMI object.

This can be easily done via the wmic.exe command or via powershell:

```bash
wmic process call create cmd.exe
```


<pre><code class="language-yaml">
name: Windows.Detection.WMIProcessCreation
description: |
  WMI Process creation is a common lateral movement technique. The
  attacker simply uses WMI to call the Create() method on the
  Win32_Process WMI object.

  This can be easily done via the wmic.exe command or via powershell:

  ```bash
  wmic process call create cmd.exe
  ```

type: CLIENT_EVENT

sources:
  - query: |
        SELECT Parse from wmi_events(
          query="SELECT * FROM MSFT_WmiProvider_ExecMethodAsyncEvent_Pre WHERE ObjectPath=\"Win32_Process\" AND MethodName=\"Create\"",
          namespace="ROOT/CIMV2",
          wait=50000000)

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.network.listeningports.md
======
---
title: Windows.Network.ListeningPorts
hidden: true
tags: [Client Artifact]
---

Processes with listening (bound) network sockets/ports.

<pre><code class="language-yaml">
name: Windows.Network.ListeningPorts
description: Processes with listening (bound) network sockets/ports.
sources:
  - precondition:
      SELECT OS From info() where OS = 'windows'
    query: |
        LET process &lt;= SELECT Name, Pid from pslist()

        SELECT * from foreach(
          row={
            SELECT Pid AS PortPid, Laddr.Port AS Port,
                   TypeString as Protocol, FamilyString as Family,
                   Laddr.IP as Address
            FROM netstat() where Status = 'LISTEN'
          },
          query={
            SELECT Pid, Name, Port, Protocol, Family, Address
            FROM process where Pid = PortPid
          })

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.forensics.shellbags.md
======
---
title: Windows.Forensics.Shellbags
hidden: true
tags: [Client Artifact]
---

Windows uses the Shellbag keys to store user preferences for GUI
folder display within Windows Explorer.

This artifact uses the raw registry parser to inspect various user
registry hives around the filesystem for BagMRU keys. Different OS
versions may have slightly different locations for the MRU keys.


<pre><code class="language-yaml">
name: Windows.Forensics.Shellbags
description: |
  Windows uses the Shellbag keys to store user preferences for GUI
  folder display within Windows Explorer.

  This artifact uses the raw registry parser to inspect various user
  registry hives around the filesystem for BagMRU keys. Different OS
  versions may have slightly different locations for the MRU keys.

reference:
  - https://www.sans.org/blog/computer-forensic-artifacts-windows-7-shellbags/

parameters:
  - name: SearchSpecs
    type: csv
    description: Define locations of MRU bags in various registries.
    default: |
      HiveGlob,KeyGlob
      C:/Users/*/NTUSER.dat,\Software\Microsoft\Windows\Shell\BagMRU\**
      C:/Users/*/AppData/Local/Microsoft/Windows/UsrClass.dat,\Local Settings\Software\Microsoft\Windows\Shell\BagMRU\**


imports:
  # Link files use the same internal format as shellbags so we import
  # the profile here.
  - Windows.Forensics.Lnk

sources:
  - query: |
      LET AllHives = SELECT * FROM foreach(row=SearchSpecs,
        query={
            SELECT OSPath AS HivePath, KeyGlob
            FROM glob(globs=HiveGlob)
            WHERE log(message="Inspecting hive " + HivePath)
        })

      LET ShellValues = SELECT * FROM foreach(row=AllHives,
        query={
           SELECT OSPath, Data, ModTime
           FROM glob(
              root=pathspec(DelegatePath=HivePath),
              globs=KeyGlob,
              accessor="raw_reg")
           WHERE Data.type =~ "BINARY" AND OSPath.Basename =~ "^[0-9]+$"
        })

      LET ParsedValues = SELECT
          OSPath.Dirname AS KeyPath,
          parse_binary(profile=Profile, filename=Data.value,
                       accessor="data", struct="ItemIDList") as _Parsed,
          base64encode(string=Data.value) AS _RawData, ModTime
      FROM ShellValues

      LET AllResults &lt;= SELECT KeyPath,
        _Parsed.ShellBag.Description AS Description,
        _Parsed, _RawData, ModTime
      FROM ParsedValues

      // Recursive function to join path components together.
      // Limit recursion depth just in case.
      LET FormPath(MRUPath, Description, Depth) = SELECT * FROM if(
        condition=Depth &lt; 20,
        then={SELECT * FROM chain(
          b={
            SELECT MRUPath, Description, Depth,
              -- Signify unknown component as ?
              Description.LongName || Description.ShortName || "?" AS Name
            FROM scope()
          },
          c={
            SELECT * FROM foreach(row={
              SELECT KeyPath, Description, Depth
              FROM AllResults
              WHERE KeyPath = MRUPath.Dirname
              LIMIT 1
            }, query={
              SELECT * FROM FormPath(MRUPath=KeyPath,
                                     Description=Description, Depth=Depth + 1)
            })
          })
          ORDER BY Depth DESC
          LIMIT 10
        })

        // Now display all hits and their reconstructed path
        LET ReconstructedPath = SELECT ModTime, KeyPath, Description, {
           SELECT * FROM FormPath(
                MRUPath=KeyPath, Description=Description, Depth=0)
        } AS Chain, _RawData, _Parsed
        FROM AllResults

        SELECT ModTime,
           KeyPath AS _OSPath,
           KeyPath.DelegatePath AS Hive,
           KeyPath.Path AS KeyPath, Description,
               join(array=Chain.Name, sep=" -&gt; ") AS Path,
               _RawData, _Parsed
        FROM ReconstructedPath
        ORDER BY Path

column_types:
  - name: _RawData
    type: base64

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/linux.ssh.authorizedkeys.md
======
---
title: Linux.Ssh.AuthorizedKeys
hidden: true
tags: [Client Artifact]
---

Find and parse ssh authorized keys files.

From `man authorized_keys`:

`AUTHORIZED_KEYS FILE FORMAT`: Each line of the file contains one
key (empty lines and lines starting with a ‘#’ are ignored as
comments). Public keys consist of the following space-separated
fields: options, keytype, base64-encoded key, comment. The options
field is optional.


<pre><code class="language-yaml">
name: Linux.Ssh.AuthorizedKeys
description: |
  Find and parse ssh authorized keys files.

  From `man authorized_keys`:

  `AUTHORIZED_KEYS FILE FORMAT`: Each line of the file contains one
  key (empty lines and lines starting with a ‘#’ are ignored as
  comments). Public keys consist of the following space-separated
  fields: options, keytype, base64-encoded key, comment. The options
  field is optional.

parameters:
  - name: sshKeyFiles
    default: '.ssh/authorized_keys*'
    description: Glob of authorized_keys file relative to a user's home directory.
  - name: keyTypes
    type: regex
    description: A regex to identify supported key types
    default: "sk-ecdsa-sha2-nistp256|ecdsa-sha2-nistp256|ecdsa-sha2-nistp384|ecdsa-sha2-nistp521|sk-ssh-ed25519|ssh-ed25519|ssh-dss|ssh-rsa"

  - name: AlsoUpload
    type: bool
    description: Also upload the raw files for closer inspection.

sources:
  - precondition: |
      SELECT OS From info() where OS = 'linux'

    query: |
      -- Find all eligible files.
      LET authorized_keys = SELECT * from foreach(
          row={
             SELECT Uid, User, Homedir from Artifact.Linux.Sys.Users()
          },
          query={
             SELECT OSPath,
                    if(condition=AlsoUpload, then=upload(file=OSPath)) AS _Upload,
                    Mtime, Ctime, User, Uid
             FROM glob(root=Homedir, globs=sshKeyFiles)
             WHERE log(message="Parsing file %v", args=OSPath, dedup=-1)
          })

      -- Split each line into parts considering possible quoting
      LET Parse(OSPath) =
         -- Pad a bit so index does not wrap.
         SELECT ParseParts(Parts=commandline_split(command=Line, bash_style=TRUE) + ("", "", "", "", "")) AS Parsed
         FROM parse_lines(filename=OSPath)
         WHERE NOT Line =~ "^#" AND Parsed.keytype =~ keyTypes

      -- The option may or may not be there - determine by the key regex
      LET ParseParts(Parts) = if(condition= Parts[0] =~ keyTypes,
        -- No options
        then=dict(options="", keytype=Parts[0], base64key=Parts[1], comment=Parts[2] || ""),

        -- The line has options
        else=dict(options=ParseOptions(Opts=Parts[0]),
                  keytype=Parts[1], base64key=Parts[2], comment=Parts[3] || ""))

      -- Option can have value or just be bare
      LET ParseOptions(Opts) = split(string=Opts, sep_string=",")

      SELECT * FROM foreach(row=authorized_keys,
      query={
        SELECT Uid, User, OSPath, _Upload, *
        FROM foreach(column="Parsed", row= Parse(OSPath=OSPath))
      })

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.system.vad.md
======
---
title: Windows.System.VAD
hidden: true
tags: [Client Artifact]
---

This artifact enables enumeration of process memory sections via the Virtual
Address Descriptor (VAD). The VAD is used by the Windows memory manager to
describe allocated process memory ranges.

Available filters include process, mapping path, memory permissions
or by content with yara.

Use the UploadSection switch to upload any sections.

A notebook suggestion is available for Strings analysis on uploaded sections.

NOTE:

- ProtectionChoice is a choice to filter on section protection. Default is
all sections and ProtectionRegex can override selection.
- To filter on unmapped sections the MappingNameRegex: ^$ can be used.
- When uploading sections during analysis, its recommended to run once for 
scoping, then a second time once confirmed for upload.


<pre><code class="language-yaml">
name: Windows.System.VAD
author: "Matt Green - @mgreen27"
description: |
  This artifact enables enumeration of process memory sections via the Virtual
  Address Descriptor (VAD). The VAD is used by the Windows memory manager to
  describe allocated process memory ranges.

  Available filters include process, mapping path, memory permissions
  or by content with yara.
  
  Use the UploadSection switch to upload any sections.
  
  A notebook suggestion is available for Strings analysis on uploaded sections.

  NOTE:

  - ProtectionChoice is a choice to filter on section protection. Default is
  all sections and ProtectionRegex can override selection.
  - To filter on unmapped sections the MappingNameRegex: ^$ can be used.
  - When uploading sections during analysis, its recommended to run once for 
  scoping, then a second time once confirmed for upload.

parameters:
  - name: ProcessRegex
    description: A regex applied to process names.
    default: .
    type: regex
  - name: PidRegex
    default: .
    type: regex
  - name: ProtectionChoice
    type: choices
    description: Select memory permission you would like to return. Default All.
    default: Any
    choices:
      - Any
      - Execute, read and write
      - Any executable
  - name: ProtectionRegex
    type: regex
    description: Allows a manual regex selection of section Protection permissions. If configured take preference over Protection choice.
  - name: MappingNameRegex
    type: regex
  - name: UploadSection
    description: Upload suspicious section.
    type: bool
  - name: SuspiciousContent
    description: A yara rule of suspicious section content
    type: yara
  - name: ContextBytes
    description: Include this amount of bytes around yara hit as context.
    default: 0
    type: int


sources:
  - query: |
      -- firstly find processes in scope
      LET processes = SELECT int(int=Pid) AS Pid,
              Name, Exe, CommandLine, StartTime
        FROM process_tracker_pslist()
        WHERE Name =~ ProcessRegex
            AND format(format="%d", args=Pid) =~ PidRegex
            AND log(message="Scanning pid %v : %v", args=[Pid, Name])

      -- next find sections in scope
      LET sections = SELECT * FROM foreach(
          row=processes,
          query={
            SELECT StartTime as ProcessCreateTime,Pid, Name, MappingName,
                format(format='%x-%x', args=[Address, Address+Size]) AS AddressRange,
                Address as _Address,
                State,Type,ProtectionMsg,Protection,
                Size as SectionSize,
                pathspec(
                    DelegateAccessor="process",
                    DelegatePath=Pid,
                    Path=Address) AS _PathSpec
            FROM vad(pid=Pid)
            WHERE if(condition=MappingNameRegex,
                    then= MappingName=~MappingNameRegex,
                    else= True)
                AND if(condition = ProtectionRegex,
                    then= Protection=~ProtectionRegex,
                    else= if(condition= ProtectionChoice='Any',
                        then= TRUE,
                    else= if(condition= ProtectionChoice='Execute, read and write',
                        then= Protection= 'xrw',
                    else= if(condition= ProtectionChoice='Any executable',
                        then= Protection=~'x'))))
          })

      -- if suspicious yara added, search for it
      LET yara_sections = SELECT *
        FROM foreach(row={
                SELECT * FROM sections
                WHERE NOT State =~ "RESERVE"
            }, query={
                SELECT
                    ProcessCreateTime, Pid, Name,MappingName,
                    AddressRange,State,Type,ProtectionMsg,
                    Protection,SectionSize,
                    dict(Rule=Rule,
                         Meta=Meta,
                         Tags=Tags,
                         Offset=String.Offset,
                         Name=String.Name) as YaraHit,
                    upload( accessor='scope',
                            file='String.Data',
                            name=format(format="%v-%v_%v.bin-%v-%v",
                            args=[
                                Name, Pid, AddressRange,
                                if(condition= String.Offset - ContextBytes &lt; 0,
                                    then= 0,
                                    else= String.Offset - ContextBytes),
                                if(condition= String.Offset + ContextBytes &gt; SectionSize,
                                    then= SectionSize,
                                    else= String.Offset + ContextBytes ) ])
                            ) as HitContext,
                    _PathSpec, _Address
                FROM yara(  blocksize=if(condition= SectionSize &lt; 10000000,
                                            then= SectionSize,
                                            else= 10000000 ),
                            accessor='offset',
                            files=_PathSpec,
                            rules=SuspiciousContent,
                            end=SectionSize,  key='X',
                            number=1,
                            context=ContextBytes
                        )
            })

      -- finalise results
      LET results = SELECT *,
             process_tracker_callchain(id=Pid).Data as ProcessChain
        FROM if(condition= SuspiciousContent,
                    then= yara_sections,
                    else= sections)

      -- upload sections if selected
      LET upload_results = SELECT *,
        upload(accessor='sparse',
               file=pathspec(
                    DelegateAccessor="process",
                    DelegatePath=Pid,
                    Path=[dict(Offset=_Address, Length=SectionSize),]),
                name=pathspec(
                    Path=format(
                        format='%v-%v_%v.bin',
                        args= [ Name, Pid, AddressRange ]))) as SectionDump
            FROM results

      -- output rows
      SELECT * FROM if(condition= UploadSection,
                    then= upload_results,
                    else= results)

    notebook:
      - type: vql_suggestion
        name: Strings analysis
        template: |

            /*
            # Strings analysis
            */
            
            LET MinStringSize = 8
            LET FindPrintable = '''
                    rule find_strings {
                        strings:
                            $wide = /(^|[^ -~\s]\x00)([ -~\s]\x00){%#%,}(\x00|[^ -~\s]|$)/
                            $ascii = /(^|[^ -~\s])([ -~\s]{%#%,})([^ -~\s]|$)/
                        condition:
                            any of them
                    }'''
            LET YaraRule = regex_replace(source=FindPrintable,re='''\%\#\%''',replace=str(str=MinStringSize))
            
            
            LET sections = SELECT vfs_path, client_path,file_size, uploaded_size
                FROM uploads(client_id=ClientId, flow_id=FlowId)
                WHERE vfs_path =~ '\.bin$'
            
            LET find_result(name) = SELECT *
                FROM source(artifact="Windows.System.VAD")
                WHERE SectionDump.StoredName = name
                LIMIT 1
            
            
            LET row_results = SELECT *, find_result(name=client_path)[0] as Result
            FROM sections
            WHERE Result
            
            SELECT * FROM foreach(row=row_results,
                query={
                    SELECT
                        regex_replace(source=String.Data,re='[^ -~]',replace='') as String,
                        strip(prefix='$',string=String.Name) as Type,
                        String.Offset as Offset,
                        Result.MappingName as MappingName,
                        Result.AddressRange as AddressRange,
                        Result.Name as ProcesName, 
                        Result.Pid as Pid,
                        Result.Protection as Protection
                        --,vfs_path
                    FROM yara(
                            accessor='fs',
                            files=vfs_path,
                            rules=YaraRule,
                            key='X',
                            number=9999999999999999 )
                })
                WHERE NOT String =~ '''^\s*$'''

column_types:
  - name: HitContext
    type: preview_upload

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.eventlogs.explicitlogon.md
======
---
title: Windows.EventLogs.ExplicitLogon
hidden: true
tags: [Client Artifact]
---

This artifact enables querying for explicit logon events.  i.e Event ID 4648:
A logon was attempted using explicit credentials.

If logging is enabled, these events are generated on the source machine when
an authentication attempt occurs under a different user context. Examples
include a user authenticating to another machine using wmic or mapping a
drive using different credentials, or using the RunAs option locally.

This artifact by default filters all events with localhost as the server and
MACHINE$ as target user. A recommended hunt for lateral movement would be
activity to other machines from commonly abused lolbins or explicit logon
events from unusual processes.


<pre><code class="language-yaml">
name: Windows.EventLogs.ExplicitLogon
description: |
    This artifact enables querying for explicit logon events.  i.e Event ID 4648:
    A logon was attempted using explicit credentials.

    If logging is enabled, these events are generated on the source machine when
    an authentication attempt occurs under a different user context. Examples
    include a user authenticating to another machine using wmic or mapping a
    drive using different credentials, or using the RunAs option locally.

    This artifact by default filters all events with localhost as the server and
    MACHINE$ as target user. A recommended hunt for lateral movement would be
    activity to other machines from commonly abused lolbins or explicit logon
    events from unusual processes.


author: Matt Green - @mgreen27

precondition: SELECT OS From info() where OS = 'windows'

parameters:
  - name: EvtxGlob
    default: '%SystemRoot%\System32\Winevt\Logs\Security.evtx'
  - name: UsernameRegex
    description: "Target username Regex"
    default: .
    type: regex
  - name: UsernameWhitelist
    description: "Target username witelist Regex"
    default: '\\$$'
    type: regex
  - name: ServerRegex
    description: "Target server regex"
    default: .
    type: regex
  - name: ServerWhitelist
    description: "Target server whitelist regex"
    default: 'localhost'
    type: regex
  - name: ProcessNameRegex
    description: "Target process Regex"
    default: .
  - name: ProcessNameWhitelist
    description: "Target process whitelist Regex"
    type: regex

  - name: VSSAnalysisAge
    type: int
    default: 0
    description: |
      If larger than zero we analyze VSS within this many days
      ago. (e.g 7 will analyze all VSS within the last week).  Note
      that when using VSS analysis we have to use the ntfs accessor
      for everything which will be much slower.

  - name: DateAfter
    type: timestamp
    description: "search for events after this date. YYYY-MM-DDTmm:hh:ssZ"
  - name: DateBefore
    type: timestamp
    description: "search for events before this date. YYYY-MM-DDTmm:hh:ssZ"


sources:
  - query: |
      LET VSS_MAX_AGE_DAYS &lt;= VSSAnalysisAge
      LET Accessor = if(condition=VSSAnalysisAge &gt; 0, then="ntfs_vss", else="auto")

      -- firstly set timebounds for performance
      LET DateAfterTime &lt;= if(condition=DateAfter,
        then=timestamp(epoch=DateAfter), else=timestamp(epoch="1600-01-01"))
      LET DateBeforeTime &lt;= if(condition=DateBefore,
        then=timestamp(epoch=DateBefore), else=timestamp(epoch="2200-01-01"))

      -- expand provided glob into a list of paths on the file system (fs)
      LET fspaths = SELECT OSPath
        FROM glob(globs=expand(path=EvtxGlob), accessor=Accessor)

      -- function returning IOC hits
      LET evtxsearch(PathList) = SELECT * FROM foreach(
            row=PathList,
            query={
                SELECT
                    timestamp(epoch=int(int=System.TimeCreated.SystemTime)) AS EventTime,
                    System.Computer as Computer,
                    System.EventID.Value as EventID,
                    System.EventRecordID as EventRecordID,
                    EventData.SubjectUserName as SubjectUserName,
                    EventData.SubjectDomainName as SubjectDomainName,
                    EventData.TargetUserName as TargetUserName,
                    EventData.TargetDomainName as TargetDomainName,
                    EventData.TargetServerName as TargetServerName,
                    EventData.ProcessName as ProcessName,
                    EventData,
                    Message,
                    OSPath
                FROM parse_evtx(filename=OSPath, accessor=Accessor)
                WHERE
                    EventID = 4648
                    AND EventTime &lt; DateBeforeTime
                    AND EventTime &gt; DateAfterTime
                    AND TargetUserName =~ UsernameRegex
                    AND NOT if(condition=UsernameWhitelist,
                        then= TargetUserName =~ UsernameWhitelist,
                        else= FALSE)
                    AND TargetServerName =~ ServerRegex
                    AND NOT if(condition=ServerWhitelist,
                        then= TargetServerName =~ ServerWhitelist,
                        else= FALSE)
                    AND ProcessName =~ ProcessNameRegex
                    AND NOT if(condition=ProcessNameWhitelist,
                        then= ProcessName =~ ProcessNameWhitelist,
                        else= FALSE)
            }
          )

        SELECT * FROM evtxsearch(PathList=fspaths)

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.ntfs.extendedattributes.md
======
---
title: Windows.NTFS.ExtendedAttributes
hidden: true
tags: [Client Artifact]
---

Adversaries may use NTFS file attributes for defence evasion to hide malicious
data. This artifact parses NTFS Extended attributes ($EA).
The artifact firstly queries the MFT, then enriches NTFS data to check for
Extended Attributes. Several filters can be applied such as file search,
Extended Attribute size, name or content.

NOTE:
By default an EAName exclusion has been applied to filter some common $EA names
found on Windows System. Recommended hunt would be by rare name or $EA size.
By default we only parse $EA and discard $EA_INFORMATION. $EA_INFORMATION
typically is very small and available in NtfsMetadata field of output.


<pre><code class="language-yaml">
name: Windows.NTFS.ExtendedAttributes
author: "Matt Green - @mgreen27"
description: |
  Adversaries may use NTFS file attributes for defence evasion to hide malicious
  data. This artifact parses NTFS Extended attributes ($EA).
  The artifact firstly queries the MFT, then enriches NTFS data to check for
  Extended Attributes. Several filters can be applied such as file search,
  Extended Attribute size, name or content.

  NOTE:
  By default an EAName exclusion has been applied to filter some common $EA names
  found on Windows System. Recommended hunt would be by rare name or $EA size.
  By default we only parse $EA and discard $EA_INFORMATION. $EA_INFORMATION
  typically is very small and available in NtfsMetadata field of output.


reference:
  - https://attack.mitre.org/techniques/T1564/004/
  - https://posts.specterops.io/host-based-threat-modeling-indicator-design-a9dbbb53d5ea
  - http://inform.pucp.edu.pe/~inf232/Ntfs/ntfs_doc_v0.5/attributes/ea.html

parameters:
  - name: MFTDrive
    default: "C:"
  - name: HostPathRegex
    description: "Regex search over OSPath."
    default: "."
    type: regex
  - name: DateAfter
    type: timestamp
    description: "search for host files with timestamps after this date. YYYY-MM-DDTmm:hh:ssZ"
  - name: DateBefore
    type: timestamp
    description: "search for  host files with timestamps before this date. YYYY-MM-DDTmm:hh:ssZ"
  - name: AllDrives
    type: bool
    description: "Select MFT search on all attached ntfs drives."
  - name: EANameRegex
    description: "$EA Name regex filter to include in results."
    default: .
    type: regex
  - name: EANameExclusion
    description: Regex of ADS name to exclude.
    default: ^(\$KERNEL\.PURGE\.(ESBCACHE|APPXFICACHE)|\$CI\.CATALOGHINT|\w{8}-\w{4}-\w{4}-\w{4}-\w{12}\.CSC\.\w+)$
    type: regex
  - name: EAContentRegex
    description: "$EA content to search for by regex."
    default: .
    type: regex
  - name: SizeMax
    type: int64
    description: "Total $EA attributes in the MFT under this size in bytes."
    default: 100000
  - name: SizeMin
    type: int64
    description: "Total $EA attributes in the MFT over this size in bytes."
    default: 0
  - name: UploadHits
    type: bool
    description: "Upload complete complete attribute data."

sources:
  - query: |
      LET Profile = '''[
         ["EAData", 0, [
            ["Entries", 0, "Array",{
                "type": "EA",
                "count": 99 }],
         ]],
         ["EA", "x=&gt;x.__NextOffset", [
            ["__NextOffset", 0, "uint32"],
            ["__NameLength", 5, "uint8"],
            ["__ValueLength", 6, "uint16"],
            ["Name", 8, String, {
                length: "x=&gt;x.__NameLength" }],
            ["Flags", 4, "uint8"],
            ["ValueLength", 6, "uint16"],
            ["Value", "x=&gt;9 + x.__NameLength", "String",{
                term: "********** NO TERM **********",
                length: "x=&gt;x.__ValueLength",
                max_length: 10000 }],
       ]]
       ]'''

      -- find all MFT entries with an $EA - ignore VSS
      LET mft_entries = SELECT *,
            parse_ntfs(mft=EntryNumber, device=MFTDrive ) as NtfsMetadata
        FROM Artifact.Windows.NTFS.MFT(
           MFTDrive=MFTDrive,
           Accessor='ntfs',
           PathRegex=HostPathRegex,
           DateAfter=DateAfter,
           DateBefore=DateBefore,
           AllDrives=AllDrives)
        WHERE -- NOT OSPath =~ 'HarddiskVolumeShadowCopy' AND
          NtfsMetadata.Attributes.Type =~ '^\\$EA'

      -- enrich results for size filter, dropping metadata field output as this attribute is viewable in Ntfs field.
      LET enriched_results = SELECT OSPath,NtfsMetadata,
            --{ SELECT * FROM NtfsMetadata.Attributes WHERE Type = '$EA_INFORMATION'} as _EA_INFORMATION_Metadata,
            { SELECT * FROM NtfsMetadata.Attributes WHERE Type = '$EA'} as _EA_Metadata
        FROM mft_entries
        WHERE _EA_Metadata.Size &gt; SizeMin AND _EA_Metadata.Size &lt; SizeMax

      -- parse EA attribute
      LET parse_ea = SELECT OSPath, NtfsMetadata, _EA_Metadata,
            parse_binary(accessor="mft",
                filename=NtfsMetadata.Device + _EA_Metadata.Inode,
                profile=Profile, struct="EAData").Entries AS EA
        FROM enriched_results

      -- flattern results and output a row for each EA parsed
      LET flatten_results = SELECT  OSPath, NtfsMetadata, EA, _EA_Metadata
        FROM flatten(
            query={
                SELECT *
                    {
                        SELECT Name,Value,Flags,ValueLength
                        FROM foreach(row=EA)
                    } as EA
                FROM parse_ea
                WHERE EA.Name =~ EANameRegex
                    AND NOT if(condition=EANameExclusion,
                            then= EA.Name =~ EANameExclusion,
                            else= False )
                    AND EA.Value =~ EAContentRegex
            })

      -- upload extended EA data
      LET upload_hits=SELECT OSPath, NtfsMetadata, EA,
            upload(file=NtfsMetadata.Device + _EA_Metadata.Inode,accessor='mft') AS Upload
            --upload(file=Ntfs.Device + _EA_INFORMATION_Metadata.Inode,accessor='mft') AS EA_INFORMATION_Upload
        FROM flatten_results

      -- return rows
      SELECT *
      FROM if(condition=UploadHits,
        then=upload_hits,
        else=flatten_results)

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/server.internal.frontendmetrics.md
======
---
title: Server.Internal.FrontendMetrics
hidden: true
tags: [Internal Artifact]
---

An internal queue that receives metrics from all frontends. The
master Frontend manager service will aggregate these into a combined
metric stream.


<pre><code class="language-yaml">
name: Server.Internal.FrontendMetrics
description: |
  An internal queue that receives metrics from all frontends. The
  master Frontend manager service will aggregate these into a combined
  metric stream.

type: INTERNAL

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.sigma.eventlogs.md
======
---
title: Windows.Sigma.EventLogs
hidden: true
tags: [Client Artifact]
---

Parse Windows event logs and matches then against Sigma Rules.

NOTE: This is a very simple artifact for demonstration only. For
more extensive Sigma rules use the `Server.Import.CuratedSigma`
artifact to import a curated set of Sigma rules from
https://sigma.velocidex.com/


<pre><code class="language-yaml">
name: Windows.Sigma.EventLogs
description: |
  Parse Windows event logs and matches then against Sigma Rules.

  NOTE: This is a very simple artifact for demonstration only. For
  more extensive Sigma rules use the `Server.Import.CuratedSigma`
  artifact to import a curated set of Sigma rules from
  https://sigma.velocidex.com/

parameters:
- name: EventLogDirectory
  default: C:/Windows/System32/WinEvt/Logs/
- name: InlineSigmaRules
  description: A single string of sigma rules separated by --- lines
- name: SigmaRuleFile
  type: upload
  description: A file containing sigma rules separated by --- lines
- name: Debug
  type: bool
  description: Enable full debug trace

export: |
  LET StandardSigmaLogSource &lt;= sigma_log_sources(
  `process_creation/windows` = {
    SELECT *
    FROM parse_evtx(
      filename= EventLogDirectory + "/Microsoft-Windows-Sysmon%4Operational.evtx")
  },
  `*/windows/sysmon` = {
    SELECT *
    FROM parse_evtx(
      filename= EventLogDirectory + "/Microsoft-Windows-Sysmon%4Operational.evtx")
  })

  LET StandardSigmaFieldMapping &lt;= dict(
    AccessList="x=&gt;x.EventData.AccessList",
    AccessMask="x=&gt;x.EventData.AccessMask",
    Accesses="x=&gt;x.EventData.Accesses",
    AccountDomain="x=&gt;x.EventData.AccountDomain",
    AccountName="x=&gt;x.EventData.AccountName",
    Account_Name="x=&gt;x.EventData.Account_Name",
    Action="x=&gt;x.EventData.Action",
    AllowedToDelegateTo="x=&gt;x.EventData.AllowedToDelegateTo",
    ApplicationPath="x=&gt;x.EventData.ApplicationPath",
    AttributeLDAPDisplayName="x=&gt;x.EventData.AttributeLDAPDisplayName",
    AttributeValue="x=&gt;x.EventData.AttributeValue",
    AuditPolicyChanges="x=&gt;x.EventData.AuditPolicyChanges",
    AuditSourceName="x=&gt;x.EventData.AuditSourceName",
    AuthenticationPackageName="x=&gt;x.EventData.AuthenticationPackageName",
    CallTrace="x=&gt;x.EventData.CallTrace",
    CallerProcessName="x=&gt;x.EventData.CallerProcessName",
    Caller_Process_Name="x=&gt;x.EventData.Caller_Process_Name",
    CallingProcessName="x=&gt;x.EventData.CallingProcessName",
    CategoryName="x=&gt;x.EventData.`Category Name`",
    CertThumbprint="x=&gt;x.EventData.CertThumbprint",
    Channel="x=&gt;x.System.Channel",
    ClassName="x=&gt;x.EventData.ClassName",
    ClientAddress="x=&gt;x.EventData.ClientAddress",
    Client_Address="x=&gt;x.EventData.Client_Address",
    ClientName="x=&gt;x.EventData.ClientName",
    CommandLine="x=&gt;x.EventData.CommandLine",
    Company="x=&gt;x.EventData.Company",
    Computer="x=&gt;x.System.Computer",
    ComputerName="x=&gt;x.System.Computer",
    ContextInfo="x=&gt;x.EventData.ContextInfo",
    CurrentDirectory="x=&gt;x.EventData.CurrentDirectory",
    Description="x=&gt;x.EventData.Description",
    DestAddress="x=&gt;x.EventData.DestAddress",
    DestPort="x=&gt;x.EventData.DestPort",
    Destination="x=&gt;x.EventData.Destination",
    DestinationAddress="x=&gt;x.EventData.DestinationAddress",
    DestinationHostname="x=&gt;x.EventData.DestinationHostname",
    DestinationIp="x=&gt;x.EventData.DestinationIp",
    DestinationIsIpv6="x=&gt;x.EventData.DestinationIsIpv6",
    DestinationPort="x=&gt;x.EventData.DestinationPort",
    Details="x=&gt;x.EventData.Details",
    DetectionSource="x=&gt;x.EventData.DetectionSource",
    DetectionUser="x=&gt;x.EventData.`Detection User`",
    Device="x=&gt;x.EventData.Device",
    DeviceClassName="x=&gt;x.EventData.DeviceClassName",
    DeviceDescription="x=&gt;x.EventData.DeviceDescription",
    DeviceInstanceID="x=&gt;x.UserData.InstallDeviceID.DeviceInstanceID",
    DeviceName="x=&gt;x.EventData.DeviceName",
    DomainName="x=&gt;x.EventData.SubjectDomainName",
    DriverDescription="x=&gt;x.UserData.InstallDeviceID.DriverDescription",
    DriverProvider="x=&gt;x.UserData.InstallDeviceID.DriverProvider",
    InstallStatus="x=&gt;x.UserData.InstallDeviceID.InstallStatus",
    EngineVersion="x=&gt;x.EventData.EngineVersion",
    ErrorCode="x=&gt;x.EventData.ErrorCode",
    EventID="x=&gt;x.System.EventID.Value",
    EventType="x=&gt;x.EventData.EventType",
    ExecutionProcessID="x=&gt;x.System.Execution_attributes.ProcessID",
    FailureCode="x=&gt;x.EventData.FailureCode",
    FilePath="x=&gt;x.EventData.FilePath",
    FileVersion="x=&gt;x.EventData.FileVersion",
    Filename="x=&gt;x.EventData.Filename",
    GrantedAccess="x=&gt;x.EventData.GrantedAccess",
    GroupName="x=&gt;x.EventData.GroupName",
    GroupSid="x=&gt;x.EventData.GroupSid",
    Hashes="x=&gt;x.EventData.Hashes",
    HiveName="x=&gt;x.EventData.HiveName",
    HostApplication="x=&gt;x.EventData.HostApplication",
    HostName="x=&gt;x.EventData.HostName",
    HostVersion="x=&gt;x.EventData.HostVersion",
    Image="x=&gt;x.EventData.Image",
    image="x=&gt;x.EventData.Image",
    ImageLoaded="x=&gt;x.EventData.ImageLoaded",
    ImagePath="x=&gt;x.EventData.ImagePath",
    Imphash="x=&gt;x.EventData.Hashes",
    Initiated="x=&gt;x.EventData.Initiated",
    InstanceID="x=&gt;x.UserData.UMDFHostDeviceArrivalBegin.InstanceId",
    IntegrityLevel="x=&gt;x.EventData.IntegrityLevel",
    IpAddress="x=&gt;x.EventData.IpAddress",
    IpPort="x=&gt;x.EventData.IpPort",
    JobTitle="x=&gt;x.EventData.name",
    KeyLength="x=&gt;x.EventData.KeyLength",
    Keywords="x=&gt;x.System.Keywords",
    LDAPDisplayName="x=&gt;x.EventData.LDAPDisplayName",
    LayerRTID="x=&gt;x.EventData.LayerRTID",
    Level="x=&gt;x.System.Level",
    LogFileClearedChannel="x=&gt;x.UserData.LogFileCleared.Channel",
    LogFileClearedSubjectUserName="x=&gt;x.UserData.LogFileCleared.SubjectUserName",
    LogonId="x=&gt;x.EventData.LogonId",
    LogonID="x=&gt;x.EventData.LogonID",
    LogonProcessName="x=&gt;x.EventData.LogonProcessName",
    LogonType="x=&gt;x.EventData.LogonType",
    Logon_Account="x=&gt;x.EventData.Logon_Account",
    MachineName="x=&gt;x.EventData.MachineName",
    MemberName="x=&gt;x.EventData.MemberName",
    MemberSid="x=&gt;x.EventData.MemberSid",
    Message="x=&gt;x.EventData",
    ModifyingApplication="x=&gt;x.EventData.ModifyingApplication",
    NewName="x=&gt;x.EventData.NewName",
    NewTemplateContent="x=&gt; Event.EventData.NewTemplateContent",
    NewUacValue="x=&gt;x.EventData.NewUacValue",
    NewValue="x=&gt;x.EventData.NewValue",
    New_Value="x=&gt;x.EventData.`New Value`",
    NewProcessName="x=&gt;x.EventData.NewProcessName",
    NewProcessId="x=&gt;x.EventData.NewProcessId",
    ObjectClass="x=&gt;x.EventData.ObjectClass",
    ObjectName="x=&gt;x.EventData.ObjectName",
    ObjectServer="x=&gt;x.EventData.ObjectServer",
    ObjectType="x=&gt;x.EventData.ObjectType",
    ObjectValueName="x=&gt;x.EventData.ObjectValueName",
    OldUacValue="x=&gt;x.EventData.OldUacValue",
    Origin="x=&gt;x.EventData.Origin",
    OriginalFileName="x=&gt;x.EventData.OriginalFileName",
    OriginalFilename="x=&gt;x.EventData.OriginalFileName",
    param1="x=&gt;x.EventData.param1",
    param2="x=&gt;x.EventData.param2",
    param3="x=&gt;x.EventData.param3",
    param4="x=&gt;x.EventData.param4",
    param5="x=&gt;x.EventData.param5",
    ParentCommandLine="x=&gt;x.EventData.ParentCommandLine",
    ParentImage="x=&gt;x.EventData.ParentImage",
    ParentIntegrityLevel="x=&gt;x.EventData.ParentIntegrityLevel",
    ParentProcessName="x=&gt;x.EventData.ParentProcessName",
    ParentUser="x=&gt;x.EventData.ParentUser",
    PasswordLastSet="x=&gt;x.EventData.PasswordLastSet",
    Path="x=&gt;x.EventData.Path",
    Payload="x=&gt;x.EventData.Payload",
    PipeName="x=&gt;x.EventData.PipeName",
    PossibleCause="x=&gt;x.UserData.PossibleCause",
    PreAuthType="x=&gt;x.EventData.PreAuthType",
    PrivilegeList="x=&gt;x.EventData.PrivilegeList",
    ProcessCommandLine="x=&gt;x.EventData.ProcessCommandLine",
    ProcessGuid="x=&gt;x.EventData.ProcessGuid",
    ProcessId="x=&gt;x.EventData.ProcessId",
    ProcessName="x=&gt;x.EventData.ProcessName",
    Product="x=&gt;x.EventData.Product",
    Properties="x=&gt;x.EventData.Properties",
    Provider="x=&gt;x.UserData.Provider",
    ProviderName="x=&gt;x.System.Provider_attributes.Name",
    Provider_Name="x=&gt;x.System.Provider_attributes.Name",
    QNAME="x=&gt;x.EventData.QNAME",
    query="x=&gt;x.EventData.Query",
    Query="x=&gt;x.UserData.Query",
    QueryName="x=&gt;x.EventData.QueryName",
    QueryResults="x=&gt;x.EventData.QueryResults",
    QueryStatus="x=&gt;x.EventData.QueryStatus",
    RelativeTargetName="x=&gt;x.EventData.RelativeTargetName",
    RuleName="x=&gt;x.EventData.RuleName",
    SAMAccountName="x=&gt;x.EventData.SamAccountName",
    ScriptBlockText="x=&gt;x.EventData.ScriptBlockText",
    SearchFilter="x=&gt;x.System.SearchFilter",
    SecurityUserID="x=&gt;x.System.Security_attributes.UserID",
    ServerName="x=&gt;x.System.ServerName",
    Service="x=&gt;x.EventData.Service",
    ServiceFileName="x=&gt;x.EventData.ServiceFileName",
    ServiceName="x=&gt;x.EventData.ServiceName",
    ServicePrincipalNames="x=&gt;x.EventData.ServicePrincipalNames",
    ServiceStartType="x=&gt;x.EventData.ServiceStartType",
    ServiceType="x=&gt;x.EventData.ServiceType",
    SeverityID="x=&gt;x.EventData.`Severity ID`",
    SeverityName="x=&gt;x.EventData.`Severity Name`",
    ShareLocalPath="x=&gt;x.EventData.ShareLocalPath",
    ShareName="x=&gt;x.EventData.ShareName",
    SidHistory="x=&gt;x.EventData.SidHistory",
    Signature="x=&gt;x.EventData.Signature",
    SignatureStatus="x=&gt;x.EventData.SignatureStatus",
    Signed="x=&gt;x.EventData.Signed",
    Source="x=&gt;x.System.Provider_Name",
    SourceAddress="x=&gt;x.EventData.SourceAddress",
    SourceImage="x=&gt;x.EventData.SourceImage",
    SourceNetworkAddress="x=&gt;x.EventData.SourceNetworkAddress",
    SourcePort="x=&gt;x.EventData.SourcePort",
    Source_Name="x=&gt;x.EventData.`Source Name`",
    Source_Network_Address="x=&gt;x.EventData.Source_Network_Address",
    Source_WorkStation="x=&gt;x.EventData.Source_WorkStation",
    StartAddress="x=&gt;x.EventData.StartAddress",
    StartFunction="x=&gt;x.EventData.StartFunction",
    StartModule="x=&gt;x.EventData.StartModule",
    StartType="x=&gt;x.EventData.StartType",
    State="x=&gt;x.EventData.State",
    Status="x=&gt;x.EventData.Status",
    SubStatus="x=&gt;x.EventData.SubStatus",
    SubjectDomainName="x=&gt;x.EventData.SubjectDomainName",
    SubjectLogonId="x=&gt;x.EventData.SubjectLogonId",
    SubjectUserName="x=&gt;x.EventData.SubjectUserName",
    SubjectUserSid="x=&gt;x.EventData.SubjectUserSid",
    TargetDomainName="x=&gt;x.EventData.TargetDomainName",
    TargetFilename="x=&gt;x.EventData.TargetFilename",
    TargetInfo="x=&gt;x.EventData.TargetInfo",
    TargetImage="x=&gt;x.EventData.TargetImage",
    TargetLogonId="x=&gt;x.EventData.TargetLogonId",
    TargetObject="x=&gt;x.EventData.TargetObject",
    TargetProcessAddress="x=&gt;x.EventData.TargetProcessAddress",
    TargetServerName="x=&gt;x.EventData.TargetServerName",
    TargetSid="x=&gt;x.EventData.TargetSid",
    TargetUserName="x=&gt;x.EventData.TargetUserName",
    TaskDate="x=&gt;x.EventData.TaskContent",
    TaskName="x=&gt;x.EventData.TaskName",
    TemplateContent="x=&gt;x.EventData.TemplateContent",
    ThreatName="x=&gt;x.EventData.`Threat Name`",
    TicketEncryptionType="x=&gt;x.EventData.TicketEncryptionType",
    TicketOptions="x=&gt;x.EventData.TicketOptions",
    Url="x=&gt;x.EventData.url",
    User="x=&gt;x.EventData.User",
    UserName="x=&gt;x.EventData.UserName",
    Value="x=&gt;x.EventData.Value",
    Version="x=&gt;x.System.Version",
    WindowsDefenderProcessName="x=&gt;x.EventData.`Process Name`",
    Workstation="x=&gt;x.EventData.Workstation",
    WorkstationName="x=&gt;x.EventData.WorkstationName",
    param1="x=&gt;x.EventData.param1",
    param2="x=&gt;x.EventData.param2",
    service="x=&gt;x.EventData.Service",
    sha1="x=&gt;x.EventData.Hashes_sha1",
    UserDataProviderName="x=&gt;x.UserData.Operation_StartedOperational.ProviderName",
    UserDataCode="x=&gt;x.UserData.Operation_StartedOperational.Code",
    UserDataHostProcess="x=&gt;x.UserData.Operation_StartedOperational.HostProcess",
    UserDataProviderPath="x=&gt;x.UserData.Operation_StartedOperational.ProviderPath",
    UserDataProcessID="x=&gt;x.UserData.Operation_StartedOperational.ProcessID",
    UserDataNamespace="x=&gt;x.UserData.Operation_ESStoConsumerBinding.Namespace",
    UserDataNamespaceName="x=&gt;x.UserData.Operation_TemporaryEssStarted.NamespaceName",
    UserDataQuery="x=&gt;x.UserData.Operation_TemporaryEssStarted.Query",
    UserDataUser="x=&gt;x.UserData.Operation_TemporaryEssStarted.User",
    UserDataProcessid="x=&gt;x.UserData.Operation_TemporaryEssStarted.Processid",
    UserDataConsumer="x=&gt;x.UserData.Operation_ESStoConsumerBinding.CONSUMER",
    UserDataESS="x=&gt;x.UserData.Operation_ESStoConsumerBinding.ESS",
    UserDataPossibleCause="x=&gt;x.UserData.Operation_ESStoConsumerBinding.PossibleCause",
    UserDataParam1="x=&gt;x.UserData.EventXML.Param1",
    UserDataParam2="x=&gt;x.UserData.EventXML.Param2",
    UserDataParam3="x=&gt;x.UserData.EventXML.Param3",
    UserDataUser="x=&gt;x.UserData.EventXML.User",
    UserDataSessionID="x=&gt;x.UserData.EventXML.SessionID",
    UserDataAddress="x=&gt;x.UserData.EventXML.Address",
    SysmonVersion="x=&gt;x.EventData.SysmonVersion",
    OperationEssStartedNamespaceName="x=&gt;x.UserData.Operation_EssStarted.NamespaceName",
    OperationEssStartedQuery="x=&gt;x.UserData.Operation_EssStarted.Query",
    OperationEssStartedUser="x=&gt;x.UserData.Operation_EssStarted.User",
    OperationEssStartedProcessid="x=&gt;x.UserData.Operation_EssStarted.Processid",
    OperationEssStartedProvider="x=&gt;x.UserData.Operation_EssStarted.Provider",
    OperationEssStartedPossibleCause="x=&gt;x.UserData.Operation_EssStarted.PossibleCause",
    DvrFmwkInstanceId="x=&gt;x.UserData.UMDFHostDeviceRequest.InstanceId",
    DvrFmwk2003InstanceId="x=&gt;x.UserData.UMDFHostDeviceArrivalBegin.InstanceId"
  )

sources:
- query: |
    LET Rules = InlineSigmaRules ||
       if(condition=SigmaRuleFile, then=SigmaRuleFile)

    SELECT * FROM sigma(
       rules=split(string= Rules, sep_string="\n---\n"),
       log_sources= StandardSigmaLogSource, debug=Debug,
       field_mapping= StandardSigmaFieldMapping)

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.detection.psexecservice.kill.md
======
---
title: Windows.Detection.PsexecService.Kill
hidden: true
tags: [Client Event Artifact]
---

Psexec can launch a service remotely. This artifact implements a
client side response plan whereby all the child processes of the
service are killed.

NOTE: There is an inherent race between detection and response. If
the psexec is very quick we will miss it.


<pre><code class="language-yaml">
name: Windows.Detection.PsexecService.Kill
description: |
    Psexec can launch a service remotely. This artifact implements a
    client side response plan whereby all the child processes of the
    service are killed.

    NOTE: There is an inherent race between detection and response. If
    the psexec is very quick we will miss it.

type: CLIENT_EVENT

parameters:
  - name: yaraRule
    type: yara
    default: |
        rule Hit {
           strings:
             $a = "psexec" nocase wide ascii
           condition:
             any of them
        }

sources:
  - query: |
        SELECT * FROM foreach(
          row={ SELECT * FROM Artifact.Windows.Detection.PsexecService() },
          query={
             SELECT ServiceName, PathName, Modified, FileSize, Timestamp,
                    ServiceType, ChildProcess, Stdout, Stderr FROM execve(
               argv=["taskkill", "/PID", PID, "/T", "/F"])
        })

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/macos.system.packages.md
======
---
title: MacOS.System.Packages
hidden: true
tags: [Client Artifact]
---

Parse packages installed on Macs


<pre><code class="language-yaml">
name: MacOS.System.Packages
description: |
  Parse packages installed on Macs
parameters:
  - name: Length
    description: Size (in bytes) of output that will be returned
    type: int
    default: "100000000"
sources:
  - precondition: |
      SELECT OS From info() where OS = 'darwin'
    query: |
        LET packages = SELECT parse_json(data=Stdout) AS Json 
          FROM execve(argv=[
            "system_profiler", "-json", "SPApplicationsDataType"
          ], length=Length)

        SELECT  _name AS Name,
                get(field="version") AS Version, 
                path AS Path, 
                lastModified AS LastModified, 
                obtained_from AS ObtainedFrom,
                get(field="signed_by") AS SignedBy,
                arch_kind AS _Architecture
        FROM foreach(
           row=packages[0].Json.SPApplicationsDataType)

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.applications.chrome.cookies.md
======
---
title: Windows.Applications.Chrome.Cookies
hidden: true
tags: [Client Artifact]
---

Enumerate the users chrome cookies.

The cookies are typically encrypted by the DPAPI using the user's
credentials. Since Velociraptor is typically not running in the user
context we can not decrypt these. It may be possible to decrypt the
cookies off line.

The pertinant information from a forensic point of view is the
user's Created and LastAccess timestamp and the fact that the user
has actually visited the site and obtained a cookie.

## NOTES:

This artifact is deprecated in favor of
Generic.Forensic.SQLiteHunter and will be removed in future


<pre><code class="language-yaml">
name: Windows.Applications.Chrome.Cookies
description: |
  Enumerate the users chrome cookies.

  The cookies are typically encrypted by the DPAPI using the user's
  credentials. Since Velociraptor is typically not running in the user
  context we can not decrypt these. It may be possible to decrypt the
  cookies off line.

  The pertinant information from a forensic point of view is the
  user's Created and LastAccess timestamp and the fact that the user
  has actually visited the site and obtained a cookie.

  ## NOTES:

  This artifact is deprecated in favor of
  Generic.Forensic.SQLiteHunter and will be removed in future

parameters:
  - name: cookieGlobs
    default: \AppData\Local\Google\Chrome\User Data\*\Cookies
  - name: cookieSQLQuery
    default: |
      SELECT creation_utc, host_key, name, value, path, expires_utc,
             last_access_utc, encrypted_value
      FROM cookies
  - name: userRegex
    default: .
    type: regex

precondition: SELECT OS From info() where OS = 'windows'

sources:
  - query: |
        LET cookie_files = SELECT * from foreach(
          row={
             SELECT Uid, Name AS User,
                    expand(path=Directory) AS HomeDirectory
             FROM Artifact.Windows.Sys.Users()
             WHERE Name =~ userRegex
          },
          query={
             SELECT User, OSPath, Mtime
             FROM glob(root=HomeDirectory, globs=cookieGlobs)
          })

        SELECT * FROM foreach(row=cookie_files,
          query={
            SELECT timestamp(winfiletime=creation_utc * 10) as Created,
                   timestamp(winfiletime=last_access_utc * 10) as LastAccess,
                   timestamp(winfiletime=expires_utc * 10) as Expires,
                   host_key, name, path, value,
                   base64encode(string=encrypted_value) as EncryptedValue
            FROM sqlite(
              file=OSPath,
              query=cookieSQLQuery)
          })

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/server.internal.clientping.md
======
---
title: Server.Internal.ClientPing
hidden: true
tags: [Internal Artifact]
---

An internal event channel for notifying about client pings.


<pre><code class="language-yaml">
name: Server.Internal.ClientPing
type: INTERNAL
description: |
  An internal event channel for notifying about client pings.

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/server.internal.clientconflict.md
======
---
title: Server.Internal.ClientConflict
hidden: true
tags: [Internal Artifact]
---

This event artifact is an internal event stream receiving events
about client conflict.

When two clients attempt to connect to the server with the same
client id, the server rejects one of these with a 409 Conflict HTTP
message. The client id will be forwarded on this artifact as well so
the server may take action.


<pre><code class="language-yaml">
name: Server.Internal.ClientConflict
description: |
  This event artifact is an internal event stream receiving events
  about client conflict.

  When two clients attempt to connect to the server with the same
  client id, the server rejects one of these with a 409 Conflict HTTP
  message. The client id will be forwarded on this artifact as well so
  the server may take action.

type: INTERNAL

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/admin.client.upgrade.redhat.md
======
---
title: Admin.Client.Upgrade.RedHat
hidden: true
tags: [Client Artifact]
---

Remotely push new client updates to Red Hat hosts.

NOTE: This artifact requires that you supply a client Red Hat package using the
tools interface or using the "rpm client" command. Simply click on the tool
in the GUI and upload a package.


<pre><code class="language-yaml">
name: Admin.Client.Upgrade.RedHat
description: |
  Remotely push new client updates to Red Hat hosts.

  NOTE: This artifact requires that you supply a client Red Hat package using the
  tools interface or using the "rpm client" command. Simply click on the tool
  in the GUI and upload a package.

tools:
  - name: VelociraptorRedHat

parameters:
  - name: SleepDuration
    default: "600"
    type: int
    description: |
      The package is typically large and we do not want to
      overwhelm the server so we stagger the download over this many
      seconds.

  - name: ServiceName
    default: "velociraptor_client"
    type: str
    description: |
      The name of the service to restart after the upgrade.

sources:
  - precondition:
      SELECT OS From info() where OS =~ 'linux'

    query:  |
      // FetchBinary downloads to /tmp on linux
      LET bin &lt;= SELECT OSPath AS Dest
      FROM Artifact.Generic.Utils.FetchBinary(
         ToolName="VelociraptorRedHat", IsExecutable=FALSE,
         SleepDuration=SleepDuration)

      // Call the binary and return all its output in a single row.
      // If we fail to download the binary we do not run the command.
      SELECT * FROM foreach(row=bin,
      query={
        SELECT * FROM chain(
          // Install the new client (Disabled preun because older versions
          // had a bug where preun would shut down the service - see #3122).

          b={SELECT * FROM execve(argv=["rpm", "--nopreun", "-U", str(str=Dest)])},
          c={SELECT * FROM execve(argv=["systemctl", "restart", ServiceName])}
        )
      })

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.system.signers.md
======
---
title: Windows.System.Signers
hidden: true
tags: [Client Artifact]
---

This artifact searches for all signed files and stacks them by signer.


<pre><code class="language-yaml">
name: Windows.System.Signers
description: |
   This artifact searches for all signed files and stacks them by signer.

parameters:
   - name: ExecutableGlobs
     default: C:/Windows/**/*.{dll,exe}
   - name: ShowAllSigners
     description: When checked we show all signed files instead of stacking them.
     type: bool
   - name: DISABLE_DANGEROUS_API_CALLS
     type: bool
     description: |
       Enable this to disable potentially flakey APIs which may cause
       crashes.

sources:
  - precondition:
      SELECT OS From info() where OS = 'windows'

    query: |
        LET results = SELECT OSPath, count() AS Count,
               parse_pe(file=OSPath).Authenticode.Signer.Subject AS Signer
        FROM glob(globs=ExecutableGlobs)
        WHERE Signer

        SELECT * FROM if(condition=ShowAllSigners,
        then={
            SELECT OSPath, Signer FROM results
        }, else={
            SELECT Count, Signer FROM results
            GROUP BY Signer
            ORDER BY Count DESC
        })

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.forensics.sam.md
======
---
title: Windows.Forensics.SAM
hidden: true
tags: [Client Artifact]
---

Parses user account information from the SAM hive.

Based on Omer Yampel's parser


<pre><code class="language-yaml">
name: Windows.Forensics.SAM
description: |
   Parses user account information from the SAM hive.

   Based on Omer Yampel's parser

reference:
  - https://github.com/yampelo/samparser/blob/master/samparser.py

parameters:
   - name: SAMPath
     description: Path to the SAM file to parse.
     default: C:/Windows/System32/Config/SAM

export: |
     // Reference: https://github.com/yampelo/samparser/blob/master/samparser.py
     LET Profile = '''
     [
       ["F", 0, [
         ["LastLoginDate", 8, "WinFileTime"],
         ["PasswordResetDate", 24, "WinFileTime"],
         ["PasswordFailDate", 40, "WinFileTime"],
         ["RID", 48, "uint32"],
         ["Flags", 56, "Flags", {
             "type": "uint16",
             "bitmap": {
              "Account Disabled": 0,
              "Home directory required": 1,
              "Password not required": 2,
              "Temporary duplicate account": 3,
              "Normal user account": 4,
              "MNS logon user account": 5,
              "Interdomain trust account": 6,
              "Workstation trust account": 7,
              "Server trust account": 8,
              "Password does not expire": 9,
              "Account auto locked": 10
             }
         }],
         ["FailedLoginCount", 64, "uint16"],
         ["LoginCount", 66, "uint16"],
       ]],
       ["V", 0, [
        ["AccountType", 4, "Enumeration", {
            "type": "uint32",
            "choices": {
               "188" : "Default Admin User",
               "212" : "Custom Limited Acct",
               "176" : "Default Guest Acct"
            }
        }],
        ["__username_offset", 12, "uint32"],
        ["__username_length", 16, "uint32"],
        ["username", "x=&gt;x.__username_offset + 0xcc", "String", {
            "length": "x=&gt;x.__username_length",
            "encoding": "utf16",
        }],
        ["__fullname_offset", 24, "uint32"],
        ["__fullname_length", 28, "uint32"],
        ["fullname", "x=&gt;x.__fullname_offset + 0xcc", "String", {
            "length": "x=&gt;x.__fullname_length",
            "encoding": "utf16",
        }],
        ["__comment_offset", 36, "uint32"],
        ["__comment_length", 40, "uint32"],
        ["comment", "x=&gt;x.__comment_offset + 0xcc", "String", {
            encoding: "utf16",
            length: "x=&gt;x.__comment_length",
        }],

        ["__driveletter_offset", 84, "uint32"],
        ["__driveletter_length", 88, "uint32"],
        ["driveletter", "x=&gt;x.__driveletter_offset + 0xcc", "String", {
            encoding: "utf16",
            length: "x=&gt;x.__driveletter_length",
        }],

        ["__logon_script_offset", 96, "uint32"],
        ["__logon_script_length", 100, "uint32"],
        ["logon_script", "x=&gt;x.__logon_script_offset + 0xcc", "String", {
            encoding: "utf16",
            length: "x=&gt;x.__logon_script_length",
        }],

        ["__profile_path_offset", 108, "uint32"],
        ["__profile_path_length", 112, "uint32"],
        ["profile_path", "x=&gt;x.__profile_path_offset + 0xcc", "String", {
            encoding: "utf16",
            length: "x=&gt;x.__profile_path_length",
        }],

        ["__workstation_offset", 120, "uint32"],
        ["__workstation_length", 124, "uint32"],
        ["workstation", "x=&gt;x.__workstation_offset + 0xcc", "String", {
            encoding: "utf16",
            length: "x=&gt;x.__workstation_length",
        }],

        ["__lmpwd_hash_offset", 156, "uint32"],
        ["__lmpwd_hash_length", 160, "uint32"],
        ["lmpwd_hash", "x=&gt;x.__lmpwd_hash_offset + 0xcc", "String", {
            encoding: "utf16",
            length: "x=&gt;x.__lmpwd_hash_length",
        }],

        ["__ntpwd_hash_offset", 168, "uint32"],
        ["__ntpwd_hash_length", 172, "uint32"],
        ["ntpwd_hash", "x=&gt;x.__ntpwd_hash_offset + 0xcc", "String", {
            encoding: "utf16",
            length: "x=&gt;x.__ntpwd_hash_length",
        }]
       ]]
     ]
     '''

precondition:
  SELECT OS From info() where OS = 'windows'

sources:
  - name: Parsed
    query: |
        SELECT Key.OSPath.Path AS Key,
           Key.OSPath.DelegatePath AS Hive,
           get(field="F") AS _F,
           get(field="V") AS _V,
           get(field="SupplementalCredentials") AS _SupplementalCredentials,
           parse_binary(accessor="data", filename=F,
                        profile=Profile, struct="F") AS ParsedF,
           parse_binary(accessor="data", filename=V,
                        profile=Profile, struct="V") AS ParsedV
        FROM read_reg_key(
           globs='SAM\\Domains\\Account\\Users\\0*',
           root=pathspec(DelegatePath=SAMPath),
           accessor="raw_reg")
        WHERE _F AND _V

  - name: CreateTimes
    description: "Show the modified times of the \\SAM\\Domains\\Account\\Users\\Names keys"
    query: |
      SELECT Name AS Username, Mtime AS CreatedTime
      FROM glob(globs='SAM\\Domains\\Account\\Users\\Names\\*',
                root=pathspec(DelegatePath=SAMPath),
                accessor="raw_reg")
      WHERE Data.type =~ "Key"

column_types:
  - name: F
    type: hex
  - name: V
    type: hex

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/server.alerts.processcreation.md
======
---
title: Server.Alerts.ProcessCreation
hidden: true
tags: [Server Event Artifact]
---

This artifact alerts when a process was detected with the artifact 'Windows.Detection.ProcessCreation' (which is a client_event artifact that needs to be enabled first).


<pre><code class="language-yaml">
name: Server.Alerts.ProcessCreation
description: |
   This artifact alerts when a process was detected with the artifact 'Windows.Detection.ProcessCreation' (which is a client_event artifact that needs to be enabled first).

author: Jos Clephas - @DfirJos

type: SERVER_EVENT

parameters:
  - name: SlackToken
    description: The token URL obtained from Slack/Teams/Discord (or basicly any communication-service that supports webhooks). Leave blank to use server metadata. e.g. https://hooks.slack.com/services/XXXX/YYYY/ZZZZ

sources:
  - query: |
        LET token_url = if(
           condition=SlackToken,
           then=SlackToken,
           else=server_metadata().SlackToken)

        LET hits = SELECT * from watch_monitoring(artifact='Windows.Detection.ProcessCreation')

        SELECT * FROM foreach(row=hits,
        query={
           SELECT EventData.CommandLine, EventData, Hostname, ClientId, Url, Content, Response FROM http_client(
            data=serialize(item=dict(
                text=format(format="Alert - Command detected '%v' on system %v with client Id %v. Syslog timestamp: %v ",
                            args=[EventData.CommandLine, Hostname, ClientId, Timestamp])),
                format="json"),
            headers=dict(`Content-Type`="application/json"),
            method="POST",
            url=token_url)
        })

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.registry.enableunsafeclientmailrules.md
======
---
title: Windows.Registry.EnableUnsafeClientMailRules
hidden: true
tags: [Client Artifact]
---

Checks for Outlook EnableUnsafeClientMailRules = 1 (turned on).
This registry key enables execution from Outlook inbox rules which can be used as a persistence mechanism.
Microsoft has released a patch to disable execution but attackers can reenable by changing this value to 1.

HKEY_USERS\*\Software\Microsoft\Office\*\Outlook\Security\EnableUnsafeClientMailRules = 0 (expected)
https://support.microsoft.com/en-us/help/3191893/how-to-control-the-rule-actions-to-start-an-application-or-run-a-macro


<pre><code class="language-yaml">
name: Windows.Registry.EnableUnsafeClientMailRules
description: |
  Checks for Outlook EnableUnsafeClientMailRules = 1 (turned on).
  This registry key enables execution from Outlook inbox rules which can be used as a persistence mechanism.
  Microsoft has released a patch to disable execution but attackers can reenable by changing this value to 1.

  HKEY_USERS\*\Software\Microsoft\Office\*\Outlook\Security\EnableUnsafeClientMailRules = 0 (expected)
  https://support.microsoft.com/en-us/help/3191893/how-to-control-the-rule-actions-to-start-an-application-or-run-a-macro

author: "@mgreen27"

precondition: SELECT OS From info() where OS = 'windows'

parameters:
   - name: KeyGlob
     default: Software\Microsoft\Office\*\Outlook\Security\
   - name: userRegex
     default: .
     type: regex

sources:
  - query: |
        LET UserProfiles = Select Name as Username,
            {
                SELECT OSPath FROM glob(root=expand(path=Directory),
                   globs="/NTUSER.DAT", accessor="auto")
            } as NTUser,
            expand(path=Directory) as Directory
        FROM Artifact.Windows.Sys.Users()
        WHERE Directory and NTUser and Name =~ userRegex

         SELECT * FROM foreach(
           row={
              SELECT Username, NTUser FROM UserProfiles
           },
           query={
              SELECT Username,
                NTUser as Userhive,
                OSPath.Path as Key,
                key.Mtime AS LastModified,
                EnableUnsafeClientMailRules,
                OutlookSecureTempFolder
              FROM read_reg_key(
                 globs=KeyGlob,
                 root=pathspec(DelegatePath=OSPath),
                 accessor="raw_reg")
              WHERE EnableUnsafeClientMailRules = 1
           })

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/server.internal.metadatamodifications.md
======
---
title: Server.Internal.MetadataModifications
hidden: true
tags: [Server Event Artifact]
---

This event artifact is an internal event stream over which
notifications of server metadata modifications are sent.

Note: This is an automated system artifact. You do not need to start it.


<pre><code class="language-yaml">
name: Server.Internal.MetadataModifications
description: |
  This event artifact is an internal event stream over which
  notifications of server metadata modifications are sent.

  Note: This is an automated system artifact. You do not need to start it.

type: SERVER_EVENT

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.eventlogs.cleared.md
======
---
title: Windows.EventLogs.Cleared
hidden: true
tags: [Client Artifact]
---

Extract Event Logs related to EventLog clearing
- Security Log  - EventID 1102
- System Log - EventID 104


<pre><code class="language-yaml">
name: Windows.EventLogs.Cleared
author: Matt Green - @mgreen27

description: |
  Extract Event Logs related to EventLog clearing
  - Security Log  - EventID 1102
  - System Log - EventID 104

reference:
  - https://attack.mitre.org/versions/v6/techniques/T1070/

type: CLIENT

parameters:
  - name: TargetGlob
    default: C:\Windows\System32\Winevt\Logs\{System,Security}.evtx
  - name: DateAfter
    type: timestamp
    description: "search for events after this date. YYYY-MM-DDTmm:hh:ssZ"
  - name: DateBefore
    type: timestamp
    description: "search for events before this date. YYYY-MM-DDTmm:hh:ssZ"

  - name: VSSAnalysisAge
    type: int
    default: 0
    description: |
      If larger than zero we analyze VSS within this many days
      ago. (e.g 7 will analyze all VSS within the last week).  Note
      that when using VSS analysis we have to use the ntfs accessor
      for everything which will be much slower.

sources:
  - query: |
      SELECT
        EventTime,
        UserData.LogFileCleared.Channel || Channel as ClearedLog,
        Message,
        UserData.LogFileCleared.SubjectDomainName + "\\" + UserData.LogFileCleared.SubjectUserName as Username,
        UserData.LogFileCleared.SubjectUserSid || UserSID as UserSID,
        dict(
            EventTime=EventTime,
            Computer=Computer,
            Channel=Channel,
            EventID=EventID,
            EventRecordID=EventRecordID,
            OSPath=OSPath,
            UserData=UserData
        ) as EventData
      FROM Artifact.Windows.EventLogs.EvtxHunter(EvtxGlob=TargetGlob,
            ChannelRegex='^(Security|System)$',
            IdRegex='^(1102|104)',
            IocRegex='clear|cleared',
            DateAfter=DateAfter,
            DateBefore=DateBefore,
            VSSAnalysisAge=VSSAnalysisAge)

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.registry.recentdocs.md
======
---
title: Windows.Registry.RecentDocs
hidden: true
tags: [Client Artifact]
---

This artifact extracts RecentDocs MRU from the target.

By default the artifact will target all users on the machine when run in
live mode but can be targeted directly using the HiveGlob parameter.

Output includes LastWriteTime of key and a list of MRU items in the
order specified in the MRUListEx key value.
MruEntries has the format: [KeyName] := [Parsed Key value]

Available filters include:
    - Time bounds to select LastWrite timestamp within time ranges.
    - EntryRegex to target specific entry values
    - UserRegex to target specific users. Note: this filter does not work
    when using HiveGlob.
    - SidRegex to target a specific SID.

Note: both UserRegex and SidRegex does not work when using HiveGlob
     and all MRU will be returned.


<pre><code class="language-yaml">
name: Windows.Registry.RecentDocs
author: Matt Green - @mgreen27
description: |
    This artifact extracts RecentDocs MRU from the target.

    By default the artifact will target all users on the machine when run in
    live mode but can be targeted directly using the HiveGlob parameter.

    Output includes LastWriteTime of key and a list of MRU items in the
    order specified in the MRUListEx key value.
    MruEntries has the format: [KeyName] := [Parsed Key value]

    Available filters include:
        - Time bounds to select LastWrite timestamp within time ranges.
        - EntryRegex to target specific entry values
        - UserRegex to target specific users. Note: this filter does not work
        when using HiveGlob.
        - SidRegex to target a specific SID.

    Note: both UserRegex and SidRegex does not work when using HiveGlob
         and all MRU will be returned.

parameters:
  - name: KeyGlob
    type: hidden
    default: Software\Microsoft\Windows\CurrentVersion\Explorer\RecentDocs\**
  - name: HiveGlob
    description: "optional hive glob to target for offline processing."
  - name: DateAfter
    description: "search for events after this date. YYYY-MM-DDTmm:hh:ssZ"
    type: timestamp
  - name: DateBefore
    description: "search for events before this date. YYYY-MM-DDTmm:hh:ssZ"
    type: timestamp
  - name: EntryRegex
    default: .
    description: "regex filter for document/entry name."
  - name: UserRegex
    default: .
    description: "regex filter for username over standard query."
  - name: SidRegex
    default: .
    description: "regex filter for user SID over standard query."
  - name: Profile
    type: hidden
    default: |
        [
            ["Target", 0, [
              ["Filename", 0, "String", {
                  encoding: "utf16",
              }],
            ]]
        ]

sources:
 - query: |
      -- time testing
      LET time_test(stamp) =
            if(condition= DateBefore AND DateAfter,
                then= stamp &lt; DateBefore AND stamp &gt; DateAfter,
                else=
            if(condition=DateBefore,
                then= stamp &lt; DateBefore,
                else=
            if(condition= DateAfter,
                then= stamp &gt; DateAfter,
                else= True
            )))


      -- dynamic function to extract RecentDocs order from MRUListEx data value
      LET find_order(value) = SELECT
            parse_binary(accessor='data',
                filename=substr(str=value,start=_value,end=_value + 4),
                struct='uint32') as Int
        FROM range(end=len(list=value),start=0,step=4)
        WHERE NOT Int = 4294967295

      -- NTUser method is most accurate
      LET NTUserValues = SELECT
            Mtime,
            OSPath.Components[-2] AS Type,
            OSPath.Components[-1] AS Name,
            if(condition= OSPath.Basename = 'MRUListEx',
               then= find_order(value=Data.value).Int,
               else= parse_binary(
                  accessor="data",
                  filename=Data.value,
                  profile=Profile, struct="Target").Filename ) as Value,
            Data,
            OSPath.DelegatePath as HiveName,
            OSPath,
            Username,
            UUID
        FROM Artifact.Windows.Registry.NTUser(KeyGlob=KeyGlob)
        WHERE Username =~ UserRegex
            AND UUID =~ SidRegex
            AND Data.type =~ 'BINARY'


      -- Glob method allows offline processing but can not filter by user
      LET GlobValues = SELECT
            Mtime,
            OSPath.Components[-2] AS Type,
            OSPath.Components[-1] AS Name,
            if(condition= OSPath.Basename = 'MRUListEx',
               then= find_order(value=Data.value).Int,
               else= parse_binary(
                  accessor="data",
                  filename=Data.value,
                  profile=Profile,
                  struct="Target").Filename ) as Value,
            Data,
            OSPath.DelegatePath as HiveName,
            OSPath
        FROM glob(
           globs=KeyGlob,
           root=pathspec(DelegatePath=HiveGlob),
           accessor="raw_reg")
        WHERE Data.type =~ 'BINARY'

      -- precalculate all hive values for performance
      LET AllValues &lt;= SELECT * FROM if(condition= HiveGlob,
                                        then={ SELECT * FROM GlobValues},
                                        else={ SELECT * FROM NTUserValues} )
            WHERE time_test(stamp=Mtime)


      -- memorise for lookup / performance
      LET Items &lt;= memoize(query={
            SELECT Type, Name, Value,
                Type + ':' + Name + ':' + HiveName  AS Key
            FROM AllValues
        }, key="Key")


      -- flattern output then add lookup of processed data
      LET flat_data(type,hivename) = SELECT *,
            str(str=Value) + ' := ' +
              get(item=Items, field=str(str=Type) + ':' +
              str(str=Value) + ':' + str(str=hivename) ).Value  AS Value
        FROM flatten(query={
            SELECT Mtime, Type, Name, Value,HiveName
            FROM AllValues
            WHERE Name = 'MRUListEx'
            AND Type = type AND HiveName = hivename
          })
         GROUP BY Value


      -- prep results
      LET results = SELECT Mtime as LastWriteTime, Type,
            flat_data(type=Type, hivename=HiveName).Value as MruEntries,
            OSPath.Path as Key,
            HiveName,
            if(condition=HiveGlob,
                then='', else=Username) as Username,
            if(condition=HiveGlob,
                then='', else=UUID) as UUID
          FROM AllValues
          WHERE Name = 'MRUListEx'


      -- print rows, remove Username/SID from offline
      SELECT * FROM if(condition=HiveGlob,
        then = {
            SELECT LastWriteTime, Type,
                if(condition= NOT MruEntries[0],
                    then= Null,
                    else= MruEntries) as MruEntries,
                Key, HiveName
            FROM results
        },
        else={
            SELECT LastWriteTime, Type,
                if(condition= NOT MruEntries[0],
                    then= Null,
                    else= MruEntries) as MruEntries,
                Key, HiveName, Username, UUID
            FROM results
        })
      WHERE format(format='%v', args=MruEntries) =~ EntryRegex

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/linux.proc.arp.md
======
---
title: Linux.Proc.Arp
hidden: true
tags: [Client Artifact]
---

ARP table via /proc/net/arp.

<pre><code class="language-yaml">
name: Linux.Proc.Arp
description: ARP table via /proc/net/arp.
parameters:
  - name: ProcNetArp
    default: /proc/net/arp
sources:
  - precondition: |
      SELECT OS From info() where OS = 'linux'

    query: |
        SELECT * from split_records(
           filenames=ProcNetArp,
           regex='\\s{3,20}',
           first_row_is_headers=true)

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/admin.events.postprocessuploads.md
======
---
title: Admin.Events.PostProcessUploads
hidden: true
tags: [Server Event Artifact]
---

Sometimes we would like to post process uploads collected as part of
the hunt's artifact collections

Post processing means to watch the hunt for completed flows and run
a post processing command on the files obtained from each host.

The command will receive the list of paths of the files uploaded by
the artifact. We dont actually care what the command does with those
files - we will just relay our stdout/stderr to the artifact's
result set.


<pre><code class="language-yaml">
name: Admin.Events.PostProcessUploads
description: |
  Sometimes we would like to post process uploads collected as part of
  the hunt's artifact collections

  Post processing means to watch the hunt for completed flows and run
  a post processing command on the files obtained from each host.

  The command will receive the list of paths of the files uploaded by
  the artifact. We dont actually care what the command does with those
  files - we will just relay our stdout/stderr to the artifact's
  result set.

type: SERVER_EVENT

required_permissions:
  - EXECVE

parameters:
  - name: uploadPostProcessCommand
    type: json_array
    description: |
      The command to run - must be a json array of strings! The list
      of files will be appended to the end of the command.
    default: |
      ["/bin/ls", "-l"]

  - name: uploadPostProcessArtifact
    description: |
      The name of the artifact to watch.
    default: Windows.Registry.NTUser.Upload

sources:
  - query: |
        LET files = SELECT Flow,
            uploadPostProcessCommand + file_store(path=Flow.uploaded_files) AS Argv
        FROM watch_monitoring(artifact='System.Flow.Completion')
        WHERE uploadPostProcessArtifact in Flow.artifacts_with_results

        SELECT * from foreach(
          row=files,
          query={
             SELECT Flow.session_id as FlowId, Argv,
                    Stdout, Stderr, ReturnCode
             FROM execve(argv=Argv)
          })

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.detection.psexecservice.md
======
---
title: Windows.Detection.PsexecService
hidden: true
tags: [Client Event Artifact]
---

PSExec works by installing a new service in the system. The service
can be renamed using the -r flag and therefore it is not enough to
just watch for a new service called psexecsvc.exe. This artifact
improves on this by scanning the service binary to detect the
original psexec binary.

NOTE that if the service is very quick we are unable to examine
the service binary in time and will miss it.


<pre><code class="language-yaml">
name: Windows.Detection.PsexecService
description: |
  PSExec works by installing a new service in the system. The service
  can be renamed using the -r flag and therefore it is not enough to
  just watch for a new service called psexecsvc.exe. This artifact
  improves on this by scanning the service binary to detect the
  original psexec binary.

  NOTE that if the service is very quick we are unable to examine
  the service binary in time and will miss it.

type: CLIENT_EVENT

parameters:
  - name: yaraRule
    type: yara
    default: |
        rule Hit {
           strings:
             $a = "psexec" nocase wide ascii
           condition:
             any of them
        }

sources:
  - query: |
        LET file_scan = SELECT  Name AS ServiceName,
               PathName, File.ModTime AS Modified,
               File.Size AS FileSize,
               String.Offset AS StringOffset,
               String.HexData AS StringContext,
               now() AS Timestamp,
               ServiceType, PID,
               {
                  SELECT Name, Exe, CommandLine
                  FROM pslist() WHERE Ppid = PID
                  LIMIT 2
               } AS ChildProcess
        FROM yara(rules=yaraRule, files=PathName)
        WHERE Rule

        LET service_creation = SELECT Parse,
            Parse.TargetInstance.Name AS Name,
            Parse.TargetInstance.PathName As PathName,
            Parse.TargetInstance.ServiceType As ServiceType,
            Parse.TargetInstance.ProcessId AS PID
        FROM wmi_events(
           query="SELECT * FROM __InstanceCreationEvent WITHIN 1 WHERE TargetInstance ISA 'Win32_Service'",
           wait=5000000,
           namespace="ROOT/CIMV2")

        SELECT * FROM foreach(
          row=service_creation,
          query=file_scan)

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.detection.processcreation.md
======
---
title: Windows.Detection.ProcessCreation
hidden: true
tags: [Client Event Artifact]
---

This artifact logs specific process creation events to
Velociraptor. It auto-installs Sysmon and it watches the Sysmon ETW
provider for new events.


<pre><code class="language-yaml">
name: Windows.Detection.ProcessCreation
description: |
  This artifact logs specific process creation events to
  Velociraptor. It auto-installs Sysmon and it watches the Sysmon ETW
  provider for new events.

author: Jos Clephas - @DfirJos

type: CLIENT_EVENT

tools:
  - name: SysmonBinary
    url: https://live.sysinternals.com/tools/sysmon64.exe
    serve_locally: true

  - name: SysmonConfig
    url: https://raw.githubusercontent.com/SwiftOnSecurity/sysmon-config/master/sysmonconfig-export.xml
    serve_locally: true

parameters:
  - name: ImageRegex
    default: .
  - name: CommandLineRegex
    default: .
  - name: ParentImageRegex
    default: .
  - name: OriginalFileNameRegex
    default: .
  - name: ParentUserRegex
    default: .
  - name: UserRegex
    default: .
  - name: HashesRegex
    default: .
  - name: ParentCommandLineRegex
    default: .
  - name: IntegrityLevelRegex
    default: .
  - name: ProductRegex
    default: .
  - name: CompanyRegex
    default: .
  - name: DescriptionRegex
    default: .
  - name: FileVersionRegex
    default: .
  - name: SysmonFileLocation
    description: If set, we check this location first for sysmon installed.
    default: C:/Windows/sysmon64.exe

sources:
  - precondition:
      SELECT OS From info() where OS = 'windows'

    query: |
      // Make sure sysmon is installed.
      LET _ &lt;= SELECT * FROM Artifact.Windows.Sysinternals.SysmonInstall(
         SysmonFileLocation=SysmonFileLocation)

      SELECT *, { SELECT Hostname FROM info() } as Hostname FROM Artifact.Windows.Sysinternals.SysmonLogForward()
      WHERE ID = 1 AND
        EventData.Image =~ ImageRegex AND
        EventData.CommandLine =~ CommandLineRegex AND
        EventData.ParentImage =~ ParentImageRegex AND
        EventData.OriginalFileName =~ OriginalFileNameRegex AND
        EventData.ParentUser =~ ParentUserRegex AND
        EventData.User =~ UserRegex AND
        EventData.Hashes =~ HashesRegex AND
        EventData.ParentCommandLine =~ ParentCommandLineRegex AND
        EventData.IntegrityLevel =~ IntegrityLevelRegex AND
        EventData.Product =~ ProductRegex AND
        EventData.Company =~ CompanyRegex AND
        EventData.Description =~ DescriptionRegex AND
        EventData.FileVersion =~ FileVersionRegex

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/macos.detection.yara.process.md
======
---
title: MacOS.Detection.Yara.Process
hidden: true
tags: [Client Artifact]
---

This artifact enables running Yara over processes in memory.

There are 2 kinds of Yara rules that can be deployed:

1. Url link to a yara rule.
2. A Standard Yara rule attached as a parameter.

Only one method of Yara will be applied and search order is as above. The
default is Cobalt Strike opcodes.

Regex parameters can be applied for process name and pid for targeting. The
artifact also has an option to upload any process with Yara hits.

Note: the Yara scan will stop after one hit. Multi-string rules will also only
show one string in returned rows.


<pre><code class="language-yaml">
name: Linux.Detection.Yara.Process
author: Matt Green - @mgreen27
description: |
  This artifact enables running Yara over processes in memory.

  There are 2 kinds of Yara rules that can be deployed:

  1. Url link to a yara rule.
  2. A Standard Yara rule attached as a parameter.

  Only one method of Yara will be applied and search order is as above. The
  default is Cobalt Strike opcodes.

  Regex parameters can be applied for process name and pid for targeting. The
  artifact also has an option to upload any process with Yara hits.

  Note: the Yara scan will stop after one hit. Multi-string rules will also only
  show one string in returned rows.

aliases:
- MacOS.Detection.Yara.Process

type: CLIENT
parameters:
  - name: ProcessRegex
    default: .
    type: regex
  - name: PidRegex
    default: .
    type: regex
  - name: UploadHits
    type: bool
  - name: YaraUrl
    description: If configured will attempt to download Yara rules from Url
    type: upload
  - name: YaraRule
    type: yara
    description: Final Yara option and the default if no other options provided.
    default: |
      rule keyword_search {
         strings:
           $a = "velociraptor" ascii

        condition:
            any of them
      }
  - name: NumberOfHits
    description: THis artifact will stop by default at one hit. This setting allows additional hits
    default: 1
    type: int
  - name: ContextBytes
    description: Include this amount of bytes around hit as context.
    default: 0
    type: int
  - name: ExePathWhitelist
    description: Regex of ProcessPaths to exclude
    type: regex


sources:
  - precondition:
      SELECT OS From info() where OS = 'linux' OR OS = 'darwin'

    query: |
      -- check which Yara to use
      LET yara_rules &lt;= YaraUrl || YaraRule

      -- find velociraptor process
      LET me = SELECT Pid FROM pslist(pid=getpid())

      -- find all processes and add filters
      LET processes = SELECT
             Name as ProcessName,
             CommandLine, Pid
        FROM pslist()
        WHERE
            Name =~ ProcessRegex
            AND format(format="%d", args=Pid) =~ PidRegex
            AND NOT Pid in me.Pid
            AND NOT if(condition=ExePathWhitelist,
                    then= Exe=~ExePathWhitelist)
            AND log(message=format(format="Scanning pid %v: %v", args=[
                Pid, CommandLine]))

      -- scan processes in scope with our rule, limit 1 hit
      LET hits = SELECT * FROM foreach(
        row=processes,
        query={
            SELECT
                ProcessName,
                CommandLine,
                Pid,
                Rule,
                Tag,
                Meta,
                String.Name as YaraString,
                String.Offset as HitOffset,
                if(condition=String.Data,
                   then=upload(
                     accessor='scope',
                     file='String.Data',
                     name=format(format="%v-%v_%v_%v",
                     args=[ ProcessName, Pid, String.Offset, ContextBytes ]
                    ))) as HitContext
             FROM proc_yara(
                        pid=Pid,
                        rules=yara_rules,
                        context=ContextBytes,
                        number=NumberOfHits
                    )
          })

      -- upload hits using the process accessor
      LET upload_hits = SELECT *,
          upload(
            accessor="process",
            file=format(format="/%v", args=Pid),
            name=pathspec(Path=format(format='%v-%v.dmp',
                          args= [ ProcessName, Pid ]))) as ProcessDump
      FROM hits
      WHERE log(message=format(format='Will upload %v: %v', args=[Pid, ProcessName]))

      -- return rows
      SELECT * FROM if(condition=UploadHits,
        then=upload_hits,
        else=hits)

column_types:
  - name: HitContext
    type: preview_upload

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/network.externalipaddress.md
======
---
title: Network.ExternalIpAddress
hidden: true
tags: [Client Artifact]
---

Detect the external ip address of the end point.

<pre><code class="language-yaml">
name: Network.ExternalIpAddress
description: Detect the external ip address of the end point.
parameters:
  - name: externalUrl
    default: http://www.myexternalip.com/raw
    description: The URL of the external IP detection site.
sources:
  - precondition: SELECT * from info()
    query: |
        SELECT Content as IP from http_client(url=externalUrl)

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/server.internal.pong.md
======
---
title: Server.Internal.Pong
hidden: true
tags: [Internal Artifact]
---

An internal queue for Ping replies


<pre><code class="language-yaml">
name: Server.Internal.Pong
description: |
  An internal queue for Ping replies

type: INTERNAL

column_types:
  - name: ClientId
  - name: Connected

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/macos.forensics.appledoublezip.md
======
---
title: MacOS.Forensics.AppleDoubleZip
hidden: true
tags: [Client Artifact]
---

Search for zip files containing leaked download URLs included by
MacOS users.

MacOS filesystem can represent extended attributes. Similarly to
Windows's ZoneIdentifier, when a file is downloaded on MacOS it also
receives an extended attribute recording where the file was
downloaded from. (See the `Windows.Analysis.EvidenceOfDownload`
artifact)

What makes MacOS different however, is that when a user adds a file
to a Zip file (in Finder, right click the file and select
"compress"), MacOS will also record the extended attributes in the
zip file under the __MACOSX folder.

This is a huge privacy leak because people often do not realize that
the source of downloads for a file is being included inside the zip
file, which they end up sending to other people!

Therefore this artifact can also work on other platforms because Zip
files created by MacOS users can end up on other systems, and
contain sensitive URLs embedded within them.


<pre><code class="language-yaml">
name: MacOS.Forensics.AppleDoubleZip
description: |
  Search for zip files containing leaked download URLs included by
  MacOS users.

  MacOS filesystem can represent extended attributes. Similarly to
  Windows's ZoneIdentifier, when a file is downloaded on MacOS it also
  receives an extended attribute recording where the file was
  downloaded from. (See the `Windows.Analysis.EvidenceOfDownload`
  artifact)

  What makes MacOS different however, is that when a user adds a file
  to a Zip file (in Finder, right click the file and select
  "compress"), MacOS will also record the extended attributes in the
  zip file under the __MACOSX folder.

  This is a huge privacy leak because people often do not realize that
  the source of downloads for a file is being included inside the zip
  file, which they end up sending to other people!

  Therefore this artifact can also work on other platforms because Zip
  files created by MacOS users can end up on other systems, and
  contain sensitive URLs embedded within them.

reference:
  - https://opensource.apple.com/source/Libc/Libc-391/darwin/copyfile.c
  - https://datatracker.ietf.org/doc/html/rfc1740

parameters:
  - name: ZipGlob
    description: Where to search for zip files.
    default: /Users/*/Downloads/*.zip

export: |
    -- Offsets are aligned to 4 bytes
    LET Align(value) = value + value - int(int=value / 4) * 4

    LET Profile = '''[
    ["Header", 0, [
      ["Magic", 0, "uint32b"],
      ["Version", 4, "uint32b"],
      ["Filler", 8, "String", {
          length: 16,
      }],
      ["Count", 24, "uint16b"],
      ["Items", 26, "Array", {
          count: "x=&gt;x.Count",
          type: "Entry",
      }],
      ["attr_header", 84, "attr_header"]
    ]],
    ["Entry", 12, [
      ["ID", 0, "uint32b"],
      ["Offset", 4, "uint32b"],
      ["Length", 8, "uint32b"],
      ["Value", 0, "Profile", {
           type: "ASFinderInfo",
           offset: "x=&gt;x.Offset",
      }]
    ]],
    ["attr_header", 0, [

      # Should be ATTR
      ["Magic", 0, "String", {
          length: 4,
      }],

      ["total_size", 8, "uint32b"],
      ["data_start", 12, "uint32b"],
      ["data_length",16, "uint32b"],
      ["flags", 32, "uint16b"],
      ["num_attr", 34, "uint16b"],
      ["attrs", 36, "Array", {
          count: "x=&gt;x.num_attr",
          type: "attr_t",
      }]
    ]],
    ["attr_t", "x=&gt;Align(value=x.name_length + 11)", [
     ["offset", 0, "uint32b"],
     ["length", 4, "uint32b"],
     ["flags", 8, "uint16b"],
     ["name_length", 10, "uint8"],
     ["name", 11, "String", {
         length: "x=&gt;x.name_length",
     }],
     ["data", 0, "Profile", {
        type: "String",
        type_options: {
            term: "",
            length: "x=&gt;x.length",
        },
        offset: "x=&gt;x.offset",
     }]
    ]]
    ]
    '''

    LET ParseData(data) = if(condition=data =~ "^bplist",
         then=plist(accessor="data", file=data), else=data)

    LET ParseAppleDouble(double_data) = SELECT name AS Key, ParseData(data=data) AS Value
       FROM foreach(row=parse_binary(
            filename=double_data, accessor="data",
            profile=Profile, struct="Header").attr_header.attrs)

sources:
 - query: |
     LET DoubleFiles = SELECT * FROM foreach(row={
        SELECT OSPath AS ZipPath
        FROM glob(globs=ZipGlob)
     }, query={
        SELECT OSPath, pathspec(parse=OSPath) AS PathSpec
        FROM glob(
             globs="__MACOSX/**",
             accessor="zip",
             root=pathspec(DelegatePath=ZipPath))
     })

     SELECT * FROM foreach(row=DoubleFiles,
     query={
       SELECT PathSpec.DelegatePath AS ZipFile,
              PathSpec.Path AS Member,
              Key, Value
       FROM ParseAppleDouble(double_data=read_file(filename=OSPath, accessor="zip"))
     })

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.detection.mutants.md
======
---
title: Windows.Detection.Mutants
hidden: true
tags: [Client Artifact]
---

Enumerate the mutants from selected processes.

Mutants are often used by malware to prevent re-infection.


<pre><code class="language-yaml">
name: Windows.Detection.Mutants
description: |
  Enumerate the mutants from selected processes.

  Mutants are often used by malware to prevent re-infection.

parameters:
  - name: processRegex
    description: A regex applied to process names.
    default: .
    type: regex
  - name: MutantNameRegex
    default: .+
    type: regex
  - name: MutantWhitelistRegex
    default:
    type: regex

sources:
  - name: Handles
    description: Open handles to mutants. This shows processes owning a handle open to the mutant.
    query: |
        LET processes = SELECT Pid AS ProcPid, Name AS ProcName, Exe
        FROM pslist()
        WHERE ProcName =~ processRegex AND ProcPid &gt; 0

        SELECT * FROM foreach(
          row=processes,
          query={
            SELECT ProcPid, ProcName, Exe, Type, Name, Handle
            FROM handles(pid=ProcPid, types="Mutant")
          })
        WHERE Name =~ MutantNameRegex
            AND if(condition= MutantWhitelistRegex,
                then= NOT Name =~ MutantWhitelistRegex,
                else= True )

  - name: ObjectTree
    description: Reveals all Mutant objects in the Windows Object Manager namespace.
    query: |
        SELECT Name, Type FROM winobj()
        WHERE Type = 'Mutant' AND Name =~ MutantNameRegex
            AND if(condition= MutantWhitelistRegex,
                then= NOT Name =~ MutantWhitelistRegex,
                else= True )

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/server.information.clients.md
======
---
title: Server.Information.Clients
hidden: true
tags: [Server Artifact]
---

This artifact returns the total list of clients, their hostnames and
the last times they were seen.


<pre><code class="language-yaml">
name: Server.Information.Clients
description: |
  This artifact returns the total list of clients, their hostnames and
  the last times they were seen.

type: SERVER

sources:
  - query: |
        SELECT client_id,
               os_info.fqdn as HostName,
               os_info.system as OS,
               os_info.release as Release,
               timestamp(epoch=last_seen_at/ 1000000).String as LastSeenAt,
               last_ip AS LastIP,
               last_seen_at AS _LastSeenAt
        FROM clients()
        ORDER BY _LastSeenAt DESC

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.collectors.file.md
======
---
title: Windows.Collectors.File
hidden: true
tags: [Client Artifact]
---

Collects files using a set of globs. All globs must be on the same
device. The globs will be searched in one pass - so you can provide
many globs at the same time.


<pre><code class="language-yaml">
name: Generic.Collectors.File
description: |
   Collects files using a set of globs. All globs must be on the same
   device. The globs will be searched in one pass - so you can provide
   many globs at the same time.

aliases:
  - Windows.Collectors.File

parameters:
  - name: collectionSpec
    description: |
       A CSV file with a Glob column with all the globs to collect.
       NOTE: Globs must not have a leading device.
    type: csv
    default: |
       Glob
       Users\*\NTUser.dat

  - name: Root
    description: |
      On Windows, this is the device to apply all the glob on
      (e.g. `C:`). On *NIX, this should be a path to a subdirectory or
      /.
    default: "C:"

  - name: Accessor
    default: auto
    description: |
      On Windows, this can be changed to `ntfs`.

  - name: NTFS_CACHE_TIME
    type: int
    description: How often to flush the NTFS cache. (Default is never).
    default: "1000000"


sources:
   - name: All Matches Metadata
     query: |
      LET RootPath &lt;= pathspec(Path=Root, accessor=Accessor)

      -- Generate the collection globs for each device
      LET specs = SELECT RootPath + Glob AS Glob
            FROM collectionSpec
            WHERE log(message=format(
               format="Processing Device %v with %v: glob is %v",
               args=[Root, Accessor, Glob]))

      -- Join all the collection rules into a single Glob plugin. This ensure we
      -- only make one pass over the filesystem. We only want LFNs.
      LET hits = SELECT OSPath AS SourceFile, Size,
               Btime AS Created,
               Ctime AS Changed,
               Mtime AS Modified,
               Atime AS LastAccessed
        FROM glob(globs=specs.Glob, accessor=Accessor)
        WHERE NOT IsDir AND log(message="Found " + SourceFile)

      -- Pass all the results to the next query. This will serialize
      -- to disk if there are too many results.
      LET all_results &lt;=
         SELECT Created, Changed, LastAccessed, Modified, Size, SourceFile
         FROM hits

      SELECT * FROM all_results

   - name: Uploads
     query: |
      -- Upload the files
      LET uploaded_files = SELECT * FROM foreach(row={
          SELECT * FROM all_results
        },
        workers=30,
        query={
          SELECT Created, Changed, LastAccessed, Modified, SourceFile, Size,
               upload(file=SourceFile,
                      accessor=Accessor,
                      mtime=Modified) AS Upload
            FROM scope()
        })

      -- Separate the hashes into their own column.
      SELECT now() AS CopiedOnTimestamp, SourceFile,
             Upload.Path AS DestinationFile,
               Size AS FileSize, Upload.sha256 AS SourceFileSha256,
               Created, Changed, Modified, LastAccessed
        FROM uploaded_files

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.detection.yara.device.md
======
---
title: Windows.Detection.Yara.Device
hidden: true
tags: [Client Artifact]
---

This artifact enables running Yara over a Physical device and offset
specific targeting.

There are 2 kinds of Yara rules that can be deployed:

1. Url link to a yara rule.  
2. or a Standard Yara rule attached as a parameter.  

Only one method of Yara will be applied and search order is as above. The
default is targeting the Master Boot Record (MBR).

Note: by default the Yara scan will stop after one hit. Multi-string rules will also only
show one string in returned rows.

Due to scanning raw devices and size being potentially very large I have included
an example on how to upload the MBR as the default yara rule.


<pre><code class="language-yaml">
name: Windows.Detection.Yara.Device
author: Matt Green - @mgreen27
description: |
  This artifact enables running Yara over a Physical device and offset
  specific targeting.

  There are 2 kinds of Yara rules that can be deployed:

  1. Url link to a yara rule.  
  2. or a Standard Yara rule attached as a parameter.  

  Only one method of Yara will be applied and search order is as above. The
  default is targeting the Master Boot Record (MBR).

  Note: by default the Yara scan will stop after one hit. Multi-string rules will also only
  show one string in returned rows.

  Due to scanning raw devices and size being potentially very large I have included
  an example on how to upload the MBR as the default yara rule.

parameters:
  - name: DevicePath
    default: \\.\PHYSICALDRIVE0
    description: Raw Device for main disk to target.
  - name: StartOffest
    type: int
    default: 0
  - name: ScanLength
    type: int
    default: 512
  - name: YaraUrl
    description: If configured will attempt to download Yara rules from Url
    type: upload
  - name: YaraRule
    type: yara
    default: |
        rule MBR {
            meta:
                author = "Matt Green - @mgreen27"
                description = "Checks MBR header at offset 510 and collects MBR in HitContext"
            strings:
                $mbr = /^.{512}$/ //first entry covering bytes we want to upload.
                $mbrheader = { 55 AA }
            condition:
                $mbr and $mbrheader at 510
        }
  - name: NumberOfHits
    description: THis artifact will stop by default at one hit. This setting allows additional hits
    default: 1
    type: int
  - name: ContextBytes
    description: Include this amount of bytes around hit as context.
    default: 0
    type: int64

sources:
  - query: |
      -- check which Yara to use
      LET yara_rules &lt;= YaraUrl || YaraRule

      -- target yara with raw_file pachspec
      SELECT
        DevicePath,
        StartOffest,
        ScanLength,
        Namespace,
        Rule,
        Meta,
        Tags,
        String.Name as YaraString,
        String.Offset AS HitOffset,
        upload(
            accessor='data',
            file=String.Data,
            name=format(format='%s_%s',
                    args=[basename(path=DevicePath),str(str=String.Offset)])
                ) AS HitContext
      FROM yara(files=pathspec(
                    DelegateAccessor="raw_file",
                    DelegatePath=DevicePath,
                    Path=StartOffest),
                accessor='offset',
                start=0,
                end=ScanLength,
                rules=yara_rules,
                context=ContextBytes,
                number=NumberOfHits )

column_types:
  - name: HitContext
    type: upload_preview

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/linux.debian.aptsources.md
======
---
title: Linux.Debian.AptSources
hidden: true
tags: [Client Artifact]
---

Parse Debian apt sources.

This Artifact searches for all apt sources files and parses all
fields in both one–line `*.list` files and `*.sources` files
(deb822-style format). The results are presented both in a readable
table and a flattened version for parsing.

`*.list` files contains lines of the form

```
deb http://us.archive.ubuntu.com/ubuntu/ bionic main restricted
deb-src [arch=amd64,i386 signed-by=/usr/share/keyrings/foo.gpg] https://foo.bar.baz/ubuntu/main jammy main restricted universe multiverse # Comment
```

deb indicates a source for binary packages, and deb-src instructs APT where
to find source code for packages.

`*.sources` files (deb822-style format) are in the form of key–value
lines, and as opposed to the one–line format, they may contain
multiple URIs, components and types (deb/deb-src), along with
embedded GPG keys. Example:

```
Types: deb deb-src
URIs: file:/home/apt/debian http://foo.bar.baz/main
Suites: unstable
Components: main contrib non-free
```

The exported function `parse_aptsources(OSPath, flatten)` parses
both formats and returns an (optionally flattened) table with

 - OSPath
 - Types (deb/deb-src)
 - Components (e.g. main/contrib/non-free/restricted,universe)
 - Suites (e.g. unstable/bookworm/jammy)
 - _URIBase (.e.g us.archive.ubuntu.com/ubuntu/)
 - _Transport (e.g. http/https/file/cdrom/ftp)
 - URIs (e.g. http://us.archive.ubuntu.com/ubuntu/)

Any option is added to an individual column. The most common options
are

 - Architectures (e.g. amd64/i386/armel)
 - Signed-By (e.g. /usr/share/keyrings/osquery.gpg)

All known option names are transformed to the plural PascalCase
variants as listed in the sources.list man page. Any undocumented
options will still be included in the results, with names unchanged.
Options in the one-line format of the form "lang+=de"/"arch-=i386"
will be put in columns like "Languages-Add"/"Architectures-Remove",
matching the option names having the same effect in deb822.

Entries in deb822 sources files may be disabled by including
"Enabled: no" instead of commenting out all lines. If this field
is not present with a falsly value, the entry is enabled. Use the
exported functions DebTrue()/DebFalse() to correctly parse all
accepted true/false strings, or use the VQL suggestion "Only enabled
sources" to filter on this column (true), if present.

If the GPG key is embedded in a .sources file, the whole GPG key
will be included in the cell. Otherwise the value will be a file
path. Use the VQL suggestion "Hide embedded GPG keys" to replace
embedded GPG keys with "(embedded)" in the results. In order to
inspect the keys themselves (files or embedded data), use the
exchange artifact Linux.Debian.GPGKeys.

If the function parameter "flatten" is False, multi–value fields
(like Components) will be combined in a single space-separated
string in each row.

In addition to the two apt sources tables, a third table correlates
information from InRelease and Release files to provide additional
metadata. The modification timestamps may tell when the package
lists where last updated.


<pre><code class="language-yaml">
name: Linux.Debian.AptSources
description: |
  Parse Debian apt sources.

  This Artifact searches for all apt sources files and parses all
  fields in both one–line `*.list` files and `*.sources` files
  (deb822-style format). The results are presented both in a readable
  table and a flattened version for parsing.

  `*.list` files contains lines of the form

  ```
  deb http://us.archive.ubuntu.com/ubuntu/ bionic main restricted
  deb-src [arch=amd64,i386 signed-by=/usr/share/keyrings/foo.gpg] https://foo.bar.baz/ubuntu/main jammy main restricted universe multiverse # Comment
  ```

  deb indicates a source for binary packages, and deb-src instructs APT where
  to find source code for packages.

  `*.sources` files (deb822-style format) are in the form of key–value
  lines, and as opposed to the one–line format, they may contain
  multiple URIs, components and types (deb/deb-src), along with
  embedded GPG keys. Example:

  ```
  Types: deb deb-src
  URIs: file:/home/apt/debian http://foo.bar.baz/main
  Suites: unstable
  Components: main contrib non-free
  ```

  The exported function `parse_aptsources(OSPath, flatten)` parses
  both formats and returns an (optionally flattened) table with

   - OSPath
   - Types (deb/deb-src)
   - Components (e.g. main/contrib/non-free/restricted,universe)
   - Suites (e.g. unstable/bookworm/jammy)
   - _URIBase (.e.g us.archive.ubuntu.com/ubuntu/)
   - _Transport (e.g. http/https/file/cdrom/ftp)
   - URIs (e.g. http://us.archive.ubuntu.com/ubuntu/)

  Any option is added to an individual column. The most common options
  are

   - Architectures (e.g. amd64/i386/armel)
   - Signed-By (e.g. /usr/share/keyrings/osquery.gpg)

  All known option names are transformed to the plural PascalCase
  variants as listed in the sources.list man page. Any undocumented
  options will still be included in the results, with names unchanged.
  Options in the one-line format of the form "lang+=de"/"arch-=i386"
  will be put in columns like "Languages-Add"/"Architectures-Remove",
  matching the option names having the same effect in deb822.

  Entries in deb822 sources files may be disabled by including
  "Enabled: no" instead of commenting out all lines. If this field
  is not present with a falsly value, the entry is enabled. Use the
  exported functions DebTrue()/DebFalse() to correctly parse all
  accepted true/false strings, or use the VQL suggestion "Only enabled
  sources" to filter on this column (true), if present.

  If the GPG key is embedded in a .sources file, the whole GPG key
  will be included in the cell. Otherwise the value will be a file
  path. Use the VQL suggestion "Hide embedded GPG keys" to replace
  embedded GPG keys with "(embedded)" in the results. In order to
  inspect the keys themselves (files or embedded data), use the
  exchange artifact Linux.Debian.GPGKeys.

  If the function parameter "flatten" is False, multi–value fields
  (like Components) will be combined in a single space-separated
  string in each row.

  In addition to the two apt sources tables, a third table correlates
  information from InRelease and Release files to provide additional
  metadata. The modification timestamps may tell when the package
  lists where last updated.

reference:
  - https://manpages.debian.org/bookworm/apt/sources.list.5.en.html
  - https://manpages.debian.org/bookworm/dpkg-dev/deb822.5.en.html
  - https://salsa.debian.org/apt-team/apt/-/blob/main/apt-pkg/sourcelist.cc
  - https://wiki.debian.org/DebianRepository/Format#A.22Release.22_files

export: |
        /* Remove whitespace from the beginning and end of a string: */
        LET Trim(string) = regex_transform(source=string, map=dict(
            `(?m)^\\s+`='',
            `(?m)\\s+$`=''
        ))

        /* Replace any repeating whitespace with a single space: */
        LET Simplify(string) = regex_replace(source=string, re='''\s+''', replace=' ')

        /* The syntax in lists (deb822) and sources (one-line) files varies a bit,
           and deb822 is case-insensitive. Normalise all known fields (as per
           the man page): */
        LET NormaliseOpts(string) = regex_transform(source=string, map=dict(
            `(?i)types|type`='Types',
            `(?i)uris|uri`='URIs',
            `(?i)suites|suite`='Suites',
            `(?i)components|component`='Components',
            `(?i)architectures$|arch$`='Architectures',
            `(?i)architectures-add`='Architectures-Add',
            `(?i)architectures-remove`='Architectures-Remove',
            `(?i)languages$|lang$`='Languages',
            `(?i)languages-add`='Languages-Add',
            `(?i)languages-remove`='Languages-Remove',
            `(?i)targets$|target$`='Targets',
            `(?i)targets-add`='Targets-Add',
            `(?i)targets-remove`='Targets-Remove',
            `(?i)pdiffs`='PDiffs',
            `(?i)by-hash`='By-Hash',
            `(?i)allow-insecure`='Allow-Insecure',
            `(?i)allow-weak`='Allow-Weak',
            `(?i)allow-downgrade-to-insecure`='Allow-Downgrade-To-Insecure',
            `(?i)trusted`='Trusted',
            `(?i)signed-by`='Signed-By',
            `(?i)check-valid-until`='Check-Valid-Until',
            `(?i)valid-until-min`='Valid-Until-Min',
            `(?i)valid-until-max`='Valid-Until-Max',
            `(?i)check-date`='Check-Date',
            `(?i)date-max-future`='Date-Max-Future',
            `(?i)inrelease-path`='InRelease-Path',
            `(?i)enabled`='Enabled'
        ))

        LET DebTrue(string) = if(
            condition=string=~'(?i)^(?:yes|true|with|on|enable)$',
            then=true, else=false)
        LET DebFalse(string) = if(
            condition=string=~'(?i)^(?:no|false|without|off|disable)$',
            then=true, else=false)

        /* Extract Key–Value pairs from option string. If assignment is -=/+=,
           the -/+ operator is captured in Op: */
        LET OptStringToKeyValues__(string) = SELECT *
            FROM parse_records_with_regex(
                regex='''(?P&lt;Key&gt;[^ ]+?)(?P&lt;Op&gt;-|\+)?=(?P&lt;Value&gt;[^ ]+)''',
                accessor='data', file=string
        )

        /* Since option values may have multiple words, split them and flatten
           the results for further processing: */
        LET OptStringToKeyValues_(string) = SELECT *
            FROM flatten(query={
                SELECT Key,
                    Op,
                    split(sep_string=',', string=Value) AS Value
                    FROM OptStringToKeyValues__(string=string)
            })

        /* Since options may be repeated, enumerate and group all values
           per key and operation: */
        LET OptStringToKeyValues(string) = SELECT Key,
            Op,
            enumerate(items=Value) AS Value
            FROM OptStringToKeyValues_(string=string)
            GROUP BY Key, Op

        /* When an option is specified with +/-, represent this by appending
           -Add/-Remove to the option name. These names match the syntax in
           the deb822 format (i.e. "arch-=i386" == "Arhitectures-Remove: i386").
           The purpose of these assignments is to keep the default values
           (rather than overriding them), but add or remove one or several
           values: */
        LET OpName(op) = if(condition=op='+',then='-Add',else=
            if(condition=op='-',then='-Remove',else=''))

        /* Convert a string of key–value pairs to a dict, and use consistent
           option names: */
        LET OptStringToDict(string, flatten) = to_dict(item={
            SELECT NormaliseOpts(string=Key)+OpName(op=Op) AS _key,
                if(condition=flatten, then=Value,
                    else=join(array=Value, sep=' ')) AS _value
            FROM OptStringToKeyValues(string=string)
        })

        /* Parse a one-line deb sources.list file with options as a single string: */
        LET DebOneLine_Opts(OSPath) = SELECT OSPath, Type AS Types,
            Simplify(string=Options) AS Options, URI AS URIs,
            Transport AS _Transport, URIBase AS _URIBase, Suite AS Suites,
            Simplify(string=Trim(string=Components)) AS Components
            FROM parse_records_with_regex(
                file=OSPath,
                /* This regex attemps to cover most of the ways a sources
                   line can be written without being overly complex. Quotes
                   ("" and []) are actually allowed to certain degree by the
                   apt source code, but this is considered obscure syntax and
                   is not expected to be found in the wild. The exception is
                   "cdrom:[word word…]", which is capture correctly in order
                   to not end up with incorrectly captured words: */
                regex='''(?m)^\s*(?P&lt;Type&gt;deb(-src)?)(?:\s+\[(?P&lt;Options&gt;[^\]#]+)(?:#[^\]]+)?\])?\s+"?(?P&lt;URI&gt;(?P&lt;Transport&gt;[^:]+):(?://)?(?P&lt;URIBase&gt;\[.+?\]|\S+?))"?\s+(?P&lt;Suite&gt;\S+)\s+(?P&lt;Components&gt;[^\n#]+)'''
            )

        /* Parse a one-line deb sources.list file and output a dict: */
        LET DebOneLine_Dict(OSPath, flatten) = SELECT OSPath, *
            FROM foreach(row=DebOneLine_Opts(OSPath=OSPath),
                query={SELECT _value +
                        OptStringToDict(string=Options, flatten=flatten) AS Contents
                    FROM items(item={SELECT Types, URIs, _Transport, _URIBase, Suites,
                        if(condition=flatten, then=split(sep_string=' ',
                            string=Components), else=Components) AS Components
                        FROM scope()
                    })
                })

        /* Parse a one-line deb sources.list file with options in individual columns: */
        LET DebOneLine(OSPath) = SELECT OSPath, * FROM foreach(
            row=DebOneLine_Dict(OSPath=OSPath, flatten=false),
            column='Contents'
        )

        /* Parse a one-line deb sources.list file with options in individual
           columns and flatten: */
        LET DebOneLine_Flattened(OSPath) = SELECT OSPath, * FROM flatten(
            query={SELECT * FROM foreach(
                row=DebOneLine_Dict(OSPath=OSPath, flatten=true),
                column='Contents'
                )
            })

        /* Extract the transport/protocol and base from a URI: */
        LET URIComponents(URI) = parse_string_with_regex(
            regex='''(?P&lt;Transport&gt;[^:]+):(?://)?(?P&lt;URIBase&gt;[^\s]+)''',
            string=URI
        )

        /* Although the documentation says to use whitespace and not comma
           for multi-values in deb822, comma still appears to be supported,
           and this use is seen in the wild. Treat these values correctly.
           Note that this does not affect all keys, like suites and
           components:
        */
        LET MaybeReplaceComma(key, value) = if(
            condition=key=~'(?i)^(?:arch|lang|targets)',
            then=regex_replace(re='\s*,\s*', source=value, replace=' '),
            else=value)

        /* Parse a deb822 sources file section into a series of key–value pairs.
           Notes about the format:
             - Keys must be at the beginning of the line (no whitespace allowed)
             - Keys are case-insensitive
             - Keys may be repeated. Values are not overridden, but combined
             - Special keys that end in -Add/-Remove uses the default values,
               but add or remove individual values. These keys are treated as
               individual option names.
             - Comments may only appear at the beginning of the line
             - Multiple values are separated by whitespace, not comma. However,
               some multi-value fields separated by comma are still split, even
               if this is not mentioned in the documentation.
             - Values may be multi-line (like when containing an embedded GPG key),
               but following lines must be prefixed by whitespace. Multilines
               may contain comments (prefixed by whitespace or not). Empty lines
               part of a multi-line value must be prefixed by whitespace and "."
             - A file may contain multiple entries, separated by empty lines.
               A file must be split into sections, fed individually to this function
        */
        LET Deb822_KeyValues___(section) = SELECT Key,
            /* Signed-By is special (it could be an embedded GPG key),and
               shouldn't be split: */
            if(condition=NormaliseOpts(string=Key)!='Signed-By',
                then=split(sep_string=' ',
                string=MaybeReplaceComma(key=Key,
                    value=Simplify(string=Trim(string=Value)))),
                else=Value) AS Value
            FROM parse_records_with_regex(
                accessor='data',
                /* A key is anything but whitespace up to a colon
                   Values can continue on several lines, but only if the following
                   lines are indented with whitespace
                */
                regex='''(?m)^(?P&lt;Key&gt;[^#:\s]+)\s*:[^\S\n]*(?P&lt;Value&gt;[^\n]*(?:\n[^\S\n]+[^\n]+)*)''',
                /* Before parsing the key–values, remove all comments from the file
                   (otherwise forming a regex without lookarounds would be very
                   difficult, if not impossible), Luckily, comments follow strict
                   rules and must start with ^#.
                */
                file=regex_replace(
                    re='''(?m)^#.+\n''',
                    source=section
                )
            )

        LET Deb822_KeyValues__(section) = SELECT * FROM flatten(query={
            SELECT * FROM Deb822_KeyValues___(section=section)
        })

        LET Deb822_KeyValues_(section) = SELECT Key,
            enumerate(items=Value) AS Value
            FROM Deb822_KeyValues__(section=section)
            GROUP BY Key

        /* Parse a deb822 sources file section into a dict with consistent option
           names: */
        LET Deb822_KeyValues(section, flatten) = SELECT to_dict(
            item={
                SELECT NormaliseOpts(string=Key) as _key,
                    if(condition=flatten, then=Value,
                        else=join(array=Value, sep=' ')) AS _value
                FROM Deb822_KeyValues_(section=section)
            }) AS Contents
            FROM scope()

        /* Split paragraphs in a file (separated by one or several empty
           lines) into rows. ('regex' is just anything that is illegal in Deb822Sections
           to prevent splitting data into records.): */
        LET Deb822Sections(OSPath) = SELECT OSPath,* FROM split_records(
            filenames=OSPath,
            columns='Section',
            regex='^ #', record_regex='''\n{2,}'''
        )

        LET Deb822_Flattened_(OSPath) = SELECT * FROM foreach(
            row=Deb822Sections(OSPath=OSPath),
            query={SELECT OSPath, * FROM flatten(query={
                SELECT * FROM foreach(
                    row=Deb822_KeyValues(section=Section, flatten=true),
                    column='Contents'
                )
            })}
        )
        /* DEB822_Sections() may produce empty rows. Exclude these by filtering
           for a required column, like URIs: */
        WHERE URIs

        /* Parse a deb822 sources file with options in individual columns.
           Note that, as opposed to DebOneLine and Deb822_Flattened, this
           function does not return the columns _URIBase and _Transport, since
           this format supports mulitple URIs to be specified: */
        LET Deb822(OSPath) = SELECT * FROM foreach(
            row=Deb822Sections(OSPath=OSPath),
            query={SELECT OSPath, * FROM foreach(
                row=Deb822_KeyValues(section=Section, flatten=false),
                column='Contents'
            )}
        )
        WHERE URIs

        /* Parse a deb822 sources file with options in individual columns, flattened: */
        LET Deb822_Flattened(OSPath) = SELECT * FROM flatten(query={
            SELECT OSPath, *, URIComponents(URI=URIs).URIBase AS _URIBase,
                URIComponents(URI=URIs).Transport AS _Transport
            FROM Deb822_Flattened_(OSPath=OSPath)
        })

        /* Parse an apt sources/list file */
        LET parse_aptsources(OSPath, flatten) = if(
            condition=OSPath=~'.list$',
            then=if(condition=flatten,
                then=DebOneLine_Flattened(OSPath=OSPath),
                else=DebOneLine(OSPath=OSPath)
            ),
            else=if(condition=flatten,
                then=Deb822_Flattened(OSPath=OSPath),
                else=Deb822(OSPath=OSPath)
            )
        )

        LET files = SELECT OSPath FROM glob(
           globs=linuxAptSourcesGlobs.ListGlobs)

        LET deb_sources = SELECT * FROM foreach(row=files,
            query={SELECT * FROM parse_aptsources(OSPath=OSPath, flatten=true)}
        )

parameters:
  - name: linuxAptSourcesGlobs
    description: Globs to find apt source *.list and .sources files.
    type: csv
    default: |
        ListGlobs
        /etc/apt/sources.list
        /etc/apt/sources.list.d/*.list
        /etc/apt/sources.list.d/*.sources
  - name: aptCacheDirectory
    description: Location of the apt cache directory.
    default: /var/lib/apt/lists/

precondition:
    SELECT OS From info() where OS = 'linux'

sources:
  - name: Sources
    query: |
        /* Output sources in a readable format: */
        SELECT * FROM foreach(row=files,
            query={SELECT * FROM parse_aptsources(OSPath=OSPath, flatten=false)}
        )
    notebook:
      - type: vql_suggestion
        name: Only enabled sources
        template: |
            /*
            # Sources (enabled only)
            */
            SELECT * FROM source()
            WHERE Enabled =~ '(?i)^(?:yes|true|with|on|enable)$' || true

      - type: vql_suggestion
        name: Trusted sources (apt-secure bypassed)
        template: |
            /*
            # "Trusted" sources (apt-secure bypassed)

            When the Trusted option is true, apt does not verify the GPG
            signature of the Release files of the repository, and it also
            doe not warn about this.
            */
            SELECT * FROM source()
            WHERE Trusted =~ '(?i)^(?:yes|true|with|on|enable)$' || false

      - type: vql_suggestion
        name: Hide embedded GPG keys
        template: |
            /*
            # Sources (embedded GPG keys hidden)
            */
            SELECT *, if(condition=get(field='Signed-By')=~'BEGIN PGP PUBLIC KEY',
                then='(embedded)', else=get(field='Signed-By')) AS `Signed-By`
                FROM source()

  - name: SourcesFlattened
    query: |
        /* Output sources flattened for ease of analysis: */
        SELECT * FROM deb_sources

  - name: SourcesCacheFiles
    query: |
        /* We try to get at the Release file in /var/lib/apt/ by munging
           the components and URL.
           Strip the last component off, convert / and space to _ and
           add _Release/_InRelease to get the filename.
        */
        LET parsed_apt_lines = SELECT get(field='Architectures', default='') AS Architectures, URIs,
            _URIBase + " " + Suites + " " + Components as Name, Types,
            OSPath as Source, aptCacheDirectory + regex_replace(
              replace="_",
              re="_+",
              source=regex_replace(
                replace="_", re="[ /]",
                source=_URIBase + "_dists_" + Suites
              )) as cache_file
        FROM deb_sources
        GROUP BY URIs, Suites

        /* This runs if the file was found. Read the entire file into
            memory and parse the same record using multiple RegExps.
        */
        LET parsed_cache_files(file) = SELECT Name, Architectures, URIs, Types,
            Source, parse_string_with_regex(
                string=regex_replace(source=Record,
                    re='(?m)^Version: GnuPG v.+$', replace=''
                ),
                regex=["Codename: (?P&lt;Release&gt;[^\\n]+)",
                       "Version: (?P&lt;Version&gt;[^\\n]+)",
                       "Origin: (?P&lt;Origin&gt;[^\\n]+)",
                       "Architectures: (?P&lt;Architectures&gt;[^\\n]+)",
                       "Components: (?P&lt;Components&gt;[^\\n]+)"]) as Record
           FROM parse_records_with_regex(file=file, regex="(?sm)(?P&lt;Record&gt;.+)")

         // Foreach row in the parsed cache file, collect the FileInfo too.
         LET add_stat_to_parsed_cache_file(file) = SELECT * from foreach(
           query={
             SELECT OSPath, Mtime, Ctime, Atime, Record, Types,
               Name, Architectures, URIs, Source from stat(filename=file)
           }, row=parsed_cache_files(file=file))
           WHERE Record
           GROUP BY OSPath

         /* For each row in the parsed file, run the appropriate query
            depending on if the cache file exists.
            If the cache file is not found, we just copy the lines we
            parsed from the source file and fill in empty values for
            stat.
         */
         LET parse_cache_or_pass = SELECT * from if(
           condition={
              SELECT * from stat(filename=cache_file + '_InRelease')
           },
           then=add_stat_to_parsed_cache_file(file=cache_file + '_InRelease'),
           else={SELECT * FROM if(
            condition={
              SELECT * from stat(filename=cache_file + '_Release')
            },
            then=add_stat_to_parsed_cache_file(file=cache_file + '_Release'),
            else={
            SELECT Source, NULL AS OSPath, Null as Mtime, Null as Ctime,
               Null as Atime, Types,
               Null as Record, Architectures, URIs, Name from scope()
            })
           })

         -- For each parsed apt .list file line produce some output.
         SELECT * from foreach(
             row={
                 SELECT * FROM parsed_apt_lines
             },
             query={
                SELECT * FROM parse_cache_or_pass
              })

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/server.internal.clientdelete.md
======
---
title: Server.Internal.ClientDelete
hidden: true
tags: [Server Event Artifact]
---

An internal queue that receives events when a client is deleted.


<pre><code class="language-yaml">
name: Server.Internal.ClientDelete
description: |
  An internal queue that receives events when a client is deleted.

type: SERVER_EVENT

column_types:
  - name: ClientId
    description: The client that was deleted.
  - name: Principal
    description: The principal who initiated the deletion.

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.forensics.rdpcache.md
======
---
title: Windows.Forensics.RDPCache
hidden: true
tags: [Client Artifact]
---

This artifact parses, views and enables simplified upload of RDP 
cache files. 

By default the artifact will parse .BIN RDPcache files.
   
Filters include User regex to target a user and Accessor to target
vss via ntfs_vss.

Best combined with:

   - Windows.EventLogs.RDPAuth to collect RDP focused event logs.
   - Windows.Registry.RDP to collect user RDP mru and server info


<pre><code class="language-yaml">
name: Windows.Forensics.RDPCache
author: Matt Green - @mgreen27
description: |
    This artifact parses, views and enables simplified upload of RDP 
    cache files. 
    
    By default the artifact will parse .BIN RDPcache files.
       
    Filters include User regex to target a user and Accessor to target
    vss via ntfs_vss.
    
    Best combined with:
    
       - Windows.EventLogs.RDPAuth to collect RDP focused event logs.
       - Windows.Registry.RDP to collect user RDP mru and server info

reference:
   - https://github.com/ANSSI-FR/bmc-tools
   - https://github.com/BSI-Bund/RdpCacheStitcher

parameters:
   - name: RDPCacheGlob
     default: C:\{{Users,Windows.old\Users}\*\AppData\Local,Documents and Settings\*\Local Settings\Application Data}\Microsoft\Terminal Server Client\Cache\*
   - name: Accessor
     description: Set accessor to use. blank is default, file for api, ntfs for raw, ntfs_vss for vss
   - name: UserRegex
     default: .
     description: Regex filter of user to target. StartOf(^) and EndOf($)) regex may behave unexpectanly.
     type: regex
   - name: ParseCache
     description: If selected will parse .BIN RDPcache files.
     type: bool
   - name: Workers
     default: 100
     type: int
     description: Number of workers to use for ParseCache
   - name: UploadRDPCache
     description: If selected will upload raw cache files. Can be used for offline processing/preservation.
     type: bool

sources:
  - name: TargetFiles
    description: RDP BitmapCache files in scope. 
    query: |
      LET results = SELECT OSPath, Size, Mtime, Atime, Ctime, Btime
        FROM glob(globs=RDPCacheGlob,accessor=Accessor)
        WHERE OSPath =~ UserRegex
        
      LET upload_results = SELECT *, upload(file=OSPath) as CacheUpload
        FROM results
    
      SELECT * FROM if(condition= UploadRDPCache,
        then= upload_results,
        else= results )
        
  - name: Parsed
    description: Parsed RDP BitmapCache files. 
    query: |
      LET PROFILE = '''[
        ["BIN_CONTAINER", 0, [
            [Magic, 0, String, {length: 8, term_hex : "FFFFFF" }],
            [Version, 8, uint32],
            [CachedFiles, 12, Array, {
                "type": "rgb32b",
                "count": 10000,
                "max_count": 2000,
                "sentinel": "x=&gt;x.__Size &lt; 15",
            }],
        ]],
        ["rgb32b","x=&gt;x.__Size",[
            [__key1, 0, uint32],
            [__key1, 4, uint32],
            ["Width", 8, "uint16"],
            ["Height", 10, "uint16"],
            [DataLength, 0, Value,{ value: "x=&gt; 4 * x.Width * x.Height"}],
            [DataOffset, 0, Value,{ "value": "x=&gt;x.StartOf + 12"}],
            ["__Size", 0, Value,{ "value": "x=&gt;x.DataLength + 12"}],
            ["Index", 0, Value,{ "value": "x=&gt;count() - 1 "}],
        ]]]'''
        
      LET parse_rgb32b(data) = SELECT
            _value  as Offset,
            _value + 3 as EndOffset,
            len(list=data) as Length,
            data[(_value):(_value + 3)] + unhex(string="FF") as Buffer
        FROM range(step=4,end=len(list=data))
        
      LET fix_bmp(data) = SELECT 
            _value  as Offset,
            _value + 255 as EndOffset,
            join(array=data[ (_value):(_value + 256 ) ],sep='') as Buffer
        FROM range(step=256, end= len(list=data) )
        ORDER BY Offset DESC
        
      LET parse_container = SELECT * OSPath,Name,Size as FileSize,
            read_file(filename=OSPath,length=12) as Header,
            parse_binary(filename=OSPath,profile=PROFILE,struct='BIN_CONTAINER') as Parsed
        FROM foreach(row={
            SELECT * FROM glob(globs=RDPCacheGlob,accessor=Accessor) 
            WHERE OSPath =~ '\.bin$'
                AND OSPath =~ UserRegex
                AND NOT IsDir
        })
        
      LET find_index_differential = SELECT *, 0 - Parsed.CachedFiles.Index[0] as IndexDif
        FROM parse_container
      
      LET parse_cache = SELECT * FROM foreach(row=find_index_differential, query={
        SELECT OSPath, IndexDif,
            OSPath.Dirname + ( OSPath.Basename + '_' + format(format='%04v',args= Index + IndexDif ) + '.bmp' ) as BmpName,
            FileSize,Header,Width,Height,DataLength,DataOffset
        FROM foreach(row=Parsed.CachedFiles)
      })
      
      LET extract_data = SELECT *
        FROM foreach(row=parse_cache,query={
            SELECT
                OSPath,BmpName,FileSize,Header,Width,Height,DataLength,DataOffset,
                join(array=parse_rgb32b(data=read_file(filename=OSPath,offset=DataOffset,length=DataLength)).Buffer,sep='') as Data 
            FROM scope()
        }, workers=Workers)
      
      -- change endianess for unint32
      LET pack_lt_l(data) = unhex(string=join(array=[ 
        format(format='%02x',args=unhex(string=format(format='%08x',args=data))[3]), 
        format(format='%02x',args=unhex(string=format(format='%08x',args=data))[2]),
        format(format='%02x',args=unhex(string=format(format='%08x',args=data))[1]),
        format(format='%02x',args=unhex(string=format(format='%08x',args=data))[0]) 
            ],sep=''))
            
      -- build bmp file, adding appropriate header
      LET build_bmp(data,width,height) = join(array=[ 
                "BM",
                pack_lt_l(data=len(list=data) + 122),
                unhex(string="000000007A0000006C000000"),
                pack_lt_l(data=width),
                pack_lt_l(data=height),
                unhex(string="0100200003000000"),
                pack_lt_l(data=len(list=data)),
                unhex(string="000000000000000000000000000000000000FF0000FF0000FF000000000000FF"),
                " niW",
                unhex(string="00" * 36),
                unhex(string="000000000000000000000000"),
                data 
            ], sep='')
        
        SELECT * FROM if(condition= ParseCache,
            then={
                SELECT 
                    BmpName, Header, Width, Height, DataLength, DataOffset,
                    upload(
                        file=build_bmp(data=join(array=fix_bmp(data=Data).Buffer,sep=''), 
                        width=Width, height=Height),
                        name=BmpName,
                        accessor='data' ) as BmpUpload,
                    OSPath as SourceFile
                FROM extract_data
                ORDER BY BmpName
            }, 
            else= Null )
            
      
column_types:
  - name: BmpUpload
    type: upload_preview
  - name: CacheUpload
    type: upload_preview
</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.forensics.prefetch.md
======
---
title: Windows.Forensics.Prefetch
hidden: true
tags: [Client Artifact]
---

Windows keeps a cache of prefetch files. When an executable is run,
the system records properties about the executable to make it faster
to run next time. By parsing this information we are able to
determine when binaries are run in the past. On Windows10 we can see
the last 8 execution times and creation time (9 potential executions).

There are several parameter's available for this artifact.
  - dateAfter enables search for prefetch evidence after this date.
  - dateBefore enables search for prefetch evidence before this date.
  - binaryRegex enables to filter on binary name, e.g evil.exe.
  - hashRegex enables to filter on prefetch hash.

NOTE: The Prefetch file format is described extensively in libscca
and painstakingly reversed by Joachim Metz (Shouts and Thank you!).


<pre><code class="language-yaml">
name: Windows.Forensics.Prefetch
description: |
  Windows keeps a cache of prefetch files. When an executable is run,
  the system records properties about the executable to make it faster
  to run next time. By parsing this information we are able to
  determine when binaries are run in the past. On Windows10 we can see
  the last 8 execution times and creation time (9 potential executions).

  There are several parameter's available for this artifact.
    - dateAfter enables search for prefetch evidence after this date.
    - dateBefore enables search for prefetch evidence before this date.
    - binaryRegex enables to filter on binary name, e.g evil.exe.
    - hashRegex enables to filter on prefetch hash.

  NOTE: The Prefetch file format is described extensively in libscca
  and painstakingly reversed by Joachim Metz (Shouts and Thank you!).

reference:
  - https://www.forensicswiki.org/wiki/Prefetch
  - https://github.com/libyal/libscca/blob/main/documentation/Windows%20Prefetch%20File%20(PF)%20format.asciidoc

parameters:
    - name: prefetchGlobs
      default: C:\Windows\Prefetch\*.pf
    - name: dateAfter
      description: "search for events after this date. YYYY-MM-DDTmm:hh:ssZ"
      type: timestamp
    - name: dateBefore
      description: "search for events before this date. YYYY-MM-DDTmm:hh:ssZ"
      type: timestamp
    - name: binaryRegex
      description: "Regex of executable name."
      type: regex
    - name: hashRegex
      description: "Regex of prefetch hash."
      type: regex
    - name: IncludeFilesAccessed
      description: Include all accessed files
      type: bool

export: |
        LET PrefetchProfile = '''[
        ["Header", 8, [
          ["Signature", 0, "String", {"length": 3}],
          ["UncompressedSize", 4, "unsigned long"],
          ["Data", 8, String, {
              length: "x=&gt;x.UncompressedSize",
              term: "",
              max_length: 10000000,
          }],
          ["Decompressed", 0, "Value", {
              value: "x=&gt;lzxpress_decompress(data=x.Data)"
          }],
        ]],
        ["SCCAHeader", 84, [
         ["Version", 0, "Enumeration", {
             type: "unsigned int",
             choices: {
               "17": "WinXP (17)",
               "23": "Vista (23)",
               "26": "Win8.1 (26)",
               "30": "Win10 (30)",
               "31": "Win11 (31)"
             }
         }],
         ["Signature", 4, "String", {"length": 4}],
         ["FileSize", 12, "unsigned long"],
         ["Executable", 16, "String", {
             encoding: "utf16",
         }],
         ["Hash", 76, "unsigned long"],

         # Hash is followed by a version specific info struct.
         ["Info", 84, "Union", {
             selector: "x=&gt;x.Version",
             choices: {
                 "WinXP (17)": "FileInformationWinXP",
                 "Vista (23)": "FileInformationVista",
                 "Win8.1 (26)": "FileInformationWin81",
                 "Win10 (30)": "FileInformationWin10",
                 "Win11 (31)": "FileInformationWin10"
             }
         }]
        ]],

        ["FileInformationWinXP", 68, [
         ["__FileMetricsOffset", 0, "unsigned long"],
         ["__NumberOfFileMetrics", 4, "unsigned long"],
         ["__TraceChainsArrayOffset", 8, "unsigned long"],
         ["__NumberOfTraceChains", 12, "unsigned long"],
         ["__FilenameOffset", 16, "unsigned long"],
         ["__FilenameSize", 20, "unsigned long"],
         ["__VolumesInformationOffset", 24, "unsigned long"],
         ["__NumberOfVolumes", 28, "unsigned long"],
         ["__VolumesInformationSize", 32, "unsigned long"],

         # This is realy just one time but we make it an
         # array to be compatible with the others.
         ["LastRunTimes", 36, "Array", {
              "type": "Timestamp",
              "count": 1
           }],
         ["RunCount", 60, "unsigned long"],

         # Metrics offset is absolute.
         ["Metrics", "x=&gt;x.__FileMetricsOffset - x.StartOf", "Array", {
             type: "FileMetricsEntryV17",
             count: "x=&gt;x.__NumberOfFileMetrics",
         }],
         ["VolumeInfo", "x=&gt;x.__VolumesInformationOffset - x.StartOf", "Array", {
             type: "VolumeInformation",
             count: "x=&gt;x.__NumberOfVolumes",
          }],
        ]],

        ["FileInformationVista", 156, [
         ["__FileMetricsOffset", 0, "unsigned long"],
         ["__NumberOfFileMetrics", 4, "unsigned long"],
         ["__TraceChainsArrayOffset", 8, "unsigned long"],
         ["__NumberOfTraceChains", 12, "unsigned long"],
         ["__FilenameOffset", 16, "unsigned long"],
         ["__FilenameSize", 20, "unsigned long"],
         ["__VolumesInformationOffset", 24, "unsigned long"],
         ["__NumberOfVolumes", 28, "unsigned long"],
         ["__VolumesInformationSize", 32, "unsigned long"],

         # This is realy just one time but we make it an
         # array to be compatible with the others.
         ["LastRunTimes", 44, "Array", {
              "type": "Timestamp",
              "count": 1
           }],
         ["RunCount", 68, "unsigned long"],

         # Metrics offset is absolute.
         ["Metrics", "x=&gt;x.__FileMetricsOffset - x.StartOf", "Array", {
             type: "FileMetricsEntryV23",
             count: "x=&gt;x.__NumberOfFileMetrics",
         }],
         ["VolumeInfo", "x=&gt;x.__VolumesInformationOffset - x.StartOf", "Array", {
             type: "VolumeInformation",
             count: "x=&gt;x.__NumberOfVolumes",
          }],
        ]],


        ["FileInformationWin81", 224, [
         ["__FileMetricsOffset", 0, "unsigned long"],
         ["__NumberOfFileMetrics", 4, "unsigned long"],
         ["__TraceChainsArrayOffset", 8, "unsigned long"],
         ["__NumberOfTraceChains", 12, "unsigned long"],
         ["__FilenameOffset", 16, "unsigned long"],
         ["__FilenameSize", 20, "unsigned long"],
         ["__VolumesInformationOffset", 24, "unsigned long"],
         ["__NumberOfVolumes", 28, "unsigned long"],
         ["__VolumesInformationSize", 32, "unsigned long"],

         # This is realy just one time but we make it an
         # array to be compatible with the others.
         ["LastRunTimes", 44, "Array", {
              "type": "Timestamp",
              "count": 8,
           }],
         ["RunCount", 124, "unsigned long"],

         # Metrics offset is absolute.
         ["Metrics", "x=&gt;x.__FileMetricsOffset - x.StartOf", "Array", {
             type: "FileMetricsEntryV23",
             count: "x=&gt;x.__NumberOfFileMetrics",
         }],
         ["VolumeInfo", "x=&gt;x.__VolumesInformationOffset - x.StartOf", "Array", {
             type: "VolumeInformation",
             count: "x=&gt;x.__NumberOfVolumes",
          }],
        ]],

        ["FileInformationWin10", 224, [
         ["__FileMetricsOffset", 0, "unsigned long"],
         ["__NumberOfFileMetrics", 4, "unsigned long"],
         ["__TraceChainsArrayOffset", 8, "unsigned long"],
         ["__NumberOfTraceChains", 12, "unsigned long"],
         ["__FilenameOffset", 16, "unsigned long"],
         ["__FilenameSize", 20, "unsigned long"],
         ["__VolumesInformationOffset", 24, "unsigned long"],
         ["__NumberOfVolumes", 28, "unsigned long"],
         ["__VolumesInformationSize", 32, "unsigned long"],
         ["__TotalDirectoryCount", 36, "unsigned long"],
         ["LastRunTimes", 44, "Array", {
              "type": "Timestamp",
              "count": 8
           }],
         ["__RunCount1", 124, "unsigned long"],
         ["__RunCountPre", 120, "unsigned long"],
         ["__RunCount2", 116, "unsigned long"],
         ["RunCount", 0, Value, {
            value: "x=&gt;if(condition=x.__RunCountPre=0, then=x.__RunCount1, else=x.__RunCount2)",
         }],

         # Metrics offset is absolute.
         ["Metrics", "x=&gt;x.__FileMetricsOffset - x.StartOf", "Array", {
             type: "FileMetricsEntryV30",
             count: "x=&gt;x.__NumberOfFileMetrics",
         }],
         ["VolumeInfo", "x=&gt;x.__VolumesInformationOffset - x.StartOf", "Array", {
             type: "VolumeInformation",
             count: "x=&gt;x.__NumberOfVolumes",
          }],
        ]],

        ["Timestamp", 8, [
          ["Date", 0, "WinFileTime"],
          ["Int", 0, "unsigned long long"]
        ]],

        ["FileMetricsEntryV17", 20, [
          ["__FilenameOffset", 8, "unsigned long"],
           ["__FilenameLength", 12, "unsigned long"],
           ["Filename", 0, "Profile", {
               offset: "x=&gt;x.ParentOf.__FilenameOffset + x.__FilenameOffset",
               type: "String",
               type_options: {
                   encoding: "utf16",
                   length: 1024,
               }
           }]
        ]],


        ["FileMetricsEntryV23", 32, [
          ["__FilenameOffset", 12, "unsigned long"],
          ["__FilenameLength", 16, "unsigned long"],
          ["__MFTFileReference", 24, "unsigned long"],
          ["Filename", 0, "Profile", {
               offset: "x=&gt;x.ParentOf.__FilenameOffset + x.__FilenameOffset",
               type: "String",
               type_options: {
                   encoding: "utf16",
                   length: 1024,
               }
           }]
        ]],

        ["FileMetricsEntryV30", 32, [
           ["__FilenameOffset", 12, "unsigned long"],
           ["__FilenameLength", 16, "unsigned long"],
           ["__MFTFileReference", 24, "unsigned long"],
           ["Filename", 0, "Profile", {
               offset: "x=&gt;x.ParentOf.__FilenameOffset + x.__FilenameOffset",
               type: "String",
               type_options: {
                   encoding: "utf16",
                   length: 1024,
               }
           }]
        ]],

        ["VolumeInformation", 40, [
          ["__DeviceOffset", 0, "unsigned long"],
          ["DeviceName", "x=&gt;x.__DeviceOffset", "String", {
              encoding: utf16,
              length: "x=&gt;x.__DeviceSize * 2",
          }],
          ["__DeviceSize", 4, "unsigned long"],
          ["DeviceCreationTime", 8, "WinFileTime"],
          ["VolumeSerialNumber", 12, "unsigned long"],
          ["VolumeSerialNumberHex", 0, Value, {
              value: "x=&gt;format(format='%#x', args=x.VolumeSerialNumber)",
          }],
          ["__FileReferenceOffset", 20, "unsigned long"],
          ["__FileReferenceDataSize", 24, "unsigned long"],
          ["__DirectoryStringsOffset", 28, "unsigned long"],
          ["__NumDirectoryStrings", 32, "unsigned long"],
          ["__Directories", "x=&gt;x.__DirectoryStringsOffset", "Array", {
              type: "DirectoryName",
              count: "x=&gt;x.__NumDirectoryStrings",
          }],
          ["Directories", 0, Value, {
              value: "x=&gt;x.__Directories.Name"
          }],
        ]],
        ["DirectoryName", "x=&gt;x.Size * 2 + 4", [
          ["Size", 0, "uint8"],
          ["Name", 2, "String", {
              encoding: "utf16",
              length: "x=&gt;x.Size * 2"
          }]
        ]]
        ]
        '''

        LET ParsePrefetch(PrefetchFile) = SELECT
          parse_binary(accessor="data", filename=Data,
            profile=PrefetchProfile, struct="SCCAHeader") AS SCCAHeader
        FROM switch(a={
            -- Handle compressed MAM prefetch files.
            SELECT
              parse_binary(filename=PrefetchFile, profile=PrefetchProfile, struct="Header") AS Header,
              parse_binary(filename=PrefetchFile, profile=PrefetchProfile, struct="Header").Decompressed AS Data
            FROM scope()
            WHERE Header.Signature = "MAM"
        },
        b={
            -- Handle uncompressed files
            SELECT read_file(filename=PrefetchFile, length=1024*1024) AS Data
            FROM scope()
        })
        WHERE SCCAHeader.Signature = "SCCA"

sources:
  - query: |
        // Parse prefetch files and apply non time filters
        LET pf = SELECT * FROM foreach(
              row={
                 SELECT * FROM glob(globs=prefetchGlobs)
              },
              query={
                SELECT SCCAHeader AS _SCCAHeader,
                  SCCAHeader.Executable AS Executable,
                  SCCAHeader.FileSize AS FileSize,
                  format(format="%#X", args=SCCAHeader.Hash) AS Hash,
                  SCCAHeader.Version AS Version,
                  filter(list=SCCAHeader.Info.LastRunTimes.Date, condition="x=&gt;x.Unix &gt; 0") AS LastRunTimes,
                  SCCAHeader.Info.RunCount AS RunCount,
                  OSPath,
                  Name AS PrefetchFileName,
                  Btime as CreationTime,
                  Mtime as ModificationTime,
                  filter(list=SCCAHeader.Info.Metrics.Filename, regex=".exe$")[0] AS Binary,
                  if(condition= IncludeFilesAccessed, then=SCCAHeader.Info.Metrics.Filename) AS FilesAccessed,
                  if(condition= IncludeFilesAccessed, then=SCCAHeader.Info.VolumeInfo) AS VolumeInfo
                FROM ParsePrefetch(PrefetchFile=OSPath)
                WHERE
                    if(condition=binaryRegex, then= Executable =~ binaryRegex, else=TRUE) AND
                    if(condition=hashRegex, then= Hash =~ hashRegex, else=TRUE)
              })

        // Flattern to enable time filters. Remember VQL is lazy.
        LET executionTimes = SELECT * FROM flatten(
                query = {
                    SELECT *,
                        OSPath as FilteredPath,
                        LastRunTimes as ExecutionTime
                    FROM pf
                })
            WHERE
                if(condition=dateAfter, then=ExecutionTime &gt; timestamp(string=dateAfter),
                    else=TRUE) AND
                if(condition=dateBefore, then=ExecutionTime &lt; timestamp(string=dateBefore),
                    else=TRUE)
        LET creationTimes = SELECT * FROM flatten(
                query = {
                    SELECT *,
                        OSPath as FilteredPath,
                        CreationTime as ExecutionTime
                    FROM pf
                    WHERE RunCount &gt; 8
                })
            WHERE
                if(condition=dateAfter, then=ExecutionTime &gt; timestamp(string=dateAfter),
                    else=TRUE) AND
                if(condition=dateBefore, then=ExecutionTime &lt; timestamp(string=dateBefore),
                        else=TRUE)
            GROUP BY ExecutionTime

        // For stdOutput with timefilters we need to group by OSPath
        LET timeFiltered = SELECT FilteredPath
            FROM chain(
                a = { SELECT * FROM executionTimes },
                b = { SELECT * FROM creationTimes  })
            GROUP BY FilteredPath

        LET timeFilteredStdOut = SELECT * FROM foreach(
                row={
                        SELECT * FROM timeFiltered
                    },
                query={
                    SELECT *
                    FROM pf
                    WHERE OSPath = FilteredPath
                })

        SELECT *
        FROM if(condition = (dateBefore OR dateAfter),
            then={ SELECT * FROM timeFilteredStdOut },
            else={ SELECT * FROM pf  })


column_types:
  - name: CreationTime
    type: timestamp
  - name: ModificationTime
    type: timestamp

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/server.audit.logs.md
======
---
title: Server.Audit.Logs
hidden: true
tags: [Server Event Artifact]
---

This internal event artifact collects relevant audit events from the
server. Audit events are significant auditable actions that a user
takes, for example, starting a new collection, creating a new hunt,
updating an artifact definition etc.


<pre><code class="language-yaml">
name: Server.Audit.Logs
description: |
  This internal event artifact collects relevant audit events from the
  server. Audit events are significant auditable actions that a user
  takes, for example, starting a new collection, creating a new hunt,
  updating an artifact definition etc.

type: SERVER_EVENT

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.etw.kernelnetwork.md
======
---
title: Windows.ETW.KernelNetwork
hidden: true
tags: [Client Event Artifact]
---

This artifact follows the Microsoft-Windows-Kernel-Network provider.

NOTE: We can only attach to this provider when running as
NT_USER/SYSTEM.


<pre><code class="language-yaml">
name: Windows.ETW.KernelNetwork
description: |
  This artifact follows the Microsoft-Windows-Kernel-Network provider.

  NOTE: We can only attach to this provider when running as
  NT_USER/SYSTEM.

references:
- "https://github.com/repnz/etw-providers-docs/blob/master/Manifests-Win10-18990/Microsoft-Windows-Kernel-Network.xml"

type: CLIENT_EVENT

parameters:
  - name: ProcessRegex
    type: regex
    description: View Processes with Executables matching this regex
    default: .

  - name: IgnoreProcessRegex
    type: regex
    description: Ignore Processes with Executables matching this regex

  - name: Events
    type: multichoice
    description: Events to view
    default: '["ConnectionAttempted", "ConnectionAccepted"]'
    choices:
      - DataSent
      - DataReceived
      - ConnectionAttempted
      - ConnectionAccepted
      - DataSentOverUDPProtocol
      - DataReceivedOverUDPProtocol

sources:
  - query: |
      LET EIDLookup &lt;= dict(
        `10`="DataSent", `11`="DataReceived", `12`="ConnectionAttempted", `15`="ConnectionAccepted",
        `42`="DataSentOverUDPProtocol",`43`="DataReceivedOverUDPProtocol")

      LET ETW = SELECT *
      FROM watch_etw(guid='{7dd42a49-5329-4832-8dfd-43d979153a88}',
           description="Microsoft-Windows-Kernel-Network")

      SELECT System.ID AS EID,
         get(item=EIDLookup, field=str(str=System.ID)) AS EventType,
         process_tracker_get(id=EventData.PID).Data AS ProcInfo,
         process_tracker_callchain(id=EventData.PID).Data.Exe AS CallChain,
         EventData
      FROM delay(query=ETW, delay=3)
      WHERE EventType IN Events
        AND EventData.ImageName =~ ProcessRegex
        AND if(condition=IgnoreProcessRegex,
               then=NOT EventData.ImageName =~ IgnoreProcessRegex,
               else=TRUE)

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/system.vfs.listdirectory.md
======
---
title: System.VFS.ListDirectory
hidden: true
tags: [Client Artifact]
---

This is an internal artifact used by the GUI to populate the
VFS. You may run it manually if you like, but typically it is
launched by the GUI when a user clicks the "Refresh this directory"
button.


<pre><code class="language-yaml">
name: System.VFS.ListDirectory
description: |
  This is an internal artifact used by the GUI to populate the
  VFS. You may run it manually if you like, but typically it is
  launched by the GUI when a user clicks the "Refresh this directory"
  button.

parameters:
  - name: Path
    description: The path of the file to download.
    default: "/"

  - name: Components
    type: json_array
    description: Alternatively, this is an explicit list of components.

  - name: Accessor
    default: file

  - name: Depth
    type: int
    default: 0

export: |
      -- Make the generator unique with the session id - so it can
      -- only be shared by the two sources in this collection.
      LET VFSGenerator = generate(name="vfs-" + _SessionId, query={
         SELECT * FROM vfs_ls(
            path="/", components=Components,
            accessor=Accessor, depth=Depth)
      }, delay=500)  -- wait a while for both sources to connect.

sources:
  - precondition: SELECT * FROM info() WHERE version(plugin="vfs_ls") = 1
    name: Listing
    description: File listing of multiple directories in a single table.
    query: |
      SELECT OSPath AS _OSPath,
             Components AS _Components,
             Accessor AS _Accessor,
             Data AS _Data,
             Name, Size, Mode,
             Mtime as mtime,
             Atime as atime,
             Ctime as ctime,
             Btime as btime,
             Idx AS _Idx
      FROM VFSGenerator
      WHERE Stats = NULL

  - precondition: SELECT * FROM info() WHERE version(plugin="vfs_ls") = 1
    name: Stats
    description: |
      A list of summary objects dividing the Listing source into
      distinct directories.
    query: |
      SELECT Components,
             Accessor,
             Stats
      FROM VFSGenerator
      WHERE Stats != NULL

  - precondition: SELECT * FROM info() WHERE NOT version(plugin="vfs_ls")
    query: |
      // Glob &gt; v2 accepts a component list for the root parameter.
      LET Path &lt;= if(condition=version(plugin="glob") &gt; 2 AND Components,
        then=Components, else=Path)

      // Old versions do not have the root parameter to glob()
      // Fixes https://github.com/Velocidex/velociraptor/issues/322
      LET LegacyQuery = SELECT OSPath as _OSPath,
           Accessor as _Accessor,
           Data as _Data,
           Name, Size, Mode.String AS Mode,
           Mtime as mtime,
           Atime as atime,
           Ctime as ctime
        FROM glob(globs=Path + if(condition=Depth,
             then=format(format='/**%v', args=Depth), else='/*'),
             accessor=Accessor)

      LET NewQuery = SELECT OSPath as _OSPath,
           Accessor as _Accessor,
           Data as _Data,
           Name, Size, Mode.String AS Mode,
           Mtime as mtime,
           Atime as atime,
           Ctime as ctime,
           Btime AS btime
        FROM glob(
             globs=if(condition=Depth,
                then=format(format='/**%v', args=Depth),
                else='/*'),
             root=Path,
             accessor=Accessor)

      SELECT * FROM if(
       condition=version(plugin="glob") &gt;= 1,
       then=NewQuery,
       else=LegacyQuery)

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/linux.applications.chrome.extensions.md
======
---
title: Linux.Applications.Chrome.Extensions
hidden: true
tags: [Client Artifact]
---

Fetch Chrome extensions.

Chrome extensions are installed into the user's home directory.  We
search for manifest.json files in a known path within each system
user's home directory. We then parse the manifest file as JSON.

Many extensions use locale packs to resolve strings like name and
description. In this case we detect the default locale and load
those locale files. We then resolve the extension's name and
description from there.


<pre><code class="language-yaml">
name: Linux.Applications.Chrome.Extensions
description: |
  Fetch Chrome extensions.

  Chrome extensions are installed into the user's home directory.  We
  search for manifest.json files in a known path within each system
  user's home directory. We then parse the manifest file as JSON.

  Many extensions use locale packs to resolve strings like name and
  description. In this case we detect the default locale and load
  those locale files. We then resolve the extension's name and
  description from there.

parameters:
  - name: extensionGlobs
    default: /.config/google-chrome/*/Extensions/*/*/manifest.json
sources:
  - precondition: |
      SELECT OS From info() where OS = 'linux'

    query: |
        /* For each user on the system, search for extension manifests
           in their home directory. */
        LET extension_manifests = SELECT * from foreach(
          row={
             SELECT Uid, User, Homedir from Artifact.Linux.Sys.Users()
          },
          query={
             SELECT OSPath, Mtime, Ctime, User, Uid
             FROM glob(
               globs=extensionGlobs,
               root=Homedir)
          })

        /* If the Manifest declares a default_locale then we
           load and parse the messages file. In this case the
           messages are actually stored in the locale file
           instead of the main manifest.json file.
        */
        LET maybe_read_locale_file =
           SELECT * from if(
              condition={
                 select * from scope() where Manifest.default_locale
              },
              then={
                 SELECT Manifest,
                        Uid, User,
                        Filename as LocaleFilename,
                        ManifestFilename,
                        parse_json(data=Data) AS LocaleManifest
                 FROM read_file(
                         -- Munge the filename to get the messages.json path.
                         filenames=regex_replace(
                           source=ManifestFilename,
                           replace="/_locales/" + Manifest.default_locale +
                                   "/messages.json",
                           re="/manifest.json$"))
              },
              else={
                  -- Just fill in empty Locale results.
                  SELECT Manifest,
                         Uid, User,
                         "" AS LocaleFilename,
                         "" AS ManifestFilename,
                         "" AS LocaleManifest
                  FROM scope()
              })

        LET parse_json_files = SELECT * from foreach(
           row={
             SELECT Filename as ManifestFilename,
                    Uid, User,
                    parse_json(data=Data) as Manifest
             FROM read_file(filenames=OSPath)
           },
           query=maybe_read_locale_file)

        LET parsed_manifest_files = SELECT * from foreach(
          row=extension_manifests,
          query=parse_json_files)

        SELECT Uid, User,

               /* If the manifest name contains __MSG_ then the real
                  name is stored in the locale manifest. This condition
                  resolves the Name column either to the main manifest or
                  the locale manifest.
               */
               if(condition="__MSG_" in Manifest.name,
                  then=get(item=LocaleManifest,
                     member=regex_replace(
                        source=Manifest.name,
                        replace="$1",
                        re="(?:__MSG_(.+)__)")).message,
                  else=Manifest.name) as Name,

               if(condition="__MSG_" in Manifest.description,
                  then=get(item=LocaleManifest,
                     member=regex_replace(
                        source=Manifest.description,
                        replace="$1",
                        re="(?:__MSG_(.+)__)")).message,
                  else=Manifest.description) as Description,

               /* Get the Identifier and Version from the manifest filename */
               regex_replace(
                 source=ManifestFilename,
                 replace="$1",
                 re="(?:.+Extensions/([^/]+)/([^/]+)/manifest.json)$") AS Identifier,
               regex_replace(
                 source=ManifestFilename,
                 replace="$2",
                 re="(?:.+Extensions/([^/]+)/([^/]+)/manifest.json)$") AS Version,

               Manifest.author as Author,
               Manifest.background.persistent AS Persistent,
               regex_replace(
                 source=ManifestFilename,
                 replace="$1",
                 re="(.+Extensions/.+/)manifest.json$") AS Path,

               Manifest.oauth2.scopes as Scopes,
               Manifest.permissions as Permissions,
               Manifest.key as Key

        FROM parsed_manifest_files

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/generic.network.interfaceaddresses.md
======
---
title: Generic.Network.InterfaceAddresses
hidden: true
tags: [Client Artifact]
---

Network interfaces and relevant metadata. This artifact works on all
supported OSs.


<pre><code class="language-yaml">
name: Generic.Network.InterfaceAddresses
description: |
  Network interfaces and relevant metadata. This artifact works on all
  supported OSs.

aliases:
  - Windows.Network.InterfaceAddresses

sources:
  - query: |
        LET interface_address =
           SELECT Index, MTU, Name,
                  HardwareAddr.String AS HardwareAddr,
                  Flags, Addrs
           from interfaces()

        SELECT Index, MTU, Name, HardwareAddr,
           Flags, Addrs.IP as IP, Addrs.Mask.String as Mask
        FROM flatten(query=interface_address)

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/server.utils.killclient.md
======
---
title: Server.Utils.KillClient
hidden: true
tags: [Server Artifact]
---

This artifact agressively kills a client.

If the client runs as a service, it will restart by the service manager.

NOTE: If the client is not running as a service (i.e. interactively)
it may not restart and further communication will be lost!


<pre><code class="language-yaml">
name: Server.Utils.KillClient
description: |
  This artifact agressively kills a client.

  If the client runs as a service, it will restart by the service manager.

  NOTE: If the client is not running as a service (i.e. interactively)
  it may not restart and further communication will be lost!

type: SERVER


parameters:
  - name: ClientIdList
    description: A list of client ids to kill.
    default:

sources:
  - query: |
      let clients_list = SELECT ClientId
      FROM parse_records_with_regex(
          accessor="data", file=ClientIdList,
          regex="(?P&lt;ClientId&gt;C\\.[0-9a-z-]+)")
      WHERE log(message="Killing client " + ClientId)

      SELECT * FROM foreach(row=clients_list,
      query={
         SELECT killkillkill(client_id=ClientId) FROM scope()
      })

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.system.auditpolicy.md
======
---
title: Windows.System.AuditPolicy
hidden: true
tags: [Client Artifact]
---

Artifact using auditpol to retrieve the logging settings 
defined in the Windows Audit Policy.

Use this artifact to determine what Windows event logs are audited
and if there are any discrepancies across the environment.


<pre><code class="language-yaml">
name: Windows.System.AuditPolicy

description: |
   Artifact using auditpol to retrieve the logging settings 
   defined in the Windows Audit Policy.
   
   Use this artifact to determine what Windows event logs are audited
   and if there are any discrepancies across the environment.

type: CLIENT

author: Zach Stanford - @svch0st

sources:
  - precondition:
      SELECT OS From info() where OS = 'windows'

    query: |
      LET output = SELECT * FROM execve(
        argv=["auditpol.exe","/get","/category:*","/r"])
      
      SELECT * FROM foreach(
        row=output,
        query={
            SELECT * FROM parse_csv(filename=Stdout,accessor="data")
        }
      )

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/linux.rhel.packages.md
======
---
title: Linux.RHEL.Packages
hidden: true
tags: [Client Artifact]
---

Parse packages installed from dnf or yum


<pre><code class="language-yaml">
name: Linux.RHEL.Packages
description: |
  Parse packages installed from dnf or yum
sources:
  - precondition: |
      SELECT OS From info() where OS = 'linux'

    query: |
        LET Data &lt;= SELECT * FROM switch(
            a={ SELECT Stdout FROM execve(argv=["dnf", "--quiet", "list", "installed"], length=10000000) WHERE Stdout },
            b={ SELECT Stdout FROM execve(argv=["yum", "--quiet", "list", "installed"], length=10000000) WHERE Stdout },
            c={SELECT "" AS Stdout FROM scope() WHERE log(level="ERROR",message="Could not retrieve package list") })

        // Sometimes lines overflow to the next line, correct for that
        LET Normalized &lt;= regex_replace(source=Data[0].Stdout, re='''(?sm)\n\s''', replace="")
        LET Parsed = SELECT parse_string_with_regex(string=Line, regex='''([^\s]+)\s+([^\s]+)\s+([^\s]+)''') AS Parsed
        FROM parse_lines(accessor="data", filename=Normalized)

        SELECT Parsed.g1 AS Package, Parsed.g2 AS Version, Parsed.g3 AS Repository
        FROM Parsed
        WHERE Repository =~ "^@"

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/generic.detection.yara.zip.md
======
---
title: Generic.Detection.Yara.Zip
hidden: true
tags: [Client Artifact]
---

This artifact enables running Yara on embeded compressed files.

The artifact:

* firstly searches for compressed zip files (PK header)
* then applies yara on files inside.
* files matching ZipFilenameRegex are recursively searched as above.

The artifact is optimised to recursively search through embedded zip,
jar,war and ear files by extracting any discovered containers.
Select UploadHits to upload Discovered file for further analysis.  It is
recommended to increase default artifact timeout for large servers or target
glob.

Some examples of path glob may include:

* Specific container: `/path/here/file.zip`
* Wildcards: `/var/www/*.{jar,war,ear}`
* More wildcards: `/var/www/**/*.jar`
* Windows: `C:/**/*.zip`

NOTE: this artifact runs the glob plugin with the nosymlink switch
turned on.  This will NOT follow any symlinks and may cause
unexpected results if unknowingly targeting a folder with
symlinks. Yara is not applied to the containers, only contained contents
that are not containers.


<pre><code class="language-yaml">
name: Generic.Detection.Yara.Zip
author: "Matt Green - @mgreen27"
description: |
    This artifact enables running Yara on embeded compressed files.

    The artifact:

    * firstly searches for compressed zip files (PK header)
    * then applies yara on files inside.
    * files matching ZipFilenameRegex are recursively searched as above.

    The artifact is optimised to recursively search through embedded zip,
    jar,war and ear files by extracting any discovered containers.
    Select UploadHits to upload Discovered file for further analysis.  It is
    recommended to increase default artifact timeout for large servers or target
    glob.

    Some examples of path glob may include:

    * Specific container: `/path/here/file.zip`
    * Wildcards: `/var/www/*.{jar,war,ear}`
    * More wildcards: `/var/www/**/*.jar`
    * Windows: `C:/**/*.zip`

    NOTE: this artifact runs the glob plugin with the nosymlink switch
    turned on.  This will NOT follow any symlinks and may cause
    unexpected results if unknowingly targeting a folder with
    symlinks. Yara is not applied to the containers, only contained contents
    that are not containers.

parameters:
  - name: TargetGlob
    default: "**/*.{zip,jar,war,ear}"
  - name: ZipFilenameRegex
    default: ".(zip|jar|war|ear)$"
    description: Regex of FileName inside container files we would like to recursively scan.
  - name: MaxRecursions
    description: Number of recursions to allow checking inside archives. Default is 10 layers.
    default: 10
    type: int
  - name: UploadHits
    description: Select to upload hits to server.
    type: bool
  - name: YaraRule
    type: yara
    description: Final Yara option and the default if no other options provided.
    default: |
        rule IsPE:TestRule {
           meta:
              author = "the internet"
              date = "2021-03-04"
              description = "A simple PE rule to test yara features"
          condition:
             uint16(0) == 0x5A4D and
             uint32(uint32(0x3C)) == 0x00004550
        }
  - name: NumberOfHits
    description: THis artifact will stop by default at one hit. This setting allows additional hits
    default: 1
    type: int
  - name: ContextBytes
    description: Include this amount of bytes around hit as context.
    default: 0
    type: int

sources:
  - query: |
      -- this section glob searches and confirms we are looking at zip container
      LET target_files = SELECT *,
            read_file(filename=OSPath,offset=0,length=2) as _Header
        FROM glob(globs=TargetGlob,nosymlink=True)
        WHERE _Header = 'PK'

      -- recursive search function
      LET Recurse(Container, File, Accessor, RecursionRounds) = SELECT * FROM if(
        condition=RecursionRounds &lt; MaxRecursions,
        then={
           SELECT * FROM foreach(
                row={
                    SELECT *
                    FROM glob(accessor='zip',
                       root=pathspec(DelegatePath=File, DelegateAccessor=Accessor),
                       globs='**')
                    WHERE NOT IsDir AND Size &gt; 0
                },
                query={
                    SELECT *
                    FROM if(condition=Name =~ ZipFilenameRegex,
                            then={
                                SELECT *
                                FROM Recurse(
                                    Container = Container,
                                    File=OSPath,
                                    Accessor="zip",
                                    RecursionRounds = RecursionRounds + 1)
                            },
                            else={
                              SELECT
                                Container,
                                OSPath.HumanString as ExtractedPath,
                                OSPath.Path as FilePath,
                                hash(accessor='zip',path=OSPath) as Hash,
                                File.Size AS Size,
                                Mtime, Atime, Ctime, Btime,
                                Rule, Tags, Meta,
                                String.Name as YaraString,
                                String.Offset as HitOffset,
                                if(condition=String.Data,
                                   then=upload(
                                    accessor='scope',
                                    file='String.Data',
                                    name=format(format="%v_%v",
                                    args=[ OSPath.HumanString, String.Offset ]
                                   ))) as HitContext
                              FROM yara(accessor='zip',files=OSPath,rules=YaraRule,
                                context=ContextBytes, number=NumberOfHits)
                            })
                    })
          })

      LET hits = SELECT * FROM foreach(row=target_files,
            query={
                SELECT *
                FROM Recurse(Container=OSPath,File=OSPath, Accessor="auto", RecursionRounds=0)
            })

      -- upload files that have hit
      LET upload_hits = SELECT *, upload(file=Container) as ContainerUpload FROM hits

      -- display rows
      SELECT * FROM if(condition=UploadHits,
        then= upload_hits,
        else= hits)

column_types:
  - name: HitContext
    type: preview_upload

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.detection.templateinjection.md
======
---
title: Windows.Detection.TemplateInjection
hidden: true
tags: [Client Artifact]
---

This content will detect injected templates in Office and RTF documents.

Template injection is a form of defence evasion.
For office documents a malicious macro is loaded into an OOXML document
via a resource file masquerading as an office template. The OOXML artifact structure
will also detect MSHTML RCE Vulnerability #CVE-2021-40444 which has a similar payload technique.
For RTF documents a malicious payload can be delivered by modifying document
formatting control via the "\\\*\template" structure.


This artifact can be modified to search for other suspicious rels files:

- document.xml.rels = macros, ole objects, images.
- settings.xml.rels = templates.
- websettings.xml.rels = frames.
- header#.xml.rels and footer#.xml.rels and others has also been observed
hosting image files for canary files or abused for NetNTLM hash collection.

Change TemplateFileRegex to '\\.xml\\.rels$' for looser file selection.
Change TemplateTargetRegex to '^(https?|smb|\\\\|//|mhtml|file)' for looser
Target selection.

This artifact can also be modified to quickly deploy yara based detections on
other documents. Simply replace RtfYara with yara of interest and modify glob
for targeting.


<pre><code class="language-yaml">
name: Windows.Detection.TemplateInjection
author: Matt Green - @mgreen27
description: |
    This content will detect injected templates in Office and RTF documents.

    Template injection is a form of defence evasion.
    For office documents a malicious macro is loaded into an OOXML document
    via a resource file masquerading as an office template. The OOXML artifact structure
    will also detect MSHTML RCE Vulnerability #CVE-2021-40444 which has a similar payload technique.
    For RTF documents a malicious payload can be delivered by modifying document
    formatting control via the "\\\*\template" structure.


    This artifact can be modified to search for other suspicious rels files:

    - document.xml.rels = macros, ole objects, images.
    - settings.xml.rels = templates.
    - websettings.xml.rels = frames.
    - header#.xml.rels and footer#.xml.rels and others has also been observed
    hosting image files for canary files or abused for NetNTLM hash collection.

    Change TemplateFileRegex to '\\.xml\\.rels$' for looser file selection.
    Change TemplateTargetRegex to '^(https?|smb|\\\\|//|mhtml|file)' for looser
    Target selection.

    This artifact can also be modified to quickly deploy yara based detections on
    other documents. Simply replace RtfYara with yara of interest and modify glob
    for targeting.



reference:
  - https://attack.mitre.org/techniques/T1221/
  - https://www.sans.org/reading-room/whitepapers/testing/template-injection-attacks-bypassing-security-controls-living-land-38780

type: CLIENT

parameters:
  - name: SearchGlob
    description: Glob to search
    default: C:\Users\**\*.{rtf,doc,dot,docx,docm,dotx,dotm,docb,xls,xlt,xlm,xlsx,xlsm,xltx,xltm,xlsb,ppt,pptx,pptm,potx,potm}
  - name: TemplateFileRegex
    description: Regex to search inside resource section.
    default: '(document|settings)\.xml\.rels$'
    type: regex
  - name: TemplateTargetRegex
    description: Regex to search inside resource section.
    default: '^(https?|smb|\\\\|//|mhtml)'
    type: regex
  - name: UploadDocument
    type: bool
    description: Select to upload document on detection.
  - name: RtfYara
    type: yara
    default: |
        rule RTF_TemplateInjection {
            meta:
                author = "Matt Green - @mgreen27"
                description = "Yara for RTF template injection. Using regex match to extract template information"

            strings:
                $regex1 = /\{\\\*\\template\s+http[^\}]+\}/ nocase
                $regex2 = /\{\\\*\\templates\s+\\u-[^\}]+\}/ nocase
                $regex3 = /\{\\\*\\template\s+file[^\}]+\}/ nocase

            condition:
              // header is {\rt only to also flag on malformed rtf heders
              uint32be(0) == 0x7B5C7274 and 1 of them
        }

sources:
  - precondition:
      SELECT OS From info() where OS = 'windows'

    query: |
      -- Find target docs
      LET office_docs = SELECT OSPath, Mtime, Size
        FROM glob(globs=SearchGlob)
        WHERE NOT IsDir and Size &gt; 0

      LET rtf_injection &lt;= SELECT * FROM foreach(
         row=office_docs,
         query={
                SELECT
                    OSPath AS DocumentPath,
                    hash(path=OSPath) as DocumentHash,
                    Mtime,
                    Size,
                    'YaraHit: ' + Rule  as Section,
                    regex_replace(
                      source=String.Data,
                      re='\{...template\s*|\}',replace='') as TemplateTarget
                FROM yara(files=OSPath, rules=RtfYara)
                WHERE NOT TemplateTarget =~ '^http(s|)://schemas\.microsoft\.com/'

            })

      -- select zip members inside the doc that have some content.
      LET document_parts = SELECT * FROM foreach(
            row={
                SELECT
                    OSPath AS OfficePath,
                    Mtime as OfficeMtime,
                    Size as OfficeSize
                FROM office_docs
                WHERE NOT OSPath in rtf_injection.OSPath
            },
            query= {
                SELECT
                    Mtime, Atime, Ctime,
                    OSPath,
                    OSPath.Path AS ZipMemberPath,
                    OfficePath
                FROM glob(
                  globs="/**",
                  root=pathspec(DelegatePath=OfficePath),
                  accessor='zip')
                WHERE not IsDir
                  AND Size &gt; 0
                  AND ZipMemberPath =~ TemplateFileRegex
            })

      -- parse settings file by line and extract config
      LET template = SELECT * FROM foreach(row=document_parts,
        query={
            SELECT
                OSPath as SectionPath,
                OSPath.DelegatePath as Document,
                OSPath.Path as Section,
                parse_string_with_regex(
                    string=Line,
                    regex=['\\s+Target="(?P&lt;Target&gt;[^"]+)"\\s+TargetMode='
                        ]).Target as TemplateTarget,
                Mtime as SectionMtime,
                Atime as SectionAtime,
                Ctime as SectionCtime
            FROM parse_lines(filename=OSPath, accessor='zip')
            WHERE TemplateTarget
        })

      -- search settings for remote or file templates, format mshtml entries
      LET hits = SELECT * FROM chain(
        rtf = { SELECT * FROM rtf_injection },
        office = {
            SELECT * FROM foreach(row=template,
                query={
                    SELECT
                        OSPath AS DocumentPath,
                        hash(path=OSPath) as DocumentHash,
                        Mtime,
                        Size,
                        Section,
                        regex_replace(source=TemplateTarget,
                            re='.*Target="(mhtml)',
                            replace='mhtml') as TemplateTarget,
                        SectionMtime,
                        hash(path=SectionPath,accessor='zip') as SectionHash
                    FROM stat(filename=Document)
                    WHERE
                        TemplateTarget =~ TemplateTargetRegex
                         AND (( Section=~'/document.xml.rels$' AND TemplateTarget=~'^mhtml:' )
                                OR NOT Section=~'/document.xml.rels$' )
                })
        })

      -- upload hits to server
      LET upload_hits = SELECT *, upload(file=DocumentPath) as Upload
        FROM hits

      -- output rows
      SELECT * FROM if(condition= UploadDocument,
            then= { SELECT * FROM upload_hits},
            else= { SELECT * FROM hits})

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/server.hunts.cancelanddelete.md
======
---
title: Server.Hunts.CancelAndDelete
hidden: true
tags: [Server Artifact]
---

Velociraptor Hunts are a way of running the same flow on
many endpoints at once. Hunts issue very quickly and wait
until each endpoint returns results.

Sometimes, the artifacts collected might take a long time and
have unacceptable performance impact on the endpoint.
In some cases the artifacts end up retrieving too much data
that is not needed.

For those cases you might want to run the following server
artifact. It cancels all currently in-flight collections.

Optionally you can also remove any files already collected if you
do not need them.

This artifact is implicitly collected by the GUI when pressing the
"Delete Hunt" Button.


<pre><code class="language-yaml">
name: Server.Hunts.CancelAndDelete
description: |
   Velociraptor Hunts are a way of running the same flow on
   many endpoints at once. Hunts issue very quickly and wait
   until each endpoint returns results.

   Sometimes, the artifacts collected might take a long time and
   have unacceptable performance impact on the endpoint.
   In some cases the artifacts end up retrieving too much data
   that is not needed.

   For those cases you might want to run the following server
   artifact. It cancels all currently in-flight collections.

   Optionally you can also remove any files already collected if you
   do not need them.

   This artifact is implicitly collected by the GUI when pressing the
   "Delete Hunt" Button.

type: SERVER

parameters:
  - name: HuntId
    description: hunt_id you would like to kill all associated flows.
    default: "H.XXXXXX"
  - name: DeleteAllFiles
    description: Also delete all collected files
    type: bool

sources:
  - name: CancelFlows
    query: |
      // Get the flows and their running state for this hunt.
      LET flows = SELECT ClientId, FlowId, HuntId, {
            SELECT state FROM flows(client_id=ClientId, flow_id=FlowId)
        } AS FlowState
      FROM hunt_flows(hunt_id=HuntId)

      // Only cancel running flows.
      SELECT *, cancel_flow(client_id=ClientId, flow_id=FlowId) as cancel_flow
      FROM flows
      WHERE FlowState = "RUNNING"

  - name: HuntFiles
    query: |
      SELECT * FROM hunt_delete(hunt_id=HuntId, really_do_it=DeleteAllFiles)

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.detection.yara.physicalmemory.md
======
---
title: Windows.Detection.Yara.PhysicalMemory
hidden: true
tags: [Client Artifact]
---

This artifact enables running Yara over physical memory.

There are 2 kinds of Yara rules that can be deployed:
 &nbsp;1. Url link to a yara rule.
 &nbsp;2. A Standard Yara rule attached as a parameter.

Only one method of Yara will be applied and search order is as above. The
default is Cobalt Strike opcodes.

The artifact will load the winpmem driver, then yara scan the
physical memory and remove the driver.

NOTE: This artifact is experimental and can crash the system!

### Handling signatures with fixed strings.

When the signature specifies fixed strings, the Yara engine will
load it into memory, causing the signature to match memory used by
Velociraptor. To avoid this false positive encode the fixed
string as an alternative string.

For example instead of:
```
$sequence_5 = { 250000ff00 33d0 8b4db0 c1e908 }
```

Write as:
```
$sequence_5 = { 250000ff00 33d0 8b4db0 c1e9 ( 08 | 08 ) }
```


<pre><code class="language-yaml">
name: Windows.Detection.Yara.PhysicalMemory
description: |
  This artifact enables running Yara over physical memory.

  There are 2 kinds of Yara rules that can be deployed:
   &amp;nbsp;1. Url link to a yara rule.
   &amp;nbsp;2. A Standard Yara rule attached as a parameter.

  Only one method of Yara will be applied and search order is as above. The
  default is Cobalt Strike opcodes.

  The artifact will load the winpmem driver, then yara scan the
  physical memory and remove the driver.

  NOTE: This artifact is experimental and can crash the system!

  ### Handling signatures with fixed strings.

  When the signature specifies fixed strings, the Yara engine will
  load it into memory, causing the signature to match memory used by
  Velociraptor. To avoid this false positive encode the fixed
  string as an alternative string.

  For example instead of:
  ```
  $sequence_5 = { 250000ff00 33d0 8b4db0 c1e908 }
  ```

  Write as:
  ```
  $sequence_5 = { 250000ff00 33d0 8b4db0 c1e9 ( 08 | 08 ) }
  ```

type: CLIENT
parameters:
  - name: ServiceName
    description: Override the name of the driver service to install.

  - name: NumberOfHits
    description: THis artifact will stop by default at one hit. This setting allows additional hits
    default: 100
    type: int64
  - name: ContextBytes
    description: Include this amount of bytes around hit as context.
    default: 0
    type: int
  - name: YaraUrl
    description: If configured will attempt to download Yara rules from Url
    type: upload
  - name: YaraRule
    type: yara
    description: Final Yara option and the default if no other options provided.
    default: |
      rule win_cobalt_strike_auto {
         meta:
           author = "Felix Bilstein - yara-signator at cocacoding dot com"
           date = "2019-11-26"
           version = "1"
           description = "autogenerated rule brought to you by yara-signator"
           tool = "yara-signator 0.2a"
           malpedia_reference = "https://malpedia.caad.fkie.fraunhofer.de/details/win.cobalt_strike"
           malpedia_license = "CC BY-SA 4.0"
           malpedia_sharing = "TLP:WHITE"

         strings:
           $sequence_0 = { 3bc7 750d ff15???????? 3d33270000 }
           $sequence_1 = { e9???????? eb0a b801000000 e9???????? }
           $sequence_2 = { 8bd0 e8???????? 85c0 7e0e }
           $sequence_3 = { ffb5f8f9ffff ff15???????? 8b4dfc 33cd e8???????? c9 c3 }
           $sequence_4 = { e8???????? e9???????? 833d?????????? 7505 e8???????? }
           $sequence_5 = { 250000ff00 33d0 8b4db0 c1e9 ( 08 | 08 ) }
           $sequence_6 = { ff75f4 ff7610 ff761c ff75 (fc | fc) }
           $sequence_7 = { 8903 6a06 eb39 33ff 85c0 762b 03 ( f1 | f1 ) }
           $sequence_8 = { 894d ( d4 | d4 ) 8b458c d1f8 894580 8b45f8 c1e818 0fb6c8 }
           $sequence_9 = { 890a 8b45 ( 08 | 08 ) 0fb64804 81e1ff000000 c1e118 8b5508 0fb64205 }
           $sequence_10 = { 33d2 e8???????? 48b873797374656d3332 4c8bc7 488903 49ffc0 }
           $sequence_11 = { 488bd1 498d4b ( d8 | d8 ) 498943e0 498943e8 }
           $sequence_12 = { b904000000 486bc9 ( 0e | 0e ) 488b542430 4c8b442430 418b0c08 8b0402 }
           $sequence_13 = { ba80000000 e8???????? 488d4c2438 e8???????? 488d4c2420 8bd0 e8???????? }
           $sequence_14 = { 488b4c2430 8b0401 ( 89 | 89 ) 442428 b804000000 486bc004 }
           $sequence_15 = { 4883c708 4883c304 49ff ( c3 | c3 ) 48ffcd 0f854fffffff 488d4c2420 }

        condition:
            7 of them
      }

sources:
  - precondition:
      SELECT OS From info() where OS = 'windows'

    query: |
      -- check which Yara to use
      LET yara_rules &lt;= YaraUrl || YaraRule

      LET SparsePath = pathspec(
           DelegateAccessor='raw_file',
           DelegatePath='''\\.\pmem''',
           Path={
              SELECT atoi(string=Start) AS Offset,
                   atoi(string=Length) AS Length
              FROM Artifact.Windows.Sys.PhysicalMemoryRanges()
              WHERE Type = 3
           })

      -- Load the winpmem binary
      LET _ &lt;= winpmem(service=ServiceName)

      SELECT
         Rule,
         Meta,
         String.Offset as HitOffset,
         String.Name as HitName,
         String.HexData as HitHexData
      FROM yara(files=SparsePath, accessor='winpmem',
                rules=yara_rules, context=ContextBytes, number=NumberOfHits)

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.detection.amcache.md
======
---
title: Windows.Detection.Amcache
hidden: true
tags: [Client Artifact]
---

This artifact collects AMCache entries with a SHA1 hash to enable threat
detection.

AmCache is an artifact which stores metadata related to PE execution and
program installation on Windows 7 and Server 2008 R2 and above. This artifact
includes EntryName, EntryPath and SHA1 as great data points for IOC collection.
Secondary datapoints include publisher/company, BinaryType and OriginalFileName.

Available filters include:

  - SHA1regex - regex entries to filter by SHA1.
  - PathRegex - filter on path if available.
  - NameRegex - filter on EntryName OR OriginalFileName.

NOTE:

  - Secondary fields are not consistent across AMCache types and some legacy
  versions do not return these fields.
  - Some enrichment has occured but any secondary fields should be treated as
  guidance only.
  - This artifact collects only entries with a SHA1, for complete AMCache
  analysis please download raw artifact sets.


<pre><code class="language-yaml">
name: Windows.Detection.Amcache
author: Matt Green - @mgreen27
description: |
    This artifact collects AMCache entries with a SHA1 hash to enable threat
    detection.

    AmCache is an artifact which stores metadata related to PE execution and
    program installation on Windows 7 and Server 2008 R2 and above. This artifact
    includes EntryName, EntryPath and SHA1 as great data points for IOC collection.
    Secondary datapoints include publisher/company, BinaryType and OriginalFileName.

    Available filters include:

      - SHA1regex - regex entries to filter by SHA1.
      - PathRegex - filter on path if available.
      - NameRegex - filter on EntryName OR OriginalFileName.

    NOTE:

      - Secondary fields are not consistent across AMCache types and some legacy
      versions do not return these fields.
      - Some enrichment has occured but any secondary fields should be treated as
      guidance only.
      - This artifact collects only entries with a SHA1, for complete AMCache
      analysis please download raw artifact sets.

reference:
  - https://www.ssi.gouv.fr/uploads/2019/01/anssi-coriin_2019-analysis_amcache.pdf

parameters:
  - name: AMCacheGlob
    default: "%SYSTEMROOT%/appcompat/Programs/Amcache.hve"
    description: AMCache hive path
  - name: KeyPathGlob
    default: /Root/{Inventory, File}*/**
    type: hidden
    description: Registry key path glob
  - name: SHA1Regex
    default: .
    description: Regex of SHA1s to filter
    type: regex
  - name: PathRegex
    description: Regex of recorded path.
    type: regex
  - name: NameRegex
    description: Regex of entry / binary name
    type: regex

sources:
  - query: |
        LET files &lt;= SELECT OSPath
           FROM glob(globs=expand(path=AMCacheGlob))

        SELECT * FROM foreach(row=files,
                query={
                    SELECT
                      Key.OSPath.DelegatePath As HivePath,
                      Key.OSPath.Path as EntryKey,
                      Key.ModTime as KeyMTime,

                      -- Key is like \Root\InventoryDriverBinary\"c:/windows/system32/drivers/1394ohci.sys"
                      Key.OSPath.Components[1] as EntryType,

                      if(condition=get(member="FileId"),
                         then=strip(string=FileId, prefix='0000'),
                      else=if(condition=get(member="101"),
                         then=strip(string=`101`, prefix='0000'),
                      else=if(condition=get(member="DriverId"),
                         then=strip(string=DriverId, prefix='0000')))) as SHA1,

                      if(condition=get(member="Name"),
                         then=Name,
                      else=if(condition=get(member="FriendlyName"),
                         then=FriendlyName,
                      else=if(condition=get(member="15"),
                         then=split(string=str(str=`15`), sep='\\\\')[-1],
                      else=if(condition=get(member="DriverName"),
                         then=DriverName)))) as EntryName,

                      if(condition=get(member="LowerCaseLongPath"),
                          then=LowerCaseLongPath,
                      else=if(condition=get(member="15"),
                          then=`15`,
                      else=if(condition=get(member="AddinCLSID"),
                          then=AddinCLSID))) as EntryPath,

                      if(condition=get(member="Publisher"),
                          then=Publisher,
                      else=if(condition=get(member="Provider"),
                          then=Provider,
                      else=if(condition=get(member="DriverCompany"),
                          then=DriverCompany))) as Publisher,

                      get(member="OriginalFileName") AS OriginalFileName,

                      if(condition=get(member="BinaryType"),
                         then=BinaryType,
                      else=if(condition=get(member="AddInType"),
                         then=AddinType + ' ' + OfficeArchitecture,
                      else=if(condition=Key.OSPath.Path =~ 'InventoryDevicePnp',
                         then='DevicePnp',
                      else=if(condition=Key.OSPath.Path =~ 'InventoryDriverBinary',
                         then='DriverBinary')))) as BinaryType

                    FROM read_reg_key(
                        globs=KeyPathGlob,
                        root=pathspec(DelegatePath=OSPath),
                        accessor='raw_reg')
                    WHERE SHA1
                        AND SHA1 =~ SHA1Regex
                        AND if(condition= NameRegex,
                                then= EntryName =~ NameRegex OR OriginalFileName =~ NameRegex,
                                else= True)
                        AND if(condition= PathRegex,
                            then= EntryPath =~ PathRegex,
                            else= True)
            })
</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.remediation.quarantinemonitor.md
======
---
title: Windows.Remediation.QuarantineMonitor
hidden: true
tags: [Client Event Artifact]
---

An event query that will ensure the client is quarantined.

We re-calculate the quarantine every 10 minutes by default to
account for changes in DNS/connectivity details. When the query is
terminated, we undo the quarantine.


<pre><code class="language-yaml">
name: Windows.Remediation.QuarantineMonitor
description: |
  An event query that will ensure the client is quarantined.

  We re-calculate the quarantine every 10 minutes by default to
  account for changes in DNS/connectivity details. When the query is
  terminated, we undo the quarantine.

type: CLIENT_EVENT

required_permissions:
  - EXECVE

parameters:
  - name: PolicyName
    default: "VelociraptorQuarantine"
  - name: RuleLookupTable
    type: csv
    default: |
        Action,SrcAddr,SrcMask,SrcPort,DstAddr,DstMask,DstPort,Protocol,Mirrored,Description
        Permit,me,,0,any,,53,udp,yes,DNS
        Permit,me,,0,any,,53,tcp,yes,DNS TCP
        Permit,me,,68,any,,67,udp,yes,DHCP
        Block,any,,,any,,,,yes,All other traffic
  - name: MessageBox
    description: |
        Optional message box notification to send to logged in users. 256
        character limit.
  - name: ReloadPeriod
    description: Reload the ipsec policy every this many seconds on the endpoint.
    default: "600"
    type: int

precondition:
  SELECT OS FROM info() WHERE OS = "windows"
     AND version(function="atexit") &gt;= 0

sources:
  - query: |
      -- When the query is done we unset the policy.
      LET _ &lt;= atexit(query={
         SELECT * FROM Artifact.Windows.Remediation.Quarantine(
           PolicyName=PolicyName, RemovePolicy=TRUE)
      })

      SELECT * FROM foreach(
        row={
           SELECT * FROM clock(period=ReloadPeriod, start=now())
           WHERE log(message="Setting quarantine policy")
        },
        query={
          SELECT * FROM Artifact.Windows.Remediation.Quarantine(
            PolicyName=PolicyName, RuleLookupTable=RuleLookupTable,
            MessageBox=MessageBox)
       })

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/linux.detection.yara.glob.md
======
---
title: Linux.Detection.Yara.Glob
hidden: true
tags: [Client Artifact]
---

This artifact returns a list of target files then runs Yara over the target
list.

There are 2 kinds of Yara rules that can be deployed:

1. Url link to a yara rule.
2. or a Standard Yara rule attached as a parameter.

Only one method of Yara will be applied and search order is as above.

The artifact leverages Glob for search so relevant filters can be applied
including Glob, Size and date. Date filters will target files with a timestamp
before LatestTime and after EarliestTime. The artifact also has an option to
upload any files with Yara hits.

Some examples of path glob may include:

* Specific binary: `/usr/bin/ls`
* Wildcards: `/var/www/*.js`
* More wildcards: `/var/www/**/*.js`
* Multiple extentions: `/var/www/*\.{php,aspx,js,html}`
* Windows: `C:/Users/**/*.{exe,dll,ps1,bat}`
* Windows: `C:\Users\**\*.{exe,dll,ps1,bat}`

NOTE: this artifact runs the glob plugin with the nosymlink switch turned on.
This will NOT follow any symlinks and may cause unexpected results if
unknowingly targeting a folder with symlinks.
If upload is selected NumberOfHits is redundant and not advised as hits are
grouped by path to ensure files only downloaded once.


<pre><code class="language-yaml">
name: Generic.Detection.Yara.Glob
author: Matt Green - @mgreen27
description: |
  This artifact returns a list of target files then runs Yara over the target
  list.

  There are 2 kinds of Yara rules that can be deployed:

  1. Url link to a yara rule.
  2. or a Standard Yara rule attached as a parameter.

  Only one method of Yara will be applied and search order is as above.

  The artifact leverages Glob for search so relevant filters can be applied
  including Glob, Size and date. Date filters will target files with a timestamp
  before LatestTime and after EarliestTime. The artifact also has an option to
  upload any files with Yara hits.

  Some examples of path glob may include:

  * Specific binary: `/usr/bin/ls`
  * Wildcards: `/var/www/*.js`
  * More wildcards: `/var/www/**/*.js`
  * Multiple extentions: `/var/www/*\.{php,aspx,js,html}`
  * Windows: `C:/Users/**/*.{exe,dll,ps1,bat}`
  * Windows: `C:\Users\**\*.{exe,dll,ps1,bat}`

  NOTE: this artifact runs the glob plugin with the nosymlink switch turned on.
  This will NOT follow any symlinks and may cause unexpected results if
  unknowingly targeting a folder with symlinks.
  If upload is selected NumberOfHits is redundant and not advised as hits are
  grouped by path to ensure files only downloaded once.

aliases:
  - Windows.Detection.Yara.Glob
  - Linux.Detection.Yara.Glob
  - MacOS.Detection.Yara.Glob

type: CLIENT
parameters:
  - name: PathGlob
    description: Only file names that match this glob will be scanned.
    default: /usr/bin/ls
  - name: SizeMax
    description: maximum size of target file.
    type: int64
  - name: SizeMin
    description: minimum size of target file.
    type: int64
  - name: UploadHits
    type: bool
  - name: DateAfter
    type: timestamp
    description: "search for events after this date. YYYY-MM-DDTmm:hh:ssZ"
  - name: DateBefore
    type: timestamp
    description: "search for events before this date. YYYY-MM-DDTmm:hh:ssZ"
  - name: YaraUrl
    description: If configured will attempt to download Yara rules form Url
    type: upload
  - name: YaraRule
    type: yara
    description: Final Yara option and the default if no other options provided.
    default: |
        rule IsELF:TestRule {
           meta:
              author = "the internet"
              date = "2021-05-03"
              description = "A simple ELF rule to test yara features"
          condition:
             uint32(0) == 0x464c457f
        }
  - name: NumberOfHits
    description: This artifact will stop by default at one hit. This setting allows additional hits
    default: 1
    type: int
  - name: ContextBytes
    description: Include this amount of bytes around hit as context.
    default: 0
    type: int

sources:
  - query: |
      -- check which Yara to use
      LET yara_rules &lt;= YaraUrl || YaraRule

      -- time testing
      LET time_test(stamp) =
            if(condition= DateBefore AND DateAfter,
                then= stamp &lt; DateBefore AND stamp &gt; DateAfter,
                else=
            if(condition=DateBefore,
                then= stamp &lt; DateBefore,
                else=
            if(condition= DateAfter,
                then= stamp &gt; DateAfter,
                else= True
            )))

      -- first find all matching glob
      LET files = SELECT OSPath, Name, Size, Mtime, Atime, Ctime, Btime
        FROM glob(globs=PathGlob,nosymlink='True')
        WHERE
          NOT IsDir AND NOT IsLink
          AND if(condition=SizeMin,
            then= SizeMin &lt; Size,
            else= True)
          AND if(condition=SizeMax,
            then=SizeMax &gt; Size,
            else= True)
          AND
             ( time_test(stamp=Mtime)
            OR time_test(stamp=Atime)
            OR time_test(stamp=Ctime)
            OR time_test(stamp=Btime))

      -- scan files and prepare hit metadata
      LET hits = SELECT * FROM foreach(row=files,
            query={
                SELECT
                    OSPath,
                    File.Size as Size,
                    Mtime, Atime, Ctime, Btime,
                    Rule, Tags, Meta,
                    String.Name as YaraString,
                    String.Offset as HitOffset,
                    upload( accessor='scope',
                            file='String.Data',
                            name=format(format="%v-%v-%v",
                            args=[
                                OSPath,
                                if(condition= String.Offset - ContextBytes &lt; 0,
                                    then= 0,
                                    else= String.Offset - ContextBytes),
                                if(condition= String.Offset + ContextBytes &gt; Size,
                                    then= Size,
                                    else= String.Offset + ContextBytes) ]
                            )) as HitContext
                FROM yara(rules=yara_rules,files=OSPath,
                  context=ContextBytes,number=NumberOfHits)
            })

      -- upload files if selected
      LET upload_hits = SELECT *, upload(file=OSPath,name=OSPath) as Upload FROM hits

      -- return rows
      SELECT * FROM if(condition= UploadHits,
                        then= upload_hits,
                        else= hits )

column_types:
  - name: HitContext
    type: preview_upload
</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/server.internal.ping.md
======
---
title: Server.Internal.Ping
hidden: true
tags: [Internal Artifact]
---

An internal queue for Ping requests. The queue is watched by the
replication service on the slave nodes which will notify the target
specified.


<pre><code class="language-yaml">
name: Server.Internal.Ping
description: |
  An internal queue for Ping requests. The queue is watched by the
  replication service on the slave nodes which will notify the target
  specified.

type: INTERNAL

column_types:
  - name: ClientId
  - name: NotifyTarget

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/linux.sys.maps.md
======
---
title: Linux.Sys.Maps
hidden: true
tags: [Client Artifact]
---

A running binary may link other binaries into its address
space. These shared objects contain exported functions which may be
used by the binary.

This artifact parses the /proc/<pid>/maps to emit all mapped files
into the process.


<pre><code class="language-yaml">
name: Linux.Sys.Maps
description: |
  A running binary may link other binaries into its address
  space. These shared objects contain exported functions which may be
  used by the binary.

  This artifact parses the /proc/&lt;pid&gt;/maps to emit all mapped files
  into the process.

precondition: SELECT OS From info() where OS = 'linux'

parameters:
  - name: processRegex
    description: A regex applied to process names.
    default: .
    type: regex

sources:
  - query: |
      LET processes = SELECT Pid, Name, Username
        FROM pslist()
        WHERE Name =~ processRegex

      SELECT Pid, Name, Username,
               "0x" + Record.Start AS StartHex,
               "0x" + Record.End AS EndHex,
               Record.Perm AS Perm,
               atoi(string="0x" + Record.Size) AS Size,
               "0x" + Record.Size AS SizeHex,
               Record.Filename AS Filename,
               if(condition=Record.Deleted, then=TRUE, else=FALSE) AS Deleted
      FROM foreach(
          row=processes,
          query={
            SELECT parse_string_with_regex(
                    string=Line,
                    regex="(?P&lt;Start&gt;^[^-]+)-(?P&lt;End&gt;[^\\s]+)\\s+(?P&lt;Perm&gt;[^\\s]+)\\s+(?P&lt;Size&gt;[^\\s]+)\\s+[^\\s]+\\s+(?P&lt;PermInt&gt;[^\\s]+)\\s+(?P&lt;Filename&gt;.+?)(?P&lt;Deleted&gt; \\(deleted\\))?$") AS Record,
                  Pid, Name, Username
            FROM parse_lines(
               filename=format(format="/proc/%d/maps", args=[Pid]),
               accessor='file'
            )
          })

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/linux.users.rootusers.md
======
---
title: Linux.Users.RootUsers
hidden: true
tags: [Client Artifact]
---

Detects users added in the `sudo` group.


<pre><code class="language-yaml">
name: Linux.Users.RootUsers

description: |
  Detects users added in the `sudo` group.

author: George-Andrei Iosif (@iosifache)

type: CLIENT

sources:
  - precondition: |
      SELECT OS
      FROM info()
      WHERE OS = 'linux'

    query: |
      SELECT *
      FROM foreach(
        row={
          SELECT *
          FROM Artifact.Linux.Sys.Users()
        },
        query={
          SELECT Fqdn AS Host,
                 User,
                 Description,
                 Uid,
                 Gid,
                 Homedir,
                 Shell
          FROM execve(argv=["id", "-Gn", User])
          WHERE ReturnCode = 0 AND Stdout =~ "root"
        }
      )

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.applications.nirsoftbrowserviewer.md
======
---
title: Windows.Applications.NirsoftBrowserViewer
hidden: true
tags: [Client Artifact]
---

This artifact wraps the Nirsoft BrowsingHistoryView tool - a tool
for parsing browser history from a variety of browsers.

More information about the tool can be found here
https://www.nirsoft.net/utils/browsing_history_view.html

NOTE: This binary is treated as malware by many detection engines
since it is capable of dumping user passwords and search history!!!
Running it on the endpoint may (hopefully) trigger endpoint defences.

BrowsingHistoryView v2.55 - View browsing history of your Web browsers
Copyright (c) 2012 - 2023 Nir Sofer


<pre><code class="language-yaml">
name: Windows.Applications.NirsoftBrowserViewer
description: |
  This artifact wraps the Nirsoft BrowsingHistoryView tool - a tool
  for parsing browser history from a variety of browsers.

  More information about the tool can be found here
  https://www.nirsoft.net/utils/browsing_history_view.html

  NOTE: This binary is treated as malware by many detection engines
  since it is capable of dumping user passwords and search history!!!
  Running it on the endpoint may (hopefully) trigger endpoint defences.

  BrowsingHistoryView v2.55 - View browsing history of your Web browsers
  Copyright (c) 2012 - 2023 Nir Sofer

tools:
 - name: NirsoftBrowsingHistoryView64
   url: https://github.com/Velocidex/Tools/raw/main/BrowsingHistoryView/BrowsingHistoryView-amd64.exe
   expected_hash: c50d3f139bc7ed05fb0f5e25671ec0268b577d5930f27964291cc8747970f2c3
   serve_locally: true

parameters:
   - name: HistorySource
     default: 1
     description: Source of history data (1=All users).
   - name: URLRegex
     default: .
     description: Filter URLs by this regex
     type: regex
   - name: DateAfter
     type: timestamp
   - name: DateBefore
     type: timestamp
   - name: AlsoUpload
     type: bool
     description: Also upload BrowsingHistoryView produced CSV file.
   - name: PARSE_TZ
     default: LOCAL
     description: Default timezone for parsing timestamps

sources:
  - precondition:
      SELECT OS From info() where OS = 'windows'

    query: |
      -- firstly set timebounds for performance
      LET DateAfterTime &lt;= if(condition=DateAfter,
        then=timestamp(epoch=DateAfter), else=timestamp(epoch="1600-01-01"))
      LET DateBeforeTime &lt;= if(condition=DateBefore,
        then=timestamp(epoch=DateBefore), else=timestamp(epoch="2200-01-01"))

      LET CSVFile &lt;= tempfile(extension='.csv')

      -- Download the binary and create a csv file to write on.
      LET tmp_exe = SELECT OSPath AS BinPath
      FROM Artifact.Generic.Utils.FetchBinary(ToolName="NirsoftBrowsingHistoryView64")

      LET results = SELECT CSVFile
      FROM foreach(row=tmp_exe,
        query={
          SELECT CSVFile,
                 if(condition=AlsoUpload,
                    then=upload(file=CSVFile,
                                name="NirsoftBrowsingHistoryView.csv")) AS Upload
          FROM execve(argv=[
             BinPath,
             "/VisitTimeFilterType", "1",
             "/HistorySource", HistorySource, "/LoadIE", "1",
             "/LoadFirefox", "1", "/LoadChrome", "1",
             "/LoadSafari", "1",
             "/scomma",  CSVFile, "/SaveDirect"])
        })
      WHERE Upload OR TRUE

      -- Filter the results by the user specs
      SELECT * FROM foreach(row=results,
      query={
        -- This timestamp is in US style time and local time... boo :-(
        SELECT *, timestamp(string=`Visit Time`,
           format="1/2/2006 3:04:05 PM") AS Visited
        FROM parse_csv(filename=CSVFile)
      })
      WHERE URL =~ URLRegex AND
            Visited &gt; DateAfterTime AND
            Visited &lt; DateBeforeTime

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/generic.forensic.localhashes.init.md
======
---
title: Generic.Forensic.LocalHashes.Init
hidden: true
tags: [Client Artifact]
---

This artifact creates an SQLite database on the endpoint to hold
local file hashes. These hashes can then be queried quickly.


<pre><code class="language-yaml">
name: Generic.Forensic.LocalHashes.Init
description: |
   This artifact creates an SQLite database on the endpoint to hold
   local file hashes. These hashes can then be queried quickly.

parameters:
  - name: HashDb
    description: Name of the local hash database
    default: hashdb.sqlite

sources:
  - query: |
      LET SQL = "
        CREATE table if not exists hashes(path text, md5 varchar(16), size bigint, timestamp bigint)
        create index if not exists hashidx on hashes(md5)
        create index if not exists pathidx on hashes(path)
        create unique index if not exists uniqueidx on hashes(path, md5)
        "

      LET hash_db &lt;= path_join(components=[dirname(path=tempfile()), HashDb])

      LET _ &lt;= log(message="Will use local hash database " + hash_db)

      // SQL to create the initial database.
      LET _ &lt;= SELECT * FROM foreach(
      row={
          SELECT Line FROM parse_lines(filename=SQL, accessor="data")
          WHERE Line
      }, query={
         SELECT * FROM sqlite(file=hash_db, query=Line)
      })

      SELECT hash_db AS OSPath FROM scope()

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.eventlogs.evtx.md
======
---
title: Windows.EventLogs.Evtx
hidden: true
tags: [Client Artifact]
---

Parses and returns events from Windows evtx logs.

Each event is returned in full, but results can be narrowed using a glob
pattern for evtx files, a timespan, and regexes to match the evtx path, event
channel, and/or event ID:

- EvtxGlob: glob of event log files (evtx) to target
- StartDate: earliest event created timestamp to target
- EndDate: latest event created timestamp to target
- PathRegex: a regex to match against paths returned from EvtxGlob
- ChannelRegex: a regex to match against the event channel
- IDRegex: a regex to match against the event ID

Gathering these logs enables VQL analysis (_e.g._, via notebooks) and bulk
export (_e.g._, to elasticsearch) for additional processing.  It can also be
used as the basis for custom artifacts with more in-depth filtering.

**Note: This artifact can be resource intensive.**

- Parsing and aggregating may use high amounts of CPU on the client. Consider
reducing the ops/second or narrowing the glob/path regex if necessary.
- Parsing may use significant memory and time when searching VSS volumes and
deduplicating events. This is proportional to the evtx file size and number
of VSS copies. Consider whether the extra events are worth the resources.
- Parsing many event logs may take longer than the default timeout.  When
parsing all log files and searching VSS, consider doubling the default or
more (especially with reduced ops/second, or if targets have high-volume
3rd-party log sources such as Sysmon).
- The artifact routinely produces hundreds of thousands of rows per host.
Consider filtering results using path, channel, and ID regexes if necessary.

Inspired by others in `Windows.EventLogs.*`, many by Matt Green (@mgreen27).


<pre><code class="language-yaml">
name: Windows.EventLogs.Evtx

description: |
  Parses and returns events from Windows evtx logs.

  Each event is returned in full, but results can be narrowed using a glob
  pattern for evtx files, a timespan, and regexes to match the evtx path, event
  channel, and/or event ID:

  - EvtxGlob: glob of event log files (evtx) to target
  - StartDate: earliest event created timestamp to target
  - EndDate: latest event created timestamp to target
  - PathRegex: a regex to match against paths returned from EvtxGlob
  - ChannelRegex: a regex to match against the event channel
  - IDRegex: a regex to match against the event ID

  Gathering these logs enables VQL analysis (_e.g._, via notebooks) and bulk
  export (_e.g._, to elasticsearch) for additional processing.  It can also be
  used as the basis for custom artifacts with more in-depth filtering.

  **Note: This artifact can be resource intensive.**

  - Parsing and aggregating may use high amounts of CPU on the client. Consider
  reducing the ops/second or narrowing the glob/path regex if necessary.
  - Parsing may use significant memory and time when searching VSS volumes and
  deduplicating events. This is proportional to the evtx file size and number
  of VSS copies. Consider whether the extra events are worth the resources.
  - Parsing many event logs may take longer than the default timeout.  When
  parsing all log files and searching VSS, consider doubling the default or
  more (especially with reduced ops/second, or if targets have high-volume
  3rd-party log sources such as Sysmon).
  - The artifact routinely produces hundreds of thousands of rows per host.
  Consider filtering results using path, channel, and ID regexes if necessary.

  Inspired by others in `Windows.EventLogs.*`, many by Matt Green (@mgreen27).

author: Chris Hendricks (chris@counteractive.net)

precondition: SELECT OS FROM info() WHERE OS = 'windows'

parameters:
  - name: EvtxGlob
    default: '%SystemRoot%\System32\winevt\Logs\*.evtx'
  - name: VSSAnalysisAge
    type: int
    default: 0
    description: |
      If larger than zero we analyze VSS within this many days
      ago. (e.g 7 will analyze all VSS within the last week).  Note
      that when using VSS analysis we have to use the ntfs accessor
      for everything which will be much slower.
  - name: StartDate
    type: timestamp
    description: "Parse events on or after this date (YYYY-MM-DDTmm:hh:ssZ)"
  - name: EndDate
    type: timestamp
    description: "Parse events on or before this date (YYYY-MM-DDTmm:hh:ssZ)"
  - name: PathRegex
    default: "."
    type: regex
  - name: ChannelRegex
    default: "."
    type: regex
  - name: IDRegex
    default: "."
    type: regex

sources:
  - query: |
      LET VSS_MAX_AGE_DAYS &lt;= VSSAnalysisAge
      LET Accessor = if(condition=VSSAnalysisAge &gt; 0, then="ntfs_vss", else="auto")

      // expand provided glob into a list of paths on the file system (fs)
      LET fspaths =
          SELECT OSPath FROM glob(globs=expand(path=EvtxGlob), accessor=Accessor)
          WHERE OSPath =~ PathRegex

      // function returning parsed evtx from list of paths
      LET evtxsearch(pathList) = SELECT * FROM foreach(
            row=pathList,
            query={
              SELECT *,
                timestamp(epoch=int(int=System.TimeCreated.SystemTime)) AS TimeCreated,
                System.Channel as Channel,
                System.EventRecordID as EventRecordID,
                System.EventID.Value as EventID,
                OSPath
              FROM parse_evtx(filename=OSPath, accessor=Accessor)
              WHERE
                if(condition=StartDate,
                   then=TimeCreated &gt;= timestamp(string=StartDate),
                   else=true)
                AND if(condition=EndDate,
                       then=TimeCreated &lt;= timestamp(string=EndDate),
                       else=true)
                AND Channel =~ ChannelRegex
                AND str(str=EventID) =~ IDRegex
            }
          )

      SELECT * FROM evtxsearch(pathList=fspaths)

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.registry.ntuser.md
======
---
title: Windows.Registry.NTUser
hidden: true
tags: [Client Artifact]
---

This artifact searches for keys or values within the user's
NTUser.dat registry hives.

When a user logs into a windows machine the system creates their own
"profile" which consists of a registry hive mapped into the
HKEY_USERS hive. This hive file is locked as long as the user is
logged in. If the user is not logged in, the file is not mapped at
all.

This artifact bypasses the locking mechanism by parsing the raw NTFS
filesystem to recover the registry hives. We then parse the registry
hives to search for the glob provided.

This artifact is designed to be reused by other artifacts that need
to access user data.

{{% notice note %}}

  Any artifacts that look into the HKEY_USERS registry hive should
  be using the `Windows.Registry.NTUser` artifact instead of
  accessing the hive via the API. The API only makes the currently
  logged in users available in that hive and so if we rely on the
  windows API we will likely miss any settings for users not
  currently logged on.

{{% /notice %}}


<pre><code class="language-yaml">
name: Windows.Registry.NTUser
description: |
  This artifact searches for keys or values within the user's
  NTUser.dat registry hives.

  When a user logs into a windows machine the system creates their own
  "profile" which consists of a registry hive mapped into the
  HKEY_USERS hive. This hive file is locked as long as the user is
  logged in. If the user is not logged in, the file is not mapped at
  all.

  This artifact bypasses the locking mechanism by parsing the raw NTFS
  filesystem to recover the registry hives. We then parse the registry
  hives to search for the glob provided.

  This artifact is designed to be reused by other artifacts that need
  to access user data.

  {{% notice note %}}

    Any artifacts that look into the HKEY_USERS registry hive should
    be using the `Windows.Registry.NTUser` artifact instead of
    accessing the hive via the API. The API only makes the currently
    logged in users available in that hive and so if we rely on the
    windows API we will likely miss any settings for users not
    currently logged on.

  {{% /notice %}}

precondition: SELECT OS From info() where OS = 'windows'

parameters:
 - name: KeyGlob
   default: Software\Microsoft\Windows\CurrentVersion\Explorer\ComDlg32\**
 - name: userRegex
   default: .
   type: regex

export: |
    -- HivePath: The path to the hive on disk
    -- RegistryPath: The path in the registry to mount the hive
    -- RegMountPoint: The path inside the hive to mount (usually /)
    LET _map_file_to_reg_path(HivePath, RegistryPath, RegMountPoint, Accessor, Description) = dict(
       type="mount", description=Description,
       `from`=dict(accessor='raw_reg',
                   prefix=pathspec(
                      Path=RegMountPoint,
                      DelegateAccessor=Accessor,
                      DelegatePath=HivePath),
                   path_type='registry'),
        `on`=dict(accessor='registry',
                  prefix=RegistryPath,
                  path_type='registry'))

    -- This needs to always be mapped because it is normally denied through the API
    LET _required_mappings = (
       _map_file_to_reg_path(
          HivePath="C:/Windows/System32/Config/SECURITY",
          RegistryPath="HKEY_LOCAL_MACHINE\\Security",
          RegMountPoint="/",
          Accessor='ntfs',
          Description="Map SECURITY Hive to HKEY_LOCAL_MACHINE"),
    )

    LET _standard_mappings = (
       _map_file_to_reg_path(
          HivePath="C:/Windows/System32/Config/SYSTEM",
          RegistryPath="HKEY_LOCAL_MACHINE\\System\\CurrentControlSet",
          RegMountPoint="/ControlSet001",
          Accessor='ntfs',
          Description="Map SYSTEM Hive to CurrentControlSet"),
       _map_file_to_reg_path(
          HivePath="C:/Windows/System32/Config/SOFTWARE",
          RegistryPath="HKEY_LOCAL_MACHINE\\Software",
          RegMountPoint="/",
          Accessor='ntfs',
          Description="Map Software hive to HKEY_LOCAL_MACHINE"),
       _map_file_to_reg_path(
          HivePath="C:/Windows/System32/Config/System",
          RegistryPath="HKEY_LOCAL_MACHINE\\System",
          RegMountPoint="/",
          Accessor='ntfs',
          Description="Map System hive to HKEY_LOCAL_MACHINE")
    )

    LET _make_ntuser_mappings(Accessor, Hive, Subpath) = SELECT _map_file_to_reg_path(
      HivePath=NTUserPath,
      RegMountPoint="/",
      Accessor=Accessor,
      Description=format(format="Map NTUSER.dat from User %v to HKEY_USERS", args=NTUserPath[2]),
      -- This is technically the SID but it is clearer to just use the username
      RegistryPath="HKEY_USERS\\" + NTUserPath[2] + Subpath) AS Mapping
    FROM foreach(row={
       SELECT pathspec(parse=expand(path=Directory),
                       path_type="windows") + Hive  AS NTUserPath
       FROM Artifact.Windows.Sys.Users()
    }, query={
        -- Verify the file actually exists
        SELECT NTUserPath FROM stat(filename=NTUserPath)
    })

    LET _user_mappings =
      _make_ntuser_mappings(Accessor='auto', Hive="NTUser.dat", Subpath="").Mapping +
      _make_ntuser_mappings(Accessor='auto',
        Hive="\\AppData\\Local\\Microsoft\\Windows\\UsrClass.dat",
        Subpath="\\Software\\Classes", Subpath="\\Software\\Classes").Mapping

    // Use this like `LET _ &lt;= MapRawRegistryHives`
    LET MapRawRegistryHives =remap(config=dict(
       remappings=_user_mappings + _standard_mappings + _required_mappings))

sources:
 - query: |
       LET UserProfiles = SELECT Uid,
            Gid,
            Name || "" as Username,
            Description,
            UUID,
            {
                SELECT OSPath FROM glob(
                   root=expand(path=Directory),
                   globs="/NTUSER.DAT",
                   accessor="auto")
            } as OSPath,
            expand(path=Directory) as Directory
       FROM Artifact.Windows.Sys.Users()
       WHERE Directory and OSPath AND Username =~ userRegex

       SELECT * FROM foreach(
            row={
                SELECT * FROM UserProfiles
            },
            query={
                SELECT OSPath, OSPath, Data, Mtime AS Mtime,
                       Username, Description, Uid, Gid, UUID, Directory
                FROM glob(
                    globs=KeyGlob,
                    root=pathspec(
                       DelegateAccessor="ntfs",
                       DelegatePath=OSPath,
                       Path="/"),
                    accessor="raw_reg")
            })

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.remediation.scheduledtasks.md
======
---
title: Windows.Remediation.ScheduledTasks
hidden: true
tags: [Client Artifact]
---

Remove malicious task from the Windows scheduled task list.

Danger: You need to make sure to test this before running.


<pre><code class="language-yaml">
name: Windows.Remediation.ScheduledTasks
description: |
   Remove malicious task from the Windows scheduled task list.

   Danger: You need to make sure to test this before running.

type: CLIENT

required_permissions:
  - EXECVE

parameters:
 - name: script
   default: |
     Unregister-ScheduledTask -TaskName "%s" -Confirm:$false
 - name: TasksPath
   default: c:/Windows/System32/Tasks/**
 - name: ArgumentRegex
   default: ThisIsAUniqueName
   type: regex
 - name: CommandRegEx
   default: ThisIsAUniqueName
   type: regex
 - name: PowerShellExe
   default: "C:\\Windows\\System32\\WindowsPowerShell\\v1.0\\powershell.exe"
 - name: ReallyDoIt
   type: bool
   default: N

sources:
  - precondition:
      SELECT OS From info() where OS = 'windows'

    query: |
      LET task_paths = SELECT Name, OSPath
        FROM glob(globs=TasksPath)
        WHERE NOT IsDir

      LET parse_task = select OSPath, Name, parse_xml(
               accessor='data',
               file=regex_replace(
                    source=utf16(string=Data),
                    re='&lt;[?].+?&gt;',
                    replace='')) AS XML
      FROM read_file(filenames=OSPath)

      LET tasks = SELECT OSPath, Name,
            XML.Task.Actions.Exec.Command as Command,
            XML.Task.Actions.Exec.Arguments as Arguments,
            XML.Task.Actions.ComHandler.ClassId as ComHandler,
            XML.Task.Principals.Principal.UserId as UserId,
            XML as _XML
      FROM foreach(row=task_paths, query=parse_task)
      WHERE (Arguments =~ ArgumentRegex AND Command =~ CommandRegEx)  AND
      log(message="Removing task " + Name)

      SELECT * FROM foreach(row=tasks,
        query={
          SELECT * FROM if(condition= ReallyDoIt='Y',
            then={
              SELECT OSPath, Name, Command, Arguments, ComHandler, UserId, _XML
              FROM execve(argv=[PowerShellExe,
                 "-ExecutionPolicy", "Unrestricted", "-encodedCommand",
                    base64encode(string=utf16_encode(
                    string=format(format=script, args=[Name])))
              ])
            }, else={
              SELECT OSPath, Name, Command, Arguments, ComHandler, UserId, _XML
              FROM scope()
            })
        })

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.forensics.usn.md
======
---
title: Windows.Forensics.Usn
hidden: true
tags: [Client Artifact]
---

This artifact parses the NTFS USN journal and allows filters to
assist investigative workflow.

NTFS is a journal filesystem. This means that it maintains a journal
file where intended filesystem changes are written first, then the
filesystem is changed. This journal is called the USN journal in NTFS.

Velociraptor can parse the USN journal from the filesystem. This
provides an indication of recent file changes. Typically the system
maintains the journal of around 30mb and depending on system
activity this can go back quite some time.

Use this artifact to determine the times when a file was
modified/added from the journal. This will be present even if the
file was later removed.

Availible filters are Filename, OSPath, MFT/Parent ID and time bounds.


<pre><code class="language-yaml">
name: Windows.Forensics.Usn
description: |
  This artifact parses the NTFS USN journal and allows filters to
  assist investigative workflow.

  NTFS is a journal filesystem. This means that it maintains a journal
  file where intended filesystem changes are written first, then the
  filesystem is changed. This journal is called the USN journal in NTFS.

  Velociraptor can parse the USN journal from the filesystem. This
  provides an indication of recent file changes. Typically the system
  maintains the journal of around 30mb and depending on system
  activity this can go back quite some time.

  Use this artifact to determine the times when a file was
  modified/added from the journal. This will be present even if the
  file was later removed.

  Availible filters are Filename, OSPath, MFT/Parent ID and time bounds.

type: CLIENT

parameters:
  - name: Device
    description: The NTFS drive to parse
    default: "C:\\"
  - name: MFTFile
    description: Alternatively provide an MFTFile to use for resolving paths.
  - name: USNFile
    description: Alternatively provide a previously extracted USN file to parse.
  - name: Accessor
    description: The accessor to use.
  - name: AllDrives
    description: Dump USN from all drives and VSC
    type: bool
  - name: FileNameRegex
    description: A regex to match the Filename field.
    default: .
  - name: PathRegex
    description: A regex to match the entire path (you can watch a directory or a file type).
    default: .
    type: regex
  - name: MFT_ID_Regex
    description: A regex to match the MFTId. e.g ^10225$ or ^(10225|232111)$
    default: .
    type: regex
  - name: Parent_MFT_ID_Regex
    description: A regex to match the MFTId. e.g ^10225$ or ^(10225|232111)$
    default: .
    type: regex
  - name: DateAfter
    type: timestamp
    description: "search for events after this date. YYYY-MM-DDTmm:hh:ssZ"
  - name: DateBefore
    type: timestamp
    description: "search for events before this date. YYYY-MM-DDTmm:hh:ssZ"
  - name: FastPaths
    type: bool
    description: When set use a faster but less accurate path reassembly algorithm.


sources:
  - precondition:
      SELECT OS From info() where OS =~ 'windows'

    query: |
      -- firstly set timebounds for performance
      LET DateAfterTime &lt;= if(condition=DateAfter,
            then=timestamp(epoch=DateAfter), else=timestamp(epoch="1600-01-01"))
      LET DateBeforeTime &lt;= if(condition=DateBefore,
            then=timestamp(epoch=DateBefore), else=timestamp(epoch="2200-01-01"))

      -- If the user specified an MFTFile then ignore the device
      LET Device &lt;= if(condition=MFTFile OR USNFile, then="",
          else=if(condition=Device,
          then=pathspec(parse=Device, path_type="ntfs")))

      LET Parse(MFT, USN, Accessor) = SELECT *
              FROM parse_usn(accessor=Accessor, fast_paths=FastPaths,
                             mft_filename=MFT, usn_filename=USN)
              WHERE Filename =~ FileNameRegex
                AND _FileMFTID =~ MFT_ID_Regex
                AND _ParentMFTID =~ Parent_MFT_ID_Regex
                AND Timestamp &lt; DateBeforeTime
                AND Timestamp &gt; DateAfterTime
                AND _Links =~ PathRegex

      LET all_drives = SELECT * FROM foreach(
      row={
        SELECT OSPath[:1] AS Drive
        FROM glob(globs="/*/$Extend/$UsnJrnl:$J", accessor="ntfs")
        WHERE log(message=format(format="Processing Drive %v", args=Drive))
      }, query={
        SELECT Timestamp,
               Filename,
               Drive + OSPath AS OSPath,
               _Links,
               Reason,
               _FileMFTID as MFTId,
               _FileMFTSequence as Sequence,
               _ParentMFTID as ParentMFTId,
               _ParentMFTSequence as ParentSequence,
               FileAttributes,
               SourceInfo,
               Usn
        FROM Parse(MFT=Drive + "$MFT",
                   USN=Drive + "$Extend/$UsnJrnl:$J",
                   Accessor="ntfs")
      })

      SELECT *
      FROM if(condition=AllDrives, then=all_drives, else={
        SELECT * FROM if(condition=Device AND
              log(message=format(format="Processing Device %v", args=Device)),
          then={
            SELECT Timestamp,
               Filename,
               Device + OSPath AS OSPath,
               _Links,
               Reason,
               _FileMFTID as MFTId,
               _FileMFTSequence as Sequence,
               _ParentMFTID as ParentMFTId,
               _ParentMFTSequence as ParentSequence,
               FileAttributes,
               SourceInfo,
               Usn
            FROM Parse(MFT=Device + "$MFT",
                 USN=Device + "$Extend/$UsnJrnl:$J",
                 Accessor="ntfs")

          }, else={
            SELECT Timestamp,
               Filename,
               OSPath,
               _Links,
               Reason,
               _FileMFTID as MFTId,
               _FileMFTSequence as Sequence,
               _ParentMFTID as ParentMFTId,
               _ParentMFTSequence as ParentSequence,
               FileAttributes,
               SourceInfo,
               Usn
            FROM Parse(MFT=MFTFile,
                 USN=USNFile, Accessor=Accessor)
          })
      })

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.registry.mountpoints2.md
======
---
title: Windows.Registry.MountPoints2
hidden: true
tags: [Client Artifact]
---

This detection will collect any items in the MountPoints2 registry key.
With a "$" in the share path. This key will store all remotely mapped
drives unless removed so is a great hunt for simple admin $ mapping based
lateral movement.


<pre><code class="language-yaml">
name: Windows.Registry.MountPoints2
description: |
    This detection will collect any items in the MountPoints2 registry key.
    With a "$" in the share path. This key will store all remotely mapped
    drives unless removed so is a great hunt for simple admin $ mapping based
    lateral movement.

author: Matt Green - @mgreen27

precondition: SELECT OS From info() where OS = 'windows'

parameters:
 - name: KeyGlob
   default: Software\Microsoft\Windows\CurrentVersion\Explorer\MountPoints2\*
 - name: MountPointFilterRegex
   type: regex
   default: "\\$"

sources:
 - query: |
        SELECT regex_replace(
            source=OSPath.Basename,
            re="#",
            replace="\\") as MountPoint,
          Mtime as ModifiedTime,
          Username,
          OSPath.DelegatePath as Hive,
          OSPath.Path as Key
        FROM Artifact.Windows.Registry.NTUser(KeyGlob=KeyGlob)
        WHERE OSPath =~ MountPointFilterRegex

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/admin.client.upgrade.windows.md
======
---
title: Admin.Client.Upgrade.Windows
hidden: true
tags: [Client Artifact]
---

Remotely push new client updates.

NOTE: This artifact requires that you supply a client MSI using the
tools interface. Simply click on the tool in the GUI and upload a
pre-packaged MSI.

While typically the MSI will contain the Velociraptor windows
client, you can install any other MSI as well by customizing this
artifact or uploading a different msi file.


<pre><code class="language-yaml">
name: Admin.Client.Upgrade.Windows
description: |
  Remotely push new client updates.

  NOTE: This artifact requires that you supply a client MSI using the
  tools interface. Simply click on the tool in the GUI and upload a
  pre-packaged MSI.

  While typically the MSI will contain the Velociraptor windows
  client, you can install any other MSI as well by customizing this
  artifact or uploading a different msi file.

tools:
  - name: WindowsMSI

parameters:
  - name: SleepDuration
    default: "600"
    type: int
    description: |
      The MSI file is typically very large and we do not want to
      overwhelm the server so we stagger the download over this many
      seconds.

sources:
  - precondition:
      SELECT OS From info() where OS = 'windows'

    query:  |
      // Force the file to be copied to the real temp directory since
      // we are just about to remove the Tools directory.
      LET bin &lt;= SELECT copy(filename=OSPath,
          dest=expand(path="%SYSTEMROOT%\\Temp\\") + basename(path=OSPath)) AS Dest
      FROM Artifact.Generic.Utils.FetchBinary(
         ToolName="WindowsMSI", IsExecutable=FALSE,
         SleepDuration=SleepDuration)

      // Call the binary and return all its output in a single row.
      // If we fail to download the binary we do not run the command.
      SELECT * FROM foreach(row=bin,
      query={
         SELECT * FROM execve(
              argv=["msiexec.exe", "/i", Dest, "/q"],
              length=10000000)
      })

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/server.orgs.neworg.md
======
---
title: Server.Orgs.NewOrg
hidden: true
tags: [Server Artifact]
---

This server artifact will create a new org and assign the current
user as an admin to it.

NOTE: This artifact is only available to users with the ORG_ADMIN
permission, normally only given to users with the administrator role
while using the root org (You might need to switch to the root org
in the GUI before collecting this artifact).

This artifact will also start a set of server artifacts in the new
org. If you need to run any initialization steps in the new org,
simple package those into a server artifact and include it in the
`InitialArtifacts` parameter.


<pre><code class="language-yaml">
name: Server.Orgs.NewOrg
description: |
  This server artifact will create a new org and assign the current
  user as an admin to it.

  NOTE: This artifact is only available to users with the ORG_ADMIN
  permission, normally only given to users with the administrator role
  while using the root org (You might need to switch to the root org
  in the GUI before collecting this artifact).

  This artifact will also start a set of server artifacts in the new
  org. If you need to run any initialization steps in the new org,
  simple package those into a server artifact and include it in the
  `InitialArtifacts` parameter.

type: SERVER

parameters:
- name: OrgName
  default: "New Org"
  description: |
    The name of the new org. A new Org ID will be assigned.

- name: InitialArtifacts
  type: artifactset
  artifact_type: SERVER
  default: |
    Artifact
    Server.Utils.CreateMSI
  description: |
    Start the following server artifacts in the new org.

sources:
- query: |
    LET org_record &lt;= org_create(name=OrgName)
    LET _ &lt;= log(message="Created New Org with ID %v", args=org_record.id)

    -- Give the current user permissions to operate in the org.
    LET _ &lt;= user_create(orgs=org_record.id,
                         roles=["administrator", "org_admin"],
                         user=whoami())

    -- Launch this as a separate collection within the Org.
    SELECT * FROM query(
      query={
        SELECT collect_client(artifacts=InitialArtifacts, client_id="server")
        FROM scope()
      }, org_id=Org.id)

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.applications.edge.history.md
======
---
title: Windows.Applications.Edge.History
hidden: true
tags: [Client Artifact]
---

Enumerate the users chrome history.


<pre><code class="language-yaml">
name: Windows.Applications.Edge.History
description: |
  Enumerate the users chrome history.

parameters:
  - name: historyGlobs
    default: \AppData\Local\Microsoft\Edge\User Data\*\History
  - name: urlSQLQuery
    default: |
      SELECT U.id AS id, U.url AS url, V.visit_time as visit_time,
      U.title AS title, U.visit_count, U.typed_count,
      U.last_visit_time, U.hidden, V.from_visit, strftime('%H:%M:%f',
      V.visit_duration/1000000.0, 'unixepoch') as visit_duration,
      V.transition FROM urls AS U JOIN visits AS V ON U.id = V.url
  - name: userRegex
    default: .
    type: regex

precondition: SELECT OS From info() where OS = 'windows'

sources:
  - query: |
      SELECT * FROM Artifact.Windows.Applications.Chrome.History(
         historyGlobs=historyGlobs, urlSQLQuery=urlSQLQuery,
         userRegex=userRegex)

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.applications.edge.favicons.md
======
---
title: Windows.Applications.Edge.Favicons
hidden: true
tags: [Client Artifact]
---

Enumerate the users Microsoft Edge favicons.

Tested against Chrome as well, replace Microsoft Edge with Google Chrome in the faviconsGlob

Chrome Favicons are stored in the 'Favicons' SQLite database, within
the 'favicons', 'favicon_bitmaps' and 'icon_mapping' tables. Older
versions of Chrome stored Favicons in a 'Thumbnails' SQLite
database, within the 'favicons' table.

## NOTES:

This artifact is deprecated in favor of
Generic.Forensic.SQLiteHunter and will be removed in future


<pre><code class="language-yaml">
name: Windows.Applications.Edge.Favicons
description: |
  Enumerate the users Microsoft Edge favicons.

  Tested against Chrome as well, replace Microsoft Edge with Google Chrome in the faviconsGlob

  Chrome Favicons are stored in the 'Favicons' SQLite database, within
  the 'favicons', 'favicon_bitmaps' and 'icon_mapping' tables. Older
  versions of Chrome stored Favicons in a 'Thumbnails' SQLite
  database, within the 'favicons' table.

  ## NOTES:

  This artifact is deprecated in favor of
  Generic.Forensic.SQLiteHunter and will be removed in future

references:
  - https://www.foxtonforensics.com/browser-history-examiner/chrome-history-location

author: Phill Moore, @phillmoore

parameters:
  - name: faviconsGlob
    default: /AppData/Local/Microsoft/Edge/User Data/*/Favicons

  - name: faviconsQuery
    default: |
      SELECT favicons.id AS ID,
             favicon_bitmaps.icon_id AS IconID,
             favicon_bitmaps.image_data as _image,
             HEX(favicon_bitmaps.image_data) as _image_hex,
             datetime( favicon_bitmaps.last_updated / 1000000 + ( strftime( '%s', '1601-01-01' ) ), 'unixepoch', 'localtime' ) AS LastUpdated,
             icon_mapping.page_url AS PageURL,
             favicons.url AS FaviconURL
             FROM favicons
             INNER JOIN icon_mapping
             INNER JOIN favicon_bitmaps
             ON icon_mapping.icon_id = favicon_bitmaps.icon_id
             AND favicons.id = favicon_bitmaps.icon_id
             ORDER BY favicons.id ASC
  - name: userRegex
    default: .
    type: regex

precondition: |
  SELECT OS From info() where OS = 'windows'

sources:
  - query: |
        LET favicons_files = SELECT * from foreach(
          row={
             SELECT Uid, Name AS User,
                    expand(path=Directory) AS HomeDirectory
             FROM Artifact.Windows.Sys.Users()
             WHERE Name =~ userRegex
          },
          query={
             SELECT User, OSPath, Mtime
             FROM glob(globs=faviconsGlob, root=HomeDirectory)
          })

        SELECT * FROM foreach(row=favicons_files,
          query={
            SELECT ID, IconID, LastUpdated, PageURL, FaviconURL,
                   upload(accessor="data",
                          file=_image,
                          name=format(format="Image%v.png", args=ID)) AS Image, _image_hex, OSPath as _OSPath
            FROM sqlite(
              file=OSPath,
              query=faviconsQuery)
          })

column_types:
- name: Image
  type: preview_upload

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.system.untrustedbinaries.md
======
---
title: Windows.System.UntrustedBinaries
hidden: true
tags: [Client Artifact]
---

Windows runs a number of services and binaries as part of the
operating system. Sometimes malware pretends to run as those well
known names in order to hide itself in plain sight. For example, a
malware service might call itself svchost.exe so it shows up in the
process listing as a benign service.

This artifact checks that the common systems binaries are
signed. If a malware replaces these files or names itself in this
way their signature might not be correct.

Note that unfortunately Microsoft does not sign all their common
binaries so many will not be signed (e.g. conhost.exe).


<pre><code class="language-yaml">
name: Windows.System.UntrustedBinaries
description: |
  Windows runs a number of services and binaries as part of the
  operating system. Sometimes malware pretends to run as those well
  known names in order to hide itself in plain sight. For example, a
  malware service might call itself svchost.exe so it shows up in the
  process listing as a benign service.

  This artifact checks that the common systems binaries are
  signed. If a malware replaces these files or names itself in this
  way their signature might not be correct.

  Note that unfortunately Microsoft does not sign all their common
  binaries so many will not be signed (e.g. conhost.exe).

parameters:
  - name: processNamesRegex
    description: A regex to select running processes which we consider should be trusted.
    default: "lsass|svchost|conhost|taskmgr|winlogon|wmiprv|dwm|csrss|velociraptor"
    type: regex
  - name: DISABLE_DANGEROUS_API_CALLS
    type: bool
    description: |
      Enable this to disable potentially flakey APIs which may cause
      crashes.

sources:
  - precondition: |
      SELECT OS From info() where OS = 'windows'
    query: |
        LET binaries = SELECT lowcase(string=Exe) As Binary
          FROM pslist()
          WHERE Exe =~ processNamesRegex
          GROUP BY Binary

        LET auth = SELECT authenticode(filename=Binary) As Authenticode
        FROM binaries

        SELECT Authenticode.Filename As Filename,
               Authenticode.IssuerName as Issuer,
               Authenticode.SubjectName as Subject,
               Authenticode.Trusted as Trusted from auth

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/server.utils.uploadtools.md
======
---
title: Server.Utils.UploadTools
hidden: true
tags: [Server Artifact]
---

Velociraptor can use external tools to deploy binaries on the
endpoint for some artifacts that require it. Usually these binaries
are automatically downloaded by the server when required. However,
sometimes a server is deployed on an air gapped network, or has
egress filtering implemented such that the server is unable to
download binaries on demand.

In these cases it is useful to automatically pre-populate tools into
a server manually. This artifact simplies the process.

1. The artifact produces a curl based script that helps to download
   required binaries on an internet connect system.

2. When binaries are placed on a directory in the server's
   filesystem, the artifact can then be used to automatically upload
   the binaries as tools to the server.

NOTE that in Velociraptor each org is completely separated, so you
will need to re-upload the binaries when you create each org.


<pre><code class="language-yaml">
name: Server.Utils.UploadTools
description: |
  Velociraptor can use external tools to deploy binaries on the
  endpoint for some artifacts that require it. Usually these binaries
  are automatically downloaded by the server when required. However,
  sometimes a server is deployed on an air gapped network, or has
  egress filtering implemented such that the server is unable to
  download binaries on demand.

  In these cases it is useful to automatically pre-populate tools into
  a server manually. This artifact simplies the process.

  1. The artifact produces a curl based script that helps to download
     required binaries on an internet connect system.

  2. When binaries are placed on a directory in the server's
     filesystem, the artifact can then be used to automatically upload
     the binaries as tools to the server.

  NOTE that in Velociraptor each org is completely separated, so you
  will need to re-upload the binaries when you create each org.

type: SERVER

parameters:
  - name: BasePath
    description: |
      The directory on the server that contains all the binaries that
      are to be synced.

sources:
  - name: DownloaderScript
    query: |
      LET AllCurlCommands =
        SELECT format(format="curl -O -L -C - %v", args=url) AS Curl
        FROM inventory()
        WHERE url
          AND NOT admin_override

      LET Script &lt;= join(sep="\r\n", array=AllCurlCommands.Curl)

      SELECT upload(accessor="scope", file="Script", name="Script.bat") AS Script
      FROM scope()

  - name:
    query: |
      LET BasePath &lt;= pathspec(parse=BasePath)

      SELECT name,
             filename,
             BasePath + filename AS UploadedFile,
             inventory_add(file=BasePath + filename, tool=name, serve_locally=TRUE).hash AS UpdatedHash
      FROM inventory()
      WHERE url
        AND NOT admin_override
        AND stat(filename=BasePath + filename).Size &gt; 100

column_types:
  - name: Script
    type: preview_upload

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.carving.usnfiles.md
======
---
title: Windows.Carving.USNFiles
hidden: true
tags: [Client Artifact]
---

The USN journal is an important source of information about when
files were manipulated on a system.

Ideally you can parse the journal directly using the
`Windows.Forensics.Usn` artifact on the endpoint itself. However,
sometimes all you have is a copy of the USN file itself (for example
after collection with the `Windows.KapeFiles.Targets`). If you only
have the file, you can use this artifact to parse the USN records
out of it by essentially carving the records out.

NOTE: This artifact is not as good as the `Windows.Forensics.Usn`
artifact because it can not resolve the full path of the files from
the MFT itself! In practice you should always prefer to collect
`Windows.Forensics.Usn` rather than just the $J file.


<pre><code class="language-yaml">
name: Windows.Carving.USNFiles
description: |
  The USN journal is an important source of information about when
  files were manipulated on a system.

  Ideally you can parse the journal directly using the
  `Windows.Forensics.Usn` artifact on the endpoint itself. However,
  sometimes all you have is a copy of the USN file itself (for example
  after collection with the `Windows.KapeFiles.Targets`). If you only
  have the file, you can use this artifact to parse the USN records
  out of it by essentially carving the records out.

  NOTE: This artifact is not as good as the `Windows.Forensics.Usn`
  artifact because it can not resolve the full path of the files from
  the MFT itself! In practice you should always prefer to collect
  `Windows.Forensics.Usn` rather than just the $J file.

imports:
  - Windows.Carving.USN

parameters:
  - name: USNFile
    default: \\.\C:\$Extend\$UsnJrnl:$J
  - name: Accessor
    default: ntfs
    type: choices
    choices:
      - ntfs
      - file
  - name: FileRegex
    description: "Regex search over File Name"
    default: "."
    type: regex
  - name: DateAfter
    type: timestamp
    description: "search for events after this date. YYYY-MM-DDTmm:hh:ssZ"
  - name: DateBefore
    type: timestamp
    description: "search for events before this date. YYYY-MM-DDTmm:hh:ssZ"

sources:
  - query: |
        -- firstly set timebounds for performance
        LET DateAfterTime &lt;= if(condition=DateAfter,
             then=DateAfter, else="1600-01-01")
        LET DateBeforeTime &lt;= if(condition=DateBefore,
            then=DateBefore, else="2200-01-01")

        -- This rule performs an initial reduction for speed, then we
        -- reduce further using other conditions.
        LET USNYaraRule = '''rule X {
            strings:
              // First byte is the record length &lt; 255 second byte should be 0-1 (0-512 bytes per record)
              // Version Major and Minor must be 2 and 0
              // D7 01 is the ending of a reasonable WinFileTime
              // Name Offset and Name Length are short ints but should be &lt; 255
              $a = { ?? (00 | 01) 00 00 02 00 00 00 [24] ?? ?? ?? ?? ?? ?? D? 01 [16] ?? 00 3c 00  }
            condition:
              any of them
        }
        '''

        -- Find all the records in the drive.
        LET Hits = SELECT String.Offset AS Offset, parse_binary(
           filename=USNFile, accessor=Accessor, struct="USN_RECORD_V2",
           profile=USNProfile, offset=String.Offset) AS _Parsed
        FROM yara(files=USNFile, accessor=Accessor,
                  rules=USNYaraRule, number=200000000)
        WHERE _Parsed.RecordLength &gt; 60 AND  // Record must be at least 60 bytes
              _Parsed.FileNameLength &gt; 3 AND _Parsed.FileNameLength &lt; 100

        SELECT Offset, _Parsed.TimeStamp AS TimeStamp,
               _Parsed.Filename AS Name,
               _Parsed.FileReferenceNumberID AS MFTId,
               _Parsed.ParentFileReferenceNumberID AS ParentMFTId,
               _Parsed.Reason AS Reason
        FROM Hits
        WHERE Name =~ FileRegex AND
              TimeStamp &lt; DateBeforeTime AND
              TimeStamp &gt; DateAfterTime

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/server.hunts.list.md
======
---
title: Server.Hunts.List
hidden: true
tags: [Server Artifact]
---

List Hunts currently scheduled on the server.


<pre><code class="language-yaml">
name: Server.Hunts.List
description: |
  List Hunts currently scheduled on the server.

type: SERVER

sources:
  - query: |
      SELECT hunt_id,
             timestamp(epoch=create_time) as Created,
             join(array=start_request.artifacts, sep=",") as Artifact,
             state
      FROM hunts()

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/server.internal.clientinfosnapshot.md
======
---
title: Server.Internal.ClientInfoSnapshot
hidden: true
tags: [Internal Artifact]
---

An internal artifact that fires when the master node writes a new
snapshot. Minion use this to trigger a refresh of their client info
snapshots.


<pre><code class="language-yaml">
name: Server.Internal.ClientInfoSnapshot
type: INTERNAL
description: |
  An internal artifact that fires when the master node writes a new
  snapshot. Minion use this to trigger a refresh of their client info
  snapshots.

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.applications.chrome.extensions.md
======
---
title: Windows.Applications.Chrome.Extensions
hidden: true
tags: [Client Artifact]
---

Fetch Chrome extensions.

Chrome extensions are installed into the user's home directory.  We
search for manifest.json files in a known path within each system
user's home directory. We then parse the manifest file as JSON.

Many extensions use locale packs to resolve strings like name and
description. In this case we detect the default locale and load
those locale files. We then resolve the extension's name and
description from there.

## NOTES:

This artifact is deprecated in favor of
Generic.Forensic.SQLiteHunter and will be removed in future


<pre><code class="language-yaml">
name: Windows.Applications.Chrome.Extensions
description: |
  Fetch Chrome extensions.

  Chrome extensions are installed into the user's home directory.  We
  search for manifest.json files in a known path within each system
  user's home directory. We then parse the manifest file as JSON.

  Many extensions use locale packs to resolve strings like name and
  description. In this case we detect the default locale and load
  those locale files. We then resolve the extension's name and
  description from there.

  ## NOTES:

  This artifact is deprecated in favor of
  Generic.Forensic.SQLiteHunter and will be removed in future


parameters:
  - name: extensionGlobs
    default: \AppData\Local\Google\Chrome\User Data\*\Extensions\*\*\manifest.json
  - name: userRegex
    default: .
    type: regex

sources:
  - precondition: |
      SELECT OS From info() where OS = 'windows'
    query: |
        /* For each user on the system, search for extension manifests
           in their home directory. */
        LET extension_manifests = SELECT * from foreach(
          row={
             SELECT Uid, Name AS User,
                    expand(path=Directory) as Directory
             FROM Artifact.Windows.Sys.Users()
             WHERE Name =~ userRegex
          },
          query={
             SELECT OSPath, Mtime, Ctime, User, Uid
             FROM glob(root=Directory, globs=extensionGlobs)
          })

        /* If the Manifest declares a default_locale then we
           load and parse the messages file. In this case the
           messages are actually stored in the locale file
           instead of the main manifest.json file.
        */
        LET maybe_read_locale_file =
           SELECT * from if(
              condition={
                 select * from scope() where Manifest.default_locale
              },
              then={
                 SELECT Manifest,
                        Uid, User,
                        Filename as LocaleFilename,
                        ManifestFilename,
                        parse_json(data=Data) AS LocaleManifest
                 FROM read_file(
                         -- Munge the filename to get the messages.json path.
                         filenames=regex_replace(
                           source=ManifestFilename,
                           replace="\\_locales\\" + Manifest.default_locale +
                                   "\\messages.json",
                           re="\\\\manifest.json$"))
              },
              else={
                  -- Just fill in empty Locale results.
                  SELECT Manifest,
                         Uid, User,
                         "" AS LocaleFilename,
                         "" AS ManifestFilename,
                         "" AS LocaleManifest
                  FROM scope()
              })

        LET parse_json_files = SELECT * from foreach(
           row={
             SELECT Filename as ManifestFilename,
                    Uid, User,
                    parse_json(data=Data) as Manifest
             FROM read_file(filenames=OSPath)
           },
           query=maybe_read_locale_file)

        LET parsed_manifest_files = SELECT * from foreach(
          row=extension_manifests,
          query=parse_json_files)

        SELECT Uid, User,

               /* If the manifest name contains __MSG_ then the real
                  name is stored in the locale manifest. This condition
                  resolves the Name column either to the main manifest or
                  the locale manifest.
               */
               if(condition="__MSG_" in Manifest.name,
                  then=get(item=LocaleManifest,
                     member=regex_replace(
                        source=Manifest.name,
                        replace="$1",
                        re="(?:__MSG_(.+)__)")).message,
                  else=Manifest.name) as Name,

               if(condition="__MSG_" in Manifest.description,
                  then=get(item=LocaleManifest,
                     member=regex_replace(
                        source=Manifest.description,
                        replace="$1",
                        re="(?:__MSG_(.+)__)")).message,
                  else=Manifest.description) as Description,

               /* Get the Identifier and Version from the manifest filename */
               regex_replace(
                 source=ManifestFilename,
                 replace="$1",
                 re="(?:.+Extensions\\\\([^\\\\]+)\\\\([^\\\\]+)\\\\manifest.json)$") AS Identifier,
               regex_replace(
                 source=ManifestFilename,
                 replace="$2",
                 re="(?:.+Extensions\\\\([^\\\\]+)\\\\([^\\\\]+)\\\\manifest.json)$") AS Version,

               Manifest.author as Author,
               Manifest.background.persistent AS Persistent,
               regex_replace(
                 source=ManifestFilename,
                 replace="$1",
                 re="(.+Extensions\\\\.+\\\\)manifest.json$") AS Path,

               Manifest.oauth2.scopes as Scopes,
               Manifest.permissions as Permissions,
               Manifest.key as Key

        FROM parsed_manifest_files

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.osquery.generic.md
======
---
title: Windows.OSQuery.Generic
hidden: true
tags: [Client Artifact]
---

OSQuery is an excellent tool for querying system state across the
three supported Velociraptor platform (Windows/Linux/MacOS).

You can read more about OSQuery on https://osquery.io/


<pre><code class="language-yaml">
name: Windows.OSQuery.Generic
description: |
  OSQuery is an excellent tool for querying system state across the
  three supported Velociraptor platform (Windows/Linux/MacOS).

  You can read more about OSQuery on https://osquery.io/

reference:
  - https://osquery.io/
  - https://github.com/osquery/osquery

# I am not actually sure if OSQuery allows arbitrary command execution via SQL?
required_permissions:
  - EXECVE

precondition: SELECT OS From info() where OS = 'windows'

tools:
  - name: OSQueryWindows
    github_project: Velocidex/OSQuery-Releases
    github_asset_regex: windows-amd64.exe

parameters:
  - name: Query
    default: "SELECT * FROM osquery_info"

sources:
  - query: |
      LET binary &lt;= SELECT OSPath
      FROM Artifact.Generic.Utils.FetchBinary(ToolName="OSQueryWindows")

      LET result = SELECT * FROM execve(
         argv=[binary[0].OSPath, "--json", Query],
         length=1000000)

      SELECT * FROM foreach(row=result,
      query={
         SELECT * FROM parse_json_array(data=Stdout)
      })

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/triage.collection.upload.md
======
---
title: Triage.Collection.Upload
hidden: true
tags: [Client Artifact]
---

A Generic uploader used by triaging artifacts.


<pre><code class="language-yaml">
name: Triage.Collection.Upload
description: |
  A Generic uploader used by triaging artifacts.

parameters:
  - name: path
    description: This is the glob of the files we use.
  - name: type
    description: The type of files these are.
  - name: accessor
    default: file

sources:
  - query: |
        LET results = SELECT OSPath, Size,
               Mtime As Modifed,
               type AS Type,
               upload(file=OSPath,
                      accessor=accessor,
                      ctime=Ctime,
                      mtime=Mtime) AS FileDetails
        FROM glob(globs=path, accessor=accessor)
        WHERE NOT IsDir

        SELECT OSPath, Size, Modifed, Type,
               FileDetails.Path AS ZipPath,
               FileDetails.Md5 as Md5,
               FileDetails.Sha256 as SHA256
        FROM results

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/notebooks.demo.md
======
---
title: Notebooks.Demo
hidden: true
tags: [notebook]
---

A notebook demonstrating features of notebooks


<pre><code class="language-yaml">
name: Notebooks.Demo
description: |
  A notebook demonstrating features of notebooks

type: NOTEBOOK

# We can include tools in notebook templates, just like artifacts.
tools:
  - name: Autorun_amd64
    url: https://live.sysinternals.com/tools/autorunsc64.exe

parameters:
  - name: StartDate
    type: timestamp
  - name: AnInteger
    type: int
    default: "5"

sources:
  - notebook:
    - type: vql
      name: Example Query with tool reference
      template: |
        SELECT StartDate, AnInteger, Tool_Autorun_amd64_URL
        FROM scope()

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/server.utils.importcollection.md
======
---
title: Server.Utils.ImportCollection
hidden: true
tags: [Server Artifact]
---

The Velociraptor offline collector is an automated, preconfigured
collection tool. Users can use the collector to automatically
collect any artifacts on endpoints that do not have the Velociraptor
client (offline endpoints).

The collector creates a ZIP archive with the results of the
collection in JSON files (and any uploaded files).

This artifact allows for these offline collections to be imported
back into the Velociraptor GUI. The collected data can then treated
exactly the same as if it was collected by the regular Velociraptor
client (i.e. post processed through the notebook interface), except
it was collected via the Sneakernet.

NOTE: This artifact reads the collection ZIP from the server's
filesystem. It is up to you to arrange for the file to be stored on
the server (e.g. scp it over).

NOTE: This artifact is still experimental - please provide feedback
on our issue board.


<pre><code class="language-yaml">
name: Server.Utils.ImportCollection
description: |
  The Velociraptor offline collector is an automated, preconfigured
  collection tool. Users can use the collector to automatically
  collect any artifacts on endpoints that do not have the Velociraptor
  client (offline endpoints).

  The collector creates a ZIP archive with the results of the
  collection in JSON files (and any uploaded files).

  This artifact allows for these offline collections to be imported
  back into the Velociraptor GUI. The collected data can then treated
  exactly the same as if it was collected by the regular Velociraptor
  client (i.e. post processed through the notebook interface), except
  it was collected via the Sneakernet.

  NOTE: This artifact reads the collection ZIP from the server's
  filesystem. It is up to you to arrange for the file to be stored on
  the server (e.g. scp it over).

  NOTE: This artifact is still experimental - please provide feedback
  on our issue board.

type: SERVER

parameters:
  - name: ClientId
    default: auto
    description: |
      The client id to upload this collection into. The
      default is "auto" which will create a new client id.
  - name: Hostname
    description: If creating a new client, this must contain the hostname.
  - name: Path
    description: A path on the server containing the zip file to upload.

sources:
  - query: |
      LET result &lt;= SELECT import_collection(
               client_id=ClientId, hostname=Hostname,
               filename=Path) AS Import
      FROM scope()

      SELECT * FROM switch(a={
         SELECT Import.client_id AS ClientId, Import.session_id AS FlowId,
                Import.total_collected_rows AS TotalRows,
                Import.total_uploaded_files AS UploadedFiles,
                Import.total_uploaded_bytes AS UploadedBytes,
                Import.artifacts_with_results AS Artifacts
        FROM result
        WHERE FlowId

        -- Hunt import
      }, b={
         SELECT Import.hunt_id AS HuntId,
                timestamp(epoch=Import.create_time) AS CreateTime,
                Import.stats.total_clients_scheduled AS TotalClients,
                Import.artifacts AS Artifacts,
                Import.creator AS Creator,
                Import AS _Hunt
        FROM result
        WHERE HuntId
      })

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/system.flow.completion.md
======
---
title: System.Flow.Completion
hidden: true
tags: [Client Event Artifact]
---

An internal artifact that produces events for every flow completion
in the system.


<pre><code class="language-yaml">
name: System.Flow.Completion
description: |
  An internal artifact that produces events for every flow completion
  in the system.

type: CLIENT_EVENT

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/system.vfs.export.md
======
---
title: System.VFS.Export
hidden: true
tags: [Server Artifact]
---

Exports parts of the VFS in a server side collection.


<pre><code class="language-yaml">
name: System.VFS.Export
description: |
  Exports parts of the VFS in a server side collection.

type: SERVER

parameters:
  - name: Path
    description: |
      A vfs path under which to search for file (NOTE: VFS paths start
      with the accessor name).
  - name: Components
    type: json_array
    default: '[]'
    description: |
      The top level to recurse from. NOTE: The first element in the
      list must be the accessor name.
  - name: ClientId
    description: The client id to apply the artifact on
  - name: FileGlob
    default: '**'
    description: |
      Only match the following files (default all of them) under the
      Path

sources:
  - query: |
      LET components &lt;= Components || pathspec(parse=Path).Components
      SELECT Name, OSPath, Size, IsDir,
             Data.DownloadInfo.flow_id AS FlowId,
             if(condition=Data.DownloadInfo.flow_id,
                then=upload(accessor="vfs", file=OSPath)) AS Upload
      FROM glob(globs=FileGlob, root=components, accessor="vfs")
      WHERE NOT IsDir

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/macos.detection.autoruns.md
======
---
title: MacOS.Detection.Autoruns
hidden: true
tags: [Client Artifact]
---

This artifact collects evidence of autoruns. We also capture the files and upload them.

This code is based on
https://github.com/CrowdStrike/automactc/blob/master/modules/mod_autoruns_v102.py


<pre><code class="language-yaml">
name: MacOS.Detection.Autoruns
description: |
   This artifact collects evidence of autoruns. We also capture the files and upload them.

   This code is based on
   https://github.com/CrowdStrike/automactc/blob/master/modules/mod_autoruns_v102.py

precondition: SELECT OS FROM info() WHERE OS =~ 'darwin'

parameters:
- name: sandboxed_loginitems
  default: /var/db/com.apple.xpc.launchd/disabled.*.plist

- name: cronTabGlob
  default: /private/var/at//tabs/*

- name: LaunchAgentsDaemonsGlob
  default: |
     ["/System/Library/LaunchAgents/*.plist","/Library/LaunchAgents/*.plist",
      "/Users/*/Library/LaunchAgents/*.plist","/private/var/*/Library/LaunchAgents/*.plist",
      "/System/Library/LaunchAgents/.*.plist","/Library/LaunchAgents/.*.plist",
      "/Users/*/Library/LaunchAgents/.*.plist", "/private/var/*/Library/LaunchAgents/.*.plist",
      "/System/Library/LaunchDaemons/*.plist","/Library/LaunchDaemons/*.plist",
      "/System/Library/LaunchDaemons/.*.plist","/Library/LaunchDaemons/.*.plist"]

- name: ScriptingAdditionsGlobs
  default: |
      ["/System/Library/ScriptingAdditions/*.osax","/Library/ScriptingAdditions/*.osax",
       "/System/Library/ScriptingAdditions/.*.osax","/Library/ScriptingAdditions/.*.osax"]

- name: StartupItemsGlobs
  default: |
       ["/System/Library/StartupItems/*/*","/Library/StartupItems/*/*"]

- name: MiscItemsGlobs
  default: |
      ["/private/etc/periodic.conf", "/private/etc/periodic/*/*", "/private/etc/*.local",
       "/private/etc/rc.common",
       "/private/etc/emond.d/*","/private/etc/emond.d/*/*"]

- name: LoginItemsGlobs
  default: |
      ["/Users/*/Library/Preferences/com.apple.loginitems.plist",
       "/private/var/*/Library/Preferences/com.apple.loginitems.plist"]

sources:
- name: Sandboxed Loginitems
  query: |
    SELECT OSPath,
           Mtime,
           plist(file=OSPath) AS Disabled,
           upload(file=OSPath) AS Upload
    FROM glob(globs=sandboxed_loginitems)

- name: crontabs
  query: |
    LET raw = SELECT * FROM foreach(
          row={
            SELECT OSPath, Name, Mtime,
                   upload(file=OSPath) AS Upload
            FROM glob(globs=split(string=cronTabGlob, sep=","))
          },
          query={
            SELECT OSPath, Name, Mtime, Upload,
              data, parse_string_with_regex(
               string=data,
               regex=[
                 /* Regex for event (Starts with @) */
                 "^(?P&lt;Event&gt;@[a-zA-Z]+)\\s+(?P&lt;Command&gt;.+)",

                 /* Regex for regular command. */
                 "^(?P&lt;Minute&gt;[^\\s]+)\\s+"+
                 "(?P&lt;Hour&gt;[^\\s]+)\\s+"+
                 "(?P&lt;DayOfMonth&gt;[^\\s]+)\\s+"+
                 "(?P&lt;Month&gt;[^\\s]+)\\s+"+
                 "(?P&lt;DayOfWeek&gt;[^\\s]+)\\s+"+
                 "(?P&lt;Command&gt;.+)$"]) as Record

            /* Read lines from the file and filter ones that start with "#" */
            FROM split_records(
               filenames=OSPath,
               regex="\n", columns=["data"]) WHERE not data =~ "^\\s*#"
            }) WHERE Record.Command

    SELECT Record.Event AS Event,
               Mtime,
               Name AS User,
               Record.Minute AS Minute,
               Record.Hour AS Hour,
               Record.DayOfMonth AS DayOfMonth,
               Record.Month AS Month,
               Record.DayOfWeek AS DayOfWeek,
               Record.Command AS Command,
               OSPath AS Path,
               Upload
    FROM raw

- name: LaunchAgentsDaemons
  query: |

    LET launchd_config = SELECT OSPath, Mtime,
           plist(file=OSPath) AS LaunchdConfig,
           upload(file=OSPath) AS Upload
    FROM glob(globs=parse_json_array(data=LaunchAgentsDaemonsGlob))

    LET programs = SELECT OSPath, Mtime, LaunchdConfig,
           get(member="LaunchdConfig.Program",
               default=get(member="LaunchdConfig.ProgramArguments.0")) AS Program
    FROM launchd_config

    SELECT OSPath, Mtime, LaunchdConfig,
           Program, hash(path=Program) AS Hash,
           upload(file=OSPath) AS Upload
    FROM programs

- name: ScriptingAdditions
  query: |
    SELECT OSPath,
           Mtime,
           upload(file=OSPath) AS Upload
    FROM glob(globs=parse_json_array(data=ScriptingAdditionsGlobs))

- name: StartupItems
  query: |
    SELECT OSPath,
           Mtime,
           upload(file=OSPath) AS Upload
    FROM glob(globs=parse_json_array(data=StartupItemsGlobs))

- name: MiscItems
  query: |
    SELECT OSPath,
           Mtime,
           upload(file=OSPath) AS Upload
    FROM glob(globs=parse_json_array(data=MiscItemsGlobs))

- name: LoginItems
  query: |
    SELECT OSPath,
           Mtime,
           plist(file=OSPath) AS LoginItemConfig,
           upload(file=OSPath) AS Upload
    FROM glob(globs=parse_json_array(data=LoginItemsGlobs))

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/linux.forensics.immutablefiles.md
======
---
title: Linux.Forensics.ImmutableFiles
hidden: true
tags: [Client Artifact]
---

Attackers sometimes enable immutable files in Linux.

This prevents files from being modified. However this is sometimes a
strong signal.

This artifact searches the filesystem for such files.

NOTE: We use the ext4 accessor to parse the low level filessystem.


<pre><code class="language-yaml">
name: Linux.Forensics.ImmutableFiles
description: |
  Attackers sometimes enable immutable files in Linux.

  This prevents files from being modified. However this is sometimes a
  strong signal.

  This artifact searches the filesystem for such files.

  NOTE: We use the ext4 accessor to parse the low level filessystem.

precondition: |
  SELECT * FROM info() where OS = 'linux'

parameters:
  - name: SearchFilesGlob
    default: /home/*
    description: Use a glob to define the files that will be searched.
  - name: OneFilesystem
    default: N
    type: bool
    description: When set we do not follow a link to go on to a different filesystem.

  - name: DoNotFollowSymlinks
    type: bool
    default: N
    description: If specified we are allowed to follow symlinks while globbing

column_types:
  - name: ATime
    type: timestamp
  - name: MTime
    type: timestamp
  - name: CTime
    type: timestamp


sources:
- query: |
    SELECT OSPath,
           Sys.mft as Inode,
           Mode.String AS Mode, Size,
           Mtime AS MTime,
           Atime AS ATime,
           Ctime AS CTime,
           IsDir, Mode, Data
    FROM glob(globs=SearchFilesGlob,
              one_filesystem=OneFilesystem,
              accessor="ext4", nosymlink=DoNotFollowSymlinks)
    WHERE Data.Flags =~ "IMMUTABLE"

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.network.arpcache.md
======
---
title: Windows.Network.ArpCache
hidden: true
tags: [Client Artifact]
---

Address resolution cache, both static and dynamic (from ARP, NDP).

<pre><code class="language-yaml">
name: Windows.Network.ArpCache
description: Address resolution cache, both static and dynamic (from ARP, NDP).
parameters:
  - name: wmiQuery
    default: |
      SELECT AddressFamily, Store, State, InterfaceIndex, IPAddress,
             InterfaceAlias, LinkLayerAddress
      from MSFT_NetNeighbor
  - name: wmiNamespace
    default: ROOT\StandardCimv2

  - name: kMapOfState
    default: |
     {
      "0": "Unreachable",
      "1": "Incomplete",
      "2": "Probe",
      "3": "Delay",
      "4": "Stale",
      "5": "Reachable",
      "6": "Permanent",
      "7": "TBD"
     }

sources:
  - precondition:
      SELECT OS From info() where OS = 'windows'
    query: |
        LET interfaces &lt;=
          SELECT Index, HardwareAddr, IP
          FROM Artifact.Windows.Network.InterfaceAddresses()

        LET arp_cache = SELECT if(condition=AddressFamily=23,
                    then="IPv6",
                  else=if(condition=AddressFamily=2,
                    then="IPv4",
                  else=AddressFamily)) as AddressFamily,

               if(condition=Store=0,
                    then="Persistent",
                  else=if(condition=(Store=1),
                    then="Active",
                  else="?")) as Store,

               get(item=parse_json(data=kMapOfState),
                   member=encode(string=State, type='string')) AS State,
               InterfaceIndex, IPAddress,
               InterfaceAlias, LinkLayerAddress
            FROM wmi(query=wmiQuery, namespace=wmiNamespace)

        SELECT * FROM foreach(
          row=arp_cache,
          query={
             SELECT AddressFamily, Store, State, InterfaceIndex,
                    IP AS LocalAddress, HardwareAddr, IPAddress as RemoteAddress,
                    InterfaceAlias, LinkLayerAddress AS RemoteMACAddress
             FROM interfaces
             WHERE InterfaceIndex = Index
          })

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/admin.client.remove.md
======
---
title: Admin.Client.Remove
hidden: true
tags: [Server Artifact]
---

This artifact will remove clients that have not checked in for a
while.  All data for these clients will be removed.

The artifact enumerates all the files that are removed.


<pre><code class="language-yaml">
name: Admin.Client.Remove
description: |
  This artifact will remove clients that have not checked in for a
  while.  All data for these clients will be removed.

  The artifact enumerates all the files that are removed.

type: SERVER

parameters:
  - name: Age
    description: Remove clients older than this many days
    default: "7"
    type: int

  - name: ReallyDoIt
    type: bool

sources:
  - query: |
      LET Threshold &lt;= timestamp(epoch=now() - Age * 3600 * 24 )
      LET old_clients = SELECT os_info.fqdn AS Fqdn, client_id,
             timestamp(epoch=last_seen_at) AS LastSeen FROM clients()
      WHERE LastSeen &lt; Threshold

      SELECT * FROM foreach(row=old_clients,
      query={
         SELECT *, Fqdn, LastSeen FROM client_delete(
             client_id=client_id, really_do_it=ReallyDoIt)
      })

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.system.amcache.md
======
---
title: Windows.System.Amcache
hidden: true
tags: [Client Artifact]
---

Get information from the system's amcache.

The Amcache.hve file is a registry file that stores the information
of executed applications. Amcache.hve records the recent processes
that were run and lists the path of the files that’s executed which
can then be used to find the executed program.

This artifact works on Windows 10 1607 version.


<pre><code class="language-yaml">
name: Windows.System.Amcache
description: |
  Get information from the system's amcache.

  The Amcache.hve file is a registry file that stores the information
  of executed applications. Amcache.hve records the recent processes
  that were run and lists the path of the files that’s executed which
  can then be used to find the executed program.

  This artifact works on Windows 10 1607 version.

reference:
  - https://www.andreafortuna.org/cybersecurity/amcache-and-shimcache-in-forensic-analysis/
  - https://www.ssi.gouv.fr/uploads/2019/01/anssi-coriin_2019-analysis_amcache.pdf

parameters:
  - name: amCacheGlob
    default: "%SYSTEMROOT%/appcompat/Programs/Amcache.hve"
  - name: amCacheRegPath
    default: /Root/InventoryApplicationFile/*
  - name: NTFS_CACHE_SIZE
    type: int
    default: 1000

precondition: |
  SELECT OS From info() where OS = 'windows'

sources:
  - name: InventoryApplicationFile
    query: |
        LET X = scope()
        SELECT FileId,
               Key.OSPath.Path as Key,
               Key.OSPath.DelegatePath AS Hive,
               Key.Mtime as LastModified,
               X.LowerCaseLongPath as Binary,
               X.Name AS Name,
               X.Size AS Size,
               X.ProductName AS ProductName,
               X.Publisher AS Publisher,
               X.Version AS Version,
               X.BinFileVersion AS BinFileVersion
        FROM foreach(
          row={
            SELECT OSPath from glob(globs=expand(path=amCacheGlob))
            WHERE log(message="Processing "+OSPath)
          }, query={
            SELECT * from read_reg_key(
               globs=amCacheRegPath,
               root=pathspec(DelegatePath=OSPath),
               accessor='raw_reg'
            )
        })

  - name: File
    query: |
        SELECT * FROM foreach(
          row={
            SELECT OSPath from glob(globs=expand(path=amCacheGlob))
          }, query={
            SELECT get(item=scope(), member="100") As ProductId,
                   get(item=scope(), member="101") As SHA1,
                   get(item=scope(), member="15") As OSPath,
                   Key.Mtime as LastModifiedKey
            FROM read_reg_key(
               root=pathspec(DelegatePath=OSPath),
               globs='/Root/File/*/*',
               accessor='raw_reg'
            )
        })

reports:
  - type: CLIENT
    template: |
      {{define "recent_executions"}}
           LET recent_executions &lt;= SELECT LastModified, Name, count(items=Name) As Count,
                  int(int=_LastModified/3600) AS Hour
           FROM source(source="InventoryApplicationFile")
           GROUP BY Hour
           LIMIT 500
      {{ end }}

      {{ define "timeline" }}
         SELECT LastModified,
                format(format="%s (%d)", args=[Name, Count]) As TotalCount
         FROM recent_executions
      {{ end }}

      The AMCache file
      ================

      {{ .Description }}

      ## Execution clusters

      The AMCache artifact only shows us the time of first execution
      of a binary. We get an idea when it was installed. Typically
      execution artifacts are clustered in time - if an attacker
      copies a bunch of new tools they will all start running at about
      the same time.

      The below timeline shows a summary of execution clusters. The
      binaries are grouped in an hour interval. The label is the first
      binary name and the total number of binaries within that hour.

      &gt; For clarity we hide the names of all other binaries, and just
        show the total count.

      {{ Query "recent_executions" "timeline" | Timeline }}


      Here is the same data in tabular form.

      {{ Query "timeline" | Table }}

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.system.handles.md
======
---
title: Windows.System.Handles
hidden: true
tags: [Client Artifact]
---

Enumerate the handles from selected processes.

Uncheck all the handle types below to fetch all handle types.


<pre><code class="language-yaml">
name: Windows.System.Handles
description: |
  Enumerate the handles from selected processes.

  Uncheck all the handle types below to fetch all handle types.

parameters:
  - name: processRegex
    description: A regex applied to process names.
    default: .
    type: regex

  - name: Files
    description: Search for File Handles
    type: bool
    default: Y
  - name: Key
    description: Search for Key Handles
    type: bool

sources:
  - query: |
      LET tokens &lt;= SELECT * FROM chain(
          a={SELECT "File" AS Type FROM scope() WHERE Files = 'Y'},
          a2={SELECT "Section" AS Type FROM scope() WHERE Files = 'Y'},
          b={SELECT "Key" AS Type FROM scope() WHERE Key = 'Y'}
        )

      LET processes = SELECT Pid AS ProcPid, Name AS ProcName, Exe
        FROM pslist()
        WHERE ProcName =~ processRegex AND ProcPid &gt; 0

      SELECT * FROM foreach(
          row=processes,
          query={
            SELECT ProcPid, ProcName, Exe, Type, Name, Handle
            FROM handles(pid=ProcPid, types=tokens.Type)
          })

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.forensics.uefi.md
======
---
title: Windows.Forensics.UEFI
hidden: true
tags: [Client Artifact]
---

This artifact enables disk analysis over an EFI System Partition (ESP).

The artifact queries the specified pysical disk, parses the partition table
to targets the ESPs File Allocation Table (FAT).

The default artifact returns file information, and PE enrichment as typical EFI files are in the PE format.

We can looks for anomalities in EFI such as:

- unexpected time stamps outside install / OS updates
- unexpected paths (EFI/ is typically the root folder on this partition)
- unexpected metadata: signer non microsoft or known vendor (note we expect non trusted certificates here as the authenticode api does not service ESP binaries)

NOTE: default returns EFI files, rerun with ```TargetGlob=**/*``` glob and
return all files.


<pre><code class="language-yaml">
name: Windows.Forensics.UEFI
author: Matt Green - @mgreen27
description: |
  This artifact enables disk analysis over an EFI System Partition (ESP).

  The artifact queries the specified pysical disk, parses the partition table
  to targets the ESPs File Allocation Table (FAT).

  The default artifact returns file information, and PE enrichment as typical EFI files are in the PE format.

  We can looks for anomalities in EFI such as:

  - unexpected time stamps outside install / OS updates
  - unexpected paths (EFI/ is typically the root folder on this partition)
  - unexpected metadata: signer non microsoft or known vendor (note we expect non trusted certificates here as the authenticode api does not service ESP binaries)

  NOTE: default returns EFI files, rerun with ```TargetGlob=**/*``` glob and
  return all files.

parameters:
  - name: ImagePath
    default: \\.\PhysicalDrive0
    description: Raw Device for main disk containing partition table to parse.
  - name: SectorSize
    type: int
    default: 512
  - name: TargetGlob
    default: "**/*.efi"
  - name: DISABLE_DANGEROUS_API_CALLS
    type: bool
    description: |
      Enable this to disable potentially flakey APIs which may cause
      crashes.

sources:
- query: |
      LET find_efi = SELECT StartOffset,EndOffset,
            Size AS PartitionSize,
            name AS PartitionName
       FROM Artifact.Windows.Forensics.PartitionTable(
          ImagePath=ImagePath, SectorSize=SectorSize)
      WHERE PartitionName =~ "EFI"

      LET find_files = SELECT * FROM foreach(row=find_efi,
        query={
            SELECT *,
                StartOffset as PartitionOffset,
                PartitionSize,
                PartitionName
            FROM glob(globs=TargetGlob,
                accessor="fat",
                root=pathspec(
                    DelegateAccessor="offset",
                    DelegatePath=pathspec(
                        DelegateAccessor="raw_file",
                        DelegatePath=ImagePath,
                        Path=format(format="%d", args=StartOffset))))
        })

      SELECT
        dict(
            ImagePath=ImagePath,
            PartitionOffset=PartitionOffset,
            PartitionSize=PartitionSize,
            PartitionName=PartitionName
                ) as Partition,
        OSPath.Path as OSPath,
        Size, Mtime, Atime, Ctime, Btime,
        Data.first_cluster as FirstCluster,
        Data.attr AS Attr,
        Data.deleted as IsDeleted,
        Data.short_name AS ShortName,
        hash(accessor='fat',path=OSPath) as Hash,
        magic(accessor='fat',path=OSPath) as Magic,
        parse_pe(accessor='fat',file=OSPath) as PEInfo,
        authenticode(accessor='fat',filename=OSPath) as Authenticode
      FROM find_files

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/server.utils.reindex.md
======
---
title: Server.Utils.ReIndex
hidden: true
tags: [Client Artifact]
---

This utility artifact replays all collected Generic.Client.Info
collections to the interrogation service forcing a reindex.

It should normally not be needed.


<pre><code class="language-yaml">
name: Server.Utils.ReIndex
description: |
  This utility artifact replays all collected Generic.Client.Info
  collections to the interrogation service forcing a reindex.

  It should normally not be needed.

sources:
  - query: |
      SELECT * FROM foreach(row={
        SELECT Name AS ClientId
        FROM glob(globs="/clients/*", accessor="fs")
        WHERE Name =~ "^C."
      }, query={
        SELECT session_id,
             send_event(artifact="System.Flow.Completion",
                        row=dict(
                           Flow=dict(artifacts_with_results=artifacts_with_results),
                           ClientId=ClientId,
                           FlowId=session_id)) AS Event
        FROM flows(client_id=ClientId)
        WHERE request.artifacts =~ "Generic.Client.Info"
        LIMIT 1
      }, workers=10)

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/server.monitor.shell.md
======
---
title: Server.Monitor.Shell
hidden: true
tags: [Server Event Artifact]
---

Velociraptor can get an interactive shell on the endpoint by using
the shell command. In order to use it, the user must be directly
logged on the server.

Obviously being able to run arbitrary commands on the end point is
a powerful feature and should be used sparingly. There is an audit
trail for shell commands executed and their output available by
streaming all shell commands to the "Shell" client evnt monitoring
artifact.

This server event artifact centralizes all shell access from all
clients into the same log file.


<pre><code class="language-yaml">
name: Server.Monitor.Shell
description: |
   Velociraptor can get an interactive shell on the endpoint by using
   the shell command. In order to use it, the user must be directly
   logged on the server.

   Obviously being able to run arbitrary commands on the end point is
   a powerful feature and should be used sparingly. There is an audit
   trail for shell commands executed and their output available by
   streaming all shell commands to the "Shell" client evnt monitoring
   artifact.

   This server event artifact centralizes all shell access from all
   clients into the same log file.

# Can be CLIENT, EVENT, SERVER, SERVER_EVENT
type: SERVER_EVENT

sources:
  - query: |
      -- Watch for shell flow completions.
      LET collections = SELECT Flow
         FROM watch_monitoring(artifact="System.Flow.Completion")
         WHERE Flow.artifacts_with_results =~ "Windows.System.PowerShell|Windows.System.CmdShell"

      -- Dump the command and the results.
      SELECT * FROM foreach(row=collections,
      query={
         SELECT Flow.session_id AS FlowId,
             Flow.client_id AS ClientId,
             client_info(client_id=Flow.client_id).os_info.fqdn AS Hostname,
             timestamp(epoch=Flow.create_time / 1000000) AS Created,
             timestamp(epoch=Flow.active_time / 1000000) AS LastActive,
             get_flow(flow_id=FlowId,
                      client_id=ClientId).request.parameters.env[0].value AS Command,
             Stdout, Stderr FROM source(
                 client_id=Flow.client_id,
                 flow_id=Flow.session_id,
                 artifact=Flow.artifacts_with_results[0])
      })


# Reports can be MONITORING_DAILY, CLIENT
reports:
  - type: SERVER_EVENT
    template: |
      {{ .Description }}

      {{ $rows := Query "SELECT ClientId, Hostname, \
           timestamp(epoch=LastActive) AS Timestamp, Command, Stdout FROM source()" }}

      {{ range $row := $rows }}

      * On {{ Get $row "Timestamp" }} we ran {{ Get $row "Command" }} on {{ Get $row "Hostname" }}

      ```text
      {{ Get $row "Stdout" }}
      ```

      {{end}}

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.eventlogs.evtxhunter.md
======
---
title: Windows.EventLogs.EvtxHunter
hidden: true
tags: [Client Artifact]
---

This Artifact will hunt the Event Log message field for a regex value.
For example and IP, username or string.

Searching EventLog files is helpful for triage and scoping an incident.
The idea is a user can search for any IOC or other string of interest and
return all results across the Event Log ecosystem.

There are several parameter's available for search leveraging regex.
  - EvtxGlob glob of EventLogs to target. Default to all but can be targeted.
  - dateAfter enables search for events after this date.
  - dateBefore enables search for events before this date.
  - IocRegex enables regex search over the message field.
  - WhitelistRegex enables a regex whitelist for the Message field.
  - PathRegex enables filtering on evtx path for specific log targetting.
  - ChannelRegex allows specific EVTX Channel targets.
  - IdRegex enables a regex query to select specific event Ids.
  - SearchVSS enables searching over VSS

  Note: this artifact can potentially be heavy on the endpoint.
  Please use with caution.
  EventIds with an EventData field regex will be aplied and requires double
  escape for backslash due to serialisation of this field.
  E.g C:\\\\FOLDER\\\\binary\\.exe
  For EventIds with no EventData the Message field is queried and requires
  standard velociraptor escape. E.g C:\\FOLDER\\binary\\.exe


<pre><code class="language-yaml">
name: Windows.EventLogs.EvtxHunter
description: |
  This Artifact will hunt the Event Log message field for a regex value.
  For example and IP, username or string.

  Searching EventLog files is helpful for triage and scoping an incident.
  The idea is a user can search for any IOC or other string of interest and
  return all results across the Event Log ecosystem.

  There are several parameter's available for search leveraging regex.
    - EvtxGlob glob of EventLogs to target. Default to all but can be targeted.
    - dateAfter enables search for events after this date.
    - dateBefore enables search for events before this date.
    - IocRegex enables regex search over the message field.
    - WhitelistRegex enables a regex whitelist for the Message field.
    - PathRegex enables filtering on evtx path for specific log targetting.
    - ChannelRegex allows specific EVTX Channel targets.
    - IdRegex enables a regex query to select specific event Ids.
    - SearchVSS enables searching over VSS

    Note: this artifact can potentially be heavy on the endpoint.
    Please use with caution.
    EventIds with an EventData field regex will be aplied and requires double
    escape for backslash due to serialisation of this field.
    E.g C:\\\\FOLDER\\\\binary\\.exe
    For EventIds with no EventData the Message field is queried and requires
    standard velociraptor escape. E.g C:\\FOLDER\\binary\\.exe

author: Matt Green - @mgreen27

precondition: SELECT OS From info() where OS = 'windows'

parameters:
  - name: EvtxGlob
    default: '%SystemRoot%\System32\Winevt\Logs\*.evtx'
  - name: IocRegex
    type: regex
    description: "IOC Regex"
    default:
  - name: WhitelistRegex
    description: "Regex of string to witelist"
    type: regex
  - name: PathRegex
    description: "Event log Regex to enable filtering on path"
    default: .
    type: regex
  - name: ChannelRegex
    description: "Channel Regex to enable filtering on path"
    default: .
  - name: ProviderRegex
    description: "Provider Regex to enable filtering on provider"
    default: .
    type: regex
  - name: IdRegex
    default: .
    type: regex
  - name: VSSAnalysisAge
    type: int
    default: 0
    description: |
      If larger than zero we analyze VSS within this many days
      ago. (e.g 7 will analyze all VSS within the last week).  Note
      that when using VSS analysis we have to use the ntfs accessor
      for everything which will be much slower.
  - name: DateAfter
    type: timestamp
    description: "search for events after this date. YYYY-MM-DDTmm:hh:ssZ"
  - name: DateBefore
    type: timestamp
    description: "search for events before this date. YYYY-MM-DDTmm:hh:ssZ"
  - name: MessageDB
    type: hidden
    description: "Add message DB path if desired for offline parsing"
    
imports:
  - Windows.Sys.AllUsers

sources:
  - query: |
      LET VSS_MAX_AGE_DAYS &lt;= VSSAnalysisAge
      LET Accessor = if(condition=VSSAnalysisAge &gt; 0, then="ntfs_vss", else="auto")

      -- firstly set timebounds for performance
      LET DateAfterTime &lt;= if(condition=DateAfter,
        then=timestamp(epoch=DateAfter), else=timestamp(epoch="1600-01-01"))
      LET DateBeforeTime &lt;= if(condition=DateBefore,
        then=timestamp(epoch=DateBefore), else=timestamp(epoch="2200-01-01"))

      -- expand provided glob into a list of paths on the file system (fs)
      LET fspaths = SELECT OSPath
        FROM glob(globs=expand(path=EvtxGlob), accessor=Accessor)
        WHERE OSPath =~ PathRegex

      -- function returning IOC hits
      LET evtxsearch(PathList) = SELECT * FROM foreach(
            row=PathList,
            query={
                SELECT
                    timestamp(epoch=int(int=System.TimeCreated.SystemTime)) AS EventTime,
                    System.Computer as Computer,
                    System.Channel as Channel,
                    System.Provider.Name as Provider,
                    System.EventID.Value as EventID,
                    System.EventRecordID as EventRecordID,
                    System.Security.UserID as UserSID,
                    LookupSIDCache(SID=System.Security.UserID || "") AS Username,
                    get(field="EventData") as EventData,
                    get(field="UserData") as UserData,
                    get(field="Message") as Message,
                    OSPath
                FROM parse_evtx(filename=OSPath, accessor=Accessor, messagedb=MessageDB)
                WHERE ( EventData OR UserData OR Message )
                    AND EventTime &lt; DateBeforeTime
                    AND EventTime &gt; DateAfterTime
                    AND Channel =~ ChannelRegex
                    AND Provider =~ ProviderRegex
                    AND str(str=EventID) =~ IdRegex
                    AND format(format='%v %v %v', args=[
                               EventData, UserData, Message]) =~ IocRegex
                    AND if(condition=WhitelistRegex,
                        then= NOT format(format='%v %v %v', args=[
                               EventData, UserData, Message]) =~ WhitelistRegex,
                        else= True)
            }
          )

        SELECT * FROM evtxsearch(PathList=fspaths)

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.events.trackaccount.md
======
---
title: Windows.Events.Trackaccount
hidden: true
tags: [Client Event Artifact]
---

Artifact to detect account usage by monitoring event id 4624. This is useful for tracking attacker activity. If you want to receive Slack/Teams/Discord/etc alerts you can enable the server_event artifact named 'Server.Alerts.Trackaccount'


<pre><code class="language-yaml">
name: Windows.Events.Trackaccount
description: |
  Artifact to detect account usage by monitoring event id 4624. This is useful for tracking attacker activity. If you want to receive Slack/Teams/Discord/etc alerts you can enable the server_event artifact named 'Server.Alerts.Trackaccount'

author: Jos Clephas - @DfirJos

type: CLIENT_EVENT

parameters:
  - name: eventLog
    default: C:\Windows\system32\winevt\logs\Security.evtx
  - name: UserRegex
    default: 'admin|user'
    type: regex
  - name: LogonTypeRegex
    type: json_array
    default: '[2,3,4,5,7,8,9,10,11]'

sources:
  - precondition:
      SELECT OS From info() where OS = 'windows'
    query: |
      LET files = SELECT * FROM glob(globs=eventLog)

      SELECT timestamp(epoch=System.TimeCreated.SystemTime) As EventTime,
              System.EventRecordID as EventRecordID,
              System.EventID.Value as EventID,
              System.Computer as SourceComputer,
              EventData.TargetUserName as TargetUserName,
              EventData.LogonType as LogonType,
              EventData.IpAddress as IpAddress,
              EventData.WorkstationName as TargetWorkstationName,
              System,
              EventData,
              Message

        FROM foreach(
          row=files,
          async=TRUE,
          query={
            SELECT *
            FROM watch_evtx(filename=OSPath)
            WHERE System.EventID.Value = 4624
                AND EventData.TargetUserName =~ UserRegex
                AND EventData.LogonType in LogonTypeRegex
        })

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/linux.sys.users.md
======
---
title: Linux.Sys.Users
hidden: true
tags: [Client Artifact]
---

Get User specific information like homedir, group etc from /etc/passwd.

<pre><code class="language-yaml">
name: Linux.Sys.Users
description: Get User specific information like homedir, group etc from /etc/passwd.
parameters:
  - name: PasswordFile
    default: /etc/passwd
    description: The location of the password file.
sources:
  - precondition: |
      SELECT OS From info() where OS = 'linux'
    query: |
      SELECT User, Description, Uid, Gid, Homedir, Shell
      FROM split_records(
            filenames=PasswordFile,
            regex=":", record_regex="\r?\n",
            columns=["User", "X", "Uid", "Gid", "Description", "Homedir", "Shell"])

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/server.internal.notifications.md
======
---
title: Server.Internal.Notifications
hidden: true
tags: [Internal Artifact]
---

This event artifact is an internal event stream over which client
notifications are sent. A frontend will watch for events over this
stream and if a client is actively connected to this frontend, the
client will be notified that new work is available to it.

Note: This is an automated system artifact. You do not need to start it.


<pre><code class="language-yaml">
name: Server.Internal.Notifications
description: |
  This event artifact is an internal event stream over which client
  notifications are sent. A frontend will watch for events over this
  stream and if a client is actively connected to this frontend, the
  client will be notified that new work is available to it.

  Note: This is an automated system artifact. You do not need to start it.

type: INTERNAL

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/linux.applications.docker.version.md
======
---
title: Linux.Applications.Docker.Version
hidden: true
tags: [Client Artifact]
---

Get Dockers version by connecting to its socket.

<pre><code class="language-yaml">
name: Linux.Applications.Docker.Version
description: Get Dockers version by connecting to its socket.
parameters:
  - name: dockerSocket
    description: |
      Docker server socket. You will normally need to be root to connect.
    default: /var/run/docker.sock
sources:
  - precondition: |
      SELECT OS From info() where OS = 'linux'
    query: |
        LET data = SELECT parse_json(data=Content) as JSON
        FROM http_client(url=dockerSocket + ":unix/version")

        SELECT JSON.Version as Version,
               JSON.ApiVersion as ApiVersion,
               JSON.MinAPIVersion as MinAPIVersion,
               JSON.GitCommit as GitCommit,
               JSON.GoVersion as GoVersion,
               JSON.Os as Os,
               JSON.Arch as Arch,
               JSON.KernelVersion as KernelVersion,
               JSON.BuildTime as BuildTime
        FROM data

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/notebooks.sigma.studio.md
======
---
title: Notebooks.Sigma.Studio
hidden: true
tags: [notebook]
---

A notebook to help develop Sigma rules.


<pre><code class="language-yaml">
name: Notebooks.Sigma.Studio
description: |
  A notebook to help develop Sigma rules.

type: NOTEBOOK

tools:
  - name: SigmaProfiles
    url: https://sigma.velocidex.com/profiles.json
    serve_locally: true

parameters:
  - name: BaseType
    description: Write sigma rules to target these base artifacts
    type: choices
    default: Windows
    choices:
      - Windows
      - WindowsEvents
      - Linux
      - LinuxEvents

  - name: Debug
    description: Enable this to match all rules (even if they did not match) in order to see what detections matched.
    type: bool

  - name: LogSource
    description: The current log source to use.

sources:
  - notebook:
      - type: markdown
        name: Sigma Studio Description
        template: |
          # Sigma Studio

          This notebook is designed to help you write and test Sigma
          Rules for detection within Velociraptor!

          ## What is Sigma?

          Sigma is an open notation for writing detection rules - It
          is supported natively in Velociraptor as described in [our
          blog post](https://docs.velociraptor.app/blog/2024/2024-05-09-detection-engineering/)

          Sigma relies on a set of `Log Sources` (defining possible
          sources for log events) and `Field Mappings` (an agreed upon
          set of field transformations that may be referred to in the
          Sigma rule).

          The Sigma standard does not define those, but they are
          critical for successfully writing Sigma rules. Therefore,
          Velociraptor uses [a standard set of Log Sources and Field
          Mappings](https://sigma.velocidex.com/).

          This is the purpose of this notebook! Making it easy and
          simple to write rules **within the definitions of
          Velociraptor's curated sets**. This means that portability
          of rules to other systems is **not a goal** of this
          notebook.

          ## How to use this notebook?

          1. Before you start, collect the
             `Server.Import.CuratedSigma` artifact to download the
             latest `Sigma Profiles`. A `Sigma Profile` is a machine
             readable definition of log sources and field mappings
             that allows the GUI to guide rule authors.

          2. Collect event samples. Use the relevant `CaptureTestSet`
             artifact (e.g. `Windows.Sigma.Base.CaptureTestSet`) collect
             events from the relevant log source. You can post process
             the rows and filter in the notebook as usual.

          3. When you are ready to work with a test set, click `export
             to JSON` in the GUI to receive a JSON file with the test
             data.

          4. Upload this test set into this notebook.

          5. Open the `Sigma Editor` within this notebook.

          6. Select the relevant log source from the drop down (you
             will only see supported log sources).

          7. Follow the instructions within the Sigma editor. You can
             name any of the supported fields inside the rule.

          8. Saving the rule will automatically apply the ruleset on
             the test set. This gives visual feedback of how effective
             the rule is.

          9. When you are ready to deploy at scale download the
             ruleset from the notebook and enter it to the base sigma
             artifact (e.g. `Windows.Sigma.Base`).


          After you are familiar with the `Sigma Studio` notebook you
          can delete this instructional cell.

      - type: markdown
        name: Sigma Studio Interactive Cell
        template: |
          {{ define "Setup" }}
          LET ProfileType &lt;= dict(
             Windows="Windows.Sigma.Base",
             Linux="Linux.Sigma.Base",
             WindowsEvents="Windows.Sigma.BaseEvents",
             LinuxEvents="Linux.Sigma.BaseEvents")

          // We need to store the profile in the datastore because it
          // is too large to pass in a html tag.
          LET Rows &lt;= SELECT upload(
             accessor='data', file=Content,
             name='profile.json') AS Upload
          FROM http_client(url=Tool_SigmaProfiles_URL)

          // This is where it is.
          LET ProfileComponents &lt;= Rows[0].Upload.Components

          LET ProfileName &lt;= get(item=ProfileType,
              field=BaseType || "Windows")
          LET _ &lt;= import(artifact= ProfileName)

          // Build the Sigma rules into a downloadable rule set.
          LET Rules = SELECT read_file(
             accessor='fs',
             filename=vfs_path) AS Data FROM uploads()
          WHERE vfs_path =~ '.yaml'

          LET TestSigmaRules &lt;= join(array=Rules.Data, sep='\n---\n')

          LET Upload &lt;= upload(name='sigma_rules.yaml', accessor='data',
                                                        file=TestSigmaRules)
          LET Link &lt;= link_to(upload=Upload, text='sigma ruleset')

          SELECT * FROM scope()
          {{ end }}

          {{ $rows := Query "Setup" | Expand }}

          {{ SigmaEditor "upload" (  Scope "ProfileComponents" )  "selected_profile" ( Scope "ProfileName" )  }}

          ### Download {{ Scope "Link" }}

          # Sample Events For testing.

          You can test the sigma rules on test events in JSONL
          format. Upload samples into this notebook by using the
          `Notebook Uploads` dialog.

          {{ define "Testing" }}
          // Feed all the json rows to the log sources.
          LET AllRows = SELECT * FROM foreach(row={
            SELECT vfs_path FROM uploads()
            WHERE vfs_path =~ 'attach.+json$'
          }, query={
            SELECT * FROM parse_jsonl(accessor='fs', filename=vfs_path)
          })

          LET TestingLogSourceDict &lt;= to_dict(item={
            SELECT _key, AllRows AS _value
            FROM items(item=LogSources)
          })

          // Build the log sources automatically.
          LET TestingLogSources &lt;= sigma_log_sources(`**`=TestingLogSourceDict)

          // Apply the Sigma Rules on the samples.
          SELECT  _Rule.Title AS Rule ,
          Details,
          dict(System=System,
               EventData=X.EventData || X.UserData,
               Message=X.Message) AS Event,
          _Match AS Match
          FROM sigma(
          rules=split(string=TestSigmaRules, sep_string="\n---\n"),
            log_sources= TestingLogSources, debug=Debug,
            default_details=DefaultDetailsLambda,
            field_mapping= FieldMapping)

          {{ end }}

          ## Match rules on test set

          {{ if ( Scope "Debug" ) }}
          Debug mode is enabled, so all events will be shown. Inspect
          the Match object to see which detections matched.
          {{ else }}
          Debug mode is disabled, so only matching events will be shown. Enable Debug mode by editing the notebook.
          {{ end }}

          {{ Query "Testing" | Table}}

          ## View the test set

          {{ Query "SELECT * FROM AllRows " | Table}}

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.persistence.debug.md
======
---
title: Windows.Persistence.Debug
hidden: true
tags: [Client Artifact]
---

Windows allows specific configuration of various executables via a
registry key. Some keys allow defining a debugger to attach to a
program as it is run. If this debugger is launched for commonly used
programs (e.g. notepad) then another program can be launched at the
same time (with the same privileges).

There is an additional key for x86 executables HKEY_LOCAL_MACHINE\
SOFTWARE\wow6432node\Microsoft\Windows NT\CurrentVersion\Image File
Execution Options\* however this is kept inlign with the x64 key and
therefore does not need to be processed.

Limitations: This queries the live registry and therefore does not
parse data in Windows.old or Regback folders, or VSS.


<pre><code class="language-yaml">
name: Windows.Persistence.Debug
description: |
  Windows allows specific configuration of various executables via a
  registry key. Some keys allow defining a debugger to attach to a
  program as it is run. If this debugger is launched for commonly used
  programs (e.g. notepad) then another program can be launched at the
  same time (with the same privileges).

  There is an additional key for x86 executables HKEY_LOCAL_MACHINE\
  SOFTWARE\wow6432node\Microsoft\Windows NT\CurrentVersion\Image File
  Execution Options\* however this is kept inlign with the x64 key and
  therefore does not need to be processed.

  Limitations: This queries the live registry and therefore does not
  parse data in Windows.old or Regback folders, or VSS.

reference:
  - https://attack.mitre.org/techniques/T1183/

parameters:
  - name: imageFileExecutionOptions
    default: HKEY_LOCAL_MACHINE\SOFTWARE\Microsoft\Windows NT\CurrentVersion\Image File Execution Options\*

sources:
  - query: |
        LET X = scope()
        SELECT Key.ModTime as KeyLastWriteTimestamp,
               Key.OSPath as _Key,
               Key.Name AS Program,
               X.Debugger AS Debugger
        FROM read_reg_key(globs=imageFileExecutionOptions)
        WHERE Debugger
        Order By KeyLastWriteTimestamp

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.etw.registry.md
======
---
title: Windows.ETW.Registry
hidden: true
tags: [Client Event Artifact]
---

Windows Registry access is a great source of visibility into system
activity.

There are many ways of gaining visibility into this, the most
reliable being Sysmon. However it is also possible to gain some
visibility using ETW. The Microsoft-Windows-Kernel-Registry provides
ETW events for registry modifications.

This artifact parses these events and ties them back to the
accessing process. It is recommended to run this artifact with the
process tracker.

NOTE: Experience shows this ETW provider is not very reliable and
seems to miss a lot of registry events.

This artifact is experimental.


<pre><code class="language-yaml">
name: Windows.ETW.Registry
description: |
  Windows Registry access is a great source of visibility into system
  activity.

  There are many ways of gaining visibility into this, the most
  reliable being Sysmon. However it is also possible to gain some
  visibility using ETW. The Microsoft-Windows-Kernel-Registry provides
  ETW events for registry modifications.

  This artifact parses these events and ties them back to the
  accessing process. It is recommended to run this artifact with the
  process tracker.

  NOTE: Experience shows this ETW provider is not very reliable and
  seems to miss a lot of registry events.

  This artifact is experimental.

type: CLIENT_EVENT

precondition: SELECT * FROM info() WHERE OS = "windows"

parameters:
- name: KeyNameRegex
  type: regex
  default: .
- name: ProcessRegex
  type: regex
  default: .

sources:
- query: |
    LET Cache &lt;= lru(size=1000)
    LET EventLookup &lt;= dict(
        `1`="CreateKey",
        `2`="OpenKey",
        `3`="DeleteKey",
        `4`="QueryKey",
        `5`="SetValueKey",
        `6`="DeleteValueKey",
        `7`="QueryValue",
        `8`="EnumerateKey",
        `9`="EnumerateValueKey"
    )

    LET registry_access = SELECT System, EventData,
       get(item=EventLookup, field=str(str=System.ID)) AS EventType,
       get(item=Cache, field=EventData.KeyObject) || EventData.KeyName AS KeyName
    FROM watch_etw(
      description="Microsoft-Windows-Kernel-Registry",
      guid="{70EB4F03-C1DE-4F73-A051-33D13D5413BD}", any=0x7720)
    WHERE System.ProcessID != getpid() -- exclude ourselves
        AND EventType  -- we only care about these events
        AND if(condition=System.ID in (1, 2, 4),
              then=set(item=Cache, field=EventData.KeyObject,
                       value=EventData.RelativeName),
              else=TRUE) -- set KeyName in the lru

    LET hits = SELECT System.TimeStamp AS Timestamp,
       process_tracker_get(id=System.ProcessID).Data AS Process,
       EventType, KeyName, EventData
    FROM registry_access
    WHERE KeyName =~ KeyNameRegex

    SELECT Timestamp, EventType,
       Process.Name AS ProcessName, Process.Username AS Owner,
       Process.CommandLine AS CommandLine,
       KeyName, EventData.ValueName AS ValueName
    FROM hits
    WHERE ProcessName =~ ProcessRegex

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/linux.sys.pslist.md
======
---
title: Linux.Sys.Pslist
hidden: true
tags: [Client Artifact]
---

List processes and their running binaries.


<pre><code class="language-yaml">
name: Linux.Sys.Pslist
description: |
  List processes and their running binaries.

aliases:
  - MacOS.Sys.Pslist

parameters:
  - name: processRegex
    default: .
    type: regex

precondition: |
  SELECT OS From info() where OS =~ 'linux|darwin'

sources:
  - query: |
        SELECT Pid, Ppid, Name, CommandLine, Exe,
               hash(path=Exe) as Hash,
               Username, timestamp(epoch=CreateTime/1000) AS CreatedTime,
               MemoryInfo.RSS AS RSS,
               Exe =~ "\\(deleted\\)$" AS Deleted
        FROM process_tracker_pslist()
        WHERE Name =~ processRegex

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.forensics.srum.md
======
---
title: Windows.Forensics.SRUM
hidden: true
tags: [Client Artifact]
---

Process the SRUM database.


<pre><code class="language-yaml">
name: Windows.Forensics.SRUM
description: |
  Process the SRUM database.

reference:
  - https://www.sans.org/cyber-security-summit/archives/file/summit-archive-1492184583.pdf
  - https://cyberforensicator.com/2017/08/06/windows-srum-forensics/

type: client

parameters:
  - name: SRUMLocation
    default: c:/windows/system32/sru/srudb.dat
  - name: accessor
    default: auto
  - name: ExecutableRegex
    default: .
  - name: NetworkConnectionsGUID
    default: "{DD6636C4-8929-4683-974E-22C046A43763}"
    type: hidden
  - name: ApplicationResourceUsageGUID
    default: "{D10CA2FE-6FCF-4F6D-848E-B2E99266FA89}"
    type: hidden
  - name: ExecutionGUID
    default: "{5C8CF1C7-7257-4F13-B223-970EF5939312}"
    type: hidden
  - name: NetworkUsageGUID
    default: "{973F5D5C-1D90-4944-BE8E-24B94231A174}"
    type: hidden
  - name: Upload
    description: Select to Upload the SRUM database file 'srudb.dat'
    type: bool

export: |
  LET ResolveESEId(OSPath, Accessor, Id) = cache(
      name="ESE",
      func=srum_lookup_id(file=OSPath, accessor=Accessor, id=Id),
      key=format(format="%v-%v-%v", args=[OSPath, Accessor, Id]))

imports:
  - Windows.Sys.AllUsers

sources:
  - name: Upload
    precondition:
        SELECT * FROM scope() WHERE Upload
    query: |
        SELECT upload(file=SRUMLocation, accessor=accessor) AS Upload
        FROM scope()

  - name: Execution Stats
    query: |
        LET SRUMFiles &lt;= SELECT OSPath FROM glob(globs=SRUMLocation)

        SELECT  AutoIncId AS ID,
                TimeStamp,
                ResolveESEId(OSPath=SRUMFiles.OSPath,
                             Accessor=accessor, Id=AppId) AS App,
                ResolveESEId(OSPath=SRUMFiles.OSPath,
                             Accessor=accessor, Id=UserId) AS UserSid,
                LookupSIDCache(SID=srum_lookup_id(
                    file=SRUMFiles, accessor=accessor, id=UserId) || "") AS User,
                timestamp(winfiletime=EndTime) AS EndTime,
                DurationMS,
                NetworkBytesRaw
        FROM parse_ese(file=SRUMFiles.OSPath,
                       accessor=accessor, table=ExecutionGUID)
        WHERE App =~ ExecutableRegex

  - name: Application Resource Usage
    query: |
        LET SRUMFiles &lt;= SELECT OSPath FROM glob(globs=SRUMLocation)

        SELECT AutoIncId as SRUMId,
               TimeStamp,
               ResolveESEId(OSPath=SRUMFiles.OSPath,
                            Accessor=accessor, Id=AppId) AS App,
               ResolveESEId(OSPath=SRUMFiles.OSPath,
                            Accessor=accessor, Id=UserId) AS UserSid,
               LookupSIDCache(SID=srum_lookup_id(
                    file=SRUMFiles, accessor=accessor, id=UserId) || "") AS User,
               ForegroundCycleTime,
               BackgroundCycleTime,
               FaceTime,
               ForegroundContextSwitches,
               BackgroundContextSwitches,
               ForegroundBytesRead,
               ForegroundBytesWritten,
               ForegroundNumReadOperations,
               ForegroundNumWriteOperations,
               ForegroundNumberOfFlushes,
               BackgroundBytesRead,
               BackgroundBytesWritten,
               BackgroundNumReadOperations,
               BackgroundNumWriteOperations,
               BackgroundNumberOfFlushes
        FROM parse_ese(file=SRUMFiles.OSPath,
                       accessor=accessor, table=ApplicationResourceUsageGUID)
        WHERE App =~ ExecutableRegex

  - name: Network Connections
    query: |
        LET SRUMFiles &lt;= SELECT OSPath FROM glob(globs=SRUMLocation)

        SELECT AutoIncId as SRUMId,
             TimeStamp,
             ResolveESEId(OSPath=SRUMFiles.OSPath,
                          Accessor=accessor, Id=AppId) AS App,
             ResolveESEId(OSPath=SRUMFiles.OSPath,
                          Accessor=accessor, Id=UserId) AS UserSid,
             LookupSIDCache(SID=srum_lookup_id(
                    file=SRUMFiles, accessor=accessor, id=UserId) || "") AS User,
             InterfaceLuid,
             ConnectedTime,
             timestamp(winfiletime=ConnectStartTime) AS StartTime
        FROM parse_ese(file=SRUMFiles.OSPath,
                       accessor=accessor, table=NetworkConnectionsGUID)
        WHERE App =~ ExecutableRegex

  - name: Network Usage
    query: |
        LET SRUMFiles &lt;= SELECT OSPath FROM glob(globs=SRUMLocation)

        SELECT AutoIncId as SRUMId,
             TimeStamp,
             ResolveESEId(OSPath=SRUMFiles.OSPath,
                          Accessor=accessor, Id=AppId) AS App,
             ResolveESEId(OSPath=SRUMFiles.OSPath,
                          Accessor=accessor, Id=UserId) AS UserSid,
             LookupSIDCache(SID=srum_lookup_id(
                    file=SRUMFiles, accessor=accessor, id=UserId) || "") AS User,
             UserId,
             BytesSent,
             BytesRecvd,
             InterfaceLuid,
             L2ProfileId,
             L2ProfileFlags
        FROM parse_ese(file=SRUMFiles.OSPath,
                       accessor=accessor, table=NetworkUsageGUID)
        WHERE App =~ ExecutableRegex

    notebook:
        - type: vql_suggestion
          name: SRUM Network Usage summary
          template: |
              /*
              # SRUM Network Usage summary
              */
              SELECT Fqdn,
                  count() as TotalEntries,
                  min(item=TimeStamp) as Earliest,
                  max(item=TimeStamp) as Latest,
                  App,
                  User,UserId,
                  sum(item=BytesSent) as TotalSent,
                  sum(item=BytesRecvd) as TotalRecvd,
                  InterfaceLuid
              FROM source(artifact="Windows.Forensics.SRUM/Network Usage")
              GROUP BY App, User,InterfaceLuid
              ORDER BY TotalSent DESC

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.detection.cryptneturlcache.md
======
---
title: Windows.Detection.CryptnetUrlCache
hidden: true
tags: [Client Artifact]
---

This artifact will hunt for evidence of Certutil use as a download cradle.

The CryptnetUrlCache contains both content and metadata of files downloaded by
CertUtil and other Windows Crypto components. The artifact will first look for
content larger than a specified size, then check headers against a whitelist
of common content types. Additional options include a UrlWhitelist and search
of VSS.

NOTE: Expect some false positives and build a whitelist of Urls to add for
regular hunts. Alternatively target specific headers such as PE files by
adding '^MZ' to the HeaderRegex field.


```yaml
name: Windows.Detection.CryptnetUrlCache
description: |
   This artifact will hunt for evidence of Certutil use as a download cradle.

   The CryptnetUrlCache contains both content and metadata of files downloaded by
   CertUtil and other Windows Crypto components. The artifact will first look for
   content larger than a specified size, then check headers against a whitelist
   of common content types. Additional options include a UrlWhitelist and search
   of VSS.

   NOTE: Expect some false positives and build a whitelist of Urls to add for
   regular hunts. Alternatively target specific headers such as PE files by
   adding '^MZ' to the HeaderRegex field.

author: "@mgreen27 - Matt Green"

reference:
  - https://thinkdfir.com/2020/07/30/certutil-download-artefacts/
  - https://lolbas-project.github.io/lolbas/Binaries/Certutil/


parameters:
  - name: GlobLookup
    default: |
      FileGlob
      C:\Windows\*\config\systemprofile\AppData\LocalLow\Microsoft\CryptnetUrlCache\**
      C:\Users\*\AppData\LocalLow\Microsoft\CryptnetUrlCache\**
  - name: SusSize
    description: "Size in bytes for CryptnetUrlCache content to be suspicious"
    default: '10000'
    type: int
  - name: HeaderRegex
    description: 'Regex of content headers.'
    default: '.'
    type: regex
  - name: HeaderWhitelist
    description: 'Whitelist regex of content headers.'
    default: '^(MSCF|0|<|.<|----)'
    type: regex
  - name: UrlWhitelist
    description: 'Regex to whitelist Url field'
    type: regex
  - name: SearchVSS
    description: "Add VSS into query."
    type: bool


sources:
  - precondition:
      SELECT OS From info() where OS = 'windows'

    query: |
      -- file target globs
      LET CryptnetUrlCache <= SELECT FileGlob
            FROM parse_csv(filename=GlobLookup, accessor='data')


      -- expand provided glob into a list of paths on the file system (fs)
      LET fspaths(path) = SELECT * FROM glob(globs=path) WHERE NOT IsDir


      -- function returning list of VSS paths corresponding to path
      LET vsspaths(path) = SELECT *
        FROM Artifact.Windows.Search.VSS(SearchFilesGlob=path)
        WHERE NOT IsDir


      -- determine files in scope from globs
      LET files <= SELECT * FROM foreach(row=CryptnetUrlCache,
            query={
                SELECT * FROM if(condition=SearchVSS,
                    then= {
                       SELECT * FROM vsspaths(path=FileGlob)
                    },
                    else= {
                       SELECT * FROM fspaths(path=FileGlob)
                    })
            })


      -- extract metadata lines
      LET metadata = SELECT * FROM foreach(row=files,
        query={
            SELECT
                FullPath as MetaPath,
                Mtime as MetaMtime,
                Ctime as MetaCtime,
                Atime as MetaAtime,
                parse_string_with_regex(
                    string=utf16(string=Line),
                    regex=['[\\s\\S]*(?P<Url>(http[s]?:|\\\\\\\\|ftp:)[\\s\\S]+)']
                        ).Url as Url
            FROM parse_lines(filename=FullPath)
            WHERE MetaPath =~ '\\\\Microsoft\\\\CryptnetUrlCache\\\\metadata\\\\'
            GROUP BY MetaPath
        })


      -- find suspicious content files and extract headers
      LET hits = SELECT
            FullPath,Name,Size,
            Mtime, Atime, Ctime,
            hash(path=FullPath) as Hash,
            read_file(length=4,filename=FullPath) as Header
        FROM files
        WHERE
            FullPath =~ '\\\\Microsoft\\\\CryptnetUrlCache\\\\Content\\\\'
            AND Size > int(int=SusSize)


      -- output rows
      SELECT * FROM foreach(row=hits,
        query={
            SELECT
                FullPath,Name,Size,Header,
                Mtime, Atime, Ctime,
                Url, Hash,
                if(condition= Header=~ 'MZ',
                    then= parse_pe(file=FullPath).VersionInformation,
                    else= 'N/A' ) as VersionInformation,
                if(condition= Header=~ 'MZ',
                    then= authenticode(filename=FullPath),
                    else= 'N/A' ) as Authenticode,
                MetaPath,
                MetaMtime,MetaAtime,MetaCtime
            FROM metadata
            WHERE
                MetaPath =~ Name
                AND Header =~ HeaderRegex
                AND NOT if(condition= HeaderWhitelist,
                    then= Header =~ HeaderWhitelist,
                    else= FALSE)
                AND NOT if(condition=UrlWhitelist,
                    then= Url =~ UrlWhitelist,
                    else= FALSE)
                AND split(
                    string=FullPath,
                        sep='CryptnetUrlCache')[0] = split(string=MetaPath,
                            sep='CryptnetUrlCache')[0]
        })

```

---END OF FILE---

======
FILE: /content/artifact_references/pages/server.utils.deletemonitoringdata.md
======
---
title: Server.Utils.DeleteMonitoringData
hidden: true
tags: [Server Artifact]
---

Velociraptor collects monitoring data from endpoints all the time.

Sometimes this data is no longer needed and we might want to free
up disk space.

This artifact searches the monitoring data for each client and
optionally removes data older than the specified timestamp.

**NOTE** This artifact will destroy all data irrevocably. Take
  care! You should always do a dry run first to see which flows
  will match before using the ReallyDoIt option.


<pre><code class="language-yaml">
name: Server.Utils.DeleteMonitoringData
description: |
   Velociraptor collects monitoring data from endpoints all the time.

   Sometimes this data is no longer needed and we might want to free
   up disk space.

   This artifact searches the monitoring data for each client and
   optionally removes data older than the specified timestamp.

   **NOTE** This artifact will destroy all data irrevocably. Take
     care! You should always do a dry run first to see which flows
     will match before using the ReallyDoIt option.

type: SERVER

parameters:
   - name: DateBefore
     default: 2022-01-01
     type: timestamp
   - name: ArtifactRegex
     type: regex
     default: Generic.Client.Stats
   - name: HostnameRegex
     description: If specified only target these hosts
     type: regex
     default: .
   - name: OnlyRegisteredClients
     type: bool
     description: |
       If enabled only search registered clients. (Might be needed for
       very large deployments).
   - name: ReallyDoIt
     type: bool
     description: Do not actually delete until this is set!

sources:
  - query: |
      LET SearchDeletedClientsQuery = SELECT Name AS ClientId,
            client_info(client_id=Name).os_info.hostname AS Hostname
      FROM glob(globs="/clients/*", accessor="fs")
      WHERE IsDir
        AND Hostname =~ HostnameRegex

      LET SearchRegisteredClientsQuery = SELECT client_id,
           os_info.hostname AS hostname
      FROM clients()
      WHERE hostname =~ HostnameRegex

      LET SearchClients = SELECT * FROM if(
           condition=SearchDeletedClients,
           then=SearchDeletedClientsQuery,
           else=SearchRegisteredClientsQuery)

      SELECT * FROM foreach(row=SearchClients,
      query={
        SELECT OSPath,
               OSPath.Dirname.Basename AS ArtifactName, Size,
               timestamp(epoch=split(string=OSPath.Basename, sep="\\.")[0]) AS Timestamp,
               if(condition=ReallyDoIt, then=file_store_delete(path=OSPath)) AS ReallyDoIt
        FROM glob(
          globs="/**.json*", accessor="fs",
          root="/clients/"+ client_id + "/monitoring")
        WHERE ArtifactName =~ ArtifactRegex
          AND Timestamp &lt; DateBefore
      }, workers=10)

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/server.enrichment.greynoise.md
======
---
title: Server.Enrichment.GreyNoise
hidden: true
tags: [Server Artifact]
---

Submit an IP to the GreyNoise API.

https://developer.greynoise.io/reference/community-api

This is a rather simple artifact that can be called from within another artifact (such as one looking for network connections) to enrich the data made available by that artifact.

Ex.

  `SELECT * from Artifact.Server.Enrichment.GreyNoise(IP=$YOURIP)`


<pre><code class="language-yaml">
name: Server.Enrichment.GreyNoise
author: Wes Lambert -- @therealwlambert
description: |
  Submit an IP to the GreyNoise API.

  https://developer.greynoise.io/reference/community-api

  This is a rather simple artifact that can be called from within another artifact (such as one looking for network connections) to enrich the data made available by that artifact.

  Ex.

    `SELECT * from Artifact.Server.Enrichment.GreyNoise(IP=$YOURIP)`


type: SERVER

parameters:
    - name: IP
      type: string
      description: The IP to submit to GreyNoise.
      default:
    - name: ApiKey
      type: string
      description: The API key to submit to GreyNoise.
      default: ''
    - name: AccountType
      type: choices
      description: The GreyNoise account type - enterprise or community.
      default: community
      choices:
        - community
        - enterprise
    - name: CommunityURL
      type: string
      description: The GreyNoise community API URL.
      default: https://api.greynoise.io/v3/community/
    - name: EnterpriseURL
      type: string
      description: The GreyNoise enterprise API URL.
      default: https://api.greynoise.io/v2/noise/quick/

sources:
  - query: |
        LET URL &lt;= if(condition= AccountType='community', then=CommunityURL, else=EnterpriseURL)

        LET Data = if(condition= ApiKey!='', 
        then={
            SELECT parse_json(data=Content) AS GreyNoiseLookup
            FROM http_client(url=URL + IP, headers=dict(`Accept`="application/json",`key`=ApiKey), method='GET')
        }, else={
            SELECT parse_json(data=Content) AS GreyNoiseLookup
            FROM http_client(url=URL + IP, headers=dict(`Accept`="application/json"), method='GET')
        })

        SELECT
            GreyNoiseLookup.ip AS IP,
            GreyNoiseLookup.classification AS Classification,
            GreyNoiseLookup.name AS Name,
            GreyNoiseLookup.riot AS Riot,
            GreyNoiseLookup.noise AS Noise,
            GreyNoiseLookup.last_seen AS LastSeen,
            GreyNoiseLookup.link AS Link,
            GreyNoiseLookup AS _GreyNoiseLookup
        FROM Data

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.registry.portproxy.md
======
---
title: Windows.Registry.PortProxy
hidden: true
tags: [Client Artifact]
---

This artifact will return any items in the Windows PortProxy service
registry path. The most common configuration of this service is via the
lolbin netsh.exe; Metaspoit and other common attack tools also have
configuration modules.


<pre><code class="language-yaml">
name: Windows.Registry.PortProxy
description: |
    This artifact will return any items in the Windows PortProxy service
    registry path. The most common configuration of this service is via the
    lolbin netsh.exe; Metaspoit and other common attack tools also have
    configuration modules.

reference:
  - Port Proxy detection(http://www.dfirnotes.net/portproxy_detection/)
  - ATT&amp;CK T1090 - Connection Proxy(https://attack.mitre.org/techniques/T1090/)
    Adversaries may use a connection proxy to direct network traffic between
    systems or act as an intermediary for network communications to a command
    and control server to avoid direct connections to their infrastructure.

author: Matt Green - @mgreen27

precondition: SELECT OS From info() where OS = 'windows'

parameters:
 - name: KeyGlob
   default: HKEY_LOCAL_MACHINE\SYSTEM\*ControlSet*\services\PortProxy\**

sources:
 - name: PortProxy
   query: |
     SELECT OSPath,
         OSPath[-3] AS ProxyType,
         OSPath[-2] AS Protocol,
         regex_replace(source=OSPath.Basename, re="/", replace=":") as Listening,
         regex_replace(source=Data.value, re="/", replace=":") as Destination,
         Mtime as ModifiedTime,
         Type
       FROM glob(globs=KeyGlob, accessor="registry")
       WHERE Type


reports:
  - type: CLIENT
    template: |

      Port Forwarding: PortProxy
      ==========================
      {{ .Description }}

      {{ define "report" }}
         LET report = SELECT Protocol,
            ProxyType,
            Listening,
            Destination,
            ModifiedTime,
            ProxyType + Protocol + Listening + Destination as ServiceKey
         FROM source(source='PortProxy')
         GROUP BY ServiceKey
      {{ end }}

      {{ Query "report"  "SELECT ProxyType, Protocol, Listening, Destination, ModifiedTime FROM report" | Table }}

  - type: HUNT
    template: |

      Port Forwarding: PortProxy
      ==========================
      {{ .Description }}

      {{ define "report" }}
         LET report = SELECT Fqdn,
            Protocol,
            ProxyType,
            Listening,
            Destination,
            ModifiedTime,
            ProxyType + Protocol + Listening + Destination as ServiceKey
         FROM source(source='PortProxy')
         GROUP BY ServiceKey
      {{ end }}

      {{ Query "report"  "SELECT Fqdn, ProxyType, Protocol, Listening, Destination, ModifiedTime FROM report" | Table }}

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.registry.backuprestore.md
======
---
title: Windows.Registry.BackupRestore
hidden: true
tags: [Client Artifact]
---

This artifact will return BackupRestore configuration.

Applications that request or perform backup and restore operations can use
these keys to communicate with each other or with features such as the
Volume Shadow Copy Service (VSS) and Windows Backup.


<pre><code class="language-yaml">
name: Windows.Registry.BackupRestore
author: Matt Green - @mgreen27
description: |
    This artifact will return BackupRestore configuration.

    Applications that request or perform backup and restore operations can use
    these keys to communicate with each other or with features such as the
    Volume Shadow Copy Service (VSS) and Windows Backup.

reference:
  - https://andreafortuna.org/2017/10/02/volume-shadow-copies-in-forensic-analysis/
  - https://docs.microsoft.com/en-us/windows/win32/backup/registry-keys-for-backup-and-restore

parameters:
 - name: KeyGlob
   default: HKEY_LOCAL_MACHINE\SYSTEM\*ControlSet*\Control\BackupRestore\**

sources:
  - precondition:
      SELECT OS From info() where OS = 'windows'

    query: |
      -- output rows and dedup on unique values for each
      SELECT ModTime,OSPath,
        Name as KeyName,
        Data.value as KeyValue,
        Data.type as KeyType
      FROM glob(globs=KeyGlob, accessor="registry")
      WHERE NOT KeyType ='key'
      GROUP BY ModTime, KeyName,KeyValue,KeyType

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.sys.certificateauthorities.md
======
---
title: Windows.Sys.CertificateAuthorities
hidden: true
tags: [Client Artifact]
---

Certificate Authorities installed in Keychains/ca-bundles.

<pre><code class="language-yaml">
name: Windows.Sys.CertificateAuthorities
description: Certificate Authorities installed in Keychains/ca-bundles.
sources:
  - precondition:
      SELECT OS From info() where OS = 'windows'
    query: |
        SELECT Store, IsCA, Subject,
               encode(string=SubjectKeyId, type='hex') AS SubjectKeyId,
               encode(string=AuthorityKeyId, type='hex') AS AuthorityKeyId,
               Issuer, KeyUsageString,
               IsSelfSigned, SHA1, SignatureAlgorithm, PublicKeyAlgorithm, KeyStrength,
               NotBefore, NotAfter, HexSerialNumber
        FROM certificates()

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/server.internal.inventory.md
======
---
title: Server.Internal.Inventory
hidden: true
tags: [Internal Artifact]
---

An internal artifact to listen to inventory (tools) changes.


<pre><code class="language-yaml">
name: Server.Internal.Inventory
description: |
  An internal artifact to listen to inventory (tools) changes.

type: INTERNAL

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/reporting.hunts.details.md
======
---
title: Reporting.Hunts.Details
hidden: true
tags: [Server Artifact]
---

Report details about which client ran each hunt, how long it took
and if it has completed.


<pre><code class="language-yaml">
name: Reporting.Hunts.Details
description: |
  Report details about which client ran each hunt, how long it took
  and if it has completed.

type: SERVER

parameters:
  - name: ArtifactRegex
    type: regex
    default: .
    description: Filter hunts by this

  - name: DescriptionRegex
    type: regex
    default: .
    description: Filter hunts by this description

sources:
  - query: |
      LET hunts = SELECT hunt_id,
                         create_time,
                         hunt_description
        FROM hunts()
        WHERE artifacts =~ ArtifactRegex AND hunt_description =~ DescriptionRegex
        ORDER BY create_time DESC

      LET flows = SELECT hunt_id,
                         hunt_description,
                         client_info(client_id=ClientId).os_info.fqdn AS FQDN,
                         ClientId,
                         client_info(client_id=ClientId).os_info.system AS OS,
                         timestamp(epoch=Flow.create_time) AS create_time,
                         timestamp(epoch=Flow.start_time) AS start_time,
                         timestamp(epoch=Flow.active_time) AS active_time,
                         FlowId AS flow_id,
                         Flow.execution_duration / 1000000000 AS Duration,
                         Flow.state AS State
        FROM hunt_flows(hunt_id=hunt_id)
        ORDER BY create_time DESC

      SELECT * FROM foreach(row=hunts, query=flows)

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/server.enrichment.virustotal.md
======
---
title: Server.Enrichment.Virustotal
hidden: true
tags: [Server Artifact]
---

Submit a file hash or IP to Virustotal for details. Default Public API restriction is 4 requests/min.

This artifact can be called from within another artifact (such as one looking for files) to enrich the data made available by that artifact.

Ex.

  `SELECT * from Artifact.Server.Enrichment.Virustotal(Hash=$YOURHASH)`
  `SELECT * from Artifact.Server.Enrichment.Virustotal(IP=$YOURIP,QueryType='ip')`

`TO-DO`: Implement a timer to spread out requests


<pre><code class="language-yaml">
name: Server.Enrichment.Virustotal
author: Wes Lambert -- @therealwlambert, Whitney Champion -- @shortxstack
description: |
  Submit a file hash or IP to Virustotal for details. Default Public API restriction is 4 requests/min.

  This artifact can be called from within another artifact (such as one looking for files) to enrich the data made available by that artifact.

  Ex.

    `SELECT * from Artifact.Server.Enrichment.Virustotal(Hash=$YOURHASH)`
    `SELECT * from Artifact.Server.Enrichment.Virustotal(IP=$YOURIP,QueryType='ip')`

  `TO-DO`: Implement a timer to spread out requests

type: SERVER

parameters:
    - name: QueryType
      type: choices
      description: The type of query--hash or IP
      default: hash
      choices:
         - hash
         - ip

    - name: Hash
      type: string
      description: The file hash to submit to Hybrid Analysis (MD5, SHA1, SHA256).
      default:

    - name: IP
      type: string
      description: The IP address to submit to Hybrid Analysis.
      default:

    - name: VirustotalKey
      type: string
      description: API key for Virustotal. Leave blank here if using server metadata store.
      default:

sources:
  - query: |
        LET Creds = if(
           condition=VirustotalKey,
           then=VirustotalKey,
           else=server_metadata().VirustotalKey)

        LET URL = if(
           condition= QueryType='hash',
           then= 'https://www.virustotal.com/api/v3/files/' + Hash,
           else= 'https://www.virustotal.com/api/v3/ip_addresses/' + IP)

        LET Data = SELECT parse_json(data=Content) AS VTData
        FROM http_client(url=URL, headers=dict(`x-apikey`=Creds))

        SELECT format(format='%v/%v',
             args=[VTData.data.attributes.last_analysis_stats.malicious,
                   VTData.data.attributes.last_analysis_stats.malicious +
                   VTData.data.attributes.last_analysis_stats.undetected]) As VTRating,
            timestamp(epoch=VTData.data.attributes.first_seen_itw_date) AS FirstSeen,
            timestamp(epoch=VTData.data.attributes.first_submission_date) AS FirstSubmitted,
            timestamp(epoch=VTData.data.attributes.last_analysis_date) AS LastAnalysis,
            VTData.data.attributes.as_owner AS Owner,
            VTData.data.attributes.whois AS WhoIs,
            VTData.data.attributes.crowdsourced_yara_results AS YARAResults,
            VTData AS _Data
        FROM Data

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/linux.sys.loggrep.md
======
---
title: Linux.Sys.LogGrep
hidden: true
tags: [Client Artifact]
---

This artifact enables grep and zgrep of linux logs and gzipped log files.


<pre><code class="language-yaml">
name: Linux.Sys.LogGrep
author: "Matt Green - @mgreen27"
description: |
  This artifact enables grep and zgrep of linux logs and gzipped log files.

parameters:
  - name: TargetGlob
    default: /var/log/**
  - name: GrepRegex
    type: regex
    description: "Regex of strings to search in line."
    default: 'malware\.php'
  - name: WhitelistRegex
    type: regex
    description: "Regex of strings to leave out of output."
    default:

sources:
  - query: |
      LET files = SELECT OSPath FROM glob(globs=TargetGlob)
        WHERE NOT IsDir

      SELECT * FROM foreach(row=files,
          query={
              SELECT Line, OSPath FROM parse_lines(filename=OSPath)
              WHERE
                Line =~ GrepRegex
                AND NOT if(condition= WhitelistRegex,
                    then= Line =~ WhitelistRegex,
                    else= FALSE)
          })

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/macos.system.quarantineevents.md
======
---
title: MacOS.System.QuarantineEvents
hidden: true
tags: [Client Artifact]
---


This artifact parses the QuarantineEventsV2 database, which provides
information on when a file was downloaded from the internet.


<pre><code class="language-yaml">
name: MacOS.System.QuarantineEvents
description: |

  This artifact parses the QuarantineEventsV2 database, which provides
  information on when a file was downloaded from the internet.

type: CLIENT

author: Wes Lambert - @therealwlambert

parameters:
- name: QuarantineGlob
  default: /Users/*/Library/Preferences/com.apple.LaunchServices.QuarantineEventsV2

precondition:
      SELECT OS From info() where OS = 'darwin'

sources:
  - query: |
      LET QList = SELECT OSPath
        FROM glob(globs=QuarantineGlob)

      LET QEvents = SELECT *
        FROM sqlite(file=OSPath, query="SELECT * from LSQuarantineEvent")

      // Add delta (978307200 seconds between Cocoa timestamp
      // (2020,1,1) and epoch timestamp (1970,1,1)) to provided Cocoa
      // timestamp

      LET QEventsDetails =
          SELECT * FROM foreach(
              row=QEvents,
              query={ SELECT
                  timestamp(epoch=LSQuarantineTimeStamp + 978307200) AS DownloadTime,
                  LSQuarantineDataURLString AS DownloadURL,
                  LSQuarantineOriginURLString AS Origin,
                  LSQuarantineAgentName AS AgentName,
                  LSQuarantineAgentBundleIdentifier AS AgentBundle,
                  split(string=OSPath, sep='/')[2] AS User,
                  LSQuarantineEventIdentifier AS EventUUID
                 FROM scope()
              }
          )

      SELECT * FROM foreach(row=QList, query=QEventsDetails)

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.forensics.timeline.md
======
---
title: Windows.Forensics.Timeline
hidden: true
tags: [Client Artifact]
---

Win10 records recently used applications and files in a “timeline”
accessible via the “WIN+TAB” key. The data is recorded in a SQLite
database.

## NOTES:

This artifact is deprecated in favor of
Generic.Forensic.SQLiteHunter and will be removed in future


<pre><code class="language-yaml">
name: Windows.Forensics.Timeline
description: |
  Win10 records recently used applications and files in a “timeline”
  accessible via the “WIN+TAB” key. The data is recorded in a SQLite
  database.

  ## NOTES:

  This artifact is deprecated in favor of
  Generic.Forensic.SQLiteHunter and will be removed in future

parameters:
  - name: UserFilter
    default: ""
    description: If specified we filter by this user ID.
    type: regex

  - name: ExecutionTimeAfter
    default: ""
    type: timestamp
    description: If specified only show executions after this time.

  - name: Win10TimelineGlob
    default: C:\Users\*\AppData\Local\ConnectedDevicesPlatform\*\ActivitiesCache.db

precondition: SELECT OS From info() where OS = 'windows'

sources:
  - query: |
      LET timeline = SELECT * FROM foreach(
         row={
            SELECT OSPath
            FROM glob(globs=Win10TimelineGlob)
         },
         query={
            SELECT AppId, OSPath, LastModifiedTime
            FROM sqlite(file=OSPath, query="SELECT * FROM Activity")
         })

      LET TMP = SELECT get(
      item=parse_json_array(data=AppId).application,
               member="0") AS Application,
             parse_string_with_regex(
               string=OSPath,
               regex="\\\\L.(?P&lt;User&gt;[^\\\\]+)\\\\").User AS User,
               LastModifiedTime,
               LastModifiedTime.Unix as LastExecutionTS
        FROM timeline

      LET A1 = SELECT * FROM if(
          condition=UserFilter,
          then={
            SELECT * FROM TMP WHERE User =~ UserFilter
          }, else={ SELECT * FROM TMP})

      SELECT * FROM if(
          condition=ExecutionTimeAfter,
          then={
            SELECT * FROM A1 WHERE LastExecutionTS &gt; ExecutionTimeAfter
          }, else={ SELECT * FROM A1})

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/system.hunt.archive.md
======
---
title: System.Hunt.Archive
hidden: true
tags: [Client Event Artifact]
---

An internal artifact that receives events when a hunt is archived.

You can write a server event artifact to do something about the
hunts (like remove flows, generate zip file etc).


<pre><code class="language-yaml">
name: System.Hunt.Archive
description: |
  An internal artifact that receives events when a hunt is archived.

  You can write a server event artifact to do something about the
  hunts (like remove flows, generate zip file etc).

type: CLIENT_EVENT

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.activedirectory.bloodhound.md
======
---
title: Windows.ActiveDirectory.BloodHound
hidden: true
tags: [Client Artifact]
---

This artifact allows deployment of the BloodHound collection tool Sharphound.

BloodHound is a popular Active Directory Assessment tool that uses graph
theory to reveal the hidden and often unintended relationships. It can also be
used to identify and eliminate potentially risky domain configuration.

The Sharphound collection is in json format and upload to the server for
additional processing.

NOTE: Do not run this artifact as an unrestricted hunt. General recommendation
is to run this artifact on only a handful of machines in a typical domain,
then deduplicate output.


<pre><code class="language-yaml">
name: Windows.ActiveDirectory.BloodHound
description: |
   This artifact allows deployment of the BloodHound collection tool Sharphound.

   BloodHound is a popular Active Directory Assessment tool that uses graph
   theory to reveal the hidden and often unintended relationships. It can also be
   used to identify and eliminate potentially risky domain configuration.

   The Sharphound collection is in json format and upload to the server for
   additional processing.

   NOTE: Do not run this artifact as an unrestricted hunt. General recommendation
   is to run this artifact on only a handful of machines in a typical domain,
   then deduplicate output.


author: Matt Green - @mgreen27

reference:
  - https://github.com/BloodHoundAD/BloodHound
  - https://github.com/chryzsh/awesome-bloodhound

required_permissions:
  - EXECVE

tools:
  - name: SharpHound
    url: https://github.com/BloodHoundAD/BloodHound/raw/master/Collectors/SharpHound.exe

type: CLIENT

sources:
  - precondition:
      SELECT OS From info() where OS = 'windows'

    query: |
      -- obtain hostname for output prefix
      LET hostname &lt;= SELECT Fqdn FROM info()

      -- get context on target binary
      LET payload &lt;= SELECT * FROM Artifact.Generic.Utils.FetchBinary(
                    ToolName="SharpHound")

      -- build tempfolder for output
      LET tempfolder &lt;= tempdir()

      -- execute payload
      LET deploy = SELECT * FROM execve(argv=[payload.OSPath[0],'--outputdirectory',
                tempfolder,'--nozip','--outputprefix',hostname.Fqdn[0] ])

      -- output rows
      SELECT * FROM if(condition= deploy.ReturnCode[0]= 0,
        then={
            SELECT Name, upload(file=OSPath,name=Name)
            FROM glob(globs="/*.json", root=tempfolder)
        },
        else=deploy)

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/generic.client.rekey.md
======
---
title: Generic.Client.Rekey
hidden: true
tags: [Client Artifact]
---

This artifact forces the client to reinitialize it's client id.

It is normally not needed! You will want to use this artifact in
very specific situation, such as the Velociraptor service was
accidentally incorporated into a VM image with an existing write
back file. This will cause multiple systems to connect with the same
client id, and the server will reject clients with a HTTP 409
Rejected message.

If this happens, you can use the Server.Monitor.ClientConflict
artifact to schedule this artifact automatically.

The Wait parameter controls how long we wait before restarting the
client. Reduce this number if you need to rekey a lot of clients
quickly.


<pre><code class="language-yaml">
name: Generic.Client.Rekey
description: |
  This artifact forces the client to reinitialize it's client id.

  It is normally not needed! You will want to use this artifact in
  very specific situation, such as the Velociraptor service was
  accidentally incorporated into a VM image with an existing write
  back file. This will cause multiple systems to connect with the same
  client id, and the server will reject clients with a HTTP 409
  Rejected message.

  If this happens, you can use the Server.Monitor.ClientConflict
  artifact to schedule this artifact automatically.

  The Wait parameter controls how long we wait before restarting the
  client. Reduce this number if you need to rekey a lot of clients
  quickly.

required_permissions:
  - EXECVE

parameters:
  - name: Wait
    description: Wait this long before restarting the client.
    type: int
    default: '10'

sources:
  - query:
      SELECT rekey(wait=Wait) FROM scope()

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.system.dlls.md
======
---
title: Windows.System.DLLs
hidden: true
tags: [Client Artifact]
---

Enumerate the DLLs loaded by a running process. It includes hash value
and certificate information.


<pre><code class="language-yaml">
name: Windows.System.DLLs
description: |
  Enumerate the DLLs loaded by a running process. It includes hash value
  and certificate information.

parameters:
  - name: ProcessRegex
    description: A regex applied to process names.
    default: .
    type: regex
  - name: PidRegex
    default: .
    type: regex
  - name: ExePathRegex
    default: .
    type: regex
  - name: CommandLineRegex
    default: .
    type: regex
  - name: DllRegex
    description: A regex applied to the full dll path (e.g. whitelist all system dlls)
    default: .
    type: regex
  - name: Calculate_Hash
    default: N
    type: bool
  - name: CertificateInfo
    default: N
    type: bool
  - name: DISABLE_DANGEROUS_API_CALLS
    type: bool
    description: |
      Enable this to disable potentially flakey APIs which may cause
      crashes.

sources:
  - query: |

      -- first find processes in scope
      LET processes = SELECT Pid, Name,Exe,CommandLine
        FROM pslist()
        WHERE Name =~ ProcessRegex
            AND Pid =~ PidRegex
            AND Exe =~ ExePathRegex
            AND CommandLine =~ CommandLineRegex

      -- find modules
      LET results = SELECT * FROM foreach(
          row=processes,
          query={
            SELECT Pid, Name,Exe as _Exe,CommandLine as _CommandLine ,
                format(format='%x-%x', args=[ModuleBaseAddress,
                     ModuleBaseAddress+ModuleBaseSize]) AS Range,
                ModuleName, ExePath as ModulePath
            FROM modules(pid=Pid)
            WHERE ModulePath =~ DllRegex
          })

      -- add additional enrichment usecases
      LET cert_hash = SELECT *,
                hash(path=expand(path=ModulePath)) AS Hash,
                authenticode(filename=ModulePath) AS Certinfo
            FROM results
      LET cert_nohash = SELECT *, authenticode(filename=ModulePath) AS Certinfo
            FROM results
      LET nocert_hash = SELECT *, hash(path=expand(path=ModulePath)) AS Hash
            FROM results

      -- output rows
      SELECT * FROM if(condition= Calculate_Hash AND CertificateInfo,
                        then= cert_hash,
                        else= if(condition= Calculate_Hash,
                                    then= nocert_hash,
                                    else= if(condition= CertificateInfo,
                                        then= cert_nohash,
                                        else= results )))

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.etw.wmiprocesscreate.md
======
---
title: Windows.ETW.WMIProcessCreate
hidden: true
tags: [Client Event Artifact]
---

This artifact the endpoints for process creation through WMI
events. This is a common attacker lateral movement technique.

The technique works by calling the Create() method on the
win32_process WMI object.

You can test this with powershell:
Invoke-WmiMethod -Path win32_process -Name create -ArgumentList notepad.exe

This artifact uses the EWT provider:
Microsoft-Windows-WMI-Activity           {1418EF04-B0B4-4623-BF7E-D74AB47BBDAA}


<pre><code class="language-yaml">
name: Windows.ETW.WMIProcessCreate
description: |
  This artifact the endpoints for process creation through WMI
  events. This is a common attacker lateral movement technique.

  The technique works by calling the Create() method on the
  win32_process WMI object.

  You can test this with powershell:
  Invoke-WmiMethod -Path win32_process -Name create -ArgumentList notepad.exe

  This artifact uses the EWT provider:
  Microsoft-Windows-WMI-Activity           {1418EF04-B0B4-4623-BF7E-D74AB47BBDAA}

type: CLIENT_EVENT

sources:
  - query: |
      LET hits = SELECT
         System.ID AS ID,
         System.TimeStamp AS Timestamp,
         get(member="EventData") AS EventData
      FROM watch_etw(
        description="Microsoft-Windows-WMI-Activity",
        guid="{1418EF04-B0B4-4623-BF7E-D74AB47BBDAA}")
      WHERE ID = 23

      SELECT ID, Timestamp, EventData.ClientMachine AS Hostname,
             {
                SELECT Pid, Name, Exe from pslist(pid=int(int=EventData.ClientProcessId))
             } AS ClientProcessInfo,
             {
                SELECT Pid, Name, Exe from pslist(pid=int(int=EventData.CreatedProcessId))
             } AS CreatedProcessInfo,
             timestamp(winfiletime=int(int=EventData.ClientProcessCreationTime)) AS ClientProcessCreationTime,
             timestamp(winfiletime=int(int=EventData.CreatedProcessCreationTime)) AS CreatedProcessCreationTime,
             EventData.Commandline AS Commandline,
             EventData.User AS User
      FROM hits

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/server.utils.collectclient.md
======
---
title: Server.Utils.CollectClient
hidden: true
tags: [Server Artifact]
---

This artifact simplifies collecting from a specific client by
performing all steps automatically:

1. The collection will be scheduled.
2. The artifact will wait for the collection to complete
3. The results from the collection will be displayed.


<pre><code class="language-yaml">
name: Server.Utils.CollectClient
description: |
  This artifact simplifies collecting from a specific client by
  performing all steps automatically:

  1. The collection will be scheduled.
  2. The artifact will wait for the collection to complete
  3. The results from the collection will be displayed.

type: SERVER

parameters:
  - name: ArtifactName
    default: Generic.Client.Info
  - name: Client
    description: A client ID or a Hostname
    default: C.1234
  - name: Parameters
    default: "{}"
    description: A key/value JSON object specifying parameters for the artifact
    type: json

sources:
  - query: |
      -- Find a client to collect from by applying the search
      -- critertia and picking the first hit
      LET clients = SELECT client_id FROM clients(search=Client) LIMIT 1
      LET client_id &lt;= clients[0].client_id

      -- If we found something then schedule the collection.
      LET collection &lt;= if(condition=client_id,
          then=collect_client(client_id=client_id,
                              artifacts=ArtifactName, env=Parameters),
          else=log(message="No clients found to match search " + Client) AND FALSE)

      -- Wait for the collection to finish - if the client is
      -- currently connected this wont take long
      LET flow_results &lt;= SELECT * FROM if(condition=collection,
      then={
         SELECT * FROM watch_monitoring(artifact='System.Flow.Completion')
         WHERE FlowId = collection.flow_id
         LIMIT 1
      })

      -- Collect the results
      SELECT * FROM foreach(row=flow_results[0].Flow.artifacts_with_results,
      query={
           SELECT *, _value AS Source, client_id
           FROM source(client_id=client_id, flow_id=collection.flow_id, artifact=_value)
      })

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/linux.sys.loghunter.md
======
---
title: Linux.Sys.LogHunter
hidden: true
tags: [Client Artifact]
---

This artifact enables grep of Linux, MacOS and Windows logs.
Parameters include SearchRegex and WhitelistRegex as regex terms.
I have also included a Path exclusion regex to improve result output
and automatically skip hitting notorious locations like /proc.

NOTE: nosymlink feature of glob is set so unexpected results may occur if
targetting includes symlink files.


<pre><code class="language-yaml">
name: Linux.Sys.LogHunter
author: "Matt Green - @mgreen27"
description: |
  This artifact enables grep of Linux, MacOS and Windows logs.
  Parameters include SearchRegex and WhitelistRegex as regex terms.
  I have also included a Path exclusion regex to improve result output
  and automatically skip hitting notorious locations like /proc.

  NOTE: nosymlink feature of glob is set so unexpected results may occur if
  targetting includes symlink files.

parameters:
  - name: TargetFiles
    default: '/var/log/**'
  - name: SearchRegex
    description: "Regex of strings to search in log line."
    default: ' POST '
    type: regex
  - name: FilterRegex
    description: "Regex of strings to leave out of output."
    default:
    type: regex
  - name: ExcludeDirectoryRegex
    type: regex
    description: "Does not descend into directories that match this Regex."
    default: "^/(shared|proc|snap)"
  - name: ExcludePathRegex
    description: "Regex of paths to exclude from scanning."
    default: '\.journal$'
    type: regex

sources:
  - query: |
      LET RecursionCB &lt;= if(condition= ExcludeDirectoryRegex,
         then="x =&gt; NOT x.OSPath =~ ExcludeDirectoryRegex",
         else="x =&gt; NOT x.OSPath =~ '^/proc' ")

      LET files = SELECT OSPath
        FROM glob(globs=TargetFiles,
            nosymlink=TRUE,
            recursion_callback=RecursionCB)
        WHERE NOT IsDir AND NOT OSPath =~ ExcludePathRegex
          AND log(message="Scanning %v", args=OSPath)

      LET hits = SELECT * FROM foreach(row=files,
          query={
              SELECT OSPath, Line FROM parse_lines(filename=OSPath)
              WHERE Line =~ SearchRegex
          })

      SELECT * FROM if(condition=FilterRegex,
        then={
           SELECT * FROM hits
           WHERE NOT Line =~ FilterRegex
        },
        else={
           SELECT * FROM hits
        })

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.sys.programs.md
======
---
title: Windows.Sys.Programs
hidden: true
tags: [Client Artifact]
---

Represents products as they are installed by Windows Installer. A product generally
correlates to one installation package on Windows. Some fields may be blank as Windows
installation details are left to the discretion of the product author.

Limitations: This key parses the live registry hives - if a user is not logged in then their data will not be resident in HKU and therefore you should parse the hives on disk (including within VSS/Regback).


<pre><code class="language-yaml">
name: Windows.Sys.Programs
description: |
  Represents products as they are installed by Windows Installer. A product generally
  correlates to one installation package on Windows. Some fields may be blank as Windows
  installation details are left to the discretion of the product author.

  Limitations: This key parses the live registry hives - if a user is not logged in then their data will not be resident in HKU and therefore you should parse the hives on disk (including within VSS/Regback).

reference:
  - https://github.com/facebook/osquery/blob/master/specs/windows/programs.table

parameters:
  - name: programKeys
    default: &gt;-
      HKEY_LOCAL_MACHINE\SOFTWARE\Microsoft\Windows\CurrentVersion\Uninstall\*,
      HKEY_LOCAL_MACHINE\SOFTWARE\WOW6432Node\Microsoft\Windows\CurrentVersion\Uninstall\*,
      HKEY_USERS\*\Software\Microsoft\Windows\CurrentVersion\Uninstall\*

sources:
  - precondition:
      SELECT OS From info() where OS = 'windows'
    queries:
      - |
        SELECT Key.Name as KeyName,
               Key.Mtime AS KeyLastWriteTimestamp,
               DisplayName,
               DisplayVersion,
               InstallLocation,
               InstallSource,
               Language,
               Publisher,
               UninstallString,
               InstallDate,
               Key.OSPath as KeyPath
        FROM read_reg_key(globs=split(string=programKeys, sep=',[\\s]*'),
                          accessor="registry")

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.applications.sbecmd.md
======
---
title: Windows.Applications.SBECmd
hidden: true
tags: [Client Artifact]
---

Execute Eric Zimmerman's SBECmd and return output for analysis.

SBECmd is a CLI for analyzing shellbags data.

Objective:

- Find which folders were accessed on the local machine, the
  network, and/or removable devices. Evidence of previously
  existing folders after deletion/overwrite. When certain folders
  were accessed.

Interpretation:

- Stores information about which folders were most recently
  browsed by the user.

NOTE: Velociraptor can now parse Shellbags natively with the
Windows.Forensics.Shellbags artifact.

MITRE ATT&CK ID: TA0009 - Collection


<pre><code class="language-yaml">
name: Windows.Applications.SBECmd
description: |
    Execute Eric Zimmerman's SBECmd and return output for analysis.

    SBECmd is a CLI for analyzing shellbags data.

    Objective:

    - Find which folders were accessed on the local machine, the
      network, and/or removable devices. Evidence of previously
      existing folders after deletion/overwrite. When certain folders
      were accessed.

    Interpretation:

    - Stores information about which folders were most recently
      browsed by the user.

    NOTE: Velociraptor can now parse Shellbags natively with the
    Windows.Forensics.Shellbags artifact.

    MITRE ATT&amp;CK ID: TA0009 - Collection

author: Eduardo Mattos - @eduardfir

reference:
  - https://github.com/EricZimmerman

type: CLIENT

tools:
  - name: SBECmd
    url: https://github.com/Velocidex/Tools/raw/main/SBECmd/ShellBagsExplorer/SBECmd.exe

precondition: SELECT OS From info() where OS = 'windows'

parameters:
  - name: userRegex
    default: .
    type: regex

  - name: UploadFiles
    description: "Select to Upload SBECmd Output files."
    type: bool

  - name: RemovePayload
    description: "Select to Remove Payload after execution."
    type: bool


sources:
  - query: |
      -- get context on target binary
      LET payload &lt;= SELECT * FROM Artifact.Generic.Utils.FetchBinary(
                    ToolName="SBECmd", IsExecutable=TRUE)

      -- build tempfolder for output
      LET tempfolder &lt;= tempdir(remove_last=TRUE)

      -- get users with profiles
      LET UserProfiles = SELECT
         Uid, Name,
         expand(path=Directory) AS HomeDirectory, UUID, Mtime
      FROM Artifact.Windows.Sys.Users()
      WHERE Name =~ userRegex and HomeDirectory =~ "Users"

      -- execute payload
      LET deploy &lt;= SELECT * FROM foreach(row=UserProfiles,
                    query={
                        SELECT *, Name
                        FROM execve(argv=[
                            payload.OSPath[0],
                            "-d", HomeDirectory,
                            "--csv", tempfolder + "\\" + Name,
                            "--dedupe"])
                    })

      -- parse csvs
      SELECT * FROM foreach(row=deploy,
      query={
        SELECT *, Name as UserName
        FROM parse_csv(filename=tempfolder + "\\" + Name + "\\Deduplicated.csv")
      })

  - name: Uploads
    query: |
      SELECT * FROM chain(
      a={
         SELECT * FROM if(
           condition=UploadFiles,
           then={
             SELECT Name, upload(file=OSPath,
                                 name=relpath(base=tempfile, path=OSPath)) as FileDetails
             FROM glob(globs="/**", root=tempfolder)
           })
      },
      b={
         SELECT * FROM if(
           condition=RemovePayload,
           then={
             SELECT * FROM execve(argv=['powershell','Remove-Item',
                                             payload.OSPath[0],'-Force' ])
           })
      })
      WHERE Stdout =~ "SBECmd"

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/system.flow.archive.md
======
---
title: System.Flow.Archive
hidden: true
tags: [Client Event Artifact]
---

An internal artifact that produces events for every flow completion
in the system.


<pre><code class="language-yaml">
name: System.Flow.Archive
description: |
  An internal artifact that produces events for every flow completion
  in the system.

type: CLIENT_EVENT

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/custom.linux.sudousers.md
======
---
title: Custom.Linux.SudoUsers
hidden: true
tags: [Client Artifact]
---

Detects users added in the `sudo` group.


```yaml
name: Custom.Linux.SudoUsers

description: |
  Detects users added in the `sudo` group.

author: George-Andrei Iosif (@iosifache)

type: CLIENT

sources:
  - precondition: |
      SELECT OS
      FROM info()
      WHERE OS = 'linux'

    query: |
      SELECT *
      FROM foreach(
        row={
          SELECT *
          FROM Artifact.Linux.Sys.Users()
        },
        query={
          SELECT Fqdn AS Host,
                 User,
                 Description,
                 Uid,
                 Gid,
                 Homedir,
                 Shell
          FROM execve(argv=["id", "-Gn", User])
          WHERE ReturnCode = 0 AND Stdout =~ "root"
        }
      )

```

---END OF FILE---

======
FILE: /content/artifact_references/pages/server.internal.interrogation.md
======
---
title: Server.Internal.Interrogation
hidden: true
tags: [Internal Artifact]
---

This event artifact is an internal event stream over which client
interrogations are sent. When the interrogation service finishes
updating a client record, it will send an event on this artifact.

Note: This is an automated system artifact. You do not need to start it.


<pre><code class="language-yaml">
name: Server.Internal.Interrogation
description: |
  This event artifact is an internal event stream over which client
  interrogations are sent. When the interrogation service finishes
  updating a client record, it will send an event on this artifact.

  Note: This is an automated system artifact. You do not need to start it.

type: INTERNAL

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/linux.ssh.knownhosts.md
======
---
title: Linux.Ssh.KnownHosts
hidden: true
tags: [Client Artifact]
---

Find and parse ssh known hosts files.

<pre><code class="language-yaml">
name: Linux.Ssh.KnownHosts
description: Find and parse ssh known hosts files.
parameters:
  - name: sshKnownHostsFiles
    default: '.ssh/known_hosts*'

precondition: SELECT OS From info() where OS = 'linux'

sources:
  - query: |
        // For each user on the system, search for known_hosts files.
        LET authorized_keys = SELECT * from foreach(
          row={
             SELECT Uid, User, Homedir from Artifact.Linux.Sys.Users()
          },
          query={
             SELECT OSPath, Mtime, Ctime, User, Uid
             FROM glob(
               globs=sshKnownHostsFiles,
               root=Homedir)
          })

        // For each known_hosts file, extract each line on a different row.
        SELECT * from foreach(
          row=authorized_keys,
          query={
            SELECT Uid, User, OSPath, Hostname, Type, PublicKey
            FROM split_records(
               filenames=OSPath, regex=" ", record_regex="\n",
               columns=["Hostname", "Type", "PublicKey"])
            /* Ignore comment lines. */
            WHERE not Hostname =~ "^[^#]+#"
          })

  - name: HostPublicKeys
    query: |
      LET Me &lt;= SELECT * FROM info()

      SELECT * FROM foreach(row={
        SELECT OSPath
        FROM glob(globs="/etc/ssh/ssh_host*.pub")
      }, query={
        SELECT *, Me[0].Fqdn AS Fqdn
        FROM split_records(columns=["Type", "PublicKey", "KeyName"],
                   filenames=OSPath,
                   regex=" +")
      })

    notebook:
      - type: vql_suggestion
        name: "Resolve Known Hosts"
        template: |
          /*
          # Resolve Hostnames

          This query resolves the public keys in the known hosts file
          with the collected public keys from all hosts.

          This works best when this cell applies to a hunt collection
          from a wide number of hosts. It helps to resolve the
          hostnames from known hosts to real host names (these are
          usually hashed within the file).

          This artifact helps to establish historical SSH access from
          one machine to another machine.
          */

          LET lookup &lt;= memoize(
             key="PublicKey",
             query={
               SELECT *
               FROM source(artifact="Linux.Ssh.KnownHosts/HostPublicKeys")
          })

          SELECT *, get(item=lookup, field=PublicKey) AS Hostname
          FROM source(artifact="Linux.Ssh.KnownHosts")

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/server.internal.tooldependencies.md
======
---
title: Server.Internal.ToolDependencies
hidden: true
tags: [Client Artifact]
---

An internal artifact that defines some tool
dependencies. Velociraptor releases for offline collector

NOTE: Do not modify - this artifact is generated during build in magefile.go


<pre><code class="language-yaml">
name: Server.Internal.ToolDependencies
description: |
  An internal artifact that defines some tool
  dependencies. Velociraptor releases for offline collector

  NOTE: Do not modify - this artifact is generated during build in magefile.go

tools:
  - name: VelociraptorWindows
    url: https://github.com/Velocidex/velociraptor/releases/download/v0.74/velociraptor-v0.74.0-rc1-windows-amd64.exe
    serve_locally: true
    version: 0.74.0-rc1

  - name: VelociraptorWindows_x86
    url: https://github.com/Velocidex/velociraptor/releases/download/v0.74/velociraptor-v0.74.0-rc1-windows-386.exe
    serve_locally: true
    version: 0.74.0-rc1

  - name: VelociraptorLinux
    url: https://github.com/Velocidex/velociraptor/releases/download/v0.74/velociraptor-v0.74.0-rc1-linux-amd64-musl
    serve_locally: true
    version: 0.74.0-rc1

  # On MacOS we can not embed the config in the binary so we use a
  # shell script stub instead. See
  # https://github.com/Velocidex/velociraptor/issues/2898

  # A Generic collector to be used with the --embedded_config flag.
  - name: VelociraptorCollector
    url: https://github.com/Velocidex/velociraptor/releases/download/v0.74/velociraptor-collector
    serve_locally: true

  - name: VelociraptorWindowsMSI
    url: https://github.com/Velocidex/velociraptor/releases/download/v0.74/velociraptor-v0.74.0-rc1-windows-amd64.msi
    serve_locally: true
    version: 0.74.0-rc1

  - name: VelociraptorWindows_x86MSI
    url: https://github.com/Velocidex/velociraptor/releases/download/v0.74/velociraptor-v0.74.0-rc1-windows-386.msi
    serve_locally: true
    version: 0.74.0-rc1

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/linux.search.filefinder.md
======
---
title: Linux.Search.FileFinder
hidden: true
tags: [Client Artifact]
---

Find files on the filesystem using the filename or content.


## Performance Note

This artifact can be quite expensive, especially if we search file
content. It will require opening each file and reading its entire
content. To minimize the impact on the endpoint we recommend this
artifact is collected with a rate limited way (about 20-50 ops per
second).

This artifact is useful in the following scenarios:

  * We need to locate all the places on our network where customer
    data has been copied.

  * We’ve identified malware in a data breach, named using short
    random strings in specific folders and need to search for other
    instances across the network.

  * We believe our user account credentials have been dumped and
    need to locate them.

  * We need to search for exposed credit card data to satisfy PCI
    requirements.

  * We have a sample of data that has been disclosed and need to
    locate other similar files


<pre><code class="language-yaml">
name: Linux.Search.FileFinder
description: |
  Find files on the filesystem using the filename or content.


  ## Performance Note

  This artifact can be quite expensive, especially if we search file
  content. It will require opening each file and reading its entire
  content. To minimize the impact on the endpoint we recommend this
  artifact is collected with a rate limited way (about 20-50 ops per
  second).

  This artifact is useful in the following scenarios:

    * We need to locate all the places on our network where customer
      data has been copied.

    * We’ve identified malware in a data breach, named using short
      random strings in specific folders and need to search for other
      instances across the network.

    * We believe our user account credentials have been dumped and
      need to locate them.

    * We need to search for exposed credit card data to satisfy PCI
      requirements.

    * We have a sample of data that has been disclosed and need to
      locate other similar files


precondition:
  SELECT * FROM info() where OS = 'linux'

parameters:
  - name: SearchFilesGlob
    default: /home/*
    description: Use a glob to define the files that will be searched.

  - name: SearchFilesGlobTable
    type: csv
    default: |
      Glob
      /home/someuser/*
    description: Alternative specify multiple globs in a table

  - name: YaraRule
    type: yara
    default:
    description: A yara rule to search for matching files.

  - name: Upload_File
    default: N
    type: bool

  - name: Calculate_Hash
    default: N
    type: bool

  - name: MoreRecentThan
    default: ""
    type: timestamp

  - name: ModifiedBefore
    default: ""
    type: timestamp

  - name: ExcludePathRegex
    default: "^/(proc|sys|run|snap)"
    type: regex
    description: If this regex matches the path of any directory we do not even descend inside of it.

  - name: LocalFilesystemOnly
    default: Y
    type: bool
    description: When set we stay on local attached filesystems including loop, attached disk, cdrom, device mapper, and excluding proc, nfs etc.

  - name: OneFilesystem
    default: N
    type: bool
    description: When set we do not follow a link to go on to a different filesystem.

  - name: DoNotFollowSymlinks
    type: bool
    default: N
    description: If specified we are allowed to follow symlinks while globbing

sources:
- query: |
    -- This list comes from cat /proc/devices and represents actual
    -- devices. Most virtual devices like /proc, fuse and network
    -- filesystems have a major number of 0.
    LET LocalDeviceMajor &lt;= (
       253,
       7,   -- loop
       8,   -- sd
       9,   -- md
       11,  -- sr
       65,  -- sd
       66,  -- sd
       67,  -- sd
       68,  -- sd
       69,  -- sd
       70,  -- sd
       71,  -- sd
       128, -- sd
       129, -- sd
       130, -- sd
       131, -- sd
       132, -- sd
       133, -- sd
       134, -- sd
       135, -- sd
       202, -- xvd
       253, -- device-mapper
       254, -- mdp
       259, -- blkext
    )

    LET RecursionCallback = if(
       condition=LocalFilesystemOnly,
         then=if(condition=ExcludePathRegex,
                 then="x=&gt;x.Data.DevMajor IN LocalDeviceMajor AND NOT x.OSPath =~ ExcludePathRegex",
                 else="x=&gt;x.Data.DevMajor IN LocalDeviceMajor"),
         else=if(condition=ExcludePathRegex,
                 then="x=&gt;NOT x.OSPath =~ ExcludePathRegex",
                 else=""))

    LET file_search = SELECT OSPath,
               Sys.mft as Inode,
               Mode.String AS Mode, Size,
               Mtime AS MTime,
               Atime AS ATime,
               Ctime AS CTime,
               IsDir, Mode, Data
        FROM glob(globs=SearchFilesGlobTable.Glob + SearchFilesGlob,
                  recursion_callback=RecursionCallback,
                  one_filesystem=OneFilesystem,
                  accessor="file", nosymlink=DoNotFollowSymlinks)

    LET more_recent = SELECT * FROM if(
        condition=MoreRecentThan,
        then={
          SELECT * FROM file_search
          WHERE MTime &gt; MoreRecentThan
        }, else={
          SELECT * FROM file_search
        })

    LET modified_before = SELECT * FROM if(
        condition=ModifiedBefore,
        then={
          SELECT * FROM more_recent
          WHERE MTime &lt; ModifiedBefore
            AND MTime &gt; MoreRecentThan
        }, else={
          SELECT * FROM more_recent
        })

    LET keyword_search = SELECT * FROM if(
        condition=YaraRule,
        then={
          SELECT * FROM foreach(
            row={
               SELECT * FROM modified_before
               WHERE Mode.IsRegular
            },
            query={
               SELECT OSPath, Inode, Mode,
                      Size, ATime, MTime, CTime,
                      str(str=String.Data) As Keywords

               FROM yara(files=OSPath,
                         key="A",
                         rules=YaraRule,
                         accessor="file")
            })
        }, else={
          SELECT *, NULL AS Keywords FROM modified_before
        })

    SELECT OSPath, Inode, Mode, Size, ATime,
             MTime, CTime, Keywords,
               if(condition=Upload_File and Mode.IsRegular,
                  then=upload(file=OSPath,
                              accessor="file")) AS Upload,
               if(condition=Calculate_Hash and Mode.IsRegular,
                  then=hash(path=OSPath,
                            accessor="file")) AS Hash
    FROM keyword_search

column_types:
  - name: ATime
    type: timestamp
  - name: MTime
    type: timestamp
  - name: CTime
    type: timestamp
  - name: Upload
    type: preview_upload

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.detection.forwardedimports.md
======
---
title: Windows.Detection.ForwardedImports
hidden: true
tags: [Client Artifact]
---

In Windows a common DLL hooking technique is to replace a dll with a
forwarder dll - i.e. one that forwards all imports to the real
dll. If the forwarder DLL is placed earlier in the import order, the
malicous DLL will be seamlessly loaded and injected into another
process.

This artifact searches for dlls which are named the same as the DLL
they are forwarding to.


<pre><code class="language-yaml">
name: Windows.Detection.ForwardedImports
description: |
  In Windows a common DLL hooking technique is to replace a dll with a
  forwarder dll - i.e. one that forwards all imports to the real
  dll. If the forwarder DLL is placed earlier in the import order, the
  malicous DLL will be seamlessly loaded and injected into another
  process.

  This artifact searches for dlls which are named the same as the DLL
  they are forwarding to.

reference:
  - https://github.com/monoxgas/Koppeling
  - https://silentbreaksecurity.com/adaptive-dll-hijacking/
  - https://www.mdsec.co.uk/2020/10/i-live-to-move-it-windows-lateral-movement-part-3-dll-hijacking/

parameters:
  - name: DLLGlob
    default: C:\windows\**\*.dll
  - name: ExcludeRegex
    default: WinSXS|Servicing
    type: regex
  - name: LogPeriod
    type: int
    description: How often to log progress in seconds (Default every 1 sec)
    default: 1

sources:
  - query: |
      LET DLLs = SELECT OSPath, Name,

             -- Remove the .dll extension if present to get the bare dll filename.
             lowcase(string=parse_string_with_regex(
                  regex="^(?P&lt;BareName&gt;[^.]+)", string=Name).BareName) AS DLLBareName,
             count() AS Total
        FROM glob(globs=DLLGlob)
        WHERE NOT OSPath =~ ExcludeRegex

      LET ParsedDLLs = SELECT *,
         log(message="Examining %v after checking %v DLLs",
                     args=[OSPath, Total], dedup= LogPeriod ) AS Log
      FROM foreach(
          row=DLLs, workers=20,
          query={
              SELECT OSPath, Name,
                     parse_pe(file=OSPath).Forwards AS Forwards,
                     DLLBareName, Total
              FROM scope()
          })

      -- Speed up analysis a bit by using more workers.
      SELECT * FROM foreach(row=ParsedDLLs,
        query={
           SELECT OSPath AS DllPath, ForwardedImport,

                  -- The Bare DLL Name from the forwarded name
                  Parse.DllPath AS DllImportPath,

                  -- The export this is forwarding to.
                  Parse.Export AS DLLExportFunc,
                  DLLBareName,

                  -- The bare dll name the export is referring to.
                  basename(path=lowcase(string=Parse.DllPath)) AS ExportDLLName
           FROM foreach(row=Forwards,
             query={
                 SELECT parse_string_with_regex(
                               regex="(?P&lt;DllPath&gt;.+)\\.(?P&lt;Export&gt;[^.]+$)",
                               string=_value) AS Parse,
                        _value AS ForwardedImport
                 FROM scope()
             })

          -- Only flag imports for forwarder dll name the same as its own dll.
          WHERE ExportDLLName = DLLBareName
      })

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.forensics.bam.md
======
---
title: Windows.Forensics.Bam
hidden: true
tags: [Client Artifact]
---

The Background Activity Moderator (BAM) is a Windows service that
Controls activity of background applications.  This service exists
in Windows 10 only after Fall Creators update – version 1709.

It provides full path of the executable file that was run on the
system and last execution date/time


<pre><code class="language-yaml">
name: Windows.Forensics.Bam
description: |
  The Background Activity Moderator (BAM) is a Windows service that
  Controls activity of background applications.  This service exists
  in Windows 10 only after Fall Creators update – version 1709.

  It provides full path of the executable file that was run on the
  system and last execution date/time

reference:
  - https://andreafortuna.org/2018/05/23/forensic-artifacts-evidences-of-program-execution-on-windows-systems/

parameters:
  - name: bamKeys
    type: csv
    default: |
      KeyGlob
      HKEY_LOCAL_MACHINE\SYSTEM\CurrentControlSet\Services\bam\UserSettings\*\*
      HKEY_LOCAL_MACHINE\SYSTEM\CurrentControlSet\Services\bam\State\UserSettings\*\*
  - name: userRegex
    default: .
    type: regex

sources:
  - precondition:
      SELECT OS from info() where OS = "windows"
    query: |
        LET users &lt;= SELECT Name, UUID
            FROM Artifact.Windows.Sys.Users()
            WHERE Name =~ userRegex

        SELECT OSPath.Components[-2] as SID, {
            SELECT Name FROM users
            WHERE UUID = OSPath.Components[-2]
          } As UserName,
          Name as Binary,
          timestamp(winfiletime=parse_binary(
               filename=Data.value, accessor="data",
               profile="[]", struct="int64")) AS Bam_time
        FROM glob(globs=bamKeys.KeyGlob, accessor="registry")
        WHERE Data.type =~ "BINARY"

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.memory.processdump.md
======
---
title: Windows.Memory.ProcessDump
hidden: true
tags: [Client Artifact]
---

Dump process memory and upload to the server.

Previously named Windows.Triage.ProcessMemory


<pre><code class="language-yaml">
name: Windows.Memory.ProcessDump
description: |
  Dump process memory and upload to the server.

  Previously named Windows.Triage.ProcessMemory

precondition: SELECT OS From info() where OS = 'windows'

parameters:
  - name: ProcessRegex
    default: notepad
    type: regex
  - name: PidRegex
    default: .
    type: regex
  - name: VelociraptorCompatible
    type: bool
    description: |
      If specified we upload a Velociraptor Compatible sparse file
      upload instead of a crash dump. This makes it easier to run
      postprocessing using Velociraptor

sources:
  - query: |
        LET processes = SELECT Name as ProcessName, CommandLine, Pid
            FROM pslist()
            WHERE Name =~ ProcessRegex
              AND str(str=Pid) =~ PidRegex

        LET Regions(Pid) = SELECT dict(Offset=Address, Length=Size) AS Sparse
          FROM vad(pid=Pid)
          WHERE Protection =~ "r"

        LET UploadDump(Pid, ProcessName, CommandLine) =
          SELECT * FROM if(condition= VelociraptorCompatible,
          then={
             SELECT ProcessName, CommandLine, Pid,
                    upload(accessor="sparse",
                           file=pathspec(
                              Path=serialize(item=Regions(Pid=Pid).Sparse),
                              DelegateAccessor="process",
                              DelegatePath=format(format="/%d", args=Pid)),
                              name=pathspec(Path=format(format="%d.dd", args=Pid))) AS ProcessMemory
             FROM scope()
          }, else={
            SELECT ProcessName, CommandLine, Pid, OSPath,
                   upload(file=OSPath) as CrashDump
            FROM proc_dump(pid=Pid)
          })

        SELECT * FROM foreach(
          row=processes,
          query={
             SELECT * FROM UploadDump(Pid=Pid, ProcessName = ProcessName, CommandLine = CommandLine)
          })

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/linux.events.httpconnections.md
======
---
title: Linux.Events.HTTPConnections
hidden: true
tags: [Client Event Artifact]
---

This artifact uses eBPF to track HTTP and parse connections from
various processes.

NOTE: This event is generated from network traffic - it is unable to
view TLS encrypted data.

If the process tracker is enabled we also show more information
about the process.


<pre><code class="language-yaml">
name: Linux.Events.HTTPConnections
description: |
  This artifact uses eBPF to track HTTP and parse connections from
  various processes.

  NOTE: This event is generated from network traffic - it is unable to
  view TLS encrypted data.

  If the process tracker is enabled we also show more information
  about the process.

type: CLIENT_EVENT

precondition: |
  SELECT OS From info() where OS = 'linux'

parameters:
  - name: HostFilter
    description: Filter Events by Host header
    type: regex
    default: .
  - name: URLFilter
    description: Filter Events by URL
    type: regex
    default: .
  - name: ProcessNameFilter
    description: Filter Events by Process Name
    type: regex
    default: .
  - name: IncludeHeaders
    type: bool
    description: If set we include more details like HTTP Headers
  - name: IncludeProcessInfo
    type: bool
    description: If set we include more process information.

sources:
  - query: |
      SELECT System.Timestamp AS Timestamp,
             System.ProcessName AS ProcessName,
             System.ProcessID AS Pid,
             if(condition=IncludeProcessInfo,
                then=process_tracker_get(id=System.ProcessID).Data) AS ProcessInfo,
             EventData.metadata.src_ip AS src_ip,
             EventData.metadata.src_port AS src_port,
             EventData.metadata.dst_ip AS dest_ip,
             EventData.metadata.dst_port AS dest_port,
             EventData.http_request.host AS host,
             EventData.http_request.uri_path AS uri_path,
             if(condition=IncludeHeaders,
                then=EventData.http_request) AS _HTTPRequest
      FROM watch_ebpf(events="net_packet_http_request")
      WHERE host =~ HostFilter
        AND uri_path =~ URLFilter
        AND ProcessName =~ ProcessNameFilter

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/server.utils.cancelhunt.md
======
---
title: Server.Utils.CancelHunt
hidden: true
tags: [Server Artifact]
---

Sometimes a hunt is issued which is no longer useful. While stopping
the hunt from the GUI prevents new clients from receiving the hunt,
it does not actively cancel collections currently in flight.

This artifact enumerates all flows in the hunt and actively cancels
them.


<pre><code class="language-yaml">
name: Server.Utils.CancelHunt
description: |
  Sometimes a hunt is issued which is no longer useful. While stopping
  the hunt from the GUI prevents new clients from receiving the hunt,
  it does not actively cancel collections currently in flight.

  This artifact enumerates all flows in the hunt and actively cancels
  them.

type: SERVER

parameters:
  - name: HuntId

sources:
  - query: |
      LET all_flows = SELECT Flow.client_id AS client_id, Flow.session_id AS flow_id
      FROM hunt_flows(hunt_id=HuntId)
      WHERE Flow.state = "RUNNING"

      LET cancellations = SELECT client_id, flow_id,
             cancel_flow(client_id=client_id, flow_id=flow_id) AS Cancellation
      FROM all_flows

      SELECT * FROM if(condition=HuntId, then=cancellations,
      else={
         SELECT * FROM scope()
         WHERE log(message="Hunt ID must be specified.") AND NULL
      })

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/linux.mounts.md
======
---
title: Linux.Mounts
hidden: true
tags: [Client Artifact]
---

List mounted filesystems by reading /proc/mounts

<pre><code class="language-yaml">
name: Linux.Mounts
description: List mounted filesystems by reading /proc/mounts

parameters:
  - name: ProcMounts
    default: /proc/mounts

precondition: |
   SELECT OS From info() where OS = 'linux'

sources:
  - query: |
      SELECT Device, Mount, FSType, split(string=Opts, sep=",") As Options
      FROM parse_records_with_regex(
         file=ProcMounts,
         regex='(?m)^(?P&lt;Device&gt;[^ ]+) (?P&lt;Mount&gt;[^ ]+) (?P&lt;FSType&gt;[^ ]+) '+
             '(?P&lt;Opts&gt;[^ ]+)')


reports:
  - type: CLIENT
    template: |
      # Mounted filesystems

      {{ Query "SELECT * FROM source()" | Table }}

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.applications.outlook.pst.md
======
---
title: Windows.Applications.Outlook.PST
hidden: true
tags: [Client Artifact]
---

This artifact fetch emails and attachments from outlook PST file.
This artifact parse for outlook pst files and display the details and save 
all attachments to user specified directory.


<pre><code class="language-yaml">
name: Windows.Applications.Outlook.PST
author: "Sikha Puthanveedu @SikhaMohan"
description: |
  This artifact fetch emails and attachments from outlook PST file.
  This artifact parse for outlook pst files and display the details and save 
  all attachments to user specified directory.
parameters:
  - name: outlookPSTfile
    type: .pst
    description: Full path to the outlook .pst file (For example - D:/MyPST/MyOutlookDataFile.pst)
  - name: AttachmentFolder
    type: directory path
    description: If selected it will save all the attachments from emails to the specified directory.

sources:
  - precondition:
      SELECT OS FROM info() WHERE OS = 'windows'
    query: |
        
            LET PSTInfo = SELECT Sender as Sender,
                 Receiver as Receiver,
                 Subject as Subject,
                 Message as Message,
                 DateandTime as DeliveryTime,
                 Attachments as AttachmentNames,
                 Body as Body
            from parse_pst(filename=outlookPSTfile, FolderPath=AttachmentFolder)
          
            SELECT  
               Sender,
               Receiver,
               Subject,
               DeliveryTime,
               AttachmentNames,
               Message 
            FROM PSTInfo
</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/generic.forensic.carving.urls.md
======
---
title: Generic.Forensic.Carving.URLs
hidden: true
tags: [Client Artifact]
---

Carve URLs from files located in a glob. Note that we do not parse
any files - we simply carve anything that looks like a URL.


<pre><code class="language-yaml">
name: Generic.Forensic.Carving.URLs
description: |
  Carve URLs from files located in a glob. Note that we do not parse
  any files - we simply carve anything that looks like a URL.


parameters:
  - name: UrlGlob
    default: |
      ["C:/Documents and Settings/*/Local Settings/Application Data/Google/Chrome/User Data/**",
       "C:/Users/*/AppData/Local/Google/Chrome/User Data/**",
       "C:/Documents and Settings/*/Local Settings/History/**",
       "C:/Documents and Settings/*/Local Settings/Temporary Internet Files/**",
       "C:/Users/*/AppData/Local/Microsoft/Windows/WebCache/**",
       "C:/Users/*/AppData/Local/Microsoft/Windows/INetCache/**",
       "C:/Users/*/AppData/Local/Microsoft/Windows/INetCookies/**",
       "C:/Users/*/AppData/Roaming/Mozilla/Firefox/Profiles/**",
       "C:/Documents and Settings/*/Application Data/Mozilla/Firefox/Profiles/**"
       ]

sources:
  - query: |
        LET matching = SELECT OSPath FROM glob(
            globs=parse_json_array(data=UrlGlob))

        SELECT OSPath, URL FROM foreach(
          row=matching,
          query={
            SELECT OSPath,
                   URL FROM parse_records_with_regex(file=OSPath,
               regex="(?P&lt;URL&gt;https?:\\/\\/[\\w\\.-]+[\\/\\w \\.-]*)")
          })

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/server.utils.backups3.md
======
---
title: Server.Utils.BackupS3
hidden: true
tags: [Server Event Artifact]
---

This server monitoring artifact will automatically zip and backup
any collected artifacts to s3.

You will need to provide credentials to upload to the bucket. The
credentials can be given as parameters or they will be taken from
the server metadata (as DefaultBucket, DefaultRegion,
S3AccessKeyId, S3AccessSecret, S3AccessToken)

Thanks to @shortxstack and @Recon_InfoSec


<pre><code class="language-yaml">
name: Server.Utils.BackupS3
description: |
   This server monitoring artifact will automatically zip and backup
   any collected artifacts to s3.

   You will need to provide credentials to upload to the bucket. The
   credentials can be given as parameters or they will be taken from
   the server metadata (as DefaultBucket, DefaultRegion,
   S3AccessKeyId, S3AccessSecret, S3AccessToken)

   Thanks to @shortxstack and @Recon_InfoSec

type: SERVER_EVENT

parameters:
   - name: ArtifactNameRegex
     default: "."
     description: A regular expression to select which artifacts to upload
     type: regex
     
   - name: Bucket
     description: The bucket to upload to (blank to use server metadata)

   - name: Endpoint
     
   - name: Region
   
   - name: CredentialsKey
   
   - name: CredentialsSecret
   
   - name: CredentialsToken
   
   - name: Secret
     description: A Secret name to use for uploading.
     
   - name: RemoveDownloads
     type: bool
     description: If set, remove the flow export files after upload

sources:
  - query: |
      -- Allow these settings to be set by the artifact parameter or
      -- the server metadata.
      LET completions = SELECT *,
         client_info(client_id=ClientId).os_info.fqdn AS Fqdn,
         create_flow_download(client_id=ClientId,
             flow_id=FlowId, wait=TRUE) AS FlowDownload
      FROM watch_monitoring(artifact="System.Flow.Completion")
      WHERE Flow.artifacts_with_results =~ ArtifactNameRegex

      SELECT upload_s3(
         bucket=Bucket,
         credentials_key=CredentialsKey,
         credentials_secret=CredentialsSecret,
         endpoint=Endpoint,
         credentials_token=CredentialsToken,
         secret=Secret,
         region=Region,
         file=FlowDownload,
         accessor="fs",
         name=format(format="Host %v %v %v.zip",
                     args=[Fqdn, FlowId, timestamp(epoch=now())])) AS Upload
      FROM completions
      WHERE Upload OR
        if(condition=RemoveDownloads,
           then=rm(filename=file_store(path=FlowDownload)))

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.analysis.evidenceofdownload.md
======
---
title: Windows.Analysis.EvidenceOfDownload
hidden: true
tags: [Client Artifact]
---

Simple artifact to find evidence of user download activity.

Based on the Zone.Identifier alternate data stream that is created
alongside with the file downloaded from the internet or
intranet. Zone.Identifier is generated by applications when user
saves files to the local file system from differnet security zone.

This artifact searches the directory provided for any file with
alternate data stream named Zone.Identifier and then lists all
files with zoneId = 3 or 4 and calculate the hash value of the file
and prints the content of Zone.Identifier alternate stream as it
could contain useful info in some cases.


<pre><code class="language-yaml">
name: Windows.Analysis.EvidenceOfDownload
description: |
   Simple artifact to find evidence of user download activity.

   Based on the Zone.Identifier alternate data stream that is created
   alongside with the file downloaded from the internet or
   intranet. Zone.Identifier is generated by applications when user
   saves files to the local file system from differnet security zone.

   This artifact searches the directory provided for any file with
   alternate data stream named Zone.Identifier and then lists all
   files with zoneId = 3 or 4 and calculate the hash value of the file
   and prints the content of Zone.Identifier alternate stream as it
   could contain useful info in some cases.


reference:
  - https://cyberforensicator.com/2018/06/26/where-did-it-come-from-forensic-analysis-of-zone-identifier/
  - https://www.sans.org/security-resources/posters/windows-forensic-analysis/170/download
  - https://www.csee.umbc.edu/courses/undergraduate/FYS102D/Recycle.Bin.Forensics.for.Windows7.and.Windows.Vista.pdf

author: M.Soheem @msoheem | Antonio Blescia (TheThMando)

type: CLIENT

parameters:
 - name: DirectoryPathGlob
   type: csv
   default: |
    Path
    C:/Users/*/Downloads/**/*
    C:/$Recycle.Bin/*/**/$R*

 - name: ZoneIdRegex
   description: A Regular expression to match the required zone (default Internet and Restricted Zones).
   default: "ZoneId=[34]"

sources:
 - precondition:
      SELECT OS From info() where OS = 'windows'

   query: |
      LET glob_patterns = SELECT Path + ':Zone.Identifier' AS Glob FROM DirectoryPathGlob
      LET X = SELECT
         split(string=OSPath, sep=":Zone.Identifier")[0] AS DownloadedFilePath,
         Mtime,
         read_file(filename=OSPath, accessor="ntfs") AS _ZoneIdentifierContent
      FROM glob(globs=glob_patterns.Glob, accessor="ntfs")
      WHERE NOT IsDir

      SELECT *,
        if(condition=DownloadedFilePath, then=hash(path=DownloadedFilePath)) AS FileHash,
        parse_string_with_regex(regex="ZoneId=([^\\r\\n]+)", string=_ZoneIdentifierContent).g1 AS ZoneId,
        parse_string_with_regex(regex="HostUrl=([^\\r\\n]+)", string=_ZoneIdentifierContent).g1 AS HostUrl,
        parse_string_with_regex(regex="ReferrerUrl=([^\\r\\n]+)", string=_ZoneIdentifierContent).g1 AS ReferrerUrl
      FROM X

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.sysinternals.sysmoninstall.md
======
---
title: Windows.Sysinternals.SysmonInstall
hidden: true
tags: [Client Artifact]
---

Sysmon is a kernel level system monitor written by
Sysinternals. While we are not able to distribute Sysmon ourselves,
Velociraptor can help you manage its deployment and installation.

NOTE: By default we install the sysmon config from SwiftOnSecurity -
we recommend you review the config file and override it in the GUI
with one that better suits your needs.


<pre><code class="language-yaml">
name: Windows.Sysinternals.SysmonInstall
description: |
  Sysmon is a kernel level system monitor written by
  Sysinternals. While we are not able to distribute Sysmon ourselves,
  Velociraptor can help you manage its deployment and installation.

  NOTE: By default we install the sysmon config from SwiftOnSecurity -
  we recommend you review the config file and override it in the GUI
  with one that better suits your needs.

tools:
  - name: SysmonBinary
    url: https://live.sysinternals.com/tools/sysmon64.exe
    serve_locally: true

  - name: SysmonConfig
    url: https://raw.githubusercontent.com/SwiftOnSecurity/sysmon-config/master/sysmonconfig-export.xml
    serve_locally: true

precondition: SELECT OS From info() where OS = 'windows'

required_permissions:
- EXECVE

parameters:
  - name: SysmonFileLocation
    description: If set, we check this location first for sysmon installed.
    default: C:/Windows/sysmon64.exe

sources:
- query: |
    LET bin &lt;= SELECT * FROM switch(
    a={
      SELECT * FROM glob(globs=SysmonFileLocation)
    }, b={
      SELECT * FROM Artifact.Generic.Utils.FetchBinary(
       ToolName="SysmonBinary")
    })

    LET existing_hash = SELECT lowcase(
       string=parse_string_with_regex(
          string=Stdout, regex="hash:.+SHA256=([^\\n\\r]+)").g1) AS Hash
    FROM execve(argv=[bin[0].OSPath, "-c"])

    LET sysmon_config = SELECT * FROM Artifact.Generic.Utils.FetchBinary(
       ToolName="SysmonConfig", IsExecutable=FALSE)

    LET ensure_service_running =
       SELECT * FROM execve(argv=["sc.exe", "start", "sysmon64"])

    LET doit = SELECT * FROM chain(
    a={
       // First force an uninstall to clear the config
       SELECT * FROM execve(argv= [ bin[0].OSPath, "-accepteula", "-u"], length=10000000)
    }, b={
       SELECT * FROM execve(argv= [ bin[0].OSPath,
           "-accepteula", "-i", sysmon_config[0].OSPath ], length=10000000)
    }, c=ensure_service_running)

    // Only install sysmon if the existing config hash is not the same
    // as the specified hash.
    SELECT * FROM if(
    condition=if(
        condition=bin AND sysmon_config,
        else=log(message="Failed to fetch sysmon tools!"),
        then=if(
           condition=existing_hash[0].Hash != Tool_SysmonConfig_HASH,
           then=log(message="Sysmon config hash has changed (%v vs %v) - reinstalling",
                    args=[existing_hash[0].Hash, Tool_SysmonConfig_HASH]),
           else=log(message="Existing sysmon config hash has not changed (%v) - skipping reinstall",
                    args=Tool_SysmonConfig_HASH) AND FALSE
          )
        ),
    then={ SELECT * FROM doit },
    else={ SELECT * FROM ensure_service_running })

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/linux.sys.crontab.md
======
---
title: Linux.Sys.Crontab
hidden: true
tags: [Client Artifact]
---

Displays parsed information from crontab.


<pre><code class="language-yaml">
name: Linux.Sys.Crontab
description: |
  Displays parsed information from crontab.
parameters:
  - name: cronTabGlob
    default: /etc/crontab,/etc/cron.d/**,/var/at/tabs/**,/var/spool/cron/**,/var/spool/cron/crontabs/**
  - name: cronTabScripts
    default: /etc/cron.daily/*,/etc/cron.hourly/*,/etc/cron.monthly/*,/etc/cron.weekly/*
  - name: Length
    default: 10000
    type: int

precondition: SELECT OS From info() where OS = 'linux'

sources:
  - name: CronTabs
    query: |
      LET raw = SELECT * FROM foreach(
          row={
            SELECT OSPath from glob(globs=split(string=cronTabGlob, sep=","))
          },
          query={
            SELECT OSPath, data, parse_string_with_regex(
              string=data,
              regex=[
                 /* Regex for event (Starts with @) */
                 "^(?P&lt;Event&gt;@[a-zA-Z]+)\\s+(?P&lt;Command&gt;.+)",

                 /* Regex for regular command. */
                 "^(?P&lt;Minute&gt;[^\\s]+)\\s+"+
                 "(?P&lt;Hour&gt;[^\\s]+)\\s+"+
                 "(?P&lt;DayOfMonth&gt;[^\\s]+)\\s+"+
                 "(?P&lt;Month&gt;[^\\s]+)\\s+"+
                 "(?P&lt;DayOfWeek&gt;[^\\s]+)\\s+"+
                 "(?P&lt;User&gt;[^\\s]+)\\s+"+
                 "(?P&lt;Command&gt;.+)$"]) as Record

            /* Read lines from the file and filter ones that start with "#" */
            FROM split_records(
               filenames=OSPath,
               regex="\n", columns=["data"]) WHERE not data =~ "^\\s*#"
            }) WHERE Record.Command

      SELECT Record.Event AS Event,
               Record.User AS User,
               Record.Minute AS Minute,
               Record.Hour AS Hour,
               Record.DayOfMonth AS DayOfMonth,
               Record.Month AS Month,
               Record.DayOfWeek AS DayOfWeek,
               Record.Command AS Command,
               OSPath AS Path
      FROM raw
  - name: CronScripts
    query: |
      SELECT Mtime, OSPath, read_file(filename=OSPath,length=Length) AS Content
      FROM glob(globs=split(string=cronTabScripts, sep=","))
  - name: Uploaded
    query: |
      SELECT OSPath, upload(file=OSPath) AS Upload
      FROM glob(globs=split(string=cronTabGlob + "," + cronTabScripts, sep=","))

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.registry.enabledmacro.md
======
---
title: Windows.Registry.EnabledMacro
hidden: true
tags: [Client Artifact]
---

Checks for Registry key indicating macro was enabled by user.

HKEY_USERS\*\Software\Microsoft\Office\*\Security\Trusted Documents\TrustRecords reg keys for values ending in FFFFFF7F
http://az4n6.blogspot.com/2016/02/more-on-trust-records-macros-and.html


<pre><code class="language-yaml">
name: Windows.Registry.EnabledMacro
description: |
  Checks for Registry key indicating macro was enabled by user.

  HKEY_USERS\*\Software\Microsoft\Office\*\Security\Trusted Documents\TrustRecords reg keys for values ending in FFFFFF7F
  http://az4n6.blogspot.com/2016/02/more-on-trust-records-macros-and.html

author: "@mgreen27"

precondition: SELECT OS From info() where OS = 'windows'

parameters:
 - name: KeyGlob
   default: Software\Microsoft\Office\*\*\Security\Trusted Documents\TrustRecords\*
 - name: userRegex
   default: .
   type: regex

sources:
 - query: |
        LET UserProfiles = Select Name as Username,
            {
                SELECT OSPath FROM glob(
                  root=expand(path=Directory),
                  globs="/NTUSER.DAT",
                  accessor="auto")
            } as NTUser,
            expand(path=Directory) as Directory
        FROM Artifact.Windows.Sys.Users()
        WHERE Directory and NTUser and Name =~ userRegex

        SELECT * FROM foreach(
          row={
            SELECT Username,NTUser FROM UserProfiles
          },
          query={
            SELECT Name as Document,
              Username,
              NTUser as Userhive,
              OSPath.Dirname AS Key,
              Mtime AS LastModified
            FROM glob(
              globs=KeyGlob,
              root=pathspec(DelegatePath=NTUser),
              accessor="raw_reg")
            WHERE Data.type =~ "BINARY"
              and encode(string=Data.value, type="hex") =~ "ffffff7f$"
          })

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.triage.sds.md
======
---
title: Windows.Triage.SDS
hidden: true
tags: [Client Artifact]
---

Collects the $Secure:$SDS stream from the NTFS volume. The $Secure
stream is both a directory (it has I30 stream) and a file (it has a
$DATA stream) and therefore confuses the Windows.KapeFiles.Target
artifact which relies on globbing. Use this artifact to collect the
$SDS stream.


<pre><code class="language-yaml">
name: Windows.Triage.SDS
description: |
  Collects the $Secure:$SDS stream from the NTFS volume. The $Secure
  stream is both a directory (it has I30 stream) and a file (it has a
  $DATA stream) and therefore confuses the Windows.KapeFiles.Target
  artifact which relies on globbing. Use this artifact to collect the
  $SDS stream.

parameters:
  - name: Drive
    description: The Drive letter to analyze
    default: "C:"

sources:
  - precondition:
      SELECT OS From info() where OS = 'windows'

    query: |
      LET Device &lt;= pathspec(parse=Drive)

      SELECT *, upload(accessor="mft",
                       file=Device + Inode,
                       name=pathspec(Path=Name)) AS Upload
      FROM foreach(row=parse_ntfs(device=Device, mft=9).Attributes, column="_value")
      WHERE Name =~ "\\$S" AND TypeId IN (128, 160)

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/generic.utils.fetchbinary.md
======
---
title: Generic.Utils.FetchBinary
hidden: true
tags: [Client Artifact]
---

A utility artifact which fetches a binary from a URL and caches it on disk.
We verify the hash of the binary on disk and if it does not match we fetch it again
from the source URL.

This artifact is designed to be called from other artifacts. The
binary path will be emitted in the OSPath column.

As a result of launching an artifact with declared "tools"
field, the server will populate the following environment
variables.

Tool_<ToolName>_HASH     - The hash of the binary
Tool_<ToolName>_FILENAME - The filename to store it.
Tool_<ToolName>_URL      - The URL.


<pre><code class="language-yaml">
name: Generic.Utils.FetchBinary
description: |
   A utility artifact which fetches a binary from a URL and caches it on disk.
   We verify the hash of the binary on disk and if it does not match we fetch it again
   from the source URL.

   This artifact is designed to be called from other artifacts. The
   binary path will be emitted in the OSPath column.

   As a result of launching an artifact with declared "tools"
   field, the server will populate the following environment
   variables.

   Tool_&lt;ToolName&gt;_HASH     - The hash of the binary
   Tool_&lt;ToolName&gt;_FILENAME - The filename to store it.
   Tool_&lt;ToolName&gt;_URL      - The URL.

parameters:
  - name: ToolName
    default: Autorun_amd64

  - name: IsExecutable
    type: bool
    default: Y
    description: Set to Y if the file needs to be executable (on windows it will have .exe extension)

  - name: SleepDuration
    default: "20"
    type: int
    description: A time to sleep before fetching the binary.

  - name: ToolInfo
    type: hidden
    description: A dict containing the tool information.

  - name: TemporaryOnly
    type: bool
    description: |
      If true we use a temporary directory to hold the binary and
      remove it afterwards

  - name: Version
    description: The version of the tool to fetch

sources:
  - query: |
      -- The following VQL is particularly ancient because it is
      -- running on the client and it needs to be compatibile with
      -- clients at least back to 0.3.9

      LET info_cache &lt;= SELECT * FROM info()
      LET inventory_item = SELECT inventory_get(
         tool=ToolName, version=Version) AS Item FROM scope()

      LET args &lt;= SELECT * FROM switch(
        // Try to get info from the ToolInfo parameter.
        a={SELECT get(field="Tool_" + ToolName + "_HASH", item=ToolInfo) AS ToolHash,
                  get(field="Tool_" + ToolName + "_FILENAME", item=ToolInfo) AS ToolFilename,
                  get(field="Tool_" + ToolName + "_URL", item=ToolInfo) AS ToolURL,
                  get(field="Tool_" + ToolName + "_PATH", item=ToolInfo) AS ToolPath
           FROM scope()  WHERE ToolFilename},

        // Failing this - get it from the scope()
        b={SELECT get(field="Tool_" + ToolName + "_HASH", item=scope()) AS ToolHash,
                  get(field="Tool_" + ToolName + "_FILENAME", item=scope()) AS ToolFilename,
                  get(field="Tool_" + ToolName + "_URL", item=scope()) AS ToolURL,
                  get(field="Tool_" + ToolName + "_PATH", item=ToolInfo) AS ToolPath
           FROM scope()  WHERE ToolFilename},

        // Failing this - try to get it from the inventory service directly.
        c={SELECT get(field="Tool_" + ToolName + "_HASH", item=(inventory_item[0]).Item) AS ToolHash,
                  get(field="Tool_" + ToolName + "_FILENAME", item=(inventory_item[0]).Item) AS ToolFilename,
                  get(field="Tool_" + ToolName + "_URL", item=(inventory_item[0]).Item) AS ToolURL
           FROM scope()  WHERE ToolFilename}
      )

      // Keep the binaries cached in the temp directory. We verify the
      // hashes all the time so this should be safe.
      LET binpath &lt;= SELECT Path FROM switch(

          -- Allow user to specify a temporary directory which
          -- will be cleaned up.
          a={SELECT tempdir(remove_last=TRUE) AS Path
             FROM scope() WHERE TemporaryOnly },

          -- Otherwise use the temp directory (The official MSI
          -- sets this to a known location)
          b={SELECT dirname(path=tempfile()) AS Path
             FROM scope() WHERE Path },

          c={SELECT "/tmp" AS Path FROM info_cache WHERE OS = "linux" }
        )

      // Where we should save the file.
      LET ToolPath &lt;= SELECT path_join(components=[
           (binpath[0]).Path, (args[0]).ToolFilename]) AS Path FROM scope()

      // Support tools locally served from disk
      LET local_file =
          SELECT hash(path=(args[0]).ToolPath) as Hash,
                 (args[0]).ToolFilename AS Name,
                 "Downloaded" AS DownloadStatus,
                 (args[0]).ToolPath AS OSPath
          FROM scope()
          WHERE (args[0]).ToolPath AND
                log(message="File served from " + (args[0]).ToolPath)

      // Download the file from the binary URL and store in the local
      // binary cache.
      LET download = SELECT * FROM if(condition=log(
             message="URL for " + (args[0]).ToolFilename +
                " is at " + (args[0]).ToolURL + " and has hash of " + (args[0]).ToolHash)
             AND binpath AND (args[0]).ToolHash AND (args[0]).ToolURL,
        then={
          SELECT hash(path=Content) as Hash,
              (args[0]).ToolFilename AS Name,
              "Downloaded" AS DownloadStatus,
              copy(filename=Content, dest=(ToolPath[0]).Path,
                   permissions=if(condition=IsExecutable, then="x")) AS OSPath
          FROM http_client(url=(args[0]).ToolURL, tempfile_extension=".tmp")
          WHERE log(message=format(format="downloaded hash of %v: %v, expected %v", args=[
                    Content, Hash.SHA256, (args[0]).ToolHash]))
                AND Hash.SHA256 = (args[0]).ToolHash
        }, else={
           SELECT * FROM scope()
           WHERE NOT log(message="No valid setup - is tool " + ToolName +
                        " configured in the server inventory?")
        })

      // Check if the existing file in the binary file cache matches
      // the hash.
      LET existing = SELECT OSPath, hash(path=OSPath) AS Hash, Name,
                    "Cached" AS DownloadStatus
        FROM stat(filename=(ToolPath[0]).Path)
        WHERE log(message=format(format="Local hash of %v: %v, expected %v", args=[
            OSPath, Hash.SHA256, (args[0]).ToolHash]))
        AND Hash.SHA256 = (args[0]).ToolHash

      // Find the required_tool either in the local cache or
      // download it (and put it in the cache for next time). If we
      // have to download the file we sleep for a random time to
      // stagger server bandwidth load.
      SELECT *, OSPath AS FullPath
      FROM switch(
        a=local_file,
        b=existing,
        c={
           SELECT rand(range=SleepDuration) AS timeout
           FROM scope()
           WHERE args AND (args[0]).ToolURL AND
              log(message=format(format='Sleeping %v Seconds',
                 args=[timeout])) AND sleep(time=timeout) AND FALSE
        },
        d=download)

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.applications.chocolateypackages.md
======
---
title: Windows.Applications.ChocolateyPackages
hidden: true
tags: [Client Artifact]
---

Chocolatey packages installed in a system.

<pre><code class="language-yaml">
name: Windows.Applications.ChocolateyPackages
description: Chocolatey packages installed in a system.
parameters:
  - name: ChocolateyInstall
    default: ""

sources:
  - precondition:
      SELECT OS From info() where OS = 'windows'
    query: |
      LET SearchGlob = if(
             condition=ChocolateyInstall,
             then=ChocolateyInstall,

             -- Otherwise just use the environment.
             else=environ(var='ChocolateyInstall')) + '/lib/*/*.nuspec'

      LET files = SELECT OSPath,
              parse_xml(file=OSPath) AS Metadata
              -- Use the ChocolateyInstall parameter if it is set.

          FROM glob(globs=SearchGlob)

      SELECT * FROM if(
        condition=if(condition=ChocolateyInstall,
                     then=ChocolateyInstall,
                     else=environ(var="ChocolateyInstall")),
        then={
            SELECT OSPath,
                   Metadata.package.metadata.id as Name,
                   Metadata.package.metadata.version as Version,
                   Metadata.package.metadata.summary as Summary,
                   Metadata.package.metadata.authors as Authors,
                   Metadata.package.metadata.licenseUrl as License
            FROM files
        })

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/server.alerts.thehive.alert.md
======
---
title: Server.Alerts.TheHive.Alert
hidden: true
tags: [Server Event Artifact]
---

Create a TheHive alert when monitored artifacts complete with results.
Much of this was borrowed from: https://gist.github.com/scudette/3a32abd19350c8fe3368661c4278869d

It is recommended to use the Server Metadata section to store credentials, instead of having to store directly inside the artifact.


<pre><code class="language-yaml">
name: Server.Alerts.TheHive.Alert
description: |
   Create a TheHive alert when monitored artifacts complete with results.
   Much of this was borrowed from: https://gist.github.com/scudette/3a32abd19350c8fe3368661c4278869d
   
   It is recommended to use the Server Metadata section to store credentials, instead of having to store directly inside the artifact.
   
type: SERVER_EVENT

author: Wes Lambert - @therealwlambert

parameters:
  - name: TheHiveURL
    default: https://mythehive
  - name: TheHiveKey
    default: ''
  - name: VeloServerURL
    default: https://myvelo
  - name: ArtifactsToAlertOn
    default: .
  - name: DisableSSLVerify
    type: bool
    default: True

sources:
  - query: |
      LET thehive_key = if(
           condition=TheHiveKey,
           then=TheHiveKey,
           else=server_metadata().TheHiveKey)
      LET flow_info = SELECT timestamp(epoch=Timestamp) AS Timestamp,
             client_info(client_id=ClientId).os_info.fqdn AS FQDN,
             ClientId, FlowId, Flow.artifacts_with_results[0] AS FlowResults
      FROM watch_monitoring(artifact="System.Flow.Completion")
      WHERE Flow.artifacts_with_results =~ ArtifactsToAlertOn
     
      LET hits = SELECT * FROM foreach(row=flow_info,
      query={
        SELECT *, Timestamp, FQDN, ClientId  
        FROM source(artifact=FlowResults, 
                    client_id=ClientId, flow_id=FlowId)
      })
      
      SELECT * FROM foreach(row=flow_info,
       query={
          SELECT * FROM http_client(
          data=serialize(item=dict(
                title=format(format="Hit on %v for %v", args=[FlowResults, FQDN]), description=format(format="ClientId: %v\n\nFlowID: %v\n\nURL: %v//app/index.html?#/collected/%v/%v", args=[ClientId, FlowId, VeloServerURL, ClientId, FlowId]), type="artifact-alert", source="velociraptor", sourceRef=format(format="%v", args=[rand(range=1000000000)])), format="json"),
          headers=dict(`Content-Type`="application/json", `Authorization`=format(format="Bearer %v", args=[thehive_key])),
          disable_ssl_security=DisableSSLVerify,
          method="POST", 
          url=format(format="%v/api/alert", args=[TheHiveURL]))
       })

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/linux.sys.cputime.md
======
---
title: Linux.Sys.CPUTime
hidden: true
tags: [Client Artifact]
---

Displays information from /proc/stat file about the time the cpu
cores spent in different parts of the system.


<pre><code class="language-yaml">
name: Linux.Sys.CPUTime
description: |
  Displays information from /proc/stat file about the time the cpu
  cores spent in different parts of the system.
parameters:
  - name: procStat
    default: /proc/stat
sources:
  - precondition: |
      SELECT OS From info() where OS = 'linux'
    query: |
        LET raw = SELECT * FROM split_records(
           filenames=procStat,
           regex=' +',
           columns=['core', 'user', 'nice', 'system',
                    'idle', 'iowait', 'irq', 'softirq',
                    'steal', 'guest', 'guest_nice'])
        WHERE core =~ 'cpu.+'

        SELECT core AS Core,
               atoi(string=user) as User,
               atoi(string=nice) as Nice,
               atoi(string=system) as System,
               atoi(string=idle) as Idle,
               atoi(string=iowait) as IOWait,
               atoi(string=irq) as IRQ,
               atoi(string=softirq) as SoftIRQ,
               atoi(string=steal) as Steal,
               atoi(string=guest) as Guest,
               atoi(string=guest_nice) as GuestNice FROM raw

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/linux.sys.lastuserlogin.md
======
---
title: Linux.Sys.LastUserLogin
hidden: true
tags: [Client Artifact]
---

Find and parse system wtmp files. This indicate when the user last
logged in.


<pre><code class="language-yaml">
name: Linux.Sys.LastUserLogin
description: |
  Find and parse system wtmp files. This indicate when the user last
  logged in.

parameters:
  - name: wtmpGlobs
    default: /var/log/wtmp*

  - name: MaxCount
    default: 10000
    type: int64

  - name: LoginType
    type: choices
    default: Interactive Sessions
    choices:
        - Interactive Sessions
        - All Sessions
    description: |
      Per default, we are only interested in interactive sessions, if
      you want to see more, choose the second option


  - name: recent_x_days
    default: 100000
    type: int
    description: |
      show all logs within the last X days (default 14 days)

  - name: excluded_users
    type: regex
    default: "ansible|LOGIN"
    description: |
      List of Users (regex), you are not interested in

export: |
  LET FilterLookup = dict(
     `Interactive Sessions`="USER_PROCESS|LOGIN_PROCESS",
     `All Sessions`="RUN_LVL|BOOT_TIME|INIT_PROCESS|LOGIN_PROCESS|USER_PROCESS")

  LET wtmpProfile &lt;= '''
  [
    ["Header", 0, [

    ["records", 0, "Array", {
        "type": "utmp",
        "count": "x=&gt;MaxCount",
        "max_count": 100000,
    }],
    ]],
    ["utmp", 384, [
        ["ut_type", 0, "Enumeration", {
            "type": "short int",
            "choices": {
               "0": "EMPTY",
               "1": "RUN_LVL",
               "2": "BOOT_TIME",
               "5": "INIT_PROCESS",
               "6": "LOGIN_PROCESS",
               "7": "USER_PROCESS",
               "8": "DEAD_PROCESS"
             }
          }],
        ["ut_pid", 4, "int"],
        ["ut_terminal", 8, "String", {"length": 32}],
        ["ut_terminal_identifier", 40, "String", {"length": 4}],
        ["ut_user", 44, "String", {"length": 32}],
        ["ut_hostname", 76, "String", {"length": 256}],
        ["ut_termination_status", 332, "int"],
        ["ut_exit_status", 334, "int"],
        ["ut_session", 336, "int"],
        ["ut_timestamp", 340, "Timestamp", {
            "type": "uint32",
        }],
        ["ut_ip_address", 348, "int64"],
    ]
    ]
    ]]
    ]'''

sources:
  - precondition: |
      SELECT OS From info() where OS = 'linux'

    query: |
      LET LoginType &lt;= get(item=FilterLookup, field=LoginType) || LoginType
      LET start_time &lt;= timestamp(epoch=now() - recent_x_days * 3600 * 24)

      LET _ &lt;= log(message="Start time %v", args=start_time)

      LET parsed = SELECT OSPath, parse_binary(
                   filename=OSPath,
                   profile=wtmpProfile,
                   struct="Header"
                 ) AS Parsed
      FROM glob(globs=split(string=wtmpGlobs, sep=","))

      // In Order to combine Login/Logout into one Table, we create a
      // logout table first
      LET logout_table &lt;= SELECT * FROM foreach(row=parsed,
      query={
         SELECT * FROM foreach(row=Parsed.records,
         query={
           SELECT ut_type AS logout_Type,
              ut_pid as logout_PID,
              ut_terminal as logout_Terminal,
              ut_timestamp as logout_time
           FROM scope()
           WHERE logout_Type = "DEAD_PROCESS"
             AND logout_time &gt; start_time
        })
      })
      Order by logout_time DESC

      SELECT * FROM foreach(row=parsed,
      query={
         SELECT * FROM foreach(row=Parsed.records,
         query={
           SELECT OSPath,
              ut_type AS login_Type,
              ut_id AS login_ID,
              ut_pid as login_PID,
              ut_hostname as login_Host,
              ut_user as login_User,
              ip(netaddr4_le=ut_ip_address) AS login_IpAddr,
              ut_terminal as login_Terminal,
              ut_timestamp as login_time, {
                SELECT logout_time
                FROM logout_table
                WHERE ut_pid = logout_PID
                  AND ut_terminal = logout_Terminal
                  AND ut_timestamp &lt; logout_time
                LIMIT 1
              } AS logout_time
          FROM scope()
          WHERE login_Type =~ LoginType
            AND NOT login_User =~ excluded_users
            AND login_time &gt; start_time
        })
      })

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/demo.plugins.fifo.md
======
---
title: Demo.Plugins.Fifo
hidden: true
tags: [Client Event Artifact]
---

This is a demo of the fifo() plugin. The Fifo plugin collects and
caches rows from its inner query. Every subsequent execution of the
query then reads from the cache. The plugin will expire old rows
depending on its expiration policy - so we always see recent rows.

You can use this to build queries which consider historical events
together with current events at the same time. In this example, we
check for a successful logon preceded by a number of failed logon
attempts.

In this example, we use the clock() plugin to simulate events. We
simulate failed logon attempts using the clock() plugin every
second. By feeding the failed logon events to the fifo() plugin we
ensure the fifo() plugin cache contains the last 5 failed logon
events.

We simulate a successful logon event every 3 seconds, again using
the clock plugin. Once a successful logon event is detected, we go
back over the last 5 login events, count them and collect the last
failed logon times (using the GROUP BY operator we group the
FailedTime for every unique SuccessTime).

If we receive more than 3 events, we emit the row.

This now represents a high value signal! It will only occur when a
successful logon event is preceded by at least 3 failed logon
events in the last hour. It is now possible to escalate this on the
server via email or other alerts.

Here is sample output:

.. code-block:: json

    {
      "Count": 5,
      "FailedTime": [
        1549527272,
        1549527273,
        1549527274,
        1549527275,
        1549527276
      ],
      "SuccessTime": 1549527277
    }

Of course in the real artifact we would want to include more
information than just times (i.e. who logged on to where etc).


<pre><code class="language-yaml">
name: Demo.Plugins.Fifo
description: |
  This is a demo of the fifo() plugin. The Fifo plugin collects and
  caches rows from its inner query. Every subsequent execution of the
  query then reads from the cache. The plugin will expire old rows
  depending on its expiration policy - so we always see recent rows.

  You can use this to build queries which consider historical events
  together with current events at the same time. In this example, we
  check for a successful logon preceded by a number of failed logon
  attempts.

  In this example, we use the clock() plugin to simulate events. We
  simulate failed logon attempts using the clock() plugin every
  second. By feeding the failed logon events to the fifo() plugin we
  ensure the fifo() plugin cache contains the last 5 failed logon
  events.

  We simulate a successful logon event every 3 seconds, again using
  the clock plugin. Once a successful logon event is detected, we go
  back over the last 5 login events, count them and collect the last
  failed logon times (using the GROUP BY operator we group the
  FailedTime for every unique SuccessTime).

  If we receive more than 3 events, we emit the row.

  This now represents a high value signal! It will only occur when a
  successful logon event is preceded by at least 3 failed logon
  events in the last hour. It is now possible to escalate this on the
  server via email or other alerts.

  Here is sample output:

  .. code-block:: json

      {
        "Count": 5,
        "FailedTime": [
          1549527272,
          1549527273,
          1549527274,
          1549527275,
          1549527276
        ],
        "SuccessTime": 1549527277
      }

  Of course in the real artifact we would want to include more
  information than just times (i.e. who logged on to where etc).
type: CLIENT_EVENT

sources:
  - query: |
      // This query simulates failed logon attempts.
      LET failed_logon = SELECT Unix as FailedTime from clock(period=1)

      // This is the fifo which holds the last 5 failed logon attempts
      // within the last hour.
      LET last_5_events = SELECT FailedTime
            FROM fifo(query=failed_logon, max_rows=5, max_age=3600)

      // We need to get it started collecting data immediately by
      // materializing the cache contents. Otherwise the fifo wont
      // start until it is first called (i.e. the first successful
      // login and we will miss the failed events before hand).
       LET foo &lt;= SELECT * FROM last_5_events

      // This simulates successful logon - we assume every 3 seonds.
      LET success_logon = SELECT Unix as SuccessTime from clock(period=3)

      // For each successful logon, query the last failed logon
      // attempts from the fifo(). We also count the total number of
      // failed logons. We only actually emit results if there are more
      // than 3 failed logon attempts before each successful one.
      SELECT * FROM foreach(
          row=success_logon,
          query={
           SELECT SuccessTime,
              enumerate(items=FailedTime) as FailedTime,
              count(items=FailedTime) as Count
           FROM last_5_events GROUP BY SuccessTime
          }) WHERE Count &gt; 3

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/linux.events.dns.md
======
---
title: Linux.Events.DNS
hidden: true
tags: [Client Event Artifact]
---

This artifact uses eBPF to track DNS requests from various processes.

NOTE: This event is generated from network traffic - it is unable to
view DoH traffic.


<pre><code class="language-yaml">
name: Linux.Events.DNS
description: |
  This artifact uses eBPF to track DNS requests from various processes.

  NOTE: This event is generated from network traffic - it is unable to
  view DoH traffic.

type: CLIENT_EVENT

precondition: |
  SELECT OS From info() where OS = 'linux'

parameters:
  - name: ExcludeDestIP
    description: Only show events with a different DestIP
    type: regex
    default: "Change this to your default DNS Server IP"
  - name: Records
    description: Only show events matching these DNS records
    type: regex
    default: .
  - name: ProcessNameFilter
    description: Filter Events by Process Name
    type: regex
    default: .
  - name: IncludeDNSDetails
    type: bool
    description: If set we include more details like HTTP Headers
  - name: IncludeProcessInfo
    type: bool
    description: If set we include more process information.

sources:
  - query: |
      SELECT System.Timestamp AS Timestamp,
             System.ProcessName AS ProcessName,
             System.ProcessID AS Pid,
             if(condition=IncludeProcessInfo,
                then=process_tracker_get(id=System.ProcessID).Data) AS ProcessInfo,
             EventData.src AS src_ip,
             EventData.src_port AS src_port,
             EventData.dst AS dest_ip,
             EventData.dst_port AS dest_port,
             EventData.proto_dns.questions.name AS name,
             EventData.proto_dns.questions.type AS type,
             EventData.proto_dns.answers.IP AS IP,
             if(condition=IncludeDNSDetails,
                then=EventData) AS _DNSData
      FROM delay(delay=2, query={
        SELECT * FROM watch_ebpf(events="net_packet_dns")
      })
      WHERE NOT dest_ip =~ ExcludeDestIP
        AND if(condition=Records, then=EventData.proto_dns =~ Records, else=TRUE)
        AND ProcessName =~ ProcessNameFilter

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/linux.events.journal.md
======
---
title: Linux.Events.Journal
hidden: true
tags: [Client Event Artifact]
---

Watches the binary journal logs. Systemd uses a binary log format to
store logs.


<pre><code class="language-yaml">
name: Linux.Events.Journal
description: |
  Watches the binary journal logs. Systemd uses a binary log format to
  store logs.

type: CLIENT_EVENT

parameters:
- name: JournalGlob
  type: glob
  description: A Glob expression for finding journal files.
  default: /{run,var}/log/journal/*/*.journal

sources:
- query: |
    SELECT * FROM foreach(row={
      SELECT OSPath FROM glob(globs=JournalGlob)
    }, query={
      SELECT *
      FROM watch_journald(filename=OSPath)
    }, workers=100)

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/macos.applications.mru.md
======
---
title: MacOS.Applications.MRU
hidden: true
tags: [Client Artifact]
---

Parse the MRU from MacOS users


<pre><code class="language-yaml">
name: MacOS.Applications.MRU
description: |
   Parse the MRU from MacOS users

reference:
  - https://mac-alias.readthedocs.io/en/latest/bookmark_fmt.html
  - https://github.com/al45tair/mac_alias
  - https://www.mac4n6.com/blog/2016/7/10/new-script-macmru-most-recently-used-plist-parser

type: CLIENT

parameters:
   - name: FinderPlistPath
     default: /Users/*/Library/Preferences/com.apple.finder.plist

export: |
        -- Parser for MAC Bookmark format
        LET type_lookup &lt;= dict(
           `0x100`="__DataString",
           `0x200`="__DataData",
           `0x300`="__DataUint32",
           `0x400`="__DataDate",
           `0x500`="__DataBool",
           `0x600`="__DataArray",
           `0x700`="__DataDict",
           `0x800`="__DataUUID",
           `0x900`="__DataURL"
           )

        LET MRULookup &lt;= dict(
           `0x2040`="Volume Bookmark",
           `0x2002`="Volume Path",
           `0x2020`="Volume Flags",
           `0x2030`="Volume is Root FS",
           `0x2011`="Volume UUID",
           `0x2012`="Volume Size",
           `0x2013`="Volume Creation Date",
           `0x2005`="Volume URL",
           `0x2040`="Volume Bookmark",
           `0x2050`="Volume Mount Point",
           `0xf080`="Security Extension",
           `0xf081`="Security Extension",
           `0x1004`="Target Path",
           `0x1005`="Target CNID Path",
           `0xc001`="Containing Folder Index",
           `0x1040`="Target Creation Date",
           `0x1010`="Target Flags",
           `0x1020`="Target Filename",
           `0xc011`="Creator Username",
           `0xc012`="Creator UID"
        )

        LET BookmarkProfile = '''[
         ["Header", 0, [
          ["Magic", 0, "String", {
              length: 4,
          }],
          ["Size", 4, "uint32"],
          ["HeaderSize", 12, "uint32"],
          ["TOCOffset", "x=&gt;x.HeaderSize", "uint32"],
          ["TOC", "x=&gt;x.TOCOffset + x.HeaderSize", "TOC"]
         ]],
         ["TOC", 0, [
          ["SizeOfTOC", 0, "uint32"],
          ["Magic", 4, "uint32"],
          ["TOCId", 8, "uint32"],
          ["NextTOC", 12, "uint32"],
          ["TOCCount", 16, "uint32"],
          ["Items", 20, "Array", {
              type: "TOCItem",
              count: "x=&gt;x.TOCCount",
          }]
         ]],
         ["__TOCArrayPtr", 4, [
          ["Offset", 0, "uint32"],
          ["Item", 0, "Profile", {
            type: "TOCValue",
            offset: "x=&gt;x.Offset + 48"
           }]
         ]],
         ["TOCValue", 0, [
           ["MyOffset", 0, "Value", {
               value: "x=&gt;x.StartOf",
           }],
           ["length", 0, "uint32"],
           ["subtype", 4, "BitField", {
               type: "uint32",
               start_bit: 0,
               end_bit: 8,
            }],
            ["data_type", 4, "BitField", {
               type: "uint32",
               start_bit: 8,
               end_bit: 32,
            }],
            ["data", 0, "Value", {
               value: "x=&gt;get(item=x, field=get(item=type_lookup, field=format(format='%#x', args=x.data_type)))",
            }],
            ["__DataString", 8, "String", {
               length: "x=&gt;x.length",
               term: "",
            }],
            ["__DataData", 0, "Value", {
               value: "x=&gt;format(format='%x', args=x.__DataStr)",
            }],
            ["__DataDateFloat", 8, "float64be"],
            ["__DataDate", 0, "Value", {
               value: "x=&gt;timestamp(cocoatime=x.__DataDateFloat)",
            }],
            ["__DataUint32", 8, "uint32"],
            ["__DataBool", 0, "Value", {
                value: "x=&gt;if(condition=x.subtype, then=TRUE, else=FALSE)",
            }],
            ["__DataURL", 0, "Value", {
               value: "x=&gt;x.__DataString",
            }],
            ["__DataArrayOffsets", 8, "Array", {
               count: "x=&gt;x.length / 4",
               type: "__TOCArrayPtr"
            }],
            ["__DataArray", 0, "Value", {
               value: "x=&gt;x.__DataArrayOffsets.Item.data",
            }],
         ]],
         ["TOCItem", 12, [
           ["ID", 0, "uint32"],
           ["Offset", 4, "uint32"],
           ["TOCValue", "x=&gt;x.Offset + 48 - x.StartOf", "TOCValue"],
         ]]
        ]
        '''

        LET ParseBookmark(Bookmark) =
           SELECT _value.name AS Name,
                  get(item=MRULookup, field=format(format="%#x", args=ID)) AS Field,
                  format(format="%#x", args=ID) AS FieldID,
                  format(format="%#x", args=TOCValue.data_type) AS data_type,
                  regex_replace(re="__Data", replace="",
                        source=get(item=type_lookup,
                        field=format(format="%#x",
                              args=TOCValue.data_type))) AS type,
                  TOCValue.data AS data

           FROM foreach(row=parse_binary(
                        accessor="data", filename=Bookmark,
                        profile=BookmarkProfile, struct="Header").TOC.Items)

sources:
  - query: |
        -- Parse the Plist file
        SELECT * FROM foreach(row={
          SELECT OSPath FROM glob(globs=FinderPlistPath)
        }, query={
          SELECT * FROM foreach(row={
            SELECT FXRecentFolders FROM plist(file=OSPath)
          }, query={
            SELECT *
            FROM foreach(row=FXRecentFolders, query={
               SELECT *, OSPath
               FROM ParseBookmark(Bookmark=_value.`file-bookmark`)
            })
          })
        })

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.forensics.filenamesearch.md
======
---
title: Windows.Forensics.FilenameSearch
hidden: true
tags: [Client Artifact]
---

Did a specific file exist on this machine in the past or does it
still exist on this machine?

This common question comes up frequently in cases of IP theft,
discovery and other matters. One way to answer this question is to
search the $MFT file for any references to the specific filename. If
the filename is fairly unique then a positive hit on that name
generally means the file was present.

Simply determining that a filename existed on an endpoint in the
past is significant for some investigations.

This artifact applies a YARA search for a set of filenames of
interest on the $MFT file. For any hit, the artifact then identified
the MFT entry where the hit was found and attempts to resolve that
to an actual filename.


<pre><code class="language-yaml">
name: Windows.Forensics.FilenameSearch
description: |
  Did a specific file exist on this machine in the past or does it
  still exist on this machine?

  This common question comes up frequently in cases of IP theft,
  discovery and other matters. One way to answer this question is to
  search the $MFT file for any references to the specific filename. If
  the filename is fairly unique then a positive hit on that name
  generally means the file was present.

  Simply determining that a filename existed on an endpoint in the
  past is significant for some investigations.

  This artifact applies a YARA search for a set of filenames of
  interest on the $MFT file. For any hit, the artifact then identified
  the MFT entry where the hit was found and attempts to resolve that
  to an actual filename.

parameters:
    - name: yaraRule
      default: |
        rule Hit {
           strings:
             $a = "my secret file.txt" nocase wide ascii
           condition:
             any of them
        }
      type: yara
    - name: Device
      default: "C:"

sources:
  - query: |
        SELECT String.Offset AS Offset,
               String.HexData AS HexData,
               parse_ntfs(device=Device,
                          mft=String.Offset / 1024) AS MFT
        FROM yara(
             rules=yaraRule, files=Device + "/$MFT",
             end=10000000000,
             number=1000,
             accessor="ntfs")

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.sys.physicalmemoryranges.md
======
---
title: Windows.Sys.PhysicalMemoryRanges
hidden: true
tags: [Client Artifact]
---

List Windows physical memory ranges.

<pre><code class="language-yaml">
name: Windows.Sys.PhysicalMemoryRanges
description: List Windows physical memory ranges.
reference:
  - https://docs.microsoft.com/en-us/windows-hardware/drivers/ddi/content/wdm/ns-wdm-_cm_resource_list

parameters:
  - name: physicalMemoryKey
    default: HKEY_LOCAL_MACHINE\HARDWARE\RESOURCEMAP\System Resources\Physical Memory\.Translated

export: |
  LET Profile = '''
      [
        ["CM_RESOURCE_LIST", 0, [
          ["Count", 0, "uint32"],
          ["List", 4, "CM_FULL_RESOURCE_DESCRIPTOR"]
        ]],
        ["CM_FULL_RESOURCE_DESCRIPTOR", 0, [
           ["PartialResourceList", 8, "CM_PARTIAL_RESOURCE_LIST"]
        ]],

        ["CM_PARTIAL_RESOURCE_LIST", 0, [
           ["Version", 0, "uint16"],
           ["Revision", 2, "uint16"],
           ["Count", 4, "uint32"],
           ["PartialDescriptors", 8, "Array", {
              "type": "CM_PARTIAL_RESOURCE_DESCRIPTOR",
              "count": "x=&gt;x.Count"
           }]
        ]],

        ["CM_PARTIAL_RESOURCE_DESCRIPTOR", 20, [
           ["Type", 0, "char"],
           ["ShareDisposition", 1, "char"],
           ["Flags",2, "uint16"],
           ["Start",4, "int64"],
           ["Length",12, "uint32"]
        ]]
      ]
  '''

sources:
  - precondition:
      SELECT OS From info() where OS = 'windows'
    query: |
      SELECT * FROM foreach(
         row={SELECT Data from stat(filename=physicalMemoryKey, accessor="registry")},
         query={
            SELECT * FROM foreach(
               row=parse_binary(
                  filename=Data.value,
                  accessor="data",
                  profile=Profile,
                  struct="CM_RESOURCE_LIST").List.PartialResourceList.PartialDescriptors,
               query={
                  SELECT Type,
                         format(format="%#0x", args=Start) AS Start,
                         format(format="%#0x", args=Length) AS Length
                  FROM scope()
              })
      })

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.events.trackprocessesbasic.md
======
---
title: Windows.Events.TrackProcessesBasic
hidden: true
tags: [Client Event Artifact]
---

This artifact is a basic Process tracker using a simple polled
pslist(). The Process Tracker keeps track of exited processes, and
resolves process callchains from it in memory cache.

This event artifact enables the global process tracker and makes it
possible to run many other artifacts that depend on the process
tracker.

This tracker DOES NOT require sysmon and is **incompatible** with
Windows.Events.TrackProcesses (only one should be running).


<pre><code class="language-yaml">
name: Windows.Events.TrackProcessesBasic
description: |
  This artifact is a basic Process tracker using a simple polled
  pslist(). The Process Tracker keeps track of exited processes, and
  resolves process callchains from it in memory cache.

  This event artifact enables the global process tracker and makes it
  possible to run many other artifacts that depend on the process
  tracker.

  This tracker DOES NOT require sysmon and is **incompatible** with
  Windows.Events.TrackProcesses (only one should be running).

type: CLIENT_EVENT

parameters:
  - name: MaxSize
    type: int64
    description: Maximum size of the in memory process cache (default 10k)
  - name: PollPeriod
    type: int64
    description: How often to run pslist to track processes (in Seconds)
    default: 60

sources:
  - query: |
      LET SyncQuery =
              SELECT Pid AS id,
                 Ppid AS parent_id,
                 CreateTime AS start_time,
                 dict(
                   Name=Name,
                   Username=Username,
                   Exe=Exe,
                   CommandLine=CommandLine) AS data
              FROM pslist()

      LET Tracker &lt;= process_tracker(
        sync_query=SyncQuery, sync_period=1000 * PollPeriod)

      SELECT * FROM process_tracker_updates()
      WHERE update_type = "stats"

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.eventlogs.modifications.md
======
---
title: Windows.EventLogs.Modifications
hidden: true
tags: [Client Artifact]
---

It is possible to disable windows event logs on a per channel or per
provider basis. Attackers may disable ciritcal log sources to
prevent detections.

This artifact reads the state of the event log system from the
registry and attempts to detect when event logs were disabled.


<pre><code class="language-yaml">
name: Windows.EventLogs.Modifications
description: |
  It is possible to disable windows event logs on a per channel or per
  provider basis. Attackers may disable ciritcal log sources to
  prevent detections.

  This artifact reads the state of the event log system from the
  registry and attempts to detect when event logs were disabled.

precondition:
  SELECT * FROM info() WHERE OS =~ "windows"

parameters:
  - name: ProviderRegex
    default: .
    type: regex
  - name: DateAfter
    description: "search for modifications after this date. YYYY-MM-DDTmm:hh:ss Z"
    type: timestamp
  - name: DateBefore
    description: "search for modifications before this date. YYYY-MM-DDTmm:hh:ss Z"
    type: timestamp

sources:
  - name: Channels
    description: Detects status of log channels (event log files).
    query: |
      -- Build time bounds
      LET DateAfterTime &lt;= if(condition=DateAfter,
            then=DateAfter, else=timestamp(epoch="1600-01-01"))
      LET DateBeforeTime &lt;= if(condition=DateBefore,
            then=DateBefore, else=timestamp(epoch="2200-01-01"))

      LET Key = "HKEY_LOCAL_MACHINE\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\WINEVT\\Channels\\*"

      SELECT Key.Mtime AS Mtime,
             basename(path=Key.OSPath) AS ChannelName,
             Key.OSPath AS _Key,
             OwningPublisher, Enabled
      FROM read_reg_key(globs=Key)
      WHERE ChannelName =~ ProviderRegex
        AND Mtime &gt; DateAfterTime
        AND Mtime &lt; DateBeforeTime

  - name: Providers
    description: Inspect the state of each provider
    query: |
      LET Key = "HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Control\\WMI\\Autologger\\EventLog-System\\**\\Enabled"
      LET Publishers = "HKEY_LOCAL_MACHINE\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\WINEVT\\Publishers\\*\\@"

      LET ProviderNames &lt;= memoize(key="GUID", query={
        SELECT OSPath.Components[-2] AS GUID,
               Data.value AS Name
        FROM glob(globs=Publishers, accessor="registry")
      })

      LET X = SELECT Mtime,
                     OSPath.Dirname.Basename AS GUID,
                     Data.value AS Enabled,
                     OSPath.Dirname AS Key,
                     to_dict(item={
                        SELECT Name AS _key, Data.value AS _value
                        FROM glob(root=OSPath.Dirname,
                                  globs="/*",
                                  accessor="registry")
                     }) AS Content
        FROM glob(globs=Key, accessor="registry")

      SELECT Mtime, GUID, Key AS _RegKey,
         get(item=ProviderNames, member=GUID).Name AS ProviderName,
         Enabled, Content
      FROM X
      WHERE ProviderName =~ ProviderRegex
        AND Mtime &gt; DateAfterTime
        AND Mtime &lt; DateBeforeTime
      ORDER BY ProviderName

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.sys.firewallrules.md
======
---
title: Windows.Sys.FirewallRules
hidden: true
tags: [Client Artifact]
---

List Windows firewall rules.

<pre><code class="language-yaml">
name: Windows.Sys.FirewallRules
description: List Windows firewall rules.
reference:
  - https://social.technet.microsoft.com/Forums/azure/en-US/aaed9c6a-fb8b-4d43-8b69-9f4e0f619a8c/how-to-check-the-windows-firewall-settings-from-netsh-command?forum=winserverGP

parameters:
  - name: regKey
    default: HKEY_LOCAL_MACHINE\SYSTEM\CurrentControlSet\Services\SharedAccess\Parameters\FirewallPolicy\**\FirewallRules\*

sources:
  - precondition:
      SELECT OS From info() where OS = 'windows'
    query: |
        LET rules = SELECT Name as Value,
               parse_string_with_regex(string=Data,
                 regex=["Action=(?P&lt;Action&gt;[^|]+)",
                        "Active=(?P&lt;Active&gt;[^|]+)",
                        "Dir=(?P&lt;Dir&gt;[^|]+)",
                        "Protocol=(?P&lt;Protocol&gt;[^|]+)",
                        "LPort=(?P&lt;LPort&gt;[^|]+)",
                        "Name=(?P&lt;Name&gt;[^|]+)",
                        "Desc=(?P&lt;Desc&gt;[^|]+)",
                        "App=(?P&lt;App&gt;[^|]+)"]) as Record,
               Data,
               OSPath
        FROM glob(globs=regKey, accessor="registry")

        SELECT Value,
               Record.Name as Name,
               get(item=Record, field="Desc") as Description,
               Record.App as App,
               if(condition=Record.Active =~ "TRUE", then="Yes", else="No") as Active,
               Record.Action as Action,
               Record.Dir as Dir,
               if(condition=Record.Protocol = "6",
                  then="TCP",
                  else=if(condition=Record.Protocol = "17",
                          then="UDP",
                          else=Record.Protocol)) as Protocol,
               if(condition=Record.LPort = NULL,
                  then="Any",
                  else=Record.LPort) as LPort,
               Record.Name as Name
        FROM rules

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/server.alerts.notification.md
======
---
title: Server.Alerts.Notification
hidden: true
tags: [Server Event Artifact]
---

This artifact forwards alerts from Server.Internal.Alerts to a Slack/Teams/Discord via a Webhook.


<pre><code class="language-yaml">
name: Server.Alerts.Notification
description: |
   This artifact forwards alerts from Server.Internal.Alerts to a Slack/Teams/Discord via a Webhook.

author: Jos Clephas - @DfirJos

type: SERVER_EVENT

parameters:
  - name: SlackToken
    description: The token URL obtained from Slack/Teams/Discord (or basicly any communication-service that supports webhooks). Leave blank to use server metadata. e.g. https://hooks.slack.com/services/XXXX/YYYY/ZZZZ

sources:
  - query: |
        LET token_url = if(
           condition=SlackToken,
           then=SlackToken,
           else=server_metadata().SlackToken)

        LET hits = SELECT * from watch_monitoring(artifact='Server.Internal.Alerts')

        SELECT * FROM foreach(row=hits,
        query={
           SELECT * FROM http_client(
            data=serialize(item=dict(
                text=format(format="Alert: %v | Details: %v | Artifact: %v | ClientId: %v | Timestamp: %v)",
                            args=[name, event_data, artifact, client_id, timestamp])),
                format="json"),
            headers=dict(`Content-Type`="application/json"),
            method="POST",
            url=token_url)
        })

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.sys.diskinfo.md
======
---
title: Windows.Sys.DiskInfo
hidden: true
tags: [Client Artifact]
---

Retrieve basic information about the physical disks of a system.

<pre><code class="language-yaml">
name: Windows.Sys.DiskInfo
description: Retrieve basic information about the physical disks of a system.
sources:
  - precondition:
      SELECT OS From info() where OS = 'windows'
    query: |
        SELECT Partitions,
               Index as DiskIndex,
               InterfaceType as Type,
               PNPDeviceID,
               DeviceID,
               Size,
               Manufacturer,
               Model,
               Name,
               SerialNumber,
               Description
        FROM wmi(
           query="SELECT * from Win32_DiskDrive",
           namespace="ROOT\\CIMV2")

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.system.cmdshell.md
======
---
title: Windows.System.CmdShell
hidden: true
tags: [Client Artifact]
---

This artifact allows running arbitrary commands through the system
shell cmd.exe.

Since Velociraptor typically runs as system, the commands will also
run as System.

This is a very powerful artifact since it allows for arbitrary
command execution on the endpoints. Therefore this artifact requires
elevated permissions (specifically the `EXECVE`
permission). Typically it is only available with the `administrator`
role.

Note there are some limitations with passing commands to the cmd.exe
shell, such as when specifying quoted paths or command-line
arguments with special characters. Using Windows.System.PowerShell
artifact is likely a better option in these cases.


<pre><code class="language-yaml">
name: Windows.System.CmdShell
description: |
  This artifact allows running arbitrary commands through the system
  shell cmd.exe.

  Since Velociraptor typically runs as system, the commands will also
  run as System.

  This is a very powerful artifact since it allows for arbitrary
  command execution on the endpoints. Therefore this artifact requires
  elevated permissions (specifically the `EXECVE`
  permission). Typically it is only available with the `administrator`
  role.

  Note there are some limitations with passing commands to the cmd.exe
  shell, such as when specifying quoted paths or command-line
  arguments with special characters. Using Windows.System.PowerShell
  artifact is likely a better option in these cases.

required_permissions:
  - EXECVE

precondition:
  SELECT OS From info() where OS = 'windows'

parameters:
  - name: Command
    default: "dir C:\\"

sources:
  - query: |
      SELECT * FROM execve(argv=["cmd.exe", "/c", Command])

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.forensics.pst.md
======
---
title: Windows.Forensics.Pst
hidden: true
tags: [Client Artifact]
---

Parses PST files.


<pre><code class="language-yaml">
name: Windows.Forensics.Pst
description: |
  Parses PST files.

parameters:
  - name: PSTGlob
    description: Glob for locating PST files.
    default: "C:/Users/*/**.pst"
  - name: Accessor
    default: auto
  - name: SenderRegex
    type: regex
    default: .
  - name: ReceiverRegex
    type: regex
    default: .
  - name: SubjectRegex
    type: regex
    default: .
  - name: MessageRegex
    type: regex
    default: .
  - name: PathRegex
    type: regex
    default: .
  - name: AttachmentYaraRule
    description: |
      If specified, we Yara scan the attachment with this rule and
      only allow matched messages.
  - name: UploadAttachments
    description: If set we upload attachments
    type: bool

sources:
  - query: |
      LET X = scope()

      SELECT * FROM foreach(row={
         SELECT * FROM glob(globs=PSTGlob)
      }, query={
         SELECT *,
           if(condition=UploadAttachments, then={
             SELECT upload(
                file=pathspec(
                  DelegateAccessor=Accessor,
                  DelegatePath=OSPath,
                  Path=Path),
                accessor="pst")
             FROM foreach(row=Attachments)
           }) AS Uploads,

           if(condition=AttachmentYaraRule, then={
            SELECT * FROM foreach(row=Attachments,
            query={
              SELECT String
              FROM yara(accessor="pst",
                files=pathspec(
                  DelegateAccessor=Accessor,
                  DelegatePath=OSPath,
                  Path=Path),
                rules=AttachmentYaraRule, number=1)
             })
          }) AS YaraHit
         FROM parse_pst(filename=OSPath, accessor=Accessor)
         WHERE X.Sender =~ SenderRegex
           AND X.Receiver =~ ReceiverRegex
           AND X.Subject =~ SubjectRegex
           AND X.Message =~ MessageRegex
           AND X.Path =~ PathRegex
      })
      WHERE if(condition=AttachmentYaraRule, then=YaraHit, else=TRUE)

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/server.utils.deleteflow.md
======
---
title: Server.Utils.DeleteFlow
hidden: true
tags: [Server Artifact]
---

This artifact permanently deletes a flow including it's metadata and
uploaded files.

NOTE: This action can not be undone! The collection is deleted
permanently. Since this is a sensitive operation, typically only
users with the administrator role can run it.


<pre><code class="language-yaml">
name: Server.Utils.DeleteFlow
description: |
  This artifact permanently deletes a flow including it's metadata and
  uploaded files.

  NOTE: This action can not be undone! The collection is deleted
  permanently. Since this is a sensitive operation, typically only
  users with the administrator role can run it.

type: SERVER

required_permissions:
  - MACHINE_STATE

parameters:
  - name: FlowId
    description: The flow ID to delete
    default:
  - name: ClientId
    description: The client id that the collection was done on
    default:
  - name: ReallyDoIt
    description: If you really want to delete the collection, check this.
    type: bool
  - name: Sync
    description: If specified we ensure delete happens immediately
    type: bool

sources:
  - query: |
       SELECT Type, Data.VFSPath AS VFSPath, Error
       FROM delete_flow(flow_id=FlowId,
          client_id=ClientId, really_do_it=ReallyDoIt, sync=Sync)

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.network.netstat.md
======
---
title: Windows.Network.Netstat
hidden: true
tags: [Client Artifact]
---

Show information about open sockets. On windows the time when the
socket was first bound is also shown.


<pre><code class="language-yaml">
name: Windows.Network.Netstat
description: |
  Show information about open sockets. On windows the time when the
  socket was first bound is also shown.

sources:
- precondition: SELECT OS From info() where OS = 'windows'
  query: |
    LET processes &lt;= SELECT Name, Pid AS ProcPid FROM pslist()
    SELECT Pid, {
        SELECT Name from processes
        WHERE Pid = ProcPid
      } AS Name, FamilyString as Family,
      TypeString as Type,
      Status,
      Laddr.IP, Laddr.Port,
      Raddr.IP, Raddr.Port,
      Timestamp
    FROM netstat()

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.registry.userassist.md
======
---
title: Windows.Registry.UserAssist
hidden: true
tags: [Client Artifact]
---

Windows systems maintain a set of keys in the registry database
(UserAssist keys) to keep track of programs that executed. The
number of executions and last execution date and time are available
in these keys.

The information within the binary UserAssist values contains only
statistical data on the applications launched by the user via
Windows Explorer. Programs launched via the command­line (cmd.exe)
do not appear in these registry keys.

From a forensics perspective, being able to decode this information
can be very useful.

Limitations: Additional data not parsed by Velociraptor is the FocusTime
and FocusCount however these are not reliable.
Also please note that some methods of viewing an executable will update
the associated UserAssist key, and some methods of accessing an executable
will not update the execution counter or time. Therefore there may be
some executions that have a 0 time and 0 runcount.


<pre><code class="language-yaml">
name: Windows.Registry.UserAssist
description: |
  Windows systems maintain a set of keys in the registry database
  (UserAssist keys) to keep track of programs that executed. The
  number of executions and last execution date and time are available
  in these keys.

  The information within the binary UserAssist values contains only
  statistical data on the applications launched by the user via
  Windows Explorer. Programs launched via the command­line (cmd.exe)
  do not appear in these registry keys.

  From a forensics perspective, being able to decode this information
  can be very useful.

  Limitations: Additional data not parsed by Velociraptor is the FocusTime
  and FocusCount however these are not reliable.
  Also please note that some methods of viewing an executable will update
  the associated UserAssist key, and some methods of accessing an executable
  will not update the execution counter or time. Therefore there may be
  some executions that have a 0 time and 0 runcount.

reference:
  - https://www.aldeid.com/wiki/Windows-userassist-keys

precondition: SELECT OS From info() where OS = 'windows'

parameters:
  - name: UserFilter
    default: ""
    description: If specified we filter by this username.
    type: regex

  - name: ExecutionTimeAfter
    default: ""
    type: timestamp
    description: If specified only show executions after this time.

  - name: UserAssistKey
    default: Software\Microsoft\Windows\CurrentVersion\Explorer\UserAssist\*\Count\*

export:
  LET userAssistProfile = '''
      [
        ["Header", 0, [
          ["NumberOfExecutions", 4, "uint32"],
          ["LastExecution", 60, "uint64"]
        ]]
      ]
    '''

sources:
  - query: |
      LET TMP = SELECT OSPath.Path AS _KeyPath,
          parse_string_with_regex(
                string=OSPath.Path,
                regex="^.+Count\\\\\"?(?P&lt;Name&gt;.+?)\"?$") AS Name,
            OSPath,
            parse_binary(
               filename=Data.value,
               accessor="data",
               profile=userAssistProfile,
               struct="Header"
             ) As ParsedUserAssist,
             Username AS User
      FROM Artifact.Windows.Registry.NTUser(KeyGlob=UserAssistKey)

      LET UserAssist = SELECT _KeyPath,
          if(condition=Name.Name,
             then=rot13(string=Name.Name),
             else=OSPath.Path) AS Name,
          User,
          timestamp(winfiletime=ParsedUserAssist.LastExecution) As LastExecution,
          timestamp(winfiletime=ParsedUserAssist.LastExecution).Unix AS LastExecutionTS,
          ParsedUserAssist.NumberOfExecutions AS NumberOfExecutions
        FROM TMP
        ORDER BY LastExecution
      LET A1 = SELECT * FROM if(
          condition=UserFilter,
          then={
            SELECT * FROM UserAssist WHERE User =~ UserFilter
          },
          else={ SELECT * FROM UserAssist})

      SELECT * FROM if(
          condition=ExecutionTimeAfter,
          then={
            SELECT * FROM A1 WHERE LastExecutionTS &gt; ExecutionTimeAfter
          },
          else={ SELECT * FROM A1})

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/system.hunt.creation.md
======
---
title: System.Hunt.Creation
hidden: true
tags: [Server Event Artifact]
---

An event artifact that fires when a user schedules a new hunt.


<pre><code class="language-yaml">
name: System.Hunt.Creation
description: |
  An event artifact that fires when a user schedules a new hunt.

type: SERVER_EVENT

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.forensics.solarwindssunburst.md
======
---
title: Windows.Forensics.SolarwindsSunburst
hidden: true
tags: [Client Artifact]
---

"SolarWinds.Orion.Core.BusinessLayer.dll is a SolarWinds digitally-signed component of the Orion software framework that contains a backdoor that communicates via HTTP to third party servers."

We can look for evidence of this dll by first performing a YARA search on the MFT across all drives, then applying an additional FireEye-supplied rule against the file found via MFT.


<pre><code class="language-yaml">
name: Windows.Forensics.SolarwindsSunburst

description: |
    "SolarWinds.Orion.Core.BusinessLayer.dll is a SolarWinds digitally-signed component of the Orion software framework that contains a backdoor that communicates via HTTP to third party servers."

    We can look for evidence of this dll by first performing a YARA search on the MFT across all drives, then applying an additional FireEye-supplied rule against the file found via MFT.

reference:
  - https://www.fireeye.com/blog/threat-research/2020/12/evasive-attacker-leverages-solarwinds-supply-chain-compromises-with-sunburst-backdoor.html

author: Wes Lambert - @therealwlambert

tools:
  - name: SunburstYARARules
    url: https://raw.githubusercontent.com/fireeye/sunburst_countermeasures/main/all-yara.yar

parameters:
    - name: yaraMFT
      type: yara
      description: "The term we will use to search the MFT"
      default: |
        rule Hit {
           strings:
             $a = "SolarWinds.Orion.Core.BusinessLayer.dll" wide nocase
           condition:
             any of them
        }
    - name: SizeMax
      type: int64
      description: "Entries in the MFT under this size in bytes."
      default: 1200000
    - name: SizeMin
      type: int64
      description: "Entries in the MFT over this size in bytes."
      default: 1000000

sources:
  - query: |
      LET yara_rules &lt;= SELECT read_file(filename=OSPath) AS Rule,
           basename(path=OSPath) AS ToolName
        FROM Artifact.Generic.Utils.FetchBinary(
             ToolName="SunburstYARARules", IsExecutable=FALSE)

      LET ntfs_drives = SELECT OSPath + '/$MFT'as Path, OSPath AS Device
          FROM glob(globs="/*", accessor="ntfs")

      LET MFTEntries = SELECT * from foreach(
            row=ntfs_drives,
            query={ SELECT Device, String.Offset AS Offset,
               String.HexData AS HexData,
               Device + "\\" + parse_ntfs(device=Device,
                          mft=String.Offset / 1024).OSPath AS FilePath,
               parse_ntfs(device=Device,
                          mft=String.Offset / 1024) AS MFT
            FROM yara(
             rules=yaraMFT, files=Device + "/$MFT",
             end=10000000000,
             number=1000,
             accessor="ntfs")}) WHERE MFT.Size &gt; SizeMin AND MFT.Size &lt; SizeMax

      LET yarasearch = SELECT Rule, String.Offset AS HitOffset,
             str(str=String.Data) AS HitContext,
             FileName,
             File.Size AS Size,
             File.ModTime AS ModTime
        FROM yara(
            rules=yara_rules[0].Rule, key="A",
            files=FilePath)
        LIMIT 1

      LET yarahits = SELECT * FROM if(condition=yara_rules,
        then={
          SELECT *
          FROM foreach(row=MFTEntries,query=yarasearch)
        })

      SELECT *,
        hash(path=FileName) AS Hash
      FROM yarahits

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.system.hostsfile.md
======
---
title: Windows.System.HostsFile
hidden: true
tags: [Client Artifact]
---

Parses the Windows Hostsfile.

Regex searching for Hostname and resolution is enabled over output.
NOTE: For Hostname search is on the hostfile line and regex ^ or $
is not recommended.


<pre><code class="language-yaml">
name: Windows.System.HostsFile
author: Matt Green - @mgreen27
description: |
   Parses the Windows Hostsfile.

   Regex searching for Hostname and resolution is enabled over output.
   NOTE: For Hostname search is on the hostfile line and regex ^ or $
   is not recommended.

type: CLIENT

parameters:
  - name: HostsFile
    default: C:\Windows\System32\drivers\etc\hosts
  - name: HostnameRegex
    description: "Hostname target Regex in Hostsfile"
    default: .
    type: regex

  - name: ResolutionRegex
    description: "Resolution target Regex in Hostsfile"
    default: .
    type: regex

sources:
  - precondition:
      SELECT OS From info() where OS = 'windows'

    query: |
      -- Parse hosts file
      Let lines = SELECT split(string=Data,sep='\\r?\\n|\\r') as List
        FROM read_file(filenames=HostsFile)

      -- extract into fields
      LET results = SELECT * FROM foreach(row=lines,
                query={
                    SELECT parse_string_with_regex(
                        string=_value,
                        regex=[
                            "^\\s*(?P&lt;Resolution&gt;[^\\s]+)\\s+" +
                            "(?P&lt;Hostname&gt;[^\\#]+)\\s*" +
                            "#*\\s*(?P&lt;Comment&gt;.*)$"
                        ]) as Record
                    FROM foreach(row=List)
                    WHERE _value
                        AND NOT _value =~ '^\\s*#'
                        AND _value =~ HostnameRegex
                        AND _value =~ ResolutionRegex
                })

      -- clean up hostname output
      LET hostlist(string)=
            if(condition= len(list=split(string=regex_replace(source=string,
                    re='\\s+$', replace=''), sep='\\s+')) = 1,
                then= regex_replace(source=string,re='\\s+$', replace=''),
                else= split(string=regex_replace(source=string,re='\\s+$',
                  replace=''), sep='\\s+'))

      -- output rows
      SELECT
        Record.Resolution AS Resolution,
        hostlist(string=Record.Hostname) AS Hostname,
        Record.Comment AS Comment
      FROM results

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/linux.network.netstatenriched.md
======
---
title: Linux.Network.NetstatEnriched
hidden: true
tags: [Client Artifact]
---

Report network connections, and enrich with process information.


<pre><code class="language-yaml">
name: Linux.Network.NetstatEnriched
description: |
  Report network connections, and enrich with process information.

type: CLIENT

precondition:
  SELECT OS From info() where OS = 'linux'

parameters:
  - name: IPRegex
    description: "regex search over IP address fields."
    default:  "."
    type: regex
  - name: PortRegex
    description: "regex search over port fields."
    default: "."
    type: regex
  - name: ProcessNameRegex
    description: "regex search over source process name"
    default: "."
    type: regex
  - name: UsernameRegex
    description: "regex search over source process user context"
    default: "."
    type: regex
  - name: ConnectionStatusRegex
    description: "regex search over connection status"
    default: "LISTEN|ESTAB"
    type: regex
  - name: ProcessPathRegex
    description: "regex search over source process path"
    default: "."
    type: regex
  - name: CommandLineRegex
    description: "regex search over source process commandline"
    default: "."
    type: regex
  - name: CallChainRegex
    description: "regex search over the process callchain"
    default: "."
    type: regex


sources:
  - query: |
      SELECT Laddr.IP AS Laddr,
             Laddr.Port AS Lport,
             Raddr.IP AS Raddr,
             Raddr.Port AS Rport,
             Pid,
             Status,
             process_tracker_get(id=Pid).Data AS ProcInfo,
             join(array=process_tracker_callchain(id=Pid).Data.Name, sep=" -&gt; ") AS CallChain,
             process_tracker_tree(id=Pid) AS ChildrenTree
      FROM connections()
      WHERE Status =~ ConnectionStatusRegex
       AND  Raddr =~ IPRegex
       AND  ( Lport =~ PortRegex OR Rport =~ PortRegex )
       AND ProcInfo.Name =~ ProcessNameRegex
       AND ProcInfo.Username =~ UsernameRegex
       AND ProcInfo.Exe =~ ProcessPathRegex
       AND ProcInfo.CommandLine =~ CommandLineRegex
       AND CallChain =~ CallChainRegex

column_types:
  - name: ChildrenTree
    type: tree

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/generic.system.efisignatures.md
======
---
title: Generic.System.EfiSignatures
hidden: true
tags: [Client Artifact]
---

Collect Efi Signature information from the client.


<pre><code class="language-yaml">
name: Generic.System.EfiSignatures
description: |
  Collect Efi Signature information from the client.

type: CLIENT
export: |
    -- GUIDs are taken from
    -- https://github.com/chipsec/chipsec/blob/main/chipsec/hal/uefi_common.py
    LET PROFILE = '''[
      ["EfiSignatures", 0, [
        ["__tmp", 0, "uint32"],
        ["__Signatures", 0, "Union", {
          "selector": "x=&gt;x.__tmp &lt; 257",
          "choices": {
            "true": "EfiSignaturesListAttrib",
            "false": "EfiSignaturesList"
          }
        }],
        ["Signatures", 0, "Value", {"value": "x=&gt;x.__Signatures.Signatures"}]
      ]],
      ["EfiSignaturesListAttrib", 0, [
        ["__Attributes", 0, "uint32"],
        ["Signatures", 4, "Array", {"type": "Signature", "count": 1000}]
      ]],
      ["EfiSignaturesList", 0, [
        ["Signatures", 0, "Array", {"type": "Signature", "count": 1000}]
      ]],
      ["Signature", "x=&gt;x.__ListSize", [
        ["__Type", 0, "GUID"],
        ["Type", 0, "Value", {"value": "x=&gt;x.__Type.Value"}],
        ["__ListSize", 16, "uint32"],
        ["__HeaderSize", 20, "uint32"],
        ["Payload", 24, "Union", {
          "selector": "x=&gt;x.Type",
          "choices": {
            "{a5c059a1-94e4-4aa7-87b5-ab155c2bf072}": "Cert",
            "{c1c41626-504c-4092-aca9-41f936934328}": "HashList"
          }
        }]
      ]],
      ["Cert", "x=&gt;x.__SignatureSize + 4", [
        ["__SignatureSize", 0, "uint32"],
        ["__Owner", 4, "GUID"],
        ["Owner", 0, "Value", {"value": "x=&gt;x.__Owner.Value"}],
        ["__Data", 20, "String", {"length": "x=&gt;x.__SignatureSize - 16", "term": "", "max_length": 10000}],
        ["Cert", 0, "Value", {"value": "x=&gt;parse_x509(data=x.__Data)[0]"}]
      ]],
      ["HashList", 0, [
        ["__SignatureSize", 0, "uint32"],
        ["Hashes", 4, "Array", {"type": "Hash", "count": 1000, "sentinel": "x=&gt;x.Owner = '{00000000-0000-0000-0000-000000000000}'"}]
      ]],
      ["Hash", 48, [
        ["__Owner", 0, "GUID"],
        ["Owner", 0, "Value", {"value": "x=&gt;x.__Owner.Value"}],
        ["__Data", 16, "String", {"length": 32, "term": ""}],
        ["Hash", 0, "Value", {"value": "x=&gt;format(format='%048x', args=[x.__Data])"}]
      ]],
      ["GUID", 16, [
        ["__D1", 0, "uint32"],
        ["__D2", 4, "uint16"],
        ["__D3", 6, "uint16"],
        ["__D4", 8, "String", {"term": "", "length": 2}],
        ["__D5", 10, "String", {"term": "", "length": 6}],
        ["Value", 0, "Value", {
          "value": "x=&gt;format(format='{%08x-%04x-%04x-%02x-%02x}', args=[x.__D1, x.__D2, x.__D3, x.__D4, x.__D5])"
        }]
      ]]
    ]'''

    LET GetSignatures(Namespace, Name) = Select Name as Name,
       parse_binary(accessor="data", filename=Value,
                    profile=PROFILE, struct="EfiSignatures").Signatures as Signatures
    FROM efivariables(namespace=Namespace, name=Name, value=True)

sources:
  - name: Certificates
    query: |
      LET PK = Select * FROM foreach(
          row=GetSignatures(Namespace="{8be4df61-93ca-11d2-aa0d-00e098032b8c}", Name="PK"),
          query={
              Select * From foreach(
                  row=Signatures,
                  query={
                      Select Name, Owner, Cert as Certificate From Payload
                  })
          })
      LET DB = Select * FROM foreach(
          row=GetSignatures(Namespace="{d719b2cb-3d3a-4596-a3bc-dad00e67656f}", Name="db"),
          query={
              Select * From foreach(
                  row=Signatures,
                  query={
                      Select Name, Owner, Cert as Certificate From Payload
                  })
          })

       Select * from chain(
          a={ Select * From PK },
          b={ Select * From DB })

  - name: Hashes
    query: |
      Select * FROM foreach(
          row=GetSignatures(Namespace="{d719b2cb-3d3a-4596-a3bc-dad00e67656f}", Name="dbx"),
          query={
              Select * From foreach(
                  row=Signatures,
                  query={
                      Select * FROM foreach(
                          row=Payload.Hashes,
                          query={
                              Select Name, Owner, Hash From scope()
                          })
                  })
          })

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/admin.client.updateclientconfig.md
======
---
title: Admin.Client.UpdateClientConfig
hidden: true
tags: [Client Artifact]
---

Sometimes we wish to move a client from one org ID to another. This
requires updating the config on the client and rekeying the client.

This artifact will replace the client's config file and restart
it. The config file will be verified before replacing it. If set to
not rekey, the client will retain its client id but will be killed -
the service manager should restart it and cause the new config to
reload.

This artifact has a notebook suggestion that allows a client to be
changed to a different org.


<pre><code class="language-yaml">
name: Admin.Client.UpdateClientConfig
description: |
  Sometimes we wish to move a client from one org ID to another. This
  requires updating the config on the client and rekeying the client.

  This artifact will replace the client's config file and restart
  it. The config file will be verified before replacing it. If set to
  not rekey, the client will retain its client id but will be killed -
  the service manager should restart it and cause the new config to
  reload.

  This artifact has a notebook suggestion that allows a client to be
  changed to a different org.

parameters:
   - name: ConfigYaml
     description: The new config to write in yaml form.
   - name: ConfigPath
     description: Path of config file to overwrite
   - name: WaitPeriod
     type: int
     default: 10
   - name: RekeyClient
     type: bool
     default: Y
     description: Should the client rekey its client ID.

sources:
  - query: |

        LET ValidateConfig(Config) = Config.Client.server_urls
          AND Config.Client.ca_certificate =~ "(?ms)-----BEGIN CERTIFICATE-----.+-----END CERTIFICATE-----"
          AND Config.Client.nonce

        LET CheckConfigPath(ConfigPath) = SELECT * FROM stat(filename=ConfigPath)
        LET Config &lt;=  parse_yaml(accessor="data", filename=ConfigYaml)

        LET DoIt = if(condition=ValidateConfig(Config=Config),
          else=log(level="ERROR", message="Config is invalid") AND FALSE,
          then=if(condition=CheckConfigPath(ConfigPath=ConfigPath).OSPath,
             else=log(level="ERROR",
                      message="Config Path %v is invalid",
                      args=ConfigPath) AND FALSE,
             then=copy(accessor="data", filename=ConfigYaml, dest=ConfigPath)
                AND if(condition= RekeyClient,
                then=log(message="Rekeying in %v seconds ", args=WaitPeriod)
                     AND rekey(wait=WaitPeriod),
                else=pskill(pid=getpid()))
        ))

        SELECT DoIt AS Success FROM scope()

    notebook:
    - name: Move a client to a different OrgId
      type: vql_suggestion
      template: |

        LET ClientId = "C.622d19ea21109231"
        LET RequiredOrgId = "O123"
        LET ConfigPath = "C:/Program Files/Velociraptor/client.config.yaml"

        SELECT _client_config AS Config, OrgId ,
            collect_client(artifacts="Admin.Client.UpdateClientConfig",
                           client_id=ClientId,
                           env=dict(ConfigYaml=_client_config,
                                    ConfigPath=ConfigPath))
        FROM orgs()
        WHERE OrgId = RequiredOrgId
        LIMIT 1

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/server.utils.backupgcs.md
======
---
title: Server.Utils.BackupGCS
hidden: true
tags: [Server Event Artifact]
---

This server monitoring artifact will automatically zip and backup
any collected artifacts to GCS.

You will need to provide credentials to upload to the bucket. The
credentials can be given as parameters or they will be taken from
the server metadata (as DefaultBucket, DefaultGCSProject,
DefaultGCSKey)

Thanks to @shortxstack and @Recon_InfoSec


<pre><code class="language-yaml">
name: Server.Utils.BackupGCS
description: |
   This server monitoring artifact will automatically zip and backup
   any collected artifacts to GCS.

   You will need to provide credentials to upload to the bucket. The
   credentials can be given as parameters or they will be taken from
   the server metadata (as DefaultBucket, DefaultGCSProject,
   DefaultGCSKey)

   Thanks to @shortxstack and @Recon_InfoSec

type: SERVER_EVENT

parameters:
   - name: ArtifactNameRegex
     default: "."
     description: A regular expression to select which artifacts to upload
     type: regex

   - name: Bucket
     description: The bucket to upload to (blank to use server metadata)
   - name: Project
   - name: GCSKey

   - name: RemoveDownloads
     type: bool
     description: If set, remove the flow export files after upload

sources:
  - query: |
      -- Allow these settings to be set by the artifact parameter or the server metadata.
      LET bucket &lt;= if(condition=Bucket, then=Bucket,
           else=server_metadata().DefaultBucket)
      LET project &lt;= if(condition=Project, then=Project,
           else=server_metadata().DefaultGCSProject)
      LET gcskey &lt;= if(condition=GCSKey, then=GCSKey,
           else=server_metadata().DefaultGCSKey)

      LET completions = SELECT *,
         client_info(client_id=ClientId).os_info.fqdn AS Fqdn,
         create_flow_download(client_id=ClientId,
             flow_id=FlowId, wait=TRUE) AS FlowDownload
      FROM watch_monitoring(artifact="System.Flow.Completion")
      WHERE Flow.artifacts_with_results =~ ArtifactNameRegex

      SELECT upload_gcs(
         bucket=bucket,
         project=project,
         credentials=gcskey,
         file=FlowDownload,
         accessor="fs",
         name=format(format="Host %v %v %v.zip",
                     args=[Fqdn, FlowId, timestamp(epoch=now())])) AS Upload
      FROM completions
      WHERE Upload OR
        if(condition=RemoveDownloads,
           then=rm(filename=file_store(path=FlowDownload)))

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.system.powershell.moduleanalysiscache.md
======
---
title: Windows.System.Powershell.ModuleAnalysisCache
hidden: true
tags: [Client Artifact]
---

ModuleAnalysisCache stores metadata about loaded Powershell modules.

Recent updates include filters by regex to enable targeted hunting
use cases.


<pre><code class="language-yaml">
name: Windows.System.Powershell.ModuleAnalysisCache
description: |
    ModuleAnalysisCache stores metadata about loaded Powershell modules.

    Recent updates include filters by regex to enable targeted hunting
    use cases.

reference:
 - https://github.com/PowerShell/PowerShell/blob/281b437a65360ae869d40f3766a1f2bbba786e5e/src/System.Management.Automation/engine/Modules/AnalysisCache.cs#L649

parameters:
  - name: GlobLookup
    default: C:\{Users\*,Windows\System32\config\systemprofile}\AppData\Local\Microsoft\Windows\PowerShell\ModuleAnalysisCache
  - name: ModulePathRegex
    description: Regex of installed ModulePath to target.
    default: .
    type: regex
  - name: ModulePathIgnoreRegex
    description: Regex of installed ModulePath to ignore.
    type: regex
  - name: FunctionNameRegex
    description: Regex of FunctionName to include.
    default: .
    type: regex

sources:
  - query: |
      LET Profile = '
       [
         ["Header", 0, [
           ["Signature", 0, "String", {"length": 13}],
           ["CountOfEntries", 14, "uint32"],
           ["Entries", 18, "Array",
                 {"type": "Entry", "count": "x =&gt; x.CountOfEntries"}]
         ]],

         ["Entry", "x=&gt;x.Func.SizeOf + x.ModuleLength + 20", [
           ["Offset", 0, "Value", {"value": "x =&gt; x.StartOf"}],
           ["TimestampTicks", 0, "uint64"],
           ["ModuleLength", 8, "uint32"],
           ["ModuleName", 12, "String", {"length": "x =&gt; x.ModuleLength"}],
           ["CommandCount", "x =&gt; x.ModuleLength + 12", "uint32"],
           ["Func", "x =&gt; x.ModuleLength + 16", "Array",
                  {"type": "FunctionInfo", "count": "x =&gt; x.CommandCount"}],
           ["CountOfTypes", "x =&gt; x.Func.EndOf", "uint32"]
         ]],

         ["FunctionInfo", "x =&gt; x.NameLen + 8", [
           ["NameLen", 0, "uint32"],
           ["Name", 4, "String", {"length": "x =&gt; x.NameLen"}],
           ["Count", "x =&gt; x.NameLen + 4", "uint32"]
         ]]
       ]
      '
      LET parsed = SELECT OSPath,
         parse_binary(filename=OSPath, profile=Profile, struct="Header") AS Header
      FROM glob(globs=GlobLookup)

      SELECT * FROM foreach(row=parsed,
      query={
         SELECT * FROM foreach(row=Header.Entries,
         query={
            SELECT OSPath, ModuleName,
                  timestamp(epoch=TimestampTicks/10000000 - 62136892800) AS Timestamp,
                  Func.Name AS Functions
            FROM scope()
            WHERE ModuleName =~ ModulePathRegex
                AND NOT if(condition= ModulePathIgnoreRegex,
                            then= ModuleName =~ ModulePathIgnoreRegex,
                            else= False )
                AND filter(list=Functions,regex=FunctionNameRegex)
         })
      })

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.events.mutants.md
======
---
title: Windows.Events.Mutants
hidden: true
tags: [Client Event Artifact]
---

This artifact detects creation of Mutants and triggers an alert. 


<pre><code class="language-yaml">
name: Windows.Events.Mutants
description: |
  This artifact detects creation of Mutants and triggers an alert. 

author: Jos Clephas - @DfirJos

type: CLIENT_EVENT

precondition:
  SELECT * FROM info() WHERE OS =~ "windows"

parameters:
  - name: processRegex
    description: A regex applied to process names.
    default: .
    type: regex
  - name: Period
    type: int
    default: 120
  - name: MutantNameRegex
    default: EvilMutant
    type: regex
  - name: AlertName
    default: "Suspicious mutex created"
  - name: diff
    default: added
  - name: enrich
    description: Enrich mutex with process information. Closely monitor the performance impact if you enable this.
    type: bool
    default: N

sources:
    - query: |
    
        LET processes = SELECT Pid AS ProcPid, Name AS ProcName, Exe FROM process_tracker_pslist() WHERE ProcName =~ processRegex AND int(int=ProcPid) &gt; 0

        LET query_mutant = SELECT * FROM winobj() WHERE Type = "Mutant" AND Name =~ MutantNameRegex 

        LET query_enriched = SELECT * FROM foreach(
          row=processes,
          query={
            SELECT ProcPid, ProcName, Exe, Type, Name, Handle
            FROM handles(pid=int(int=ProcPid), types="Mutant")
          })
        WHERE Type = "Mutant" AND Name =~ MutantNameRegex
        
        LET query_diff = if(condition=enrich, then=query_enriched, else=query_mutant) 
        
        SELECT *, alert(name=AlertName, Name=Name, Type=Type, Exe=Exe) as AlertSent FROM diff(query=query_diff, period=Period, key="Name") WHERE Diff = diff

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/linux.events.ebpf.md
======
---
title: Linux.Events.EBPF
hidden: true
tags: [Client Event Artifact]
---

This artifact forwards EBPF events generated on the endpoint.


<pre><code class="language-yaml">
name: Linux.Events.EBPF
description: |
  This artifact forwards EBPF events generated on the endpoint.

precondition: |
  SELECT OS From info() where OS = 'linux'

type: CLIENT_EVENT

parameters:
  - name: Events
    description: Events to forward
    type: csv
    default: |
      Event,Desc,Enabled
      bpf_attach,A bpf program is attached,Y
      chdir,Process changes directory,N
      fchownat,File ownership is changed,Y
      file_modification,A process changes the ctime of a file,N
      kill,Kill another process,Y
      magic_write,Intercepts file writes to capture the header magic,N
      mkdir,Process makes new directory,N
      module_free,A module is unloaded from the kernel,Y
      mount,A filesystem is mounted,Y
      openat,A process is opening a file (noisy),N
      openat2,A process is opening a file (noisy),N
      sched_process_exec,A process starts,Y
      sched_process_exit,A process ends,Y
      security_file_open,Files are opened,Y
      security_inode_mknod,A new node is created with mknod (e.g. fifo or device file),Y
      security_inode_rename,File is being renamed,N
      security_inode_symlink,Create a symlink,Y
      security_kernel_post_read_file,Fires when the kernel reads a file (e.g. module),Y
      security_socket_accept,A process accepted a connection,Y
      security_socket_bind,A process bind to a local port,Y
      security_socket_connect,A process is making a connection,Y
      setxattr,Setting and extended attribute to a file,Y
      umount2,A filesystem is being unmounted,Y
      unlink,A file is deleted,Y

sources:
  - query: |
      LET SelectedEvents &lt;= SELECT * FROM Events WHERE Enabled =~ "Y"

      SELECT * FROM watch_ebpf(events=SelectedEvents.Event)

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.sys.interfaces.md
======
---
title: Windows.Sys.Interfaces
hidden: true
tags: [Client Artifact]
---

Report information about the systems interfaces. This artifact
simply parses the output from ipconfig /all.


<pre><code class="language-yaml">
name: Windows.Sys.Interfaces
description: |
  Report information about the systems interfaces. This artifact
  simply parses the output from ipconfig /all.

sources:
 - precondition:
     SELECT OS from info() where OS = "windows"
   query: |
     // Run ipconfig to get all information about interfaces.
     LET ipconfig = SELECT * FROM execve(argv=['ipconfig', '/all'])

     // This produces a single row per interface.
     LET interfaces = SELECT Name, Data FROM parse_records_with_regex(
        file=ipconfig.Stdout,
        accessor='data',      // This makes the data appear as a file.
        regex='(?s)Ethernet adapter (?P&lt;Name&gt;[^:]+?):\r\n\r\n(?P&lt;Data&gt;.+?)\r\n(\r\n|$)')

     // Now extract interesting things from each interface definition.
     SELECT Name, parse_string_with_regex(
        string=Data,
        regex=[
          "Description[^:]+: (?P&lt;Description&gt;.+)\r\n",
          "Physical Address[^:]+: (?P&lt;MAC&gt;.+)\r\n",
          "IPv4 Address[^:]+: (?P&lt;IP&gt;[0-9.]+)",
          "Default Gateway[^:]+: (?P&lt;Gateway&gt;.+)\r\n",
          "DNS Servers[^:]+: (?P&lt;DNS&gt;.+)\r\n   [^ ]",
          "DHCP Server[^:]+: (?P&lt;DHCP&gt;.+)\r\n"
        ]
     ) As Details FROM interfaces

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.detection.thumbdrives.officekeywords.md
======
---
title: Windows.Detection.Thumbdrives.OfficeKeywords
hidden: true
tags: [Client Event Artifact]
---

Users inserting Thumb drives or other Removable drive pose a
constant security risk. The external drive may contain malware or
other undesirable content. Additionally thumb drives are an easy way
for users to exfiltrate documents.

This artifact automatically scans any office files copied to a
removable drive for keywords. This could be useful to detect
exfiltration attempts of restricted documents.

We exclude very large removable drives since they might have too
many files.


<pre><code class="language-yaml">
name: Windows.Detection.Thumbdrives.OfficeKeywords
description: |
  Users inserting Thumb drives or other Removable drive pose a
  constant security risk. The external drive may contain malware or
  other undesirable content. Additionally thumb drives are an easy way
  for users to exfiltrate documents.

  This artifact automatically scans any office files copied to a
  removable drive for keywords. This could be useful to detect
  exfiltration attempts of restricted documents.

  We exclude very large removable drives since they might have too
  many files.

type: CLIENT_EVENT

parameters:
  - name: officeExtensions
    default: "\\.(xls|xlsm|doc|docx|ppt|pptm)$"
    type: regex

  - name: yaraRule
    description: This yara rule will be run on document contents.
    type: yara
    default: |
      rule Hit {
        strings:
          $a = "this is my secret" wide nocase
          $b = "this is my secret" nocase

        condition:
          any of them
      }

sources:
  - query: |
        SELECT * FROM foreach(
          row = {
            SELECT * FROM Artifact.Windows.Detection.Thumbdrives.List()
            WHERE OSPath =~ officeExtensions
          },
          query = {
            SELECT * FROM Artifact.Generic.Applications.Office.Keywords(
              yaraRule=yaraRule, searchGlob=OSPath, documentGlobs="")
          })

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.detection.yara.process.md
======
---
title: Windows.Detection.Yara.Process
hidden: true
tags: [Client Artifact]
---

This artifact enables running Yara over processes in memory.

There are 2 kinds of Yara rules that can be deployed:

1. Url link to a yara rule.
3. or a Standard Yara rule attached as a parameter.

Only one method of Yara will be applied and search order is as above. The
default is Cobalt Strike opcodes.

Regex parameters can be applied for process name and pid for targeting. The
artifact also has an option to upload any process with Yara hits.

Note: by default the Yara scan will stop after one hit. Multi-string rules will also only
show one string in returned rows.
If upload is selected NumberOfHits is redundant and not advised as hits are
grouped by path to ensure files only downloaded once.


<pre><code class="language-yaml">
name: Windows.Detection.Yara.Process
author: Matt Green - @mgreen27
description: |
  This artifact enables running Yara over processes in memory.

  There are 2 kinds of Yara rules that can be deployed:

  1. Url link to a yara rule.
  3. or a Standard Yara rule attached as a parameter.

  Only one method of Yara will be applied and search order is as above. The
  default is Cobalt Strike opcodes.

  Regex parameters can be applied for process name and pid for targeting. The
  artifact also has an option to upload any process with Yara hits.

  Note: by default the Yara scan will stop after one hit. Multi-string rules will also only
  show one string in returned rows.
  If upload is selected NumberOfHits is redundant and not advised as hits are
  grouped by path to ensure files only downloaded once.


type: CLIENT
parameters:
  - name: ProcessRegex
    default: .
    type: regex
  - name: PidRegex
    default: .
    type: regex
  - name: UploadHits
    type: bool
  - name: YaraUrl
    description: If configured will attempt to download Yara rules from Url
    type: upload
  - name: YaraRule
    type: yara
    description: Final Yara option and the default if no other options provided.
    default: |
      rule win_cobalt_strike_auto {
         meta:
           author = "Felix Bilstein - yara-signator at cocacoding dot com"
           date = "2019-11-26"
           version = "1"
           description = "autogenerated rule brought to you by yara-signator"
           tool = "yara-signator 0.2a"
           malpedia_reference = "https://malpedia.caad.fkie.fraunhofer.de/details/win.cobalt_strike"
           malpedia_license = "CC BY-SA 4.0"
           malpedia_sharing = "TLP:WHITE"

         strings:
           $sequence_0 = { 3bc7 750d ff15???????? 3d33270000 }
           $sequence_1 = { e9???????? eb0a b801000000 e9???????? }
           $sequence_2 = { 8bd0 e8???????? 85c0 7e0e }
           $sequence_3 = { ffb5f8f9ffff ff15???????? 8b4dfc 33cd e8???????? c9 c3 }
           $sequence_4 = { e8???????? e9???????? 833d?????????? 7505 e8???????? }
           $sequence_5 = { 250000ff00 33d0 8b4db0 c1e908 }
           $sequence_6 = { ff75f4 ff7610 ff761c ff75fc }
           $sequence_7 = { 8903 6a06 eb39 33ff 85c0 762b 03f1 }
           $sequence_8 = { 894dd4 8b458c d1f8 894580 8b45f8 c1e818 0fb6c8 }
           $sequence_9 = { 890a 8b4508 0fb64804 81e1ff000000 c1e118 8b5508 0fb64205 }
           $sequence_10 = { 33d2 e8???????? 48b873797374656d3332 4c8bc7 488903 49ffc0 }
           $sequence_11 = { 488bd1 498d4bd8 498943e0 498943e8 }
           $sequence_12 = { b904000000 486bc90e 488b542430 4c8b442430 418b0c08 8b0402 }
           $sequence_13 = { ba80000000 e8???????? 488d4c2438 e8???????? 488d4c2420 8bd0 e8???????? }
           $sequence_14 = { 488b4c2430 8b0401 89442428 b804000000 486bc004 }
           $sequence_15 = { 4883c708 4883c304 49ffc3 48ffcd 0f854fffffff 488d4c2420 }

        condition:
            7 of them
      }
  - name: NumberOfHits
    description: THis artifact will stop by default at one hit. This setting allows additional hits
    default: 1
    type: int
  - name: ContextBytes
    description: Include this amount of bytes around hit as context.
    default: 0
    type: int64
  - name: ExePathWhitelist
    description: Regex of ProcessPaths to exclude
    type: regex


sources:
  - precondition:
      SELECT OS From info() where OS = 'windows'

    query: |
      -- check which Yara to use
      LET yara_rules &lt;= YaraUrl || YaraRule
      
      -- find velociraptor process
      LET me = SELECT Pid FROM pslist(pid=getpid())

      -- find all processes and add filters
      LET processes = SELECT Name as ProcessName, Exe as ExePath, CommandLine, Pid, WorkingSetSize
        FROM pslist()
        WHERE
            Name =~ ProcessRegex
            AND format(format="%d", args=Pid) =~ PidRegex
            AND NOT Pid in me.Pid
            AND NOT if(condition=ExePathWhitelist,
                    then= Exe=~ExePathWhitelist)

      -- scan processes in scope with our rule, limit 1 hit
      LET hits = SELECT * FROM foreach(
        row=processes,
        query={
            SELECT
                ProcessName,
                ExePath,
                CommandLine,
                Pid,
                Rule,
                Tags,
                Meta,
                String.Name as YaraString,
                String.Offset as HitOffset,
                upload( accessor='scope',
                    file='String.Data',
                    name=format(format="%v-%v_%v",
                    args=[
                        split(string=ProcessName, sep='\\.')[0], Pid,
                        String.Offset ]
                    )) as HitContext
                
            FROM proc_yara(
                            pid=int(int=Pid),
                            rules=yara_rules,
                            context=ContextBytes,
                            number=NumberOfHits
                        )
          })

      -- upload hits using proc_dump plugin
      LET upload_hits = SELECT * FROM foreach(
        row=hits,
        query={
            SELECT 
                ProcessName,
                ExePath,
                CommandLine,
                Pid,
                Rule,
                Tags,
                Meta,
                YaraString,
                HitOffset,
                HitContext,
                upload(
                  file=OSPath,
                  name=format(format='%v-%v.dmp',
                    args= [ split(string=ProcessName, sep='\\.')[0], Pid ])
                ) as ProcessDump
            FROM proc_dump(pid=Pid)
          })
          
      -- return rows
      SELECT * FROM if(condition=UploadHits,
        then=upload_hits,
        else=hits)

column_types:
  - name: HitContext
    type: preview_upload
</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/linux.network.netstat.md
======
---
title: Linux.Network.Netstat
hidden: true
tags: [Client Artifact]
---

This artifact will parse /proc and reveal information
about current network connections.


<pre><code class="language-yaml">
name: Linux.Network.Netstat
description: |
   This artifact will parse /proc and reveal information
   about current network connections.

type: CLIENT

parameters:
   - name: StateRegex
     type: regex
     default: "LISTEN|ESTAB"
     description: Only show these states

sources:
  - precondition:
      SELECT OS From info() where OS = 'linux'

    query: |
        -- Break down the address of the form 0100007F:22B9
        LET _X(x) = parse_string_with_regex(string=addr,
          regex="(..)(..)(..)(..):(....)")

        -- Unroll hex encoded IPv4 address into more usual form.
        LET ParseAddress(addr) = dict(
            IP=format(format="%d.%d.%d.%d", args=[
               int(int="0x" + _X(x=addr).g4),
               int(int="0x" + _X(x=addr).g3),
               int(int="0x" + _X(x=addr).g2),
               int(int="0x" + _X(x=addr).g1)]),
            Port=int(int="0x" + _X(x=addr).g5)
        )

        -- https://elixir.bootlin.com/linux/latest/source/include/net/tcp_states.h#L14
        LET StateLookup &lt;= dict(
           `01`="Established",
           `02`="Syn Sent",
           `06`="Time Wait", -- No owner process
           `0A`="Listening"
        )

        -- Enumerate all the sockets and cache them in memory for
        -- reverse lookup. The following is basically lsof.
        LET X = SELECT OSPath[1] AS Pid,
               Data.Link AS Filename,
               parse_string_with_regex(
                  string=Data.Link,
                  regex="(?P&lt;Type&gt;socket|pipe):\\[(?P&lt;inode&gt;[0-9]+)\\]") AS Details
        FROM glob(globs="/proc/*/fd/*")

        LET AllSockets &lt;= SELECT atoi(string=Pid) AS Pid,
               read_file(filename="/proc/" + Pid + "/comm") AS Command,
               read_file(filename="/proc/" + Pid + "/cmdline") AS CommandLine,
               Filename,
               Details.Type AS Type,
               Details.inode AS Inode
        FROM X
        WHERE Type =~ "socket"

        -- Parse the TCP table and refer back to the socket
        -- so we can print process info.
        SELECT inode, get(item=StateLookup, field=st) AS State, uid, {
                  SELECT * FROM AllSockets
                  WHERE Inode=inode
                  LIMIT 1
               } AS ProcessInfo,
               ParseAddress(addr=local_address) AS LocalAddr,
               ParseAddress(addr=rem_address) AS RemoteAddr
        FROM split_records(
             columns=["_", "sl","local_address", "rem_address", "st", "queues", "tr_tm_when",
                      "retransmit", "uid", "timeout", "inode"],
             filenames="/proc/net/tcp",
             regex=" +")
        WHERE sl =~ ":"  -- Remove header row
          AND State =~ StateRegex

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.registry.ntuser.upload.md
======
---
title: Windows.Registry.NTUser.Upload
hidden: true
tags: [Client Artifact]
---

This artifact collects all the user's NTUser.dat registry hives.

When a user logs into a windows machine the system creates their own
"profile" which consists of a registry hive mapped into the
HKEY_USERS hive. This hive file is locked as long as the user is
logged in.

This artifact bypasses the locking mechanism by extracting the
registry hives using raw NTFS parsing. We then just upload all hives
to the server.


<pre><code class="language-yaml">
name: Windows.Registry.NTUser.Upload
description: |
  This artifact collects all the user's NTUser.dat registry hives.

  When a user logs into a windows machine the system creates their own
  "profile" which consists of a registry hive mapped into the
  HKEY_USERS hive. This hive file is locked as long as the user is
  logged in.

  This artifact bypasses the locking mechanism by extracting the
  registry hives using raw NTFS parsing. We then just upload all hives
  to the server.

parameters:
  - name: userRegex
    default: .
    type: regex

sources:
  - precondition: |
      SELECT OS From info() where OS = 'windows'
    query: |
        LET users = SELECT
            Name,
            expand(path=Directory) AS HomeDir
        FROM Artifact.Windows.Sys.Users()
        WHERE HomeDir AND Name =~ userRegex

        SELECT upload(file=HomeDir + "\\ntuser.dat",
                      accessor="auto") as Upload
        FROM users

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/notebooks.default.md
======
---
title: Notebooks.Default
hidden: true
tags: [notebook]
---

A default notebook.


<pre><code class="language-yaml">
name: Notebooks.Default
description: |
  A default notebook.

type: NOTEBOOK

sources:
  - notebook:
    - type: markdown
      name: Welcome page
      template: |
        # Welcome to Velociraptor notebooks!

        * Update this notebook with any VQL or markdown cells.
        * You can copy cells into this notebook from other collection or hunt notebooks.

    - type: vql_suggestion
      name: A Cell Suggestion
      template: |
        /*
        # This is a cell suggestion
        */
        SELECT * FROM info()

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/linux.forensics.journal.md
======
---
title: Linux.Forensics.Journal
hidden: true
tags: [Client Artifact]
---

Parses the binary journal logs. Systemd uses a binary log format to
store logs.


<pre><code class="language-yaml">
name: Linux.Forensics.Journal
description: |
  Parses the binary journal logs. Systemd uses a binary log format to
  store logs.

parameters:
- name: JournalGlob
  type: glob
  description: A Glob expression for finding journal files.
  default: /{run,var}/log/journal/*/*.journal

- name: DateAfter
  type: timestamp
  description: "search for events after this date. YYYY-MM-DDTmm:hh:ssZ"

- name: DateBefore
  type: timestamp
  description: "search for events before this date. YYYY-MM-DDTmm:hh:ssZ"

- name: AlsoUpload
  type: bool
  description: If set we also upload the raw files.

sources:
- name: Uploads
  query: |
    SELECT * FROM if(condition=AlsoUpload,
    then={
       SELECT OSPath, upload(file=OSPath) AS Upload
       FROM glob(globs=JournalGlob)
    })

- query: |
    SELECT * FROM foreach(row={
      SELECT OSPath FROM glob(globs=JournalGlob)
    }, query={
      SELECT *
      FROM parse_journald(filename=OSPath,
          start_time=DateAfter, end_time=DateBefore)
    })

  notebook:
    - type: vql_suggestion
      name: Simplified syslog-like view
      template: |
        /*
        # Simplified log view
        */
        LET ColumnTypes&lt;=dict(`_ClientId`='client')

        SELECT System.Timestamp AS Timestamp,
               ClientId AS _ClientId,
               client_info(client_id=ClientId).os_info.hostname AS Hostname,
               EventData.SYSLOG_IDENTIFIER AS Unit,
               EventData.MESSAGE AS Message
        FROM source()

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.etw.edgeurls.md
======
---
title: Windows.ETW.EdgeURLs
hidden: true
tags: [Client Event Artifact]
---

This client event artifact collects all URLs accessed by the Edge browser.

It is an example of an ETW artifact using the provider

Microsoft-Windows-URLMon                 {245F975D-909D-49ED-B8F9-9A75691D6B6B}

NOTE: This artifact can generate a lot of data - you probably want
to filter the URLs a bit and/or target collection to a narrow label
group.


<pre><code class="language-yaml">
name: Windows.ETW.EdgeURLs
description: |
  This client event artifact collects all URLs accessed by the Edge browser.

  It is an example of an ETW artifact using the provider

  Microsoft-Windows-URLMon                 {245F975D-909D-49ED-B8F9-9A75691D6B6B}

  NOTE: This artifact can generate a lot of data - you probably want
  to filter the URLs a bit and/or target collection to a narrow label
  group.

type: CLIENT_EVENT

parameters:
  - name: URLFilter
    default: .
    description: A regex that can be used to filter uninteresting URLs
    type: regex

sources:
  - query: |
      LET m &lt;= memoize(key="Pid", period=30, query={
          SELECT Pid, Exe, Username FROM pslist()
      })

      SELECT System.ID AS ID,
             System.TimeStamp AS Timestamp,
             get(item=m, field=System.ProcessID) AS ProcInfo,
             get(member="EventData.URL") AS URL
      FROM watch_etw(
        description="Microsoft-Windows-URLMon",
        guid="{245F975D-909D-49ED-B8F9-9A75691D6B6B}")
      WHERE ID = 805 AND URL =~ URLFilter

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/admin.system.compressuploads.md
======
---
title: Admin.System.CompressUploads
hidden: true
tags: [Server Event Artifact]
---

Compresses all uploaded files.

When artifacts collect files they are normally stored on the server
uncompressed. This artifact watches all completed flows and
compresses the files in the file store when the flow completes. This
is very useful for cloud based deployments with limited storage
space or when collecting large files.

In order to run this artifact you would normally run it as part of
an artifact acquisition process:

```
$ velociraptor --config /etc/server.config.yaml artifacts acquire Admin.System.CompressUploads
```

Note that there is nothing special about compressed files - you can
also just run `find` and `gzip` in the file store. Velociraptor will
automatically decompress the file when displaying it in the GUI
text/hexdump etc.


```yaml
name: Admin.System.CompressUploads
description: |
  Compresses all uploaded files.

  When artifacts collect files they are normally stored on the server
  uncompressed. This artifact watches all completed flows and
  compresses the files in the file store when the flow completes. This
  is very useful for cloud based deployments with limited storage
  space or when collecting large files.

  In order to run this artifact you would normally run it as part of
  an artifact acquisition process:

  ```
  $ velociraptor --config /etc/server.config.yaml artifacts acquire Admin.System.CompressUploads
  ```

  Note that there is nothing special about compressed files - you can
  also just run `find` and `gzip` in the file store. Velociraptor will
  automatically decompress the file when displaying it in the GUI
  text/hexdump etc.

type: SERVER_EVENT

parameters:
  - name: blacklistCompressionFilename
    type: regex
    description: Filenames which match this regex will be excluded from compression.
    default: 'ntuser.dat$'

sources:
  - query: |
      LET files = SELECT ClientId,
            Flow.session_id as Flow,
            Flow.uploaded_files as Files
        FROM watch_monitoring(artifact='System.Flow.Completion')
        WHERE Files and not Files =~ blacklistCompressionFilename

      SELECT ClientId, Flow, Files,
               compress(path=Files) as CompressedFiles
        FROM files

```

---END OF FILE---

======
FILE: /content/artifact_references/pages/server.utils.deletenotebook.md
======
---
title: Server.Utils.DeleteNotebook
hidden: true
tags: [Server Artifact]
---

Completely removes a notebook from the server including all its cells, attachments etc.


<pre><code class="language-yaml">
name: Server.Utils.DeleteNotebook
description: |
  Completely removes a notebook from the server including all its cells, attachments etc.

type: SERVER

parameters:
  - name: NotebookId
    description: The ID of the notebook to remove.
  - name: ReallyDoIt
    type: bool
    description: Set to really remove the notebook - otherwise it is a dry run.

sources:
  - query: |
      SELECT * FROM notebook_delete(
          notebook_id=NotebookId, really_do_it=ReallyDoIt)

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/server.hunts.addflow.md
======
---
title: Server.Hunts.AddFlow
hidden: true
tags: [Server Artifact]
---

This artifact adds an exisiting flow to a running hunt.

This helps in the case where the original flow in the hunt timed
out. The user then can re-run the hunt manually possibly increasing
timeout. Then they can simply click the add flow to hunt button in
the UI to add the flow to an existing time.


<pre><code class="language-yaml">
name: Server.Hunts.AddFlow
description: |
  This artifact adds an exisiting flow to a running hunt.

  This helps in the case where the original flow in the hunt timed
  out. The user then can re-run the hunt manually possibly increasing
  timeout. Then they can simply click the add flow to hunt button in
  the UI to add the flow to an existing time.

type: SERVER

parameters:
  - name: HuntId
  - name: ClientId
  - name: FlowId

sources:
  - query: |
      SELECT * FROM if(condition=HuntId AND ClientId AND FlowId,
      then={
         SELECT hunt_add(hunt_id=HuntId,
             client_id=ClientId,
             flow_id=FlowId)
         FROM scope()
      }, else={
         SELECT * FROM scope() WHERE
         log(message="&lt;red&gt;ERROR&lt;/&gt;: You must set HuntId, ClientId and FlowId.") AND FALSE
      })

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/admin.client.upgrade.debian.md
======
---
title: Admin.Client.Upgrade.Debian
hidden: true
tags: [Client Artifact]
---

Remotely push new client updates to Debian hosts.

NOTE: This artifact requires that you supply a client Debian package using the
tools interface or using the "debian client" command. Simply click on the tool
in the GUI and upload a package.


<pre><code class="language-yaml">
name: Admin.Client.Upgrade.Debian
description: |
  Remotely push new client updates to Debian hosts.

  NOTE: This artifact requires that you supply a client Debian package using the
  tools interface or using the "debian client" command. Simply click on the tool
  in the GUI and upload a package.

tools:
  - name: VelociraptorDebian

parameters:
  - name: SleepDuration
    default: "600"
    type: int
    description: |
      The package is typically large and we do not want to
      overwhelm the server so we stagger the download over this many
      seconds.

  - name: ServiceName
    default: "velociraptor_client"
    type: str
    description: |
      The name of the service to restart after the upgrade.

sources:
  - precondition:
      SELECT OS From info() where OS =~ 'linux'

    query:  |
      // FetchBinary downloads to /tmp on linux
      LET bin &lt;= SELECT OSPath AS Dest
      FROM Artifact.Generic.Utils.FetchBinary(
         ToolName="VelociraptorDebian", IsExecutable=FALSE,
         SleepDuration=SleepDuration)

      // Version handling for older clients.
      LET Rm(X) = if(
        condition=version(function='rm')!=NULL,
        then=rm(filename=X),
        else={ SELECT * FROM execve(argv=["rm", "-f", X]) })

      // Call the binary and return all its output in a single row.
      // If we fail to download the binary we do not run the command.
      SELECT * FROM foreach(row=bin,
      query={
        SELECT * FROM chain(
          // Remove the existing prerm - Previous versions had a bug that
          // would shutdown the service during uninstall. See #3122
          a={SELECT * FROM Rm(X="/var/lib/dpkg/info/velociraptor-client.prerm")},

          // Install the new client
          b={SELECT * FROM execve(argv=["dpkg", "-i", str(str=Dest)])},

          // Restart the client
          c={SELECT * FROM execve(argv=["systemctl", "restart", ServiceName])}
        )
      })

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.detection.yara.ntfs.md
======
---
title: Windows.Detection.Yara.NTFS
hidden: true
tags: [Client Artifact]
---

This artifact searches the MFT, returns a list of target files then runs Yara
over the target list.

There are 3 kinds of Yara rules that can be deployed:

1. Url link to a yara rule.
2. Shorthand yara in the format `wide nocase ascii:string1,string2,string3`.
3. or a Standard Yara rule attached as a parameter.

Only one method of Yara will be applied and search order is as above.

The artifact leverages Windows.NTFS.MFT so similar regex filters can be applied
including Path, Size and date. The artifact also has an option to search across
all attached drives and upload any files with Yara hits.

Some examples of path regex may include:

* Extension at a path: `C:\\Windows\\System32\\.+\.dll$`
* More wildcards: `Windows\\.+\\.+\.dll$`
* Specific file: `Windows\\System32\\kernel32\.dll$`
* Multiple extentions: `\.(php|aspx|resx|asmx)$`

Note: no drive and forward slashes - these expressions are for paths
relative to the root of the filesystem.
If upload is selected NumberOfHits is redundant and not advised as hits are
grouped by path to ensure files only downloaded once.


<pre><code class="language-yaml">
name: Windows.Detection.Yara.NTFS
author: Matt Green - @mgreen27
description: |
  This artifact searches the MFT, returns a list of target files then runs Yara
  over the target list.

  There are 3 kinds of Yara rules that can be deployed:

  1. Url link to a yara rule.
  2. Shorthand yara in the format `wide nocase ascii:string1,string2,string3`.
  3. or a Standard Yara rule attached as a parameter.

  Only one method of Yara will be applied and search order is as above.

  The artifact leverages Windows.NTFS.MFT so similar regex filters can be applied
  including Path, Size and date. The artifact also has an option to search across
  all attached drives and upload any files with Yara hits.

  Some examples of path regex may include:

  * Extension at a path: `C:\\Windows\\System32\\.+\.dll$`
  * More wildcards: `Windows\\.+\\.+\.dll$`
  * Specific file: `Windows\\System32\\kernel32\.dll$`
  * Multiple extentions: `\.(php|aspx|resx|asmx)$`

  Note: no drive and forward slashes - these expressions are for paths
  relative to the root of the filesystem.
  If upload is selected NumberOfHits is redundant and not advised as hits are
  grouped by path to ensure files only downloaded once.

type: CLIENT
parameters:
  - name: FileNameRegex
    description: Only file names that match this regular expression will be scanned.
    default: ^kernel32\.dll$
  - name: PathRegex
    description: Only paths that match this regular expression will be scanned.
    default: C:\\Windows\\System32\\
  - name: DriveLetter
    description: "Target drive. Default is a C:"
    default: "C:"
  - name: SizeMax
    type: int
  - name: SizeMin
    type: int
  - name: AllDrives
    type: bool
  - name: UploadHits
    type: bool
  - name: EarliestSILastChanged
    type: timestamp
  - name: LatestSILastChanged
    type: timestamp
  - name: EarliestFNCreation
    type: timestamp
  - name: LatestFNCreation
    type: timestamp
  - name: YaraUrl
    description: If configured will attempt to download Yara rules form Url
    default:
    type: upload
  - name: YaraRule
    type: yara
    description: Final Yara option and the default if no other options provided.
    default: |
        rule IsPE:TestRule {
           meta:
              author = "the internet"
              date = "2021-03-04"
              description = "A simple PE rule to test yara features"
          condition:
             uint16(0) == 0x5A4D and
             uint32(uint32(0x3C)) == 0x00004550
        }
  - name: NumberOfHits
    description: THis artifact will stop by default at one hit. This setting allows additional hits
    default: 1
    type: int64
  - name: ContextBytes
    description: Include this amount of bytes around hit as context.
    default: 0
    type: int


sources:
  - precondition:
      SELECT OS From info() where OS = 'windows'

    query: |
      -- check which Yara to use
      LET yara_rules = YaraUrl || YaraRule

      -- first find all matching files mft
      LET files = SELECT
            OSPath, IsDir
        FROM Artifact.Windows.NTFS.MFT(
            MFTDrive=DriveLetter, AllDrives=AllDrives,
            FileRegex=FileNameRegex,PathRegex=PathRegex,
            SizeMax=SizeMax, SizeMin=SizeMin)
        WHERE NOT IsDir
            AND NOT OSPath =~ '''\\\\.\\.:\\&lt;Err&gt;\\'''
            AND if(condition=EarliestSILastChanged,
                then= LastRecordChange0x10 &gt; EarliestSILastChanged,
                else= True)
            AND if(condition=LatestSILastChanged,
                then= LastRecordChange0x10 &lt; LatestSILastChanged,
                else= True)
            AND if(condition=EarliestFNCreated,
                then= Created0x30 &gt; EarliestFNCreation,
                else= True)
            AND if(condition=LatestFNCreated,
                then= Created0x30 &lt; LatestFNCreation,
                else= True)

      -- scan files and only report a single hit.
      LET hits = SELECT * FROM foreach(row=files,
            query={
                SELECT
                    FileName, OSPath,
                    File.Size AS Size,
                    File.ModTime AS ModTime,
                    Rule, Tags, Meta,
                    String.Name as YaraString,
                    String.Offset as HitOffset,
                    if(condition=String.Data,
                       then=upload(
                            accessor='scope',
                            file='String.Data',
                            name=format(format="%v-%v-%v",
                            args=[
                                OSPath,
                                if(condition= String.Offset - ContextBytes &lt; 0,
                                    then= 0,
                                    else= String.Offset - ContextBytes),
                                if(condition= String.Offset + ContextBytes &gt; File.Size,
                                    then= File.Size,
                                    else= String.Offset + ContextBytes) ]
                            ))) as HitContext
                FROM yara(rules=yara_rules,
                   files=OSPath, context=ContextBytes, number=NumberOfHits)
            })

      -- upload files that have hit
      LET upload_hits=SELECT *,
            upload(file=OSPath) AS Upload
        FROM hits
        GROUP BY OSPath

      -- return rows
      SELECT * FROM if(condition=UploadHits,
        then={ SELECT * FROM upload_hits},
        else={ SELECT * FROM hits})

column_types:
  - name: HitContext
    type: preview_upload

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.eventlogs.dhcp.md
======
---
title: Windows.EventLogs.DHCP
hidden: true
tags: [Client Artifact]
---


This artifact parses the windows dhcp event log looking for evidence
of IP address assignments.

In some investigations it is important to be able to identify the
machine which was assigned a particular IP address at a point in
time. Usually these logs are available from the DHCP server, but in
many cases the server logs are not available (for example, if the
endpoint was visiting a different network or the DHCP server is on a
wireless router with no log retention).

On windows, there are two types of logs:

  1. The first type is the admin log
     (`Microsoft-Windows-Dhcp-Client%4Admin.evt`). These only contain
     errors such as an endpoint trying to continue its lease, but
     the lease is rejected by the server.

  2. The operational log
     (`Microsoft-Windows-Dhcp-Client%4Operational.evtx`) contains
     the full log of each lease. Unfortunately this log is disabled
     by default. If it is available we can rely on the information.


<pre><code class="language-yaml">
name: Windows.EventLogs.DHCP
description: |

  This artifact parses the windows dhcp event log looking for evidence
  of IP address assignments.

  In some investigations it is important to be able to identify the
  machine which was assigned a particular IP address at a point in
  time. Usually these logs are available from the DHCP server, but in
  many cases the server logs are not available (for example, if the
  endpoint was visiting a different network or the DHCP server is on a
  wireless router with no log retention).

  On windows, there are two types of logs:

    1. The first type is the admin log
       (`Microsoft-Windows-Dhcp-Client%4Admin.evt`). These only contain
       errors such as an endpoint trying to continue its lease, but
       the lease is rejected by the server.

    2. The operational log
       (`Microsoft-Windows-Dhcp-Client%4Operational.evtx`) contains
       the full log of each lease. Unfortunately this log is disabled
       by default. If it is available we can rely on the information.

parameters:
  - name: eventDirGlob
    default: C:\Windows\system32\winevt\logs\

  - name: adminLog
    default: Microsoft-Windows-Dhcp-Client%4Admin.evtx

  - name: operationalLog
    default: Microsoft-Windows-Dhcp-Client%4Operational.evtx

  - name: accessor
    default: file

sources:
  - name: RejectedDHCP
    query: |
        LET files = SELECT *
          FROM glob(
            root=eventDirGlob,
            globs=adminLog,
            accessor=accessor)

        SELECT Time AS _Time,
               timestamp(epoch=Time) As Timestamp,
               Computer, MAC, ClientIP, DHCPServer, Type FROM foreach(
           row=files,
           query={
              SELECT System.TimeCreated.SystemTime as Time,
                     System.Computer AS Computer,
                     format(format="%x:%x:%x:%x:%x:%x", args=[EventData.HWAddress]) AS MAC,
                     ip(netaddr4_le=EventData.Address1) AS ClientIP,
                     ip(netaddr4_le=EventData.Address2) AS DHCPServer,
                     "Lease Rejected" AS Type
              FROM parse_evtx(filename=OSPath, accessor=accessor)
              WHERE System.EventID.Value = 1002
           })

  - name: AssignedDHCP
    query: |
        SELECT Time AS _Time,
               timestamp(epoch=Time) As Timestamp,
               Computer, MAC, ClientIP, DHCPServer, Type FROM foreach(
           row=files,
           query={
              SELECT System.TimeCreated.SystemTime as Time,
                     System.Computer AS Computer,
                     EventData.InterfaceGuid AS MAC,
                     ip(netaddr4_le=EventData.Address1) AS ClientIP,
                     ip(netaddr4_le=EventData.Address2) AS DHCPServer,
                     "Lease Assigned" AS Type
              FROM parse_evtx(filename=OSPath, accessor=accessor)
              WHERE System.EventID.Value = 60000
           })


reports:
  - type: CLIENT
    template: |
      Evidence of DHCP assigned IP addresses
      ======================================

      {{ .Description }}

      {{ define "assigned_dhcp" }}
            SELECT Computer, ClientIP,
                   count(items=Timestamp) AS Total,
                   enumerate(items=Timestamp) AS Times
            FROM source(source='AssignedDHCP')
            GROUP BY ClientIP
      {{ end }}
      {{ define "rejected_dhcp" }}
            SELECT Computer, ClientIP,
                   count(items=Timestamp) AS Total,
                   enumerate(items=Timestamp) AS Times
            FROM source(source='RejectedDHCP')
            GROUP BY ClientIP
      {{ end }}

      {{ $assigned := Query "assigned_dhcp"}}
      {{ if $assigned }}
      ## Operational logs

      This machine has DHCP operational logging enabled. We therefore
      can see complete references to all granted leases:
        {{ Table $assigned }}

      ## Timeline

      {{ Query "SELECT _Time * 1000, ClientIP FROM source(source='AssignedDHCP')" | Timeline }}

      {{ end }}

      ## Admin logs

      The admin logs show errors with DHCP lease requests. Typically
      rejected leases indicate that the machine held a least on a IP
      address in the past, but this lease is invalid for its current
      environment. For example, the machine has been moved to a
      different network.

      {{ Query "rejected_dhcp" | Table }}

      {{ Query "SELECT _Time * 1000, ClientIP FROM source(source='RejectedDHCP')" | Timeline }}

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.system.rootcastore.md
======
---
title: Windows.System.RootCAStore
hidden: true
tags: [Client Artifact]
---

Enumerate the root certificates in the Windows Root store.


<pre><code class="language-yaml">
name: Windows.System.RootCAStore
description: |
   Enumerate the root certificates in the Windows Root store.

reference:
   - "ATT&amp;CK: T1553"
   - https://attack.mitre.org/techniques/T1553/004/

parameters:
   - name: CertificateRootStoreGlobs
     type: csv
     default: |
       Accessor,Glob
       reg,HKEY_LOCAL_MACHINE\SOFTWARE\Microsoft\SystemCertificates\ROOT\Certificates\**\Blob
       reg,HKEY_LOCAL_MACHINE\SOFTWARE\Policies\Microsoft\SystemCertificates\ROOT\Certificates\**\Blob
       reg,HKEY_USERS\*\Software\Microsoft\SystemCertificates\Root\Certificates\**\Blob
       reg,HKEY_USERS\*\Software\Policies\Microsoft\SystemCertificates\Root\Certificates\**\Blob

sources:
  - precondition:
      SELECT OS From info() where OS = 'windows'

    query: |
        LET profile = '''[
        ["Record", "x=&gt;x.Length + 12", [
          ["Type", 0, "uint32"],
          ["Length", 8, "uint32"],
          ["Data", 12, "String", {
              length: "x=&gt;x.Length",
              term: "",
          }],
          ["UnicodeString", 12, "String", {
              encoding: "utf16",
          }]
        ]],
        ["Records", 0, [
          ["Items", 0, "Array", {
              type: "Record",
              count: 20,
          }]
        ]]
        ]'''

        // Parse the types from the certificate record itself, as well as the X509 cert structure.
        LET GetCert(CertData) = SELECT parse_x509(data=Data)[0] AS Cert
          FROM foreach(row=parse_binary(filename=CertData,
                       accessor="data", profile=profile, struct="Records").Items)
          WHERE Type = 32

        // Format the fingerprint as a hex string
        LET GetFinger(CertData) = SELECT format(format="%x", args=Data) AS FingerPrint
          FROM foreach(row=parse_binary(filename=CertData,
                       accessor="data", profile=profile, struct="Records").Items)
          WHERE Type = 3

        LET GetName(CertData) = SELECT UnicodeString AS Name
          FROM foreach(row=parse_binary(filename=CertData,
                       accessor="data", profile=profile, struct="Records").Items)
          WHERE Type = 11

        // Glob for certificates in all the locations we know about.
        SELECT * FROM foreach(row=CertificateRootStoreGlobs,
        query={
          SELECT OSPath AS _RegistryValue, ModTime,
               GetName(CertData=Data.value)[0].Name AS Name,
               GetFinger(CertData=Data.value)[0].FingerPrint AS FingerPrint,
               GetCert(CertData=Data.value)[0].Cert AS Certificate
          FROM glob(globs=Glob, accessor=Accessor)
        })

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.forensics.certutil.md
======
---
title: Windows.Forensics.CertUtil
hidden: true
tags: [Client Artifact]
---

The Windows Certutil binary is capable of downloading arbitrary
files. Attackers typically use it to fetch tools undetected using
Living off the Land (LOL) techniques.

Certutil maintains a cache of the downloaded files and this contains
valuable metadata. This artifact parses this metadata to establish
what was downloaded and when.


<pre><code class="language-yaml">
name: Windows.Forensics.CertUtil
description: |
  The Windows Certutil binary is capable of downloading arbitrary
  files. Attackers typically use it to fetch tools undetected using
  Living off the Land (LOL) techniques.

  Certutil maintains a cache of the downloaded files and this contains
  valuable metadata. This artifact parses this metadata to establish
  what was downloaded and when.

reference:
  - https://u0041.co/blog/post/3
  - https://thinkdfir.com/2020/07/30/certutil-download-artefacts/
  - https://lolbas-project.github.io/lolbas/Binaries/Certutil/

parameters:
  - name: MinSize
    type: int
    description: Only show contents larger than this size.
  - name: URLWhitelist
    type: csv
    default: |
      URL
      http://sf.symcd.com
      http://oneocsp.microsoft.com
      http://certificates.godaddy.com
      http://ocsp.pki.goog
      http://repository.certum.pl
      http://www.microsoft.com
      http://ocsp.verisign.com
      http://ctldl.windowsupdate.com
      http://ocsp.sectigo.com
      http://ocsp.usertrust.com
      http://ocsp.comodoca.com
      http://cacerts.digicert.com
      http://ocsp.digicert.com
  - name: MetadataGlobUser
    default: C:/Users/*/AppData/LocalLow/Microsoft/CryptnetUrlCache/MetaData/*
  - name: MetadataGlobSystem
    default: C:/Windows/*/config/systemprofile/AppData/LocalLow/Microsoft/CryptnetUrlCache/MetaData/*
  - name: AlsoUpload
    type: bool

  - name: VSSAnalysisAge
    type: int
    default: 0
    description: |
      If larger than zero we analyze VSS within this many days
      ago. (e.g 7 will analyze all VSS within the last week).  Note
      that when using VSS analysis we have to use the ntfs accessor
      for everything which will be much slower.

  - name: DISABLE_DANGEROUS_API_CALLS
    type: bool
    description: |
      Enable this to disable potentially flakey APIs which may cause
      crashes.


sources:
  - query: |
      LET VSS_MAX_AGE_DAYS &lt;= VSSAnalysisAge
      LET Accessor = if(condition=VSSAnalysisAge &gt; 0, then="ntfs_vss", else="auto")

      LET Profile = '[
        ["Header", 0, [
          ["UrlSize", 12, "uint32"],
          ["HashSize", 100, "uint32"],
          ["DownloadTime", 16, "uint64"],
          ["FileSize", 112, "uint32"],
          ["URL", 116, "String", {
              "encoding": "utf16",
              "length": "x=&gt;x.UrlSize"
          }],
          ["Hash", "x=&gt;x.UrlSize + 116", "String", {
              "encoding": "utf16",
              "length": "x=&gt;x.HashSize"
          }]
        ]]
      ]'

      -- Build a whitelist regex
      LET URLRegex &lt;= "^" + join(array=URLWhitelist.URL, sep="|")
      LET Files = SELECT OSPath,

          -- Parse each metadata file.
          parse_binary(filename=OSPath, accessor=Accessor,
                       profile=Profile,
                       struct="Header") AS Header,

          -- The content is kept in the Content directory.
          OSPath.Dirname.Dirname + "Content" + OSPath.Basename AS _ContentPath,
          read_file(length=4, accessor=Accessor,
                filename=OSPath.Dirname.Dirname + "Content" + OSPath.Basename) AS ContentHeader
      FROM glob(globs=[MetadataGlobUser, MetadataGlobSystem], accessor=Accessor)
      WHERE Header.FileSize &gt; MinSize

      SELECT OSPath AS _MetadataFile, _ContentPath,
               if(condition=AlsoUpload, then=upload(file=OSPath, accessor=Accessor)) AS _MetdataUpload,
               if(condition=AlsoUpload, then=upload(file=_ContentPath, accessor=Accessor)) AS _Upload,
               Header.URL AS URL,
               url(parse=Header.URL).Host AS UrlTLD,
               Header.FileSize AS FileSize,
               regex_replace(re='"', replace="", source=Header.Hash) AS Hash,
               timestamp(winfiletime=Header.DownloadTime) AS DownloadTime,
               if(condition= ContentHeader=~ 'MZ',
                    then= parse_pe(file= _ContentPath, accessor=Accessor).VersionInformation,
                    else= 'N/A' ) as VersionInformation,
               if(condition= ContentHeader=~ 'MZ',
                    then= authenticode(filename= _ContentPath, accessor=Accessor),
                    else= 'N/A' ) as Authenticode

      FROM Files
      WHERE NOT URL =~ URLRegex

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.system.wmiquery.md
======
---
title: Windows.System.WMIQuery
hidden: true
tags: [Client Artifact]
---

This artifact enables querying Windows Management Instrumentation (WMI).

Windows Management Instrumentation (WMI) is the Microsoft implementation of
Web-Based Enterprise Management (WBEM), which is an industry initiative to
develop a standard technology for accessing management information in an
enterprise environment. WMI uses the Common Information Model (CIM) industry
standard to represent systems, applications, networks, devices, and other
managed components. CIM is developed and maintained by the Distributed
Management Task Force (DMTF).

Please see the second reference link for an example of built in system classes.


<pre><code class="language-yaml">
name: Windows.System.WMIQuery
author: Matt Green - @mgreen27
description: |
    This artifact enables querying Windows Management Instrumentation (WMI).

    Windows Management Instrumentation (WMI) is the Microsoft implementation of
    Web-Based Enterprise Management (WBEM), which is an industry initiative to
    develop a standard technology for accessing management information in an
    enterprise environment. WMI uses the Common Information Model (CIM) industry
    standard to represent systems, applications, networks, devices, and other
    managed components. CIM is developed and maintained by the Distributed
    Management Task Force (DMTF).

    Please see the second reference link for an example of built in system classes.

reference:
    - https://docs.microsoft.com/en-us/windows/win32/wmisdk/wmi-start-page
    - https://docs.microsoft.com/en-us/windows/win32/cimwin32prov/operating-system-classes

required_permissions:
  - EXECVE

parameters:
  - name: WMIQuery
    description: "Add target WMI query: e.g SELECT * FROM &lt;CLASSNAME&gt;"
    default: "SELECT * FROM Win32_Process"

  - name: Namespace
    description: "Add target Namespace: e.g root/cimv2"
    default: root/cimv2

sources:
  - precondition:
      SELECT OS From info() where OS = 'windows'

    query: |
       SELECT * FROM wmi(namespace=Namespace,query=WMIQuery)

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/server.internal.alerts.md
======
---
title: Server.Internal.Alerts
hidden: true
tags: [Server Event Artifact]
---

An internal event queue for alerts. All alerts sent from clients are
collected in this event queue.

Alerts are expected to be low frequency and high value and may be
generated client or server side.


<pre><code class="language-yaml">
name: Server.Internal.Alerts
description: |
  An internal event queue for alerts. All alerts sent from clients are
  collected in this event queue.

  Alerts are expected to be low frequency and high value and may be
  generated client or server side.

type: SERVER_EVENT

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/server.alerts.thehive.case.md
======
---
title: Server.Alerts.TheHive.Case
hidden: true
tags: [Server Event Artifact]
---

Create a TheHive case when monitored artifacts complete with results.  Add the ClientId, FlowId, and FQDN as tags to the case.  Add FQDN as an observable.
Much of this was borrowed from: https://gist.github.com/scudette/3a32abd19350c8fe3368661c4278869d

It is recommended to use the Server Metadata section to store credentials, instead of having to store directly inside the artifact.


<pre><code class="language-yaml">
name: Server.Alerts.TheHive.Case
description: |
   Create a TheHive case when monitored artifacts complete with results.  Add the ClientId, FlowId, and FQDN as tags to the case.  Add FQDN as an observable.
   Much of this was borrowed from: https://gist.github.com/scudette/3a32abd19350c8fe3368661c4278869d

   It is recommended to use the Server Metadata section to store credentials, instead of having to store directly inside the artifact.

type: SERVER_EVENT

author: Wes Lambert - @therealwlambert

parameters:
  - name: TheHiveURL
    default: https://mythehive
  - name: VeloServerURL
    default: https://myvelo
  - name: ArtifactsToAlertOn
    default: .
    type: regex
  - name: DisableSSLVerify
    type: bool
    default: true

sources:
  - query: |
      LET thehive_key = if(
           condition=TheHiveKey,
           then=TheHiveKey,
           else=server_metadata().TheHiveKey)
      LET flow_info = SELECT timestamp(epoch=Timestamp) AS Timestamp,
             client_info(client_id=ClientId).os_info.fqdn AS FQDN,
             ClientId, FlowId, Flow.artifacts_with_results[0] AS FlowResults
      FROM watch_monitoring(artifact="System.Flow.Completion")
      WHERE Flow.artifacts_with_results =~ ArtifactsToAlertOn

      LET cases = SELECT * FROM foreach(row=flow_info,
       query={
          SELECT FQDN, parse_json(data=Content)._id AS CaseID FROM http_client(
          data=serialize(item=dict(
                title=format(format="Hit on %v for %v", args=[FlowResults, FQDN]), description=format(format="ClientId: %v\n\nFlowID: %v\n\nURL: %v//app/index.html?#/collected/%v/%v", args=[ClientId, FlowId, VeloServerURL, ClientId, FlowId,]), tags=[ClientId,FlowId, FQDN]), format="json"),
          headers=dict(`Content-Type`="application/json", `Authorization`=format(format="Bearer %v", args=[thehive_key])),
          disable_ssl_security=DisableSSLVerify,
          method="POST",
          url=format(format="%v/api/case", args=[TheHiveURL]))
       })

       SELECT * from foreach(row=cases,
       query={
          SELECT * FROM http_client(
          data=serialize(item=dict(data=FQDN, dataType="fqdn", message=FQDN)),
          headers=dict(`Content-Type`="application/json", `Authorization`=format(format="Bearer %v", args=[thehive_key])),
          disable_ssl_security=DisableSSLVerify,
          method="POST",
          url=format(format="%v/api/case/%v/artifact", args=[TheHiveURL, CaseID]))
       })

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/server.alerts.psexec.md
======
---
title: Server.Alerts.PsExec
hidden: true
tags: [Server Event Artifact]
---

Send an email if execution of the psexec service was detected on
any client. This is a server side artifact.

Note this requires that the Windows.Event.ProcessCreation
monitoring artifact be collected from clients.


<pre><code class="language-yaml">
name: Server.Alerts.PsExec
description: |
   Send an email if execution of the psexec service was detected on
   any client. This is a server side artifact.

   Note this requires that the Windows.Event.ProcessCreation
   monitoring artifact be collected from clients.

type: SERVER_EVENT

parameters:
  - name: EmailAddress
    default: admin@example.com
  - name: SkipVerify
    type: bool
    description: If set we skip TLS verification.
  - name: MessageTemplate
    default: |
      PsExec execution detected at %v: %v for client %v

sources:
  - query: |
        SELECT * FROM foreach(
          row={
            SELECT * from watch_monitoring(
              artifact='Windows.Events.ProcessCreation')
            WHERE Name =~ 'psexesvc'
          },
          query={
            SELECT * FROM mail(
              to=EmailAddress,
              subject='PsExec launched on host',
              period=60,
              skip_verify=SkipVerify,
              body=format(
              format=MessageTemplate,
              args=[Timestamp, CommandLine, ClientId])
          )
        })

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.packs.persistence.md
======
---
title: Windows.Packs.Persistence
hidden: true
tags: [Client Artifact]
---

This artifact pack collects various persistence mechanisms in Windows.


<pre><code class="language-yaml">
name: Windows.Packs.Persistence
description: |
  This artifact pack collects various persistence mechanisms in Windows.

precondition:
  SELECT OS from info() where OS = "windows"

sources:
  - name: WMI Event Filters
    query: |
        SELECT * FROM Artifact.Windows.Persistence.PermanentWMIEvents()

  - name: Startup Items
    query: |
        SELECT * FROM Artifact.Windows.Sys.StartupItems()

  - name: Debug Bootstraping
    query: |
      SELECT * FROM Artifact.Windows.Persistence.Debug()

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/server.monitoring.schedulehunt.md
======
---
title: Server.Monitoring.ScheduleHunt
hidden: true
tags: [Server Event Artifact]
---

Run client interrogation periodically. This is a sample event
artifact to schedule a hunt periodically. You can change it to
launch other artifacts.


<pre><code class="language-yaml">
name: Server.Monitoring.ScheduleHunt
description: |
     Run client interrogation periodically. This is a sample event
     artifact to schedule a hunt periodically. You can change it to
     launch other artifacts.

type: SERVER_EVENT

parameters:
  - name: ScheduleDayRegex
    default: Tuesday
    type: regex
  - name: ScheduleTimeRegex
    default: "01:28"
    type: regex
  - name: HuntDescription
    default: "Periodic info hunt"

sources:
  - query: |
      LET schedule = SELECT
           UTC.String AS Now,
           Weekday.String AS Today
      FROM clock(period=60)
      WHERE Now =~ ScheduleTimeRegex + ":[0-9][0-9]"
        AND Today =~ ScheduleDayRegex
        AND log(message="Launching at time " + Now)

      SELECT hunt(artifacts=["Generic.Client.Info"],
                  spec=dict(`Generic.Client.Info`=dict()),
                  description=HuntDescription)
      FROM schedule

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/server.import.registryhunter.md
======
---
title: Server.Import.RegistryHunter
hidden: true
tags: [Server Artifact]
---

This artifact will import the latest Registry Hunter artifact.

To read more about the Registry Hunter, see
https://registry-hunter.velocidex.com/


<pre><code class="language-yaml">
name: Server.Import.RegistryHunter
description: |
  This artifact will import the latest Registry Hunter artifact.

  To read more about the Registry Hunter, see
  https://registry-hunter.velocidex.com/

type: SERVER

required_permissions:
- SERVER_ADMIN

sources:
  - query: |
      SELECT * FROM Artifact.Server.Import.ArtifactExchange(
         ExchangeURL="https://registry-hunter.velocidex.com/Windows.Registry.Hunter.zip",
         Prefix="")

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/server.internal.artifactmodification.md
======
---
title: Server.Internal.ArtifactModification
hidden: true
tags: [Server Event Artifact]
---

This event artifact is an internal event stream over which
notifications of artifact modifications are sent. Interested parties
can watch for new artifact modification events and rebuild caches
etc.

Note: This is an automated system artifact. You do not need to start it.


<pre><code class="language-yaml">
name: Server.Internal.ArtifactModification
description: |
  This event artifact is an internal event stream over which
  notifications of artifact modifications are sent. Interested parties
  can watch for new artifact modification events and rebuild caches
  etc.

  Note: This is an automated system artifact. You do not need to start it.

type: SERVER_EVENT

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/server.internal.welcome.md
======
---
title: Server.Internal.Welcome
hidden: true
tags: [Server Artifact]
---

This is the welcome screen in the Velociraptor GUI. You can
customize this screen by editing this artifact.

When editing the artifact in the main `View Artifacts` screen you
will see some markdown in the reports section of the YAML
file. Simply edit this markdown and your server will display your
customized report.

You can use this to add important information to your specific
deployment.


<pre><code class="language-yaml">
name: Server.Internal.Welcome
description: |
  This is the welcome screen in the Velociraptor GUI. You can
  customize this screen by editing this artifact.

  When editing the artifact in the main `View Artifacts` screen you
  will see some markdown in the reports section of the YAML
  file. Simply edit this markdown and your server will display your
  customized report.

  You can use this to add important information to your specific
  deployment.

type: SERVER

reports:
  - type: CLIENT
    template: |
      &lt;div class="row dashboard "&gt;
      &lt;div class="card col-10"&gt;
      &lt;img src="./velo.svg" height="150"&gt;
      &lt;div class="card-body"&gt;
      {{ $X := Query "LET DebugLink &lt;= link_to(type='debug', org='root')" | Expand }}

      # Welcome to Velociraptor!

      ## Common tasks:

      * &lt;a href="#/dashboard"&gt;Inspect the server's state&lt;/a&gt;
      * &lt;a href="#/collected/server"&gt;Build an Offline Collector&lt;/a&gt;
      * &lt;a href="#/notebooks"&gt;Write VQL notebooks&lt;/a&gt;
      * &lt;a href="#/host/server"&gt;View Server Configuration&lt;/a&gt;
      * &lt;a href="#/events/server/Server.Audit.Logs"&gt;Inspect Server Audit Log&lt;/a&gt;
      * &lt;a href="#/secrets"&gt;Manage Server Secrets&lt;/a&gt;
      * &lt;a href="#/artifacts/Server.Internal.Welcome"&gt;Customize this welcome screen&lt;/a&gt;
      * &lt;a href="{{ Scope "DebugLink" }}"&gt;Debug the server&lt;/a&gt;

      Or simply search for a client in the search bar above.

      You can always get back to this welcome screen by clicking the
      little green reptile above!

      ## Tips

      1. Press `Ctrl-/` to view keyboard hotkeys.

      &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/generic.client.locallogs.md
======
---
title: Generic.Client.LocalLogs
hidden: true
tags: [Client Event Artifact]
---

Write client logs locally in an encrypted container. This helps when
we need to access what the client was doing in the past.


<pre><code class="language-yaml">
name: Generic.Client.LocalLogs
description: |
  Write client logs locally in an encrypted container. This helps when
  we need to access what the client was doing in the past.

type: CLIENT_EVENT

parameters:
- name: LocalFilename
  default: "%TEMP%/locallogs.log"
  description: The local filename that will be written (Env variables will be expanded).
- name: MaxRows
  type: int
  default: "100"
  description: Flush the file when we cache this many rows.
- name: MaxWait
  default: "60"
  type: int
  description: Flush the file at least every this many seconds.
- name: MaxSize
  default: "100000000"
  type: int
  description: Truncate the file once it reaches this length.
- name: AlsoForward
  type: bool
  description: |
    By default we do not forward any of the logs to the server but
    this allows logs to be forwarded as well as written locally.
- name: Component
  default: generic
  description: The log component to forward (default "generic")
  type: choices
  choices:
    - generic
    - client
    - frontend
    - gui
    - api

sources:
- query: |
     LET _ &lt;= log(message="Writing local log to " + expand(path=LocalFilename))

     SELECT * FROM write_crypto_file(
       max_rows=MaxRows, max_wait=MaxWait, max_size=MaxSize,
       filename=expand(path=LocalFilename),
       query={
         SELECT timestamp(epoch=now()) AS Timestamp, *
         FROM logging(component=Component)
       })
     WHERE AlsoForward

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.detection.environmentvariables.md
======
---
title: Windows.Detection.EnvironmentVariables
hidden: true
tags: [Client Artifact]
---

Find processes with the specified environment variables.


<pre><code class="language-yaml">
name: Windows.Detection.EnvironmentVariables
description: |
   Find processes with the specified environment variables.

parameters:
   - name: ProcessNameRegex
     default: .
     type: regex
   - name: PidRegex
     default: .
     type: regex
   - name: EnvironmentVariableRegex
     default: COMSPEC|COR_PROFILER
     type: regex
   - name: FilterValueRegex
     default: .
     type: regex
   - name: WhitelistValueRegex
     description: Ignore these values
     default: ^C:\\Windows\\.+cmd.exe$
     type: regex

sources:
  - precondition:
      SELECT OS From info() where OS = 'windows'

    query: |
      SELECT * FROM foreach(
      row={
          SELECT * FROM Artifact.Windows.Memory.ProcessInfo(
             ProcessNameRegex=ProcessNameRegex, PidRegex=PidRegex)
      },
      query={
          SELECT Pid, Name, ImagePathName, CommandLine,
             _key AS Var, _value AS Value
          FROM items(item=Env)
      })
      WHERE Var =~ EnvironmentVariableRegex
        AND Value =~ FilterValueRegex
        AND NOT Value =~ WhitelistValueRegex

    notebook:
      - type: Markdown
        template: |-
          # Process Environment Variables

          Environment variables control the way subprocesses work. In
          this artifact we look for processes with unusual sets of
          environment variables.

          {{ $unusual := Query "SELECT * FROM source() WHERE \
              Var =~ 'COR_PROFILER|COMPlus_ETWEnabled'" | Expand }}

          {{ if $unusual }}
          ## Some unusual environment variables.

          There have been some unusual environment variables
          detected. These normally indicate malicious activity.

          {{ Table $unusual }}

          {{ end }}

          {{ $unusual = Query "SELECT * FROM source() WHERE \
              Var =~ 'COMSPEC' AND NOT Value =~ 'cmd.exe$'" | Expand }}
          {{ if $unusual }}

          ## Unusual COMSPEC setting.

          The `COMSPEC` environment variable is usually used to launch
          the command prompt (cmd.exe) but Velociraptor found some
          hits where this is not the case. It could indicate malicious
          activity.

          {{ Table $unusual }}

          {{ end }}

      - type: VQL
        template: |

          /* Markdown
          ## All collected results.

          */

          SELECT * FROM source()
          LIMIT 50

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/linux.sys.acpitables.md
======
---
title: Linux.Sys.ACPITables
hidden: true
tags: [Client Artifact]
---

Firmware ACPI functional table common metadata and content.

<pre><code class="language-yaml">
name: Linux.Sys.ACPITables
description: Firmware ACPI functional table common metadata and content.
reference:
  - https://osquery.io/schema/3.2.6#acpi_tables
parameters:
  - name: kLinuxACPIPath
    default: /sys/firmware/acpi/tables
sources:
  - precondition: |
      SELECT OS From info() where OS = 'linux'
    query: |
        LET hashes = SELECT Name, Size, hash(path=OSPath) as Hash
                     FROM glob(globs="*", root=kLinuxACPIPath)

        SELECT Name, Size, Hash.MD5, Hash.SHA1, Hash.SHA256 from hashes

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/server.utils.createcollector.md
======
---
title: Server.Utils.CreateCollector
hidden: true
tags: [Server Artifact]
---

A utility artifact to create a stand alone collector.

This artifact is actually invoked by the Offline collector GUI and
that is the recommended way to launch it. You can find the Offline
collector builder in the `Server Artifacts` section of the GUI.


<pre><code class="language-yaml">
name: Server.Utils.CreateCollector
description: |
  A utility artifact to create a stand alone collector.

  This artifact is actually invoked by the Offline collector GUI and
  that is the recommended way to launch it. You can find the Offline
  collector builder in the `Server Artifacts` section of the GUI.

type: SERVER

parameters:
  - name: OS
    default: Windows
    type: choices
    choices:
      - Windows
      - Windows_x86
      - Linux
      - MacOS
      - MacOSArm
      - Generic

  - name: artifacts
    description: A list of artifacts to collect
    type: json_array
    default: |
      ["Generic.Client.Info"]

  - name: encryption_scheme
    description: |
      Encryption scheme to use. Currently supported are Password, X509 or PGP

  - name: encryption_args
    description: |
      Encryption arguments
    type: json
    default: |
      {}

  - name: parameters
    description: A dict containing the parameters to set.
    type: json
    default: |
      {}

  - name: target
    description: Output type
    type: choices
    default: ZIP
    choices:
      - ZIP
      - GCS
      - S3
      - SFTP
      - Azure
      - SMBShare

  - name: target_args
    description: Type Dependent args
    type: json
    default: "{}"

  - name: opt_verbose
    default: Y
    type: bool
    description: Show verbose progress.

  - name: opt_banner
    default: Y
    type: bool
    description: Show Velociraptor banner.

  - name: opt_prompt
    default: N
    type: bool
    description: Wait for a prompt before closing.

  - name: opt_admin
    default: Y
    type: bool
    description: Require administrator privilege when running.

  - name: opt_tempdir
    default:
    description: A directory to write tempfiles in

  - name: opt_level
    default: "4"
    type: int
    description: Compression level (0=no compression).

  - name: opt_concurrency
    default: "2"
    type: int
    description: Number of concurrency queries

  - name: opt_format
    default: "jsonl"
    description: Output format (jsonl or csv)

  - name: opt_output_directory
    default: ""
    description: Where we actually write the collection to. You can specify this as a mapped drive to write over the network.

  - name: opt_filename_template
    default: "Collection-%FQDN%-%TIMESTAMP%"
    description: |
      The filename to use. You can expand environment variables as
      well as the following %FQDN% and %TIMESTAMP%.

  - name: opt_collector_filename
    type: string
    description: |
      If used, this option overrides the default filename of the collector being built.

  - name: opt_cpu_limit
    default: "0"
    type: int
    description: |
      A number between 0 to 100 representing the target maximum CPU
      utilization during running of this artifact.

  - name: opt_progress_timeout
    default: "1800"
    type: int
    description: |
      If specified the collector is terminated if it made no progress
      in this long. Note: Execution time may be a lot longer since
      each time any result is produced this counter is reset.

  - name: opt_timeout
    default: "0"
    type: int
    description: |
      If specified the collection must complete in the given time. It
      will be cancelled if the collection exceeds this time.

  - name: opt_version
    default: ""
    type: string
    description: |
      If specified the collection will be packed with the specified
      version of the binary. NOTE: This is rarely what you want
      because the packed builtin artifacts are only compatible with
      the current release version.

  - name: opt_delete_at_exit
    type: bool
    default: N
    description: |
      If specified the collection will be deleted at exit. This only
      makes sense when uploading to the cloud or a remote
      location. NOTE: There is no way to check that the upload
      actually worked so this flag deletes the collection regardless
      of upload success.

  - name: StandardCollection
    type: hidden
    default: |
      LET _ &lt;= log(message="Will collect package %v", args=zip_filename)

      SELECT * FROM collect(artifacts=Artifacts,
            args=Parameters, output=zip_filename,
            cpu_limit=CpuLimit,
            progress_timeout=ProgressTimeout,
            timeout=Timeout,
            password=pass[0].Pass,
            level=Level,
            concurrency=Concurrency,
            format=Format,
            metadata=ContainerMetadata)

  - name: S3Collection
    type: hidden
    default: |
      // A utility function to upload the file.
      LET upload_file(filename, name, accessor) = upload_s3(
          file=filename,
          accessor=accessor,
          bucket=TargetArgs.bucket,
          name=name,
          credentials_key=TargetArgs.credentialsKey,
          credentials_secret=TargetArgs.credentialsSecret,
          credentials_token=TargetArgs.credentialsToken,
          region=TargetArgs.region,
          endpoint=TargetArgs.endpoint,
          serverside_encryption=TargetArgs.serverSideEncryption,
          kms_encryption_key=TargetArgs.kmsEncryptionKey,
          s3upload_root=TargetArgs.s3UploadRoot,
          skip_verify=TargetArgs.noverifycert)

  - name: GCSCollection
    type: hidden
    default: |
      LET GCSBlob &lt;= parse_json(data=target_args.GCSKey)

      // A utility function to upload the file.
      LET upload_file(filename, name, accessor) = upload_gcs(
          file=filename,
          accessor=accessor,
          bucket=target_args.bucket,
          project=GCSBlob.project_id,
          name=name,
          credentials=target_args.GCSKey)

  - name: AzureSASURL
    type: hidden
    default: |
      // A utility function to upload the file.
      LET upload_file(filename, name, accessor) = upload_azure(
          file=filename,
          accessor=accessor,
          sas_url=TargetArgs.sas_url,
          name=name)

  - name: SMBCollection
    type: hidden
    default: |
      // A utility function to upload the file.
      LET upload_file(filename, name, accessor) = upload_smb(
          file=filename,
          accessor=accessor,
          username=TargetArgs.username,
          password=TargetArgs.password,
          server_address=TargetArgs.server_address,
          name=name)

  - name: SFTPCollection
    type: hidden
    default : |
      LET upload_file(filename, name, accessor) = upload_sftp(
        file=filename,
        accessor=accessor,
        name=name,
        user=TargetArgs.user,
        path=TargetArgs.path,
        privatekey=TargetArgs.privatekey,
        endpoint=TargetArgs.endpoint,
        hostkey = TargetArgs.hostkey)

  - name: CommonCollections
    type: hidden
    default: |
      LET S = scope()

      // Add all the tools we are going to use to the inventory.
      LET _ &lt;= SELECT inventory_add(tool=ToolName, hash=ExpectedHash, version=S.Version)
       FROM parse_csv(filename="/uploads/inventory.csv", accessor="me")
       WHERE log(message="Adding tool " + ToolName +
             " version " + (S.Version || "Unknown"))

      LET baseline &lt;= SELECT Fqdn, dirname(path=Exe) AS ExePath, Exe,
         scope().CWD AS CWD FROM info()

      LET OutputPrefix &lt;= if(condition= OutputPrefix,
        then=pathspec(parse=OutputPrefix),
        else= if(condition= baseline[0].CWD,
          then=pathspec(parse= baseline[0].CWD),
          else=pathspec(parse= baseline[0].ExePath)))

      LET _ &lt;= log(message="Output Prefix : %v", args= OutputPrefix)

      LET FormatMessage(Message) = regex_transform(
          map=dict(`%FQDN%`=baseline[0].Fqdn,
                   `%Timestamp%`=timestamp(epoch=now()).MarshalText),
          source=Message)

      // Format the filename safely according to the filename
      // template. This will be the name uploaded to the bucket.
      LET formatted_zip_name &lt;= regex_replace(
          source=expand(path=FormatMessage(Message=FilenameTemplate)),
          re="[^0-9A-Za-z\\-]", replace="_") + ".zip"

      // This is where we write the files on the endpoint.
      LET zip_filename &lt;= OutputPrefix + formatted_zip_name

      // The log is always written to the executable path
      LET log_filename &lt;= pathspec(parse= baseline[0].Exe + ".log")

      -- Remove the zip file and log file when done if the user asked for it.
      LET _ &lt;= if(condition=DeleteOnExit, then=atexit(query={
         SELECT rm(filename=zip_filename), rm(filename=log_filename) FROM scope()
         WHERE log(message="Removed Zip file %v", args=zip_filename)
      }, env=dict(zip_filename=zip_filename, log_filename=log_filename)))

      -- Make a random hex string as a random password
      LET RandomPassword &lt;= SELECT format(format="%02x",
            args=rand(range=255)) AS A
      FROM range(end=25)

      LET pass = SELECT * FROM switch(a={

         -- For X509 encryption we use a random session password.
         SELECT join(array=RandomPassword.A) as Pass From scope()
         WHERE encryption_scheme =~ "pgp|x509"
          AND log(message="I will generate a container password using the %v scheme",
                  args=encryption_scheme)

      }, b={

         -- Otherwise the user specified the password.
         SELECT encryption_args.password as Pass FROM scope()
         WHERE encryption_scheme =~ "password"

      }, c={

         -- No password specified.
         SELECT Null as Pass FROM scope()
      })

      -- For X509 encryption_scheme, store the encrypted
      -- password in the metadata file for later retrieval.
      LET ContainerMetadata = if(
          condition=encryption_args.public_key,
          then=dict(
             EncryptedPass=pk_encrypt(data=pass[0].Pass,
                public_key=encryption_args.public_key,
             scheme=encryption_scheme),
          Scheme=encryption_scheme,
          PublicKey=encryption_args.public_key))

  - name: CloudCollection
    type: hidden
    default: |
      LET TargetArgs &lt;= target_args

      // When uploading to the cloud it is allowed to use directory //
      // separators and we trust the filename template to be a valid
      // filename.
      LET upload_name &lt;= regex_replace(
          source=expand(path=FormatMessage(Message=FilenameTemplate)),
          re="[^0-9A-Za-z\\-/]", replace="_")

      LET _ &lt;= log(message="Will collect package %v and upload to cloud bucket %v",
         args=[zip_filename, TargetArgs.bucket])

      LET Result &lt;= SELECT
          upload_file(filename=Container,
                      name= upload_name + ".zip",
                      accessor="file") AS Upload,
          upload_file(filename=log_filename,
                      name= upload_name + ".log",
                      accessor="file") AS LogUpload

      FROM collect(artifacts=Artifacts,
          args=Parameters,
          format=Format,
          output=zip_filename,
          cpu_limit=CpuLimit,
          progress_timeout=ProgressTimeout,
          timeout=Timeout,
          password=pass[0].Pass,
          level=Level,
          concurrency=Concurrency,
          metadata=ContainerMetadata)

      LET _ &lt;= if(condition=NOT Result[0].Upload.Path,
         then=log(message="&lt;red&gt;Failed to upload to cloud bucket!&lt;/&gt; Leaving the collection behind for manual upload!"),
         else=log(message="&lt;green&gt;Collection Complete!&lt;/&gt; Please remove %v when you are sure it was properly transferred", args=zip_filename))

      SELECT * FROM Result


  - name: FetchBinaryOverride
    type: hidden
    description: |
       A replacement for Generic.Utils.FetchBinary which
       grabs files from the local archive.

    default: |
       LET RequiredTool &lt;= ToolName
       LET S = scope()

       LET matching_tools &lt;= SELECT ToolName, Filename
       FROM parse_csv(filename="/uploads/inventory.csv", accessor="me")
       WHERE RequiredTool = ToolName

       LET get_ext(filename) = parse_string_with_regex(
             regex="(\\.[a-z0-9]+)$", string=filename).g1

        LET FullPath &lt;= if(condition=matching_tools,
        then=copy(filename=matching_tools[0].Filename,
             accessor="me", dest=tempfile(
                 extension=get_ext(filename=matching_tools[0].Filename),
                 remove_last=TRUE,
                 permissions=if(condition=IsExecutable, then="x"))))

       SELECT FullPath, FullPath AS OSPath,
              Filename AS Name
       FROM matching_tools

sources:
  - query: |
      LET Binaries &lt;= SELECT * FROM foreach(
          row={
             SELECT tools FROM artifact_definitions(deps=TRUE, names=artifacts)
          }, query={
             SELECT * FROM foreach(row=tools,
             query={
                SELECT name AS Binary FROM scope()
             })
          }) GROUP BY Binary

      // Choose the right target binary depending on the target OS
      LET tool_name = SELECT * FROM switch(
       a={ SELECT "VelociraptorWindows" AS Type FROM scope() WHERE OS = "Windows"},
       b={ SELECT "VelociraptorWindows_x86" AS Type FROM scope() WHERE OS = "Windows_x86"},
       c={ SELECT "VelociraptorLinux" AS Type FROM scope() WHERE OS = "Linux"},
       d={ SELECT "VelociraptorCollector" AS Type FROM scope() WHERE OS = "MacOS"},
       e={ SELECT "VelociraptorCollector" AS Type FROM scope() WHERE OS = "MacOSArm"},
       f={ SELECT "VelociraptorCollector" AS Type FROM scope() WHERE OS = "Generic"},
       g={ SELECT "" AS Type FROM scope()
           WHERE NOT log(message="Unknown target type " + OS) }
      )

      LET Target &lt;= tool_name[0].Type

      // This is what we will call it.
      LET CollectorName &lt;= opt_collector_filename ||
          format(format='Collector_%v', args=inventory_get(tool=Target).Definition.filename)

      LET CollectionArtifact &lt;= SELECT Value FROM switch(
        a = { SELECT CommonCollections + StandardCollection AS Value
              FROM scope()
              WHERE target = "ZIP" },
        b = { SELECT S3Collection + CommonCollections + CloudCollection AS Value
              FROM scope()
              WHERE target = "S3" },
        c = { SELECT GCSCollection + CommonCollections + CloudCollection AS Value
              FROM scope()
              WHERE target = "GCS" },
        d = { SELECT SFTPCollection + CommonCollections + CloudCollection AS Value
              FROM scope()
              WHERE target = "SFTP" },
        e = { SELECT AzureSASURL + CommonCollections + CloudCollection AS Value
              FROM scope()
              WHERE target = "Azure" },
        f = { SELECT SMBCollection + CommonCollections + CloudCollection AS Value
              FROM scope()
              WHERE target = "SMBShare" },
        z = { SELECT "" AS Value  FROM scope()
              WHERE log(message="Unknown collection type " + target) }
      )

      LET use_server_cert = encryption_scheme =~ "x509"
         AND NOT encryption_args.public_key =~ "-----BEGIN CERTIFICATE-----"
         AND log(message="Pubkey encryption specified, but no cert/key provided. Defaulting to server frontend cert")

      -- For x509, if no public key cert is specified, we use the
      -- server's own key. This makes it easy for the server to import
      -- the file again.
      LET updated_encryption_args &lt;= if(
         condition=use_server_cert,
         then=dict(public_key=server_frontend_cert(),
                   scheme="x509"),
         else=encryption_args
      )

      -- Add custom definition if needed. Built in definitions are not added
      LET definitions &lt;= SELECT * FROM chain(
      a = { SELECT name, description, tools, export, parameters, sources
            FROM artifact_definitions(deps=TRUE, names=artifacts)
            WHERE NOT compiled_in AND
              log(message="Adding artifact_definition for " + name) },

      // Create the definition of the Collector artifact.
      b = { SELECT "Collector" AS name, (
                    dict(name="Artifacts",
                         default=serialize(format='json', item=artifacts),
                         type="json_array"),
                    dict(name="Parameters",
                         default=serialize(format='json', item=parameters),
                         type="json"),
                    dict(name="encryption_scheme", default=encryption_scheme),
                    dict(name="encryption_args",
                         default=serialize(format='json', item=updated_encryption_args),
                         type="json"
                         ),
                    dict(name="Level", default=opt_level, type="int"),
                    dict(name="Concurrency", default=opt_concurrency, type="int"),
                    dict(name="Format", default=opt_format),
                    dict(name="OutputPrefix", default=opt_output_directory),
                    dict(name="FilenameTemplate", default=opt_filename_template),
                    dict(name="CpuLimit", type="int",
                         default=opt_cpu_limit),
                    dict(name="ProgressTimeout", type="int",
                         default=opt_progress_timeout),
                    dict(name="Timeout", default=opt_timeout, type="int"),
                    dict(name="DeleteOnExit", default=opt_delete_at_exit, type="bool"),
                    dict(name="target_args",
                         default=serialize(format='json', item=target_args),
                         type="json"),
                ) AS parameters,
                (
                  dict(query=CollectionArtifact[0].Value),
                ) AS sources
            FROM scope() },

      // Override FetchBinary to get files from the executable.
      c = { SELECT "Generic.Utils.FetchBinary" AS name,
            (
               dict(name="SleepDuration", type="int", default="0"),
               dict(name="ToolName"),
               dict(name="ToolInfo"),
               dict(name="TemporaryOnly", type="bool"),
               dict(name="Version"),
               dict(name="IsExecutable", type="bool", default="Y"),
            ) AS parameters,
            (
               dict(query=FetchBinaryOverride),
            ) AS sources FROM scope()  }
      )

      LET optional_cmdline = SELECT * FROM chain(
        a={ SELECT "-v" AS Opt FROM scope() WHERE opt_verbose},
        b={ SELECT "--nobanner" AS Opt FROM scope() WHERE NOT opt_banner},
        c={ SELECT "--require_admin" AS Opt FROM scope() WHERE opt_admin},
        d={ SELECT "--prompt" AS Opt FROM scope() WHERE opt_prompt},
        e={ SELECT "--tempdir" AS Opt FROM scope() WHERE opt_tempdir},
        f={ SELECT opt_tempdir AS Opt FROM scope() WHERE opt_tempdir}
      )

      // Build the autoexec config file depending on the user's
      // collection type choices.
      LET autoexec &lt;= dict(autoexec=dict(
          argv=("artifacts", "collect", "Collector",
                "--logfile", CollectorName + ".log") + optional_cmdline.Opt,
          artifact_definitions=definitions)
      )

      // Do the actual repacking.
      SELECT repack(
           upload_name=CollectorName,
           target=tool_name[0].Type,
           binaries=Binaries.Binary,
           version=opt_version,
           config=serialize(format='json', item=autoexec)) AS Repacked
      FROM scope()

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/server.internal.artifactdescription.md
======
---
title: Server.Internal.ArtifactDescription
hidden: true
tags: [Internal Artifact]
---



<pre><code class="language-yaml">
name: Server.Internal.ArtifactDescription

type: INTERNAL

reports:
  - type: INTERNAL
    template: |
      {{ $artifact := Scope "artifact" }}

      ## {{ $artifact.Name }}

      #### Type: {{ $artifact.Type }}

      {{ if $artifact.BuiltIn }}
      {{ else }}
      ##### Custom Artifact
      {{ end }}

      {{ if $artifact.Author }}
      ##### Author: {{ $artifact.Author }}
      {{end}}

      {{ if $artifact.Description }}

      &lt;div class="description-content"&gt;

      {{ $artifact.Description }}

      {{ if $artifact.Reference }}
      ---
      References:
      &lt;ul&gt;
      {{- range $item := $artifact.Reference -}}
      &lt;li&gt;{{ $item }}&lt;/li&gt;
      {{- end -}}
      &lt;/ul&gt;
      {{ end }}
      &lt;/div&gt;

      {{ end }}

      {{ if $artifact.Tools }}
      ### Tools

      {{ range $artifact.Tools -}}
      * &lt;velo-tool-viewer name="{{.Name}}" version="{{.Version}}"&gt;&lt;/velo-tool-viewer&gt;
      {{ end }}

      {{ end }}

      {{ if $artifact.Parameters }}

      ### Parameters

      &lt;table class="table table-striped"&gt;
      &lt;thead&gt;
         &lt;tr&gt;
           &lt;th&gt;Name&lt;/th&gt;
           &lt;th&gt;Type&lt;/th&gt;
           &lt;th&gt;Default&lt;/th&gt;
           &lt;th&gt;Description&lt;/th&gt;
         &lt;/tr&gt;
      &lt;/thead&gt;
      &lt;tbody&gt;
      {{- range $item := $artifact.Parameters -}}
         {{- if not (eq $item.Type "hidden") -}}
           &lt;tr&gt;
             &lt;td&gt;{{ $item.Name }}&lt;/td&gt;
             &lt;td&gt;{{ $item.Type }}&lt;/td&gt;
             &lt;td&gt;&lt;pre&gt;{{ $item.Default }}&lt;/pre&gt;&lt;/td&gt;
             &lt;td&gt;{{ $item.Description }}&lt;/td&gt;
           &lt;/tr&gt;
         {{- end -}}
      {{- end -}}
      &lt;/tbody&gt;&lt;/table&gt;

      {{ end }}

      {{ if $artifact.Imports }}

      &lt;table class="table table-striped"&gt;
      &lt;thead&gt;
         &lt;tr&gt;
           &lt;th&gt;Imports&lt;/th&gt;
         &lt;/tr&gt;
      &lt;/thead&gt;
      &lt;tbody&gt;
      {{- range $item := $artifact.Imports -}}
        &lt;tr&gt;
          &lt;td&gt;{{ $item }}&lt;/td&gt;
        &lt;/tr&gt;
      {{- end -}}
      &lt;/tbody&gt;&lt;/table&gt;

      {{ end }}

      {{ if $artifact.Export }}
      ### Exports

      ```vql
      {{ $artifact.Export }}
      ```
      {{ end }}

      {{ range $source := $artifact.Sources }}

      {{ if or $source.Queries $source.Query $source.Notebook }}

      ### Source {{ $source.Name }}

      {{ if $source.Query }}

      ```vql
      {{ $source.Query }}
      ```

      {{- else if $source.Queries -}}

      ```vql
      {{ range $query := $source.Queries -}}
      {{- $query -}}
      {{ end }}
      ```

      {{ end }}

      {{ if len $source.Notebook }}

      #### Notebook cells

      {{ range $notebook := $source.Notebook }}

      {{ if $notebook.Name }}
      * `{{ $notebook.Type }}`: {{ $notebook.Name }}
      {{ else }}
      * `{{ $notebook.Type }}`
      {{ end }}
      {{ end }}

      {{ end }}

      {{ end }}

      {{ end }}

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.ntfs.i30.md
======
---
title: Windows.NTFS.I30
hidden: true
tags: [Client Artifact]
---

Carve the $I30 index stream for a directory.

This can reveal previously deleted files. Optionally upload the I30
stream to the server as well.


<pre><code class="language-yaml">
name: Windows.NTFS.I30
description: |
  Carve the $I30 index stream for a directory.

  This can reveal previously deleted files. Optionally upload the I30
  stream to the server as well.

parameters:
 - name: DirectoryGlobs
   default: C:\Users\*

 - name: SlackOnly
   description: "Select to return only entries from Slack space."
   type: bool

 - name: AlsoUpload
   description: Select to also upload the raw $I30 stream.
   type: bool

sources:
  - name: UploadI30Streams
    precondition:
      SELECT * FROM info() where OS = 'windows' AND AlsoUpload

    query: |
       LET inodes = SELECT OSPath, Data.mft AS MFT,
             parse_ntfs(device=OSPath, inode=Data.mft) AS MFTInfo
       FROM glob(globs=DirectoryGlobs, accessor="ntfs")
       WHERE IsDir

       LET upload_streams = SELECT * FROM foreach(
         row=MFTInfo.Attributes,
         query={
           SELECT _value.Type AS Type,
                  _value.TypeId AS TypeId,
                  _value.Id AS Id,
                  _value.Inode AS Inode,
                  _value.Size AS Size,
                  _value.Name AS Name,
                  _value.OSPath AS OSPath,
                  upload(accessor="mft",
                         file=MFTInfo.Device + _value.Inode,
                         name=pathspec(Path=_value.OSPath + "/" + _value.Inode)) AS IndexUpload
           FROM scope()
           WHERE Type =~ "INDEX_"
       })

       SELECT * FROM foreach(row=inodes, query=upload_streams)

  - name: AnalyzeI30
    precondition:
      SELECT * FROM info() where OS = 'windows'

    query: |
       LET inodes = SELECT OSPath, Data.mft AS MFT,
             parse_ntfs(device=OSPath, inode=Data.mft) AS MFTInfo
       FROM glob(globs=DirectoryGlobs, accessor="ntfs")
       WHERE IsDir

       SELECT * FROM foreach(
         row=inodes,
         query={
            SELECT OSPath, Name, NameType, Size, AllocatedSize,
                   IsSlack, SlackOffset, Mtime, Atime, Ctime, Btime, MFTId
            FROM parse_ntfs_i30(device=MFTInfo.Device, inode=MFT)
            WHERE IsSlack = true or NOT SlackOnly
       })

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.system.catfiles.md
======
---
title: Windows.System.CatFiles
hidden: true
tags: [Client Artifact]
---

Windows stores many hashes in .cat files. These catalog files
contain a set of trusted hashes for drivers and other binaries,
even if the PE files do not themselves contain authenticode
signatures.

This artifact extracts all the trusted hashes from a system by
parsing all the cat files.


<pre><code class="language-yaml">
name: Windows.System.CatFiles
description: |
   Windows stores many hashes in .cat files. These catalog files
   contain a set of trusted hashes for drivers and other binaries,
   even if the PE files do not themselves contain authenticode
   signatures.

   This artifact extracts all the trusted hashes from a system by
   parsing all the cat files.

parameters:
   - name: CatGlobs
     default: C:\Windows\System32\CatRoot\*\*.cat
   - name: SignerExcludeRegex
     description: Exclude hashes from this Signer
     default: Microsoft
     type: regex

   - name: SignerFilterRegex
     description: Only show hashes from this signer.
     default: .
     type: regex

sources:
  - precondition:
      SELECT OS From info() where OS = 'windows'

    query: |
        LET parsed_cats = SELECT Name, parse_pkcs7(data=read_file(filename=OSPath)) AS PKCS7
        FROM glob(globs=CatGlobs)

        -- Extract the CertificateTrustList and Subject who signed the cat file.
        LET extracted = SELECT Name, PKCS7.Signer.Subject AS Signer,
            PKCS7.CertificateTrustList.Hash AS CTL
        FROM parsed_cats
        WHERE Signer =~ SignerFilterRegex AND NOT Signer =~ SignerExcludeRegex

        -- Expand all the hashes in the same cat file to flatten the results
        SELECT * FROM foreach(row=extracted, query={
            SELECT * FROM foreach(row=CTL, query={
                SELECT Name, Signer, _value AS Hash FROM scope()
            })
        })

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.application.firefox.downloads.md
======
---
title: Windows.Application.Firefox.Downloads
hidden: true
tags: [Client Artifact]
---

Enumerate the users Firefox downloads.


```yaml
name: Windows.Application.Firefox.Downloads
description: |
  Enumerate the users Firefox downloads.
author: Angry-Bender @angry-bender, based on Custom.Windows.Application.Firefox.History by Zach Stanford @svch0st
parameters:
  - name: placesGlobs
    default: \AppData\Roaming\Mozilla\Firefox\Profiles\*\places.sqlite
  - name: urlSQLQuery
    default: |
        SELECT * FROM moz_annos,moz_anno_attributes,moz_places WHERE moz_annos.place_id=moz_places.id AND moz_annos.anno_attribute_id=moz_anno_attributes.id
  - name: userRegex
    default: .
    type: regex

precondition: SELECT OS From info() where OS = 'windows'

sources:
  - query: |
        LET places_files = SELECT * from foreach(
          row={
             SELECT Uid, Name AS User,
                    expand(path=Directory) AS HomeDirectory
             FROM Artifact.Windows.Sys.Users()
             WHERE Name =~ userRegex
          },
          query={
             SELECT User, OSPath, Mtime
             FROM glob(root=HomeDirectory, globs=placesGlobs)
          })

        LET metadata = SELECT * FROM foreach(row=places_files,
          query={
            SELECT parse_json(data=content)
            FROM sqlite(
              file=OSPath,
              query=urlSQLQuery)
             WHERE name = 'downloads/metaData'
          })

        SELECT * FROM foreach(row=places_files,
          query={
            SELECT User,
                   timestamp(epoch=dateAdded) as startTime,
                   if(condition=name=~'metaData',
                    then=timestamp(epoch=parse_json(data=content).endTime)
                    ) AS endTime,
                   timestamp(epoch=lastModified) as last_modified,
                   id,
                   name,
                   url,
                   place_id,
                   if(condition=name=~'metaData',
                    then=parse_json(data=content).fileSize
                    ) AS fileSize,
                   if(condition=name=~'metaData',
                    then=parse_json(data=content).state
                    ) AS state,
                   if(condition=name=~'destinationFileURI',
                    then=content
                    ) AS localDirectory,
                   flags,
                   expiration,
                   type
            FROM sqlite(
              file=FullPath,
              query=urlSQLQuery)
            ORDER BY last_modified DESC
          })

```

---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.sys.drivers.md
======
---
title: Windows.Sys.Drivers
hidden: true
tags: [Client Artifact]
---

Details for in-use Windows device drivers. This does not display
installed but unused drivers.


<pre><code class="language-yaml">
name: Windows.Sys.Drivers
description: |
  Details for in-use Windows device drivers. This does not display
  installed but unused drivers.

precondition:
      SELECT OS From info() where OS = 'windows'

parameters:
  - name: AlsoCheckAuthenticode
    type: bool
    description: If selected we also check the authenticode information.
    default: "Y"

  - name: DISABLE_DANGEROUS_API_CALLS
    type: bool
    description: |
      Enable this to disable potentially flakey APIs which may cause
      crashes.

sources:
  - name: SignedDrivers
    query: |
       SELECT *
       FROM wmi(
          query="select * from Win32_PnPSignedDriver",
          namespace="ROOT\\CIMV2")

  - name: RunningDrivers
    query: |
       SELECT *, if(
         condition=AlsoCheckAuthenticode,
         then=authenticode(filename=PathName)) AS Authenticode,
         hash(path=PathName) AS Hashes
       FROM wmi(
         query="select * from Win32_SystemDriver",
         namespace="ROOT\\CIMV2")
    notebook:
      - type: vql_suggestion
        name: Unique issuers
        template: |
          /*
          # Unique Issuers of drivers

          These are the unique signers of drivers on a system
          (excluding microsoft drivers).

          */
          SELECT count() AS Count,
                 enumerate(items=Name) AS Names,
                 Authenticode.IssuerName AS Issuer, Hashes
          FROM source(artifact="Windows.Sys.Drivers/RunningDrivers")
          WHERE NOT Issuer =~ "Microsoft"
          GROUP BY Issuer

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.applications.officemacros.md
======
---
title: Windows.Applications.OfficeMacros
hidden: true
tags: [Client Artifact]
---

Office macros are a favourite initial infection vector. Many users
click through the warning dialogs.

This artifact scans through the given directory glob for common
office files. We then try to extract any embedded macros by parsing
the OLE file structure.

If a macro calls an external program (e.g. Powershell) this is very
suspicious!


<pre><code class="language-yaml">
name: Windows.Applications.OfficeMacros
description: |
  Office macros are a favourite initial infection vector. Many users
  click through the warning dialogs.

  This artifact scans through the given directory glob for common
  office files. We then try to extract any embedded macros by parsing
  the OLE file structure.

  If a macro calls an external program (e.g. Powershell) this is very
  suspicious!

parameters:
  - name: officeExtensions
    default: "*.{xls,xlsm,doc,docx,ppt,pptm}"
  - name: officeFileSearchGlob
    default: C:\Users\**\
    description: The directory to search for office documents.

sources:
  - query: |
        SELECT * FROM foreach(
           row={
              SELECT OSPath FROM glob(globs=officeFileSearchGlob + officeExtensions)
           },
           query={
               SELECT * from olevba(file=OSPath)
           })

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/macos.network.packetcapture.md
======
---
title: MacOS.Network.PacketCapture
hidden: true
tags: [Client Artifact]
---

This artifact leverages tcpdump to natively capture packets.

The `Duration` parameter is used to define how long (in seconds) the capture should be.  Specific interfaces can be defined using the `Interface` parameter, otherwise the artifact defaults to an interface assignment of `any`.

A `BPF` (Berkeley Packet Filter) expression can also be supplied to filter the captured traffic as desired.

Read more about BPF expressions here: https://biot.com/capstats/bpf.html


<pre><code class="language-yaml">
name: MacOS.Network.PacketCapture
author: Wes Lambert, @therealwlambert
description: |
  This artifact leverages tcpdump to natively capture packets.

  The `Duration` parameter is used to define how long (in seconds) the capture should be.  Specific interfaces can be defined using the `Interface` parameter, otherwise the artifact defaults to an interface assignment of `any`.

  A `BPF` (Berkeley Packet Filter) expression can also be supplied to filter the captured traffic as desired.
  
  Read more about BPF expressions here: https://biot.com/capstats/bpf.html

required_permissions:
  - EXECVE

parameters:
  - name: Duration
    type: integer
    description: Duration (in seconds) of PCAP to be recorded.
    default: 10
  
  - name: Interface
    type: string
    default: any

  - name: BPF
    type: string
    default:
    
precondition:
  SELECT * FROM info() where OS = 'darwin'

sources:
    - query: |
            LET pcap &lt;= tempfile(extension=".pcap")
            SELECT *, upload(file=pcap) AS PCAP
              FROM execve(argv=['bash', '-c', format(format='''(tcpdump -nni %v -w %v %v) &amp; sleep %v; kill $!''', args=[Interface, pcap, BPF, Duration])], length=1000000)

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.detection.binaryhunter.md
======
---
title: Windows.Detection.BinaryHunter
hidden: true
tags: [Client Artifact]
---

This artifact enables hunting for binary attributes.

The artifact takes a glob targetting input, then checks each file in scope for an MZ header.
The artifact also queries Authenticode details and parses out PE attributes.

Both PE and Authenticode output can be queried for relevant strings using a regex filter and whitelist to hunt with.
This enables unique capability to hunt for specific things such as PE imports, exports or other attributes.

Note: this artifacts filters are cumulative so a hash based hit will return
no results if the file is filtered out by other filters.
For most performant searches leverage path, size and and date filters. By default
the artifact leverages the 'auto' data accessor but can also be changed as desired.


<pre><code class="language-yaml">
name: Windows.Detection.BinaryHunter
author: "Matt Green - @mgreen27"
description: |
    This artifact enables hunting for binary attributes.

    The artifact takes a glob targetting input, then checks each file in scope for an MZ header.
    The artifact also queries Authenticode details and parses out PE attributes.

    Both PE and Authenticode output can be queried for relevant strings using a regex filter and whitelist to hunt with.
    This enables unique capability to hunt for specific things such as PE imports, exports or other attributes.

    Note: this artifacts filters are cumulative so a hash based hit will return
    no results if the file is filtered out by other filters.
    For most performant searches leverage path, size and and date filters. By default
    the artifact leverages the 'auto' data accessor but can also be changed as desired.

parameters:
  - name: TargetGlob
    description: Glob to target.
    default: "C:/Users/**/*"
  - name: Accessor
    description: Velociraptor accessor to use. Changing to ntfs will increase scan time.
    default: auto
  - name: UnexpectedExtension
    description: "Exclude binaries with expected extension: com|cpl|dll|drv|exe|mui|scr|sfx|sys|winmd"
    type: bool
  - name: ExcludeTrusted
    description: Exclude binaries with Trusted Authenticode certificates.
    type: bool
  - name: AuthenticodeRegex
    description: Regex to search through all authenrticode data.
    default: .
    type: regex
  - name: AuthenticodeWhitelistRegex
    description: Regex to whitelist in all Authenticode data.
    default:
    type: regex
  - name: PEInformationRegex
    description: Regex to filter for PE information. e.g VersionInformation, exports etc
    default: .
    type: regex
  - name: PEInformationWhitelistRegex
    description: Regex to whitelist for PE information. e.g VersionInformation, exports etc
    default:
    type: regex
  - name: DateAfter
    description: Search for binaries with timestamps after this date. YYYY-MM-DDTmm:hh:ssZ
    type: timestamp
  - name: DateBefore
    description: Search for binaries with timestamps before this date. YYYY-MM-DDTmm:hh:ssZ
    type: timestamp
  - name: SizeMax
    description: Return binaries only under this size in bytes.
    type: int64
    default: 4294967296
  - name: SizeMin
    description: Return binaries only over this size in bytes.
    type: int64
    default: 0
  - name: MD5List
    description: MD5 hash list to hunt for. New MD5 hash on each line
    default:
  - name: SHA1List
    description: SHA1 hash list to hunt for. New SHA1 hash on each line
    default:
  - name: SHA256List
    description: SHA256 hash list to hunt for. New SHA256 hash on each line
    default:
  - name: DISABLE_DANGEROUS_API_CALLS
    type: bool
    description: |
      Enable this to disable potentially flakey APIs which may cause
      crashes.

sources:
  - query: |
      -- setup hash lists if needed
      LET MD5Array &lt;= split(sep='\\s+',string=MD5List)
      LET SHA1Array &lt;=  split(sep='\\s+',string=SHA1List)
      LET SHA256Array &lt;= split(sep='\\s+',string=SHA256List)

      -- firstly find files in scope with performance
      LET find_files = SELECT *,
            read_file(filename=OSPath,accessor=Accessor,offset=0,length=2) as _Header
        FROM if(condition=DateBefore AND DateAfter,
            then={
                SELECT OSPath, Name, Size,Mtime,Atime,Ctime,Btime
                FROM glob(globs=TargetGlob,accessor=Accessor)
                WHERE NOT IsDir AND NOT IsLink
                    AND Size &gt; SizeMin AND Size &lt; SizeMax
                    AND ( Mtime &lt; DateBefore OR Ctime &lt; DateBefore OR Btime &lt; DateBefore )
                    AND ( Mtime &gt; DateAfter OR Ctime &gt; DateAfter OR Btime &gt; DateAfter )
            },
            else={ SELECT * FROM  if(condition=DateBefore,
                then={
                    SELECT OSPath, Name, Size,Mtime,Atime,Ctime,Btime
                    FROM glob(globs=OSPath,accessor=Accessor)
                    WHERE NOT IsDir AND NOT IsLink
                        AND Size &gt; SizeMin AND Size &lt; SizeMax
                        AND ( Mtime &lt; DateBefore OR Ctime &lt; DateBefore OR Btime &lt; DateBefore )
                },
                else={ SELECT * FROM  if(condition=DateAfter,
                then={
                    SELECT OSPath, Name, Size,Mtime,Atime,Ctime,Btime
                    FROM glob(globs=TargetGlob,accessor=Accessor)
                    WHERE NOT IsDir AND NOT IsLink
                        AND Size &gt; SizeMin AND Size &lt; SizeMax
                        AND ( Mtime &gt; DateAfter OR Ctime &gt; DateAfter OR Btime &gt; DateAfter )
                },
                else={
                    SELECT OSPath, Name, Size,Mtime,Atime,Ctime,Btime
                    FROM glob(globs=TargetGlob,accessor=Accessor)
                    WHERE NOT IsDir AND NOT IsLink
                        AND Size &gt; SizeMin AND Size &lt; SizeMax
                })})})
        WHERE _Header = 'MZ'
            AND if(condition= UnexpectedExtension,
                then= NOT Name =~ '\.(com|cpl|dll|drv|exe|mui|scr|sfx|sys|winmd)$',
                else= True)


      -- parse PE attributes and run final filters
      SELECT
        dict(OSPath=OSPath,Name=Name,Size=Size,
            Timestamps=dict(Mtime=Mtime,Atime=Atime,Ctime=Ctime,Btime=Btime)
                ) as File,
        authenticode(filename=OSPath) as Authenticode,
        parse_pe(file=OSPath) as PE,
        hash(path=OSPath) as Hash
      FROM find_files
      WHERE
        serialize(item=Authenticode) =~ AuthenticodeRegex
        AND NOT if(condition=WhitelistRegex,
            then= serialize(item=Authenticode) =~ AuthenticodeWhitelistRegex,
            else= False)
        AND serialize(item=PE) =~ PEInformationRegex
        AND NOT if(condition=PEInformationWhitelistRegex,
            then= serialize(item=PE) =~ PEInformationWhitelistRegex,
            else= False)
        AND if(condition= ExcludeTrusted,
                then= NOT Authenticode.Trusted = "trusted",
                else= True)
        AND if(condition= MD5List OR SHA1List OR SHA256List,
            then=(
                    if(condition= MD5List,
                    then= Hash.MD5 in MD5Array)
                 OR if(condition= SHA1List,
                        then= Hash.SHA1 in SHA1Array)
                 OR if(condition= SHA256List,
                        then= Hash.SHA256 in SHA256Array)
            ), else = True )

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/server.import.curatedsigma.md
======
---
title: Server.Import.CuratedSigma
hidden: true
tags: [Server Artifact]
---

This artifact allows importing curated Sigma rules from
https://sigma.velocidex.com

Collect this artifact on the server to automatically import or
update these artifacts.


<pre><code class="language-yaml">
name: Server.Import.CuratedSigma
description: |
  This artifact allows importing curated Sigma rules from
  https://sigma.velocidex.com

  Collect this artifact on the server to automatically import or
  update these artifacts.

type: SERVER

required_permissions:
- SERVER_ADMIN

parameters:
  - name: Prefix
    description: Add this prefix to imported artifacts
    validating_regex: '^[a-zA-Z0-9_.]*$'

sources:
  - query: |
      LET URL &lt;= "https://sigma.velocidex.com/Velociraptor.Sigma.Artifacts.zip"

      SELECT * FROM Artifact.Server.Import.ArtifactExchange(
         Prefix=Prefix, ExchangeURL=URL)

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/server.import.previousreleases.md
======
---
title: Server.Import.PreviousReleases
hidden: true
tags: [Server Artifact]
---

When upgrading the Velociraptor server the built in artifacts may
change using newer VQL features that are not present on older
clients.

If you have some older clients that can not be upgraded, sometimes
collecting standard built-in artifacts will fail. In this case it is
handy to import older VQL artifacts that work with these older
clients.

This server artifact allows you to automatically import all
artifacts that came bundled with previous versions. These should be
compatible with older clients.


<pre><code class="language-yaml">
name: Server.Import.PreviousReleases
description: |
  When upgrading the Velociraptor server the built in artifacts may
  change using newer VQL features that are not present on older
  clients.

  If you have some older clients that can not be upgraded, sometimes
  collecting standard built-in artifacts will fail. In this case it is
  handy to import older VQL artifacts that work with these older
  clients.

  This server artifact allows you to automatically import all
  artifacts that came bundled with previous versions. These should be
  compatible with older clients.

type: SERVER

required_permissions:
- SERVER_ADMIN

parameters:
  - name: VelociraptorRelease
    description: |
      The Velociraptor Release to import.
    type: choices
    default: v0.72
    choices:
      - v0.7.0
      - v0.7.1
      - v0.72

sources:
  - query: |
      LET Prefix &lt;= regex_replace(source=VelociraptorRelease, re='\\.', replace="") + "."
      LET ExchangeURL = "https://docs.velociraptor.app/release_artifacts/release_artifacts_" + VelociraptorRelease + ".zip"

      LET X = SELECT artifact_set(
           prefix=Prefix,
           definition=Definition) AS Definition
        FROM foreach(row={
          SELECT Content FROM http_client(
             remove_last=TRUE,
             tempfile_extension=".zip", url=ExchangeURL)
        }, query={
          -- Replace internal references to use the same version so
          -- artifacts are still internally consistent.
          SELECT regex_replace(source=read_file(accessor="zip", filename=OSPath),
             re='''(?sm) Artifact\.([a-z0-9._]+?[(])''',
             replace=" Artifact." + Prefix + "$1") AS Definition
          FROM glob(
             globs='/**/*.yaml',
             root=pathspec(
                DelegateAccessor="auto",
                DelegatePath=Content),
             accessor="zip")
          WHERE NOT Definition =~ "(?ms)type: +INTERNAL"
        })

        SELECT Definition.name AS Name,
               Definition.description AS Description,
               Definition.author AS Author
        FROM X

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/macos.forensics.fsevents.md
======
---
title: MacOS.Forensics.FSEvents
hidden: true
tags: [Client Artifact]
---

This artifact parses the FSEvents log files.

We can filter on Path, Flags or use time box on source file.

An interesting hunt may be filter for Entries of plist files modified or
created on a specific date. Malware often creates plist files in
/Library/LaunchAgents, Library/Preferences, /Library/LaunchDaemons, or
/Library/Internet Plugins.

NOTE:

- FSEvents do not have timestamps so we specify source file Mtime and
Btime.
- default timeout is only 600 seconds - you will need to increase for this
colection to finish.


<pre><code class="language-yaml">
name: MacOS.Forensics.FSEvents
description: |
   This artifact parses the FSEvents log files.

   We can filter on Path, Flags or use time box on source file.

   An interesting hunt may be filter for Entries of plist files modified or
   created on a specific date. Malware often creates plist files in
   /Library/LaunchAgents, Library/Preferences, /Library/LaunchDaemons, or
   /Library/Internet Plugins.

   NOTE:

   - FSEvents do not have timestamps so we specify source file Mtime and
   Btime.
   - default timeout is only 600 seconds - you will need to increase for this
   colection to finish.

author: |
  Mike Cohen, Matt Green - @mgreen27, Yogesh Khatri (@swiftforensics), CyberCX

reference:
- https://www.osdfcon.org/presentations/2017/Ibrahim-Understanding-MacOS-File-Ststem-Events-with-FSEvents-Parser.pdf
- https://www.crowdstrike.com/blog/using-os-x-fsevents-discover-deleted-malicious-artifact/

type: CLIENT

parameters:
   - name: GlobTable
     type: csv
     default: |
       Glob
       /.fseventsd/*
       /System/Volumes/Data/.fseventsd/*
   - name: Glob
     type: string
     description: Instead of providing the globs in a table, a single glob may be given.
   - name: PathRegex
     description: Filter the path by this regexp
     default: .
     type: regex
   - name: FlagsRegex
     description: Filter by flags
     type: regex
     default: .
   - name: DateAfter
     type: timestamp
     description: "search for source files with Btime after this date. YYYY-MM-DDTmm:hh:ssZ"
   - name: DateBefore
     type: timestamp
     description: "search for source files with Mtime before this date. YYYY-MM-DDTmm:hh:ssZ"

export: |
    LET FSEventProfile = '''[
    ["FSEventsProfile", 0, [
      ["Entries", 0, "Array", {
         type: "Header",
         count: 10000,
      }],
    ]],
    ["Header", "x=&gt;x.Info.StreamSize", [
      ["Version", 0, "Enumeration", {
         type: "unsigned int",
         choices: {
           "1145852721": "V1",
           "1145852722": "V2",
           "1145852723": "V3"
         }
      }],
      ["Info", 8, "Union", {
         selector: "x=&gt;x.Version",
         choices: {
             "V1": "FS1",
             "V2": "FS2",
             "V3": "FS3",
         }
      }],
    ]],
    ["FS1", "x=&gt;x.StreamSize - 8", [
      ["StreamSize", 0, uint32],
      ["Items", 4, "Array", {
          count: 10000,
          max_count: 10000,
          type: FSEventEntry1,
          sentinel: "x=&gt;this.EndOf &lt; x.EndOf",
      }],
    ]],
    ["FS2", "x=&gt;x.StreamSize - 8", [
      ["StreamSize", 0, uint32],
      ["Items", 4, "Array", {
          count: 10000,
          max_count: 10000,
          type: FSEventEntry2,
          sentinel: "x=&gt;this.EndOf &lt; x.EndOf",
      }],
    ]],
    ["FS3", "x=&gt;x.StreamSize - 8", [
      ["StreamSize", 0, uint32],
      ["Items", 4, "Array", {
          count: 10000,
          max_count: 2336,
          type: FSEventEntry3,
          sentinel: "x=&gt;this.EndOf &lt; x.EndOf",
      }],
    ]],
    ["FSEventEntry1", "x=&gt;len(list=x.path) + 13", [
      ["path", 0, "String"],
      ["id", "x=&gt;len(list=x.path) + 1", "uint64"],
      ["flags", "x=&gt;len(list=x.path) + 9", "Flags", {
          type: "uint32",
          bitmap: {
            FSE_CREATE_FILE: 0,
            FSE_DELETE: 1,
            FSE_STAT_CHANGED: 2,
            FSE_RENAME: 3,
            FSE_CONTENT_MODIFIED: 4,
            FSE_EXCHANGE: 5,
            FSE_FINDER_INFO_CHANGED: 6,
            FSE_CREATE_DIR: 7,
            FSE_CHOWN: 8,
            FSE_XATTR_MODIFIED: 9,
            FSE_XATTR_REMOVED: 10,
            FSE_DOCID_CREATED: 11,
            FSE_DOCID_CHANGED: 12,
            FSE_UNMOUNT_PENDING: 13,
            FSE_CLONE: 14,
            FSE_MODE_CLONE: 16,
            FSE_TRUNCATED_PATH: 17,
            FSE_REMOTE_DIR_EVENT: 18,
            FSE_MODE_LAST_HLINK: 19,
            FSE_MODE_HLINK: 20,
            IsSymbolicLink: 22,
            IsFile: 23,
            IsDirectory: 24,
            Mount: 25,
            Unmount: 26,
            EndOfTransaction: 29
          }
      }],
      ["file_id", 0, "Value", {"value": ""}],
    ]],
    ["FSEventEntry2", "x=&gt;len(list=x.path) + 21", [
      ["path", 0, "String"],
      ["id", "x=&gt;len(list=x.path) + 1", "uint64"],
      ["flags", "x=&gt;len(list=x.path) + 9", "Flags", {
          type: "uint32",
          bitmap: {
            FSE_CREATE_FILE: 0,
            FSE_DELETE: 1,
            FSE_STAT_CHANGED: 2,
            FSE_RENAME: 3,
            FSE_CONTENT_MODIFIED: 4,
            FSE_EXCHANGE: 5,
            FSE_FINDER_INFO_CHANGED: 6,
            FSE_CREATE_DIR: 7,
            FSE_CHOWN: 8,
            FSE_XATTR_MODIFIED: 9,
            FSE_XATTR_REMOVED: 10,
            FSE_DOCID_CREATED: 11,
            FSE_DOCID_CHANGED: 12,
            FSE_UNMOUNT_PENDING: 13,
            FSE_CLONE: 14,
            FSE_MODE_CLONE: 16,
            FSE_TRUNCATED_PATH: 17,
            FSE_REMOTE_DIR_EVENT: 18,
            FSE_MODE_LAST_HLINK: 19,
            FSE_MODE_HLINK: 20,
            IsSymbolicLink: 22,
            IsFile: 23,
            IsDirectory: 24,
            Mount: 25,
            Unmount: 26,
            EndOfTransaction: 29
          }
      }],
      ["file_id", "x=&gt;len(list=x.path) + 13", "int64"],
    ]],
    ["FSEventEntry3", "x=&gt;len(list=x.path) + 25", [
      ["path", 0, "String"],
      ["id", "x=&gt;len(list=x.path) + 1", "uint64"],
      ["flags", "x=&gt;len(list=x.path) + 9", "Flags", {
          type: "uint32",
          bitmap: {
            FSE_CREATE_FILE: 0,
            FSE_DELETE: 1,
            FSE_STAT_CHANGED: 2,
            FSE_RENAME: 3,
            FSE_CONTENT_MODIFIED: 4,
            FSE_EXCHANGE: 5,
            FSE_FINDER_INFO_CHANGED: 6,
            FSE_CREATE_DIR: 7,
            FSE_CHOWN: 8,
            FSE_XATTR_MODIFIED: 9,
            FSE_XATTR_REMOVED: 10,
            FSE_DOCID_CREATED: 11,
            FSE_DOCID_CHANGED: 12,
            FSE_UNMOUNT_PENDING: 13,
            FSE_CLONE: 14,
            FSE_MODE_CLONE: 16,
            FSE_TRUNCATED_PATH: 17,
            FSE_REMOTE_DIR_EVENT: 18,
            FSE_MODE_LAST_HLINK: 19,
            FSE_MODE_HLINK: 20,
            IsSymbolicLink: 22,
            IsFile: 23,
            IsDirectory: 24,
            Mount: 25,
            Unmount: 26,
            EndOfTransaction: 29
          }
      }],
      ["file_id", "x=&gt;len(list=x.path) + 13", "int64"],
      ["unknown_id", "x=&gt;len(list=x.path) + 21", "int32"],
    ]],
    ]'''

sources:
  - query: |
      LET files = SELECT OSPath, Mtime, Btime
        FROM glob(globs=(Glob || GlobTable.Glob))
        WHERE   if(condition=DateAfter, then= Btime &gt; DateAfter, else= True )
            AND if(condition=DateBefore, then= Mtime &lt; DateBefore, else= True )
            AND log(message=OSPath)

      LET x = SELECT * FROM foreach(row=files,
        query={
            SELECT
                Version,
                Info.Items as items,
                OSPath.Basename as SourceFile,
                Mtime as SourceMtime,
                Btime as SourceBtime
            FROM
                foreach(row=parse_binary(
                    filename=read_file(filename=OSPath, accessor="gzip", length=1000000),
                    accessor="data",
                    profile=FSEventProfile, struct="FSEventsProfile").Entries)
        })
        WHERE EntryPath =~ PathRegex AND EntryFlags =~ FlagsRegex

      SELECT
        items.path as EntryPath,
        items.id as EntryId,
        join(array=items.flags, sep=", ") AS EntryFlags,
        items.file_id as FileId,
        SourceFile,
        SourceMtime,
        SourceBtime,
        Version
      FROM
        flatten(query=x)

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.detection.service.upload.md
======
---
title: Windows.Detection.Service.Upload
hidden: true
tags: [Client Event Artifact]
---

When a new service is installed, upload the service binary to the server


<pre><code class="language-yaml">
name: Windows.Detection.Service.Upload
description: |
  When a new service is installed, upload the service binary to the server

type: CLIENT_EVENT

precondition: SELECT OS From info() where OS = 'windows'

sources:
  - query: |
      // Sometimes the image path contains the full command line - we
      // try to extract the first parameter as the binary itself. Deal
      // with two options - either quoted or not.
      SELECT ServiceName, upload(file=regex_replace(
                    source=ImagePath,
                    replace="$2",
                    re='^("([^"]+)" .+|([^ ]+) .+)')) AS Upload,
               Timestamp, _EventData, _System
      FROM Artifact.Windows.Events.ServiceCreation()

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.detection.binaryrename.md
======
---
title: Windows.Detection.BinaryRename
hidden: true
tags: [Client Artifact]
---

This artifact will detect renamed binaries commonly abused by adversaries.

Binary rename is a defence evasion technique used to bypass brittle process
name and path based detections. Observed in use across
all stages of the attack lifecycle it is a technique used by a large
selection of actors from commodity malware crews through to Nation States.

Add additional entries to the VersionInfoTable parameter. For straight
detection on an Internal or Original name, the Filename entry can be set to
an unlikely value - e.g ANY or left blank.


<pre><code class="language-yaml">
name: Windows.Detection.BinaryRename
author: "Matt Green - @mgreen27"
description: |
    This artifact will detect renamed binaries commonly abused by adversaries.

    Binary rename is a defence evasion technique used to bypass brittle process
    name and path based detections. Observed in use across
    all stages of the attack lifecycle it is a technique used by a large
    selection of actors from commodity malware crews through to Nation States.

    Add additional entries to the VersionInfoTable parameter. For straight
    detection on an Internal or Original name, the Filename entry can be set to
    an unlikely value - e.g ANY or left blank.


reference:
  - https://mgreen27.github.io/posts/2019/05/12/BinaryRename.html
  - https://attack.mitre.org/techniques/T1036/003/

type: CLIENT

parameters:
  - name: TargetGlob
    default: /**/*.exe
  - name: VersionInfoTable
    type: csv
    default: |
        Filename,Internal,Original,Description,Note
        cmd.exe,cmd,Cmd.Exe,Windows Command Processor,cmd.exe
        7z.exe,7z,7z.exe,7-Zip Console,7z.exe
        certutil.exe,CertUtil.exe,CertUtil.exe,CertUtil,certutil.exe
        cmstp.exe,CMSTP,CMSTP.EXE,Microsoft Connection Manager Profile Installer,cmstp.exe
        cscript.exe,cscript.exe,cscript.exe,Microsoft ® Console Based Script Host,cscript.exe
        mshta.exe,MSHTA.EXE,MSHTA.EXE,Microsoft ® HTML Application host,mshta.exe
        msiexec.exe,msiexec,msiexec.exe,Windows® installer,msiexec.exe
        powershell.exe,POWERSHELL,PowerShell.EXE,Windows PowerShell,powershell.exe
        psexec.exe,PsExec,psexec.c,Sysinternals PSExec,psexec.exe
        psexec64.exe,PsExec,psexec.exe,Sysinternals PSExec,psexec64.exe
        regsvr32.exe,REGSVR32,REGSVR32.EXE,Microsoft© Register Server,regsvr32.exe
        rundll32.exe,rundll,RUNDLL32.EXE,Windows host process (Rundll32),rundll32.exe
        winrar.exe,WinRAR,WinRAR.exe,WinRAR archiver,winrar.exe
        wmic.exe,wmic.exe,wmic.exe,WMI Commandline Utility,wmic.exe
        wscript.exe,wscript.exe,wscript.exe,Microsoft ® Windows Based Script Host,wscript.exe
        wevtutil.exe,wevtutil.exe,wevtutil.exe,,wevtutil.exe
        net.exe,net.exe,net.exe,,net.exe
        net1.exe,net1.exe,net1.exe,,net1.exe
        netsh.exe,netsh.exe,netsh.exe,,netsh.exe
        powershell_ise.exe,powershell_ise.exe,powershell_ise.exe,,powershell_ise.exe
        dsquery.exe,dsquery.exe,dsquery.exe,Microsoft AD DS/LDS query command line utility,dsquery.exe
        nbtstat.exe,nbtinfo.exe,nbtinfo.exe,Microsoft TCP/IP NetBios Information,nbtstat.exe
        nltest.exe,nltestrk.exe,nltestrk.exe,Microsoft® Logon Server Test Utility,nltest.exe
        qprocess.exe,qprocess,qprocess.exe,Query Process Utility,qprocess.exe
        qwinsta.exe,qwinsta,qwinsta.exe,Query Session Utility,qwinsta.exe
        ANY,nc,nc.exe,NetCat for Windows - https://github.com/diegocr/netcat,nc.exe
        ANY,AdFind.exe,AdFind.exe,Joeware ADFind,AdFind.exe
        ANY,rclone,rclone.exe,Rsync for cloud storage,rclone.exe
        ANY,MEGAsync.exe,MEGAsync.exe,MEGAsync,MEGAsync.exe
        ANY,MEGAcmdShell.exe,MEGAcmdShell,MEGAcmdShell,MEGAcmdShell
        ANY,pCloud.exe,pCloud.exe,pCloud cloud storage,pCloud.exe
        ANY,,pCloud Drive.exe,pCloud setup,pCloud Drive.exe
        ANY,mimikatz,mimikatz.exe,mimikatz for Windows,mimikatz.exe
        ANY,ProcDump,procdump,Sysinternals process dump utility,procdump.exe
        ANY,ProcDump,procdump,Sysinternals process dump utility,procdump64.exe
        ANY,Ammyy Admin,,Ammyy Admin,AA_v3.exe
        ANY,,,AnyDesk,AnyDesk.exe
        ANY,PDQDeploySetup.exe,PDQDeploySetup.exe,PDQ Deploy Install,Deploy_19.3.298.0.exe
        ANY,PDQInventory.exe,PDQInventory.exe,PDQ Inventory Installer,Inventory_19.3.298.0.exe
        ANY,,,UltraVNC Setup,UltraVNC_1_3_81_X64_Setup.exe
        ANY,,,File Shredder by PowTools,file_shredder_setup.exe
        ANY,,pCloud Drive.exe,pCloud Drive,pCloud_Windows_3.11.12_x64.exe
        plink.exe,Plink,Plink,"Command-line SSH, Telnet, and Rlogin client",plink.exe
        pscp.exe,PSCP,PSCP,Command-line SCP/SFTP client,pscp.exe
        psftp.exe,PSFTP,PSFTP,Command-line interactive SFTP client,psftp.exe
        ANY,,,Total Commander Installer,tcmd1000x32.exe
        ANY,BulletsPassView,BulletsPassView.exe,BulletsPassView,BulletsPassView.exe
        ANY,WinLister,WinLister.exe,WinLister,winlister.exe
        ANY,HRSword,HRSword.exe,Huorong Sword GUI Frontend,HRSword v5.0.47.bin
        ANY,,,Email Password-Recovery,mailpv.exe
        ANY,Process Hacker,ProcessHacker.exe,Process Hacker,ProcessHacker.exe
        ANY,peview,peview.exe,PE Viewer,peview.exe
        ANY,ChromePass,ChromePass,Chrome Password Recovery,ChromePass.exe
        ANY,,,Application for scanning networks,netscan.exe
        ANY,WKV,,Extracts wireless keys stored by Windows,WirelessKeyView.exe
        ANY,Remote Desktop PassView,rdpv.exe,Password Recovery for Remote Desktop,rdpv.exe
        ANY,RouterPassView,RouterPassView.exe,Decrypts Router files.,RouterPassView.exe
        ANY,RemCom,RemCom.exe,Remote Command Executor,RemCom.exe
        ANY,,,Remote Utilities,host7.1.2.0.exe
        ANY,,viewer.7.1.2.0.exe,Remote Utilities - Viewer,viewer7.1.2.0.exe
        ANY,Web Browser Pass View,,Web Browser Password Viewer,WebBrowserPassView.exe
        ANY,PowerTool.exe,PowerTool.exe,Anti-virus/rootkit/bootkit Tool,PowerTool64.exe
        ANY,,winscp.com,Console interface for WinSCP,WinSCP.com
        ANY,winscp,winscp.exe,"WinSCP: SFTP, FTP, WebDAV, S3 and SCP client",WinSCP.exe
        ANY,iepv,iepv.exe,IE Passwords Viewer,iepv.exe
        ANY,VNCPassView,VNCPassView.exe,VNCPassView,VNCPassView.exe
        ANY,PCHunter,PCHunter.exe,Epoolsoft Windows Information View Tools,PCHunter32.exe
        ANY,Massscan_GUI.exe,Massscan_GUI.exe,Masscan_GUI,Massscan_GUI.exe
        ANY,ProxyLite.Windows.Console.exe,ProxyLite.Windows.Console.exe,ProxyLite Console Client,ProxyLite
        ANY,action1_agent.exe,action1_agent.exe,Endpoint Agent,Action1 agent
        ANY,action1_remote.exe,action1_remote.exe,Endpoint Agent,Action1 agent
        ANY,Defender Control,Defender Control,Windows Defender Control,Windows Defender Control
        ANY,NirCmd,NirCmd.exe,Nir Sofer,nircmd.exe
        ANY,NSudo,NSudo.exe,NSudo for Windows,Nsudo
        ANY,Python Application,pythonw.exe,Python,Python 3.10.0 packaged with DWAgent - possibly noisy.


sources:
  - query: |
      LET bins &lt;= SELECT
            if(condition=Filename='',then='ANY',
                else=lowcase(string=Filename)) AS Filename,
            if(condition=Internal='',then='ANY',
                else=lowcase(string=Internal)) AS Internal,
            if(condition=Original='',then='ANY',
                else=lowcase(string=Original)) AS Original
        FROM VersionInfoTable

      SELECT
        OSPath, Name, Size,
        parse_pe(file=OSPath).VersionInformation as VersionInformation,
        hash(path=OSPath) as Hash,
        Mtime, Atime, Ctime, Btime
      FROM glob(globs=TargetGlob)
      WHERE
        NOT IsDir AND NOT IsLink
        AND (
            (( lowcase(string=VersionInformation.OriginalFilename) in bins.Original
                OR lowcase(string=VersionInformation.InternalName) in bins.Internal )
                AND NOT lowcase(string=Name) in bins.Filename )
        OR OSPath =~ 'C:\\\\Windows\\\\System32\\\\(osk|Magnify|Narrator|DisplaySwitch).exe$'
            AND NOT VersionInformation.OriginalFilename =~ '^(osk|SR|Narrator|ScreenMagnifier|DisplaySwitch)\.exe$'
        )

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/linux.users.interactiveusers.md
======
---
title: Linux.Users.InteractiveUsers
hidden: true
tags: [Client Artifact]
---

Gets the interactive users from a Linux host.


<pre><code class="language-yaml">
name: Linux.Users.InteractiveUsers

description: |
  Gets the interactive users from a Linux host.

author: George-Andrei Iosif (@iosifache)

type: CLIENT

parameters:
  - name: NonInteractiveExecutables
    description: Non-interactive executables that may appear in user's details
    type: str
    default: "/usr/sbin/nologin,/bin/false,/sbin/nologin,/bin/sync"

sources:
  - precondition: |
      SELECT OS
      FROM info()
      WHERE OS = 'linux'

    query: |
      SELECT Fqdn AS Host,
              User,
              Description,
              Uid,
              Gid,
              Homedir,
              Shell 
      FROM Artifact.Linux.Sys.Users()
      WHERE NOT Shell IN split(string=NonInteractiveExecutables, sep_string=",")

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/linux.events.processexecutions.md
======
---
title: Linux.Events.ProcessExecutions
hidden: true
tags: [Client Event Artifact]
---

This artifact collects process execution logs from the Linux kernel.

This artifact relies on the presence of `auditctl` usually included
in the auditd package. On Ubuntu you can install it using:

```
apt-get install auditd
```


<pre><code class="language-yaml">
name: Linux.Events.ProcessExecutions
description: |
  This artifact collects process execution logs from the Linux kernel.

  This artifact relies on the presence of `auditctl` usually included
  in the auditd package. On Ubuntu you can install it using:

  ```
  apt-get install auditd
  ```

precondition: SELECT OS From info() where OS = 'linux'

type: CLIENT_EVENT

required_permissions:
  - EXECVE

parameters:
  - name: pathToAuditctl
    default: /sbin/auditctl
    description: We depend on auditctl to install the correct process execution rules.

sources:
  - query: |
     // Install the auditd rule if possible.
     LET _ &lt;= SELECT * FROM execve(argv=[pathToAuditctl, "-a",
          "exit,always", "-F", "arch=b64", "-S", "execve", "-k", "procmon"])

     LET exec_log = SELECT timestamp(string=Timestamp) AS Time, Sequence,
           atoi(string=Process.PID) AS Pid,
           atoi(string=Process.PPID) AS Ppid,
           Process.PPID AS PPID,
           atoi(string=Summary.Actor.Primary) AS UserId,
           Process.Title AS CmdLine,
           Process.Exe AS Exe,
           Process.CWD AS CWD
       FROM audit()
       WHERE "procmon" in Tags AND Result = 'success'

     // Cache Uid -&gt; Username mapping.
     LET users &lt;= SELECT User, atoi(string=Uid) AS Uid
       FROM Artifact.Linux.Sys.Users()

     // Enrich the original artifact with more data.
     SELECT Time, Pid, Ppid, UserId,
              { SELECT User from users WHERE Uid = UserId} AS User,
              regex_replace(source=read_file(filename= "/proc/" + PPID + "/cmdline"),
                            replace=" ", re="[\\0]") AS Parent,
              CmdLine,
              Exe, CWD
       FROM exec_log

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/server.powershell.encodedcommand.md
======
---
title: Server.Powershell.EncodedCommand
hidden: true
tags: [Server Event Artifact]
---

It is possible to pass powershell an encoded script. This artifact
decodes the scripts.

NOTE: The client must be running the Windows.Events.ProcessCreation
event artifact to retrieve process execution logs.


<pre><code class="language-yaml">
name: Server.Powershell.EncodedCommand
description: |
  It is possible to pass powershell an encoded script. This artifact
  decodes the scripts.

  NOTE: The client must be running the Windows.Events.ProcessCreation
  event artifact to retrieve process execution logs.

type: SERVER_EVENT

sources:
  - query: |
       SELECT ClientId, ParentInfo, CommandLine, Timestamp, utf16(
          string=base64decode(
             string=parse_string_with_regex(
                string=CommandLine,
                regex='-((?i)(en|enc|encode|encodedCommand)) (?P&lt;Encoded&gt;[^ ]+)'
             ).Encoded)) AS Script
        FROM watch_monitoring(artifact='Windows.Events.ProcessCreation')
        WHERE CommandLine =~ '-(en|enc|encode|encodedCommand)'

reports:
  - type: SERVER_EVENT
    template: |

      Encoded Powershell
      ==================

      {{ .Description }}

      ## Decoded Powershell commands.

      {{ Query "SELECT ClientId, { SELECT os_info.fqdn from clients(client_id=ClientId) } AS FQDN, Script FROM source()" | Table }}

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/linux.detection.anomalousfiles.md
======
---
title: Linux.Detection.AnomalousFiles
hidden: true
tags: [Client Artifact]
---

Detects anomalous files in a Linux filesystem.

An anomalous file is considered one that matches at least one criteria:

- Hidden (prefixed with a dot);

- Large, with a size over a specified limit; or

- With SUID bit set.


<pre><code class="language-yaml">
name: Linux.Detection.AnomalousFiles

description: |
  Detects anomalous files in a Linux filesystem.

  An anomalous file is considered one that matches at least one criteria:

  - Hidden (prefixed with a dot);

  - Large, with a size over a specified limit; or

  - With SUID bit set.

author: George-Andrei Iosif (@iosifache)

type: CLIENT

parameters:
  - name: MaxNormalSize
    description: Size (in bytes) above which a file is considered large
    type: int
    default: 10485760
  - name: PathsToSearch
    description: Paths to search, separated by comma
    type: str
    default: "/home/**,tmp/**"

sources:
  - precondition: |
      SELECT OS
      FROM info()
      WHERE OS = 'linux'

    query: |
      SELECT Fqdn AS Host,
             OSPath,
             substr(str=Name, start=0, end=1) = "." AS IsHidden,
             Size,
             Size &gt; MaxNormalSize AS IsLarge,
             Mode.String AS Mode,
             Mode =~ "^u" as HasSUID
      FROM glob(globs=split(string=PathsToSearch, sep_string=","))
      WHERE IsHidden OR IsLarge OR HasSUID

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.search.smbfilefinder.md
======
---
title: Windows.Search.SMBFileFinder
hidden: true
tags: [Client Artifact]
---

Find files on a remote filesystem using the filename or content.

## Security Note

In order to access a remote share we require the credentials of a
domain user. Currently only username/password are supported (i.e. no
Kerberose). You should use Group Policy to create a user with read
only access to the remote share.

## Performance Note

This artifact can be quite expensive slow and generate a lot of
network data, especially if we search file content. It will require
opening each file and reading its entire content. To minimize the
impact on the endpoint we recommend this artifact is collected with
a rate limited way (about 20-50 ops per second).


<pre><code class="language-yaml">
name: Windows.Search.SMBFileFinder
description: |
  Find files on a remote filesystem using the filename or content.

  ## Security Note

  In order to access a remote share we require the credentials of a
  domain user. Currently only username/password are supported (i.e. no
  Kerberose). You should use Group Policy to create a user with read
  only access to the remote share.

  ## Performance Note

  This artifact can be quite expensive slow and generate a lot of
  network data, especially if we search file content. It will require
  opening each file and reading its entire content. To minimize the
  impact on the endpoint we recommend this artifact is collected with
  a rate limited way (about 20-50 ops per second).

parameters:
  - name: ServerName
    default: 127.0.0.1:445
    description: |
      The name of the server to contact. If a port is not specified we
      use port 445

  - name: Username
    default: Guest
    type: redacted
    description: The name of a network user to access the remote share with.

  - name: Password
    default: password
    type: redacted
    description: The password to use for accessing the remote share.

  - name: SearchFilesGlob
    default: C$\Users\*
    description: |
      Use a glob to define the files that will be searched. The glob
      must contain the share name as the first component.

  - name: SearchFilesGlobTable
    type: csv
    default: |
      Glob
      C$/Users/SomeUser/*
    description: Alternative specify multiple globs in a table

  - name: YaraRule
    type: yara
    default:
    description: A yara rule to search for matching files.

  - name: Upload_File
    default: N
    type: bool

  - name: Calculate_Hash
    default: N
    type: bool

  - name: MoreRecentThan
    default: ""
    type: timestamp

  - name: ModifiedBefore
    default: ""
    type: timestamp


sources:
  - query: |
      LET SMB_CREDENTIALS &lt;= set(item=dict(), field=ServerName,
         value=format(format="%s:%s", args=[Username, Password]))

      LET file_search = SELECT OSPath,
               get(item=Data, field="mft") as Inode,
               Mode.String AS Mode, Size,
               Mtime AS MTime,
               Atime AS ATime,
               Btime AS BTime,
               Ctime AS CTime, "" AS Keywords,
               IsDir, Data
        FROM glob(globs=SearchFilesGlobTable.Glob + SearchFilesGlob,
                  root=ServerName,
                  accessor="smb")

      LET more_recent = SELECT * FROM if(
        condition=MoreRecentThan,
        then={
          SELECT * FROM file_search
          WHERE MTime &gt; MoreRecentThan
        }, else=file_search)

      LET modified_before = SELECT * FROM if(
        condition=ModifiedBefore,
        then={
          SELECT * FROM more_recent
          WHERE MTime &lt; ModifiedBefore
           AND  MTime &gt; MoreRecentThan
        }, else=more_recent)

      LET keyword_search = SELECT * FROM if(
        condition=YaraRule,
        then={
          SELECT * FROM foreach(
            row={
               SELECT * FROM modified_before
               WHERE NOT IsDir
            },
            query={
               SELECT OSPath, Inode, Mode,
                      Size, MTime, ATime, CTime, BTime,
                      str(str=String.Data) As Keywords, IsDir, Data

               FROM yara(files=OSPath,
                         key="A",
                         rules=YaraRule,
                         accessor="smb")
            })
        }, else=modified_before)

      SELECT OSPath, Inode, Mode, Size, MTime, ATime,
             CTime, BTime, Keywords, IsDir,
               if(condition=Upload_File and NOT IsDir,
                  then=upload(file=OSPath, accessor="smb")) AS Upload,
               if(condition=Calculate_Hash and NOT IsDir,
                  then=hash(path=OSPath, accessor="smb")) AS Hash,
            Data
      FROM keyword_search

column_types:
  - name: Modified
    type: timestamp
  - name: ATime
    type: timestamp
  - name: MTime
    type: timestamp
  - name: CTime
    type: timestamp
  - name: Upload
    type: preview_upload

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/server.enrichment.hybridanalysis.md
======
---
title: Server.Enrichment.HybridAnalysis
hidden: true
tags: [Server Artifact]
---

Submit a file hash to Hybrid Analysis for a verdict. Default free API restriction is 200 requests/min or 2000 requests/hour.

This artifact can be called from within another artifact (such as one looking for files) to enrich the data made available by that artifact.

Ex.

  `SELECT * from Artifact.Server.Enrichment.HybridAnalysis(Hash=$YOURHASH)`


<pre><code class="language-yaml">
name: Server.Enrichment.HybridAnalysis
author: Wes Lambert -- @therealwlambert
description: |
  Submit a file hash to Hybrid Analysis for a verdict. Default free API restriction is 200 requests/min or 2000 requests/hour.

  This artifact can be called from within another artifact (such as one looking for files) to enrich the data made available by that artifact.

  Ex.

    `SELECT * from Artifact.Server.Enrichment.HybridAnalysis(Hash=$YOURHASH)`

type: SERVER

parameters:
    - name: Hash
      type: string
      description: The file hash to submit to Hybrid Analysis (MD5, SHA1, SHA256).
      default:

    - name: HybridAnalysisKey
      type: string
      description: API key for Hybrid Analysis. Leave blank here if using server metadata store.
      default:

    - name: UserAgent
      type: string
      description: Name of the user agent used for submitting hashes.
      default: Velociraptor

sources:
  - query: |
        LET Creds = if(
           condition=HybridAnalysisKey,
           then=HybridAnalysisKey,
           else=server_metadata().HybridAnalysisKey)

        LET URL &lt;= 'https://hybrid-analysis.com/api/v2/search/hash'

        LET Data = SELECT parse_json_array(data=Content) as Content
        FROM http_client(
            url=URL,
            headers=dict(`api-key`=Creds,
                         `user-agent`=UserAgent,
                         `Content-Type`="application/x-www-form-urlencoded"),
            params=dict(hash=Hash),
            method='POST')

        SELECT * from foreach (
            row=Data,
            query={
                SELECT Content as _Content,
                       Content.verdict[0] as Verdict
                FROM scope()
            })

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/generic.system.hostsfile.md
======
---
title: Generic.System.HostsFile
hidden: true
tags: [Client Artifact]
---

The system hosts file maps hostnames to IP addresses. In some cases,
entries in this file take precedence and overrides the results from
the system DNS service.

The file is a simple text file, with one line per IP address. Each
whitespace-separated word following the IP address is a hostname.
The Linux man page refers to the the first hostname as *canonical_hostname*,
and any following words as *aliases*. They are treated the same by this
artifact.

The hosts file is typically present on all Linux-based systems (including macOS),
with entries for localhost. The same file format is also supported on Windows.

The source *Hosts* returns each line in each hosts file that matches
the glob parameters for address and hostname. The hostname and aliases
are combined in a single column *Hostnames*. Columns returned:

- OSPath
- Hostnames
- Comment

Only comments that follows the hostname on the same line are captured in Comment.
Comments on their own lines are ignored.

A second source *HostsFlattened* provides a flattened result, with each row
containing an IP address and a single hostname.

This artifact also exports a function `parse_hostsfile()` that returns Hostname
and Aliases individually.


<pre><code class="language-yaml">
name: Generic.System.HostsFile
description: |
  The system hosts file maps hostnames to IP addresses. In some cases,
  entries in this file take precedence and overrides the results from
  the system DNS service.

  The file is a simple text file, with one line per IP address. Each
  whitespace-separated word following the IP address is a hostname.
  The Linux man page refers to the the first hostname as *canonical_hostname*,
  and any following words as *aliases*. They are treated the same by this
  artifact.

  The hosts file is typically present on all Linux-based systems (including macOS),
  with entries for localhost. The same file format is also supported on Windows.

  The source *Hosts* returns each line in each hosts file that matches
  the glob parameters for address and hostname. The hostname and aliases
  are combined in a single column *Hostnames*. Columns returned:

  - OSPath
  - Hostnames
  - Comment

  Only comments that follows the hostname on the same line are captured in Comment.
  Comments on their own lines are ignored.

  A second source *HostsFlattened* provides a flattened result, with each row
  containing an IP address and a single hostname.

  This artifact also exports a function `parse_hostsfile()` that returns Hostname
  and Aliases individually.

reference:
  - https://manpages.debian.org/bookworm/manpages/hosts.5.en.html

export: |
  LET _parse_hostsfile(OSPath) = SELECT parse_string_with_regex(
     string=Line,
     regex='''^[\t ]*(?P&lt;Address&gt;[^\s#]+)[\t ]+(?P&lt;Hostname&gt;[^\s#]+)(?P&lt;Aliases&gt;[^#\n\r]+)?(?:[\t ]*#(?P&lt;Comment&gt;.+))?''') AS Parsed
  FROM parse_lines(filename=OSPath)
  WHERE Parsed.Address

  LET parse_hostsfile(OSPath) = SELECT Parsed.Address AS Address,
     Parsed.Hostname AS Hostname,
     filter(list=split(sep='''\s+''', string=Parsed.Aliases), regex='.+') AS Aliases,

     /* Remove any whitespace between comment character and comment: */
     regex_replace(re='''^\s+''', source=Parsed.Comment, replace='$1') AS Comment
  FROM _parse_hostsfile(OSPath=OSPath)

  LET Files = SELECT OSPath FROM glob(globs=hostsFileGlobs.HostsFileGlobs)

  LET HostsFiles = SELECT * FROM foreach(row=Files, query={
    SELECT OSPath, Address, Hostname, Aliases, Comment
    FROM parse_hostsfile(OSPath=OSPath)
  })

parameters:
  - name: hostsFileGlobs
    description: Globs to find hosts files
    type: csv
    default: |
        HostsFileGlobs
        C:\Windows\System32\drivers\etc\hosts
        /etc/hosts
  - name: HostnameRegex
    description: Hostname or aliases to match
    default: .
    type: regex
  - name: AddressRegex
    description: IP addresses to match
    default: .
    type: regex

sources:
  - name: Hosts
    query: |
      SELECT OSPath, Address,
        (Hostname, ) + Aliases AS Hostname,
        Comment
      FROM HostsFiles
      WHERE Hostname =~ HostnameRegex
        AND Address =~ AddressRegex

  - name: HostsFlattened
    query: |
      SELECT OSPath, Address, Hostname, Comment
      FROM flatten(query={
        SELECT OSPath, Address, (Hostname, ) + Aliases AS Hostname, Comment
        FROM HostsFiles
      })
      WHERE Address =~ AddressRegex
        AND Hostname =~ HostnameRegex

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.etw.dotnetrundown.md
======
---
title: Windows.ETW.DotNetRundown
hidden: true
tags: [Client Artifact]
---

Queries the Microsoft-Windows-DotNETRuntimeRundown provider to
collect a list of DotNet modules loaded into a process. This can be
useful when responding to reflectively loaded DotNet malware.

NOTE: System.Timestamp represents when the artifact was run, NOT
when the module was loaded.


<pre><code class="language-yaml">
name: Windows.ETW.DotNetRundown
author: "@bmcder02"
description: |
   Queries the Microsoft-Windows-DotNETRuntimeRundown provider to
   collect a list of DotNet modules loaded into a process. This can be
   useful when responding to reflectively loaded DotNet malware.

   NOTE: System.Timestamp represents when the artifact was run, NOT
   when the module was loaded.


type: CLIENT

parameters:
  - name: ProcessRegex
    default: .
    type: regex
  - name: PidRegex
    default: .
    type: regex
  - name: EventIDRegex
    default: .
    type: regex
  - name: Timeout
    default: 20
    type: int

sources:
  - precondition:
      SELECT OS From info() where OS = 'windows'

    query: |
      LET EventData = SELECT System.ID AS EventID, System.ProcessID AS ProcessID,
        process_tracker_get(id=System.ProcessID) AS ProcessDetails,
        *
      FROM watch_etw(
        description="CLR Rundown Provider",
        guid="{A669021C-C450-4609-A035-5AF59AF4DF18}",
        any=0x48, timeout=Timeout)

      SELECT EventID, ProcessID, ProcessDetails.Data.Name AS ProcessName,
        ProcessDetails.Data.Exe AS ProcessPath, System, EventData, ProviderGUID,
        ProcessDetails
      FROM EventData
      WHERE EventID =~ EventIDRegex
        AND ProcessID =~ PidRegex
        AND ProcessPath =~ ProcessRegex

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.sysinternals.autoruns.md
======
---
title: Windows.Sysinternals.Autoruns
hidden: true
tags: [Client Artifact]
---

Uses Sysinternals autoruns to scan the host.

Note this requires syncing the sysinternals binary from the host.


<pre><code class="language-yaml">
name: Windows.Sysinternals.Autoruns
description: |
  Uses Sysinternals autoruns to scan the host.

  Note this requires syncing the sysinternals binary from the host.

tools:
  - name: Autorun_386
    url: https://live.sysinternals.com/tools/autorunsc.exe
    serve_locally: true

  - name: Autorun_amd64
    url: https://live.sysinternals.com/tools/autorunsc64.exe
    serve_locally: true

precondition: SELECT OS From info() where OS = 'windows'

parameters:
  - name: All
    type: bool
    default: Y
  - name: Boot execute
    type: bool
  - name: Codecs
    type: bool
  - name: Appinit DLLs
    type: bool
  - name: Explorer addons
    type: bool
  - name: Sidebar gadgets (Vista and higher)
    type: bool
  - name: Image hijacks
    type: bool
  - name: Internet Explorer addons
    type: bool
  - name: Known DLLs
    type: bool
  - name: Logon startups (this is the default)
    type: bool
  - name: WMI entries
    type: bool
  - name: Winsock protocol and network providers
    type: bool
  - name: Office addins
    type: bool
  - name: Printer monitor DLLs
    type: bool
  - name: LSA security providers
    type: bool
  - name: Autostart services and non-disabled drivers
    type: bool
  - name: Scheduled tasks
    type: bool
  - name: Winlogon entries
    type: bool
  - name: Verify digital signatures
    type: bool
    default: Y
  - name: ToolInfo
    type: hidden
    description: Override Tool information.

sources:
  - query: |
      LET Flags = '''Option,Name
      *,All
      b,Boot execute
      c,Codecs
      d,Appinit DLLs
      e,Explorer addons
      g,Sidebar gadgets (Vista and higher)
      h,Image hijacks
      i,Internet Explorer addons
      k,Known DLLs
      l,Logon startups (this is the default)
      m,WMI entries
      n,Winsock protocol and network providers
      o,Office addins
      p,Printer monitor DLLs
      r,LSA security providers
      s,Autostart services and non-disabled drivers
      t,Scheduled tasks
      w,Winlogon entries
      '''

      LET Options = '''Option,Name
      -s,Verify digital signatures
      '''

      -- The flags actually selected
      LET flags = SELECT Option FROM parse_csv(accessor="data", filename=Flags)
        WHERE get(field=Name)

      -- The options actually selected
      LET options = SELECT Option FROM parse_csv(accessor="data", filename=Options)
        WHERE get(field=Name)

      LET os_info &lt;= SELECT Architecture FROM info()

      // Get the path to the binary.
      LET bin &lt;= SELECT * FROM Artifact.Generic.Utils.FetchBinary(
              ToolName= "Autorun_" + os_info[0].Architecture,
              ToolInfo=ToolInfo)

      // Call the binary and return all its output in a single row.
      LET output = SELECT * FROM execve(argv=[bin[0].OSPath,
            '-nobanner', '-accepteula', '-t', '-a',
            join(array=flags.Option, sep=""),
            join(array=options.Option, sep=" "),
            '-c', -- CSV output
            '-h', -- Also calculate hashes
            '*'   -- All user profiles.
      ], length=10000000)

      // Parse the CSV output and return it as rows. We can filter this further.
      SELECT * FROM if(condition=bin,
      then={
        SELECT * FROM foreach(
          row=output,
          query={
             SELECT * FROM parse_csv(filename=utf16(string=Stdout),
                                     accessor="data")
          })
      })

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/generic.detection.logs.md
======
---
title: Generic.Detection.Logs
hidden: true
tags: [Client Artifact]
---

This artifact enables grep of Logs to hunt for strings of interest. Default
target glob includes /var/log/, Apache and Windows IIS paths.

Parameters include SearchRegex and WhitelistRegex as regex terms and will
return the whole line to assist with scoping.

IIS and Apache Groks are available as notebook suggestions - please feel free to PR
additions!


<pre><code class="language-yaml">
name: Generic.Detection.Logs
author: "Matt Green - @mgreen27, Apache groks thanks to Harsh Jaroli and Krishna Patel"
description: |
  This artifact enables grep of Logs to hunt for strings of interest. Default
  target glob includes /var/log/, Apache and Windows IIS paths.

  Parameters include SearchRegex and WhitelistRegex as regex terms and will
  return the whole line to assist with scoping.

  IIS and Apache Groks are available as notebook suggestions - please feel free to PR
  additions!


parameters:
  - name: TargetGlob
    default: '/{/var/log/**,*:/inetpub/logs/**/,{/var/log/httpd,/var/log/apache2,/var/log/nginx,C:/Apache/logs}/{access.log,access_log}*}'
  - name: SearchRegex
    description: "Regex of strings to search in line."
    default: 'PUT '
    type: regex
  - name: WhitelistRegex
    description: "Regex of strings to leave out of output."
    default:
    type: regex

sources:
  - query: |
      LET files = SELECT OSPath FROM glob(globs=TargetGlob)

      SELECT * FROM foreach(row=files,
          query={
              SELECT Line, OSPath 
              FROM parse_lines(filename=OSPath)
              WHERE
                Line =~ SearchRegex
                AND NOT if(condition= WhitelistRegex,
                    then= Line =~ WhitelistRegex,
                    else= FALSE)
          })

    notebook:
      - type: vql_suggestion
        name: IIS Groks
        template: |
            /*
            ### IIS grok

            Note:  IIS doesn't have a standard logging format so we have added some
            suggestions. Comment in preferred or add / modify your own.
            */

            LET target_grok = "%{TIMESTAMP_ISO8601:LogTimeStamp} %{IPORHOST:Site} %{WORD:Method} %{URIPATH:UriPath} %{NOTSPACE:QueryString} %{NUMBER:Port} %{NOTSPACE:Username} %{IPORHOST:Clienthost} %{NOTSPACE:Useragent} %{NOTSPACE:Referrer} %{NUMBER:Response} %{NUMBER:Subresponse} %{NUMBER:Win32status} %{NUMBER:Timetaken:int}"
            --LET target_grok = "%{TIMESTAMP_ISO8601:log_timestamp} %{IPORHOST:site} %{WORD:method} %{URIPATH:page} %{NOTSPACE:querystring} %{NUMBER:port} %{NOTSPACE:username} %{IPORHOST:clienthost} %{NOTSPACE:useragent} %{NOTSPACE:referer} %{NUMBER:response} %{NUMBER:subresponse} %{NUMBER:scstatus} %{NUMBER:timetaken:int}"
            --LET target_grok = "%{TIMESTAMP_ISO8601:log_timestamp} %{WORD:iisSite} %{NOTSPACE:computername} %{IPORHOST:site} %{WORD:method} %{URIPATH:page} %{NOTSPACE:querystring} %{NUMBER:port} %{NOTSPACE:username} %{IPORHOST:clienthost} %{NOTSPACE:protocol} %{NOTSPACE:useragent} %{NOTSPACE:referer} %{IPORHOST:cshost} %{NUMBER:response} %{NUMBER:subresponse} %{NUMBER:scstatus} %{NUMBER:bytessent:int} %{NUMBER:bytesrecvd:int} %{NUMBER:timetaken:int}"


            LET parsed = SELECT ClientId as _ClientId, Line as _Raw,
                  grok(data=Line,grok=target_grok) as GrokParsed
              FROM source()
              WHERE GrokParsed

            SELECT * FROM foreach(row=parsed,
                  query={ SELECT *, _Raw FROM GrokParsed })
                  
      - type: vql_suggestion
        name: Apache Groks
        template: |
            /*
            ### Apache Grok
            */

            LET target_grok = '''%{IPORHOST:client} - - \[%{HTTPDATE:timestamp}\] "%{WORD:method} %{URIPATHPARAM:request} HTTP/%{NUMBER:httpversion}" %{NUMBER:status} %{NUMBER:response_size}'''
            
            LET parsed = SELECT ClientId as _ClientId, Line as _Raw,
                  grok(data=Line,grok=target_grok) as GrokParsed
              FROM source()
              WHERE GrokParsed

            SELECT * FROM foreach(row=parsed,
                  query={ SELECT *, _Raw FROM GrokParsed })

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/server.monitoring.clientcount.md
======
---
title: Server.Monitoring.ClientCount
hidden: true
tags: [Server Event Artifact]
---

An artifact that sends an email every hour of the current state of
the deployment.


<pre><code class="language-yaml">
name: Server.Monitoring.ClientCount

description: |
   An artifact that sends an email every hour of the current state of
   the deployment.

type: SERVER_EVENT

parameters:
   - name: EmailAddress
     default: admin@example.com
   - name: SkipVerify
     type: bool
     description: If set we skip TLS verification.
   - name: CCAddress
     default:
   - name: Subject
     default: "Deployment statistics for Velociraptor"
   - name: Period
     default: "3600"

sources:
  - query: |
      LET metrics = SELECT * FROM Artifact.Server.Monitor.VeloMetrics()

      SELECT * FROM foreach(
        row={
            SELECT * FROM clock(period=atoi(string=Period))
        },
        query={
             SELECT * FROM mail(
                to=EmailAddress,
                cc=CCAddress,
                subject=Subject,
                period=60,
                skip_verify=SkipVerify,
                body=format(format='Total clients currently connected %v',
                     args=[metrics.client_comms_current_connections])
            )
        })

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.etw.viewsessions.md
======
---
title: Windows.ETW.ViewSessions
hidden: true
tags: [Client Artifact]
---

This artifact enumerates all ETW sessions and optionally kills dangling ones


<pre><code class="language-yaml">
name: Windows.ETW.ViewSessions
description: |
  This artifact enumerates all ETW sessions and optionally kills dangling ones

required_permissions:
  - EXECVE

precondition: SELECT OS From info() where OS = 'windows'
parameters:
  - name: SessionRegex
    default: "Velociraptor"
    type: regex
  - name: KillMatching
    type: bool
    description: If set will kill the relevant sessions.


sources:
  - query: |
      SELECT * FROM foreach(row={
         SELECT Stdout, parse_string_with_regex(string=Stdout, regex="(^[^ ]+)").g1 AS SessionName
         from execve(argv=["logman", "query", "-ets"], sep="\n")
         WHERE Stdout =~ "Running" AND SessionName =~ SessionRegex
      }, query={
         SELECT * FROM if(condition=KillMatching,
         then={
             SELECT SessionName, Stdout FROM execve(argv=["logman", "stop", SessionName, "-ets"])
         }, else={
             SELECT SessionName FROM scope()
         })
      })

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/linux.debian.packages.md
======
---
title: Linux.Debian.Packages
hidden: true
tags: [Client Artifact]
---

List all packages installed on the system, both deb packages and "snaps".
The installed deb package information is fetched from the DPKG status file,
while the snap package list is fetched from the snap daemon through a UNIX
socket HTTP call (since detailed snap package information is not easily
in files).

The following columns are parsed from the DPKG status file:

 - Package
 - InstalledSize
 - Version
 - Source
 - _Description
 - Architecture

The following columns are parsed from the snap package response (/v2/snaps):

- Name
- _Summary
- _Description
- InstalledSize
- Publisher
- InstalledAt
- Version
- Channel

Both package sources provide more information than this and, and the artifact
can easily be modified to include more details.


<pre><code class="language-yaml">
name: Linux.Debian.Packages
description: |
 List all packages installed on the system, both deb packages and "snaps".
 The installed deb package information is fetched from the DPKG status file,
 while the snap package list is fetched from the snap daemon through a UNIX
 socket HTTP call (since detailed snap package information is not easily
 in files).

 The following columns are parsed from the DPKG status file:

  - Package
  - InstalledSize
  - Version
  - Source
  - _Description
  - Architecture

 The following columns are parsed from the snap package response (/v2/snaps):

 - Name
 - _Summary
 - _Description
 - InstalledSize
 - Publisher
 - InstalledAt
 - Version
 - Channel

 Both package sources provide more information than this and, and the artifact
 can easily be modified to include more details.

parameters:
  - name: linuxDpkgStatus
    description: The DPKG status file to read deb package information from
    default: /var/lib/dpkg/status
  - name: snapdSocket
    description: |
     The location of the snap deamon UNIX socket, used for fetching the snap
     list through a HTTP API call. If snap is not used, the failed query
     response will simply be ignored.
    default: /run/snapd.socket

precondition: |
 SELECT OS
 FROM info()
 WHERE OS = 'linux'

sources:
  - name: DebPackages
    notebook:
      - type: none

    query: |
     LET ColumnTypes &lt;= dict(`_Description`='nobreak')

     /* First pass - split file into records start with
        Package and end with \n\n.
        Then parse each record using multiple RegExs.
     */
     LET packages = SELECT parse_string_with_regex(
         string=Record,
         regex=['Package:\\s(?P&lt;Package&gt;.+)',
                'Installed-Size:\\s(?P&lt;InstalledSize&gt;.+)',
                'Version:\\s(?P&lt;Version&gt;.+)',
                'Source:\\s(?P&lt;Source&gt;.+)',
                '''Description:\s+(?P&lt;Description&gt;.+(\n\s+.+)*)''',
                'Architecture:\\s(?P&lt;Architecture&gt;.+)']) AS Record
     FROM parse_records_with_regex(file=linuxDpkgStatus,
                                     regex='(?sm)^(?P&lt;Record&gt;Package:.+?)\\n\\n')

     SELECT Record.Package AS Package,
            humanize(bytes=atoi(string=Record.InstalledSize)) AS InstalledSize,
            Record.Version AS Version,
            Record.Source AS Source,
            regex_replace(source=Record.Description,
                          re='''^\s+\.$''') AS _Description,
            Record.Architecture AS Architecture
     FROM packages

  - name: Snaps
    query: |
     LET ColumnTypes &lt;= dict(`_Summary`='nobreak', `_Description`='nobreak')

     LET SnapSocketCheck = SELECT
         parse_json(data=Content).result AS Result
       FROM http_client(url=snapdSocket + ':unix/v2/snaps')
       WHERE Response = 200
         OR NOT log(message="Error fetching snap: %v", args=Content)

     SELECT * FROM foreach(
         row=SnapSocketCheck,
         query={
           SELECT name AS Name,
                  summary AS _Summary,
                  description AS _Description,
                  humanize(bytes=`installed-size`) AS InstalledSize,
                  publisher.`display-name` AS Publisher,
                  timestamp(string=`install-date`) AS InstalledAt,
                  version AS Version,
                  channel AS Channel,
                  id AS PackageId
           FROM foreach(row=Result)
         })

    notebook:
      - type: vql
        template: |
          /*
          ## Combined results
          */
          LET ColumnTypes &lt;= dict(`_Description`='nobreak')

          SELECT *
          FROM chain(
            debs={
              SELECT Package AS Name,
                     'deb' AS Type,
                     InstalledSize,
                     Version,
                     _Description,
                     Architecture
              FROM source(artifact="Linux.Debian.Packages/DebPackages")
            },
            snaps={
              SELECT Name,
                     'snap' AS Type,
                     InstalledSize,
                     Version,
                     _Description,
                     NULL AS Architecture
              FROM source(artifact="Linux.Debian.Packages/Snaps")
            })

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/linux.detection.yara.process.md
======
---
title: Linux.Detection.Yara.Process
hidden: true
tags: [Client Artifact]
---

This artifact enables running Yara over processes in memory.

There are 2 kinds of Yara rules that can be deployed:

1. Url link to a yara rule.
2. A Standard Yara rule attached as a parameter.

Only one method of Yara will be applied and search order is as above. The
default is Cobalt Strike opcodes.

Regex parameters can be applied for process name and pid for targeting. The
artifact also has an option to upload any process with Yara hits.

Note: the Yara scan will stop after one hit. Multi-string rules will also only
show one string in returned rows.


<pre><code class="language-yaml">
name: Linux.Detection.Yara.Process
author: Matt Green - @mgreen27
description: |
  This artifact enables running Yara over processes in memory.

  There are 2 kinds of Yara rules that can be deployed:

  1. Url link to a yara rule.
  2. A Standard Yara rule attached as a parameter.

  Only one method of Yara will be applied and search order is as above. The
  default is Cobalt Strike opcodes.

  Regex parameters can be applied for process name and pid for targeting. The
  artifact also has an option to upload any process with Yara hits.

  Note: the Yara scan will stop after one hit. Multi-string rules will also only
  show one string in returned rows.

aliases:
- MacOS.Detection.Yara.Process

type: CLIENT
parameters:
  - name: ProcessRegex
    default: .
    type: regex
  - name: PidRegex
    default: .
    type: regex
  - name: UploadHits
    type: bool
  - name: YaraUrl
    description: If configured will attempt to download Yara rules from Url
    type: upload
  - name: YaraRule
    type: yara
    description: Final Yara option and the default if no other options provided.
    default: |
      rule keyword_search {
         strings:
           $a = "velociraptor" ascii

        condition:
            any of them
      }
  - name: NumberOfHits
    description: THis artifact will stop by default at one hit. This setting allows additional hits
    default: 1
    type: int
  - name: ContextBytes
    description: Include this amount of bytes around hit as context.
    default: 0
    type: int
  - name: ExePathWhitelist
    description: Regex of ProcessPaths to exclude
    type: regex


sources:
  - precondition:
      SELECT OS From info() where OS = 'linux' OR OS = 'darwin'

    query: |
      -- check which Yara to use
      LET yara_rules &lt;= YaraUrl || YaraRule

      -- find velociraptor process
      LET me = SELECT Pid FROM pslist(pid=getpid())

      -- find all processes and add filters
      LET processes = SELECT
             Name as ProcessName,
             CommandLine, Pid
        FROM pslist()
        WHERE
            Name =~ ProcessRegex
            AND format(format="%d", args=Pid) =~ PidRegex
            AND NOT Pid in me.Pid
            AND NOT if(condition=ExePathWhitelist,
                    then= Exe=~ExePathWhitelist)
            AND log(message=format(format="Scanning pid %v: %v", args=[
                Pid, CommandLine]))

      -- scan processes in scope with our rule, limit 1 hit
      LET hits = SELECT * FROM foreach(
        row=processes,
        query={
            SELECT
                ProcessName,
                CommandLine,
                Pid,
                Rule,
                Tag,
                Meta,
                String.Name as YaraString,
                String.Offset as HitOffset,
                if(condition=String.Data,
                   then=upload(
                     accessor='scope',
                     file='String.Data',
                     name=format(format="%v-%v_%v_%v",
                     args=[ ProcessName, Pid, String.Offset, ContextBytes ]
                    ))) as HitContext
             FROM proc_yara(
                        pid=Pid,
                        rules=yara_rules,
                        context=ContextBytes,
                        number=NumberOfHits
                    )
          })

      -- upload hits using the process accessor
      LET upload_hits = SELECT *,
          upload(
            accessor="process",
            file=format(format="/%v", args=Pid),
            name=pathspec(Path=format(format='%v-%v.dmp',
                          args= [ ProcessName, Pid ]))) as ProcessDump
      FROM hits
      WHERE log(message=format(format='Will upload %v: %v', args=[Pid, ProcessName]))

      -- return rows
      SELECT * FROM if(condition=UploadHits,
        then=upload_hits,
        else=hits)

column_types:
  - name: HitContext
    type: preview_upload

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.etw.dns.md
======
---
title: Windows.ETW.DNS
hidden: true
tags: [Client Event Artifact]
---

This artifact monitors DNS queries using ETW.

There are several filteres availible to the user to filter out and target with
regex, by default duplicate DNSCache requests are filtered out.


<pre><code class="language-yaml">
name: Windows.ETW.DNS
author: Matt Green - @mgreen27
description: |
  This artifact monitors DNS queries using ETW.

  There are several filteres availible to the user to filter out and target with
  regex, by default duplicate DNSCache requests are filtered out.

type: CLIENT_EVENT

parameters:
  - name: ImageRegex
    description: "ImagePath regex filter for"
    default: .
    type: regex
  - name: CommandLineRegex
    description: "Commandline to filter for."
    default: .
    type: regex
  - name: QueryRegex
    description: "DNS query request (domain) to filter for."
    default: .
    type: regex
  - name: AnswerRegex
    description: "DNS answer to filter for."
    default: .
    type: regex
  - name: CommandLineExclusion
    description: "Commandline to filter out. Typically we do not want Dnscache events."
    default: 'svchost.exe -k NetworkService -p -s Dnscache$'
    type: regex


sources:
  - precondition:
      SELECT OS From info() where OS = 'windows'

    query: |
        LET TypeLookup &lt;= dict(
                        `1` = 'A',
                        `2` = 'NS',
                        `5` = 'CNAME',
                        `6` = 'SOA',
                        `12` = 'PTR',
                        `13` = 'HINFO',
                        `15` = 'MX',
                        `16` = 'TXT',
                        `17` = 'RP',
                        `18` = 'AFSDB',
                        `24` = 'SIG',
                        `25` = 'KEY',
                        `28` = 'AAAA',
                        `29` = 'LOC',
                        `33` = 'SRV',
                        `35` = 'NAPTR',
                        `36` = 'KX',
                        `37` = 'CERT',
                        `39` = 'DNAME',
                        `42` = 'APL',
                        `43` = 'DS',
                        `44` = 'SSHFP',
                        `45` = 'IPSECKEY',
                        `46` = 'RRSIG',
                        `47` = 'NSEC',
                        `48` = 'DNSKEY',
                        `49` = 'DHCID',
                        `50` = 'NSEC3',
                        `51` = 'NSEC3PARAM',
                        `52` = 'TLSA',
                        `53` = 'SMIMEA',
                        `55` = 'HIP',
                        `59` = 'CDS',
                        `60` = 'CDNSKEY',
                        `61` = 'OPENPGPKEY',
                        `62` = 'CSYNC',
                        `63` = 'ZONEMD',
                        `64` = 'SVCB',
                        `65` = 'HTTPS',
                        `108` = 'EUI48',
                        `109` = 'EUI64',
                        `249` = 'TKEY',
                        `250` = 'TSIG',
                        `256` = 'URI',
                        `257` = 'CAA',
                        `32768` = 'TA',
                        `32769` = 'DLV')

        SELECT System.TimeStamp AS EventTime,
            EventData.QueryName AS Query,
            get(item=TypeLookup,
                member=str(str=EventData.QueryType)) AS Type,
            EventData.QueryResults AS Answer,
            process_tracker_get(id=System.ProcessID).Data as Process
        FROM watch_etw(
          description="Microsoft-Windows-DNS-Client",
          guid="{1C95126E-7EEA-49A9-A3FE-A378B03DDB4D}")
        WHERE System.ID = 3008
           AND Query
           AND NOT Process.CommandLine =~ CommandLineExclusion
           AND Process.Exe =~ ImageRegex
           AND Query =~ QueryRegex
           AND Answer =~ AnswerRegex

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.detection.registry.md
======
---
title: Windows.Detection.Registry
hidden: true
tags: [Client Event Artifact]
---

This artifact detects registry changes and triggers an alert.


<pre><code class="language-yaml">
name: Windows.Detection.Registry
description: |
  This artifact detects registry changes and triggers an alert.

author: Jos Clephas - @DfirJos

type: CLIENT_EVENT

precondition:
  SELECT * FROM info() WHERE OS =~ "windows"

parameters:
  - name: Period
    type: int
    default: 120
  - name: RegistryPath
    default: HKEY_LOCAL_MACHINE\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\Run\\*
  - name: RegistryData
    type: regex
    default: .
  - name: AlertName
    default: "T1112 - Suspicious registry key modification"
  - name: diff
    default: added
  - name: CertificateInfo
    default: N
    type: bool
  - name: regex_IssuerName
    default: .
  - name: UntrustedAuthenticode
    description: Show only Executables that are not trusted by Authenticode.
    type: bool
    default: N
  - name: Calculate_hashes
    default: N
    type: bool
  - name: regex_sha256
    default: .
  - name: DISABLE_DANGEROUS_API_CALLS
    type: bool
    description: |
      Enable this to disable potentially flakey APIs which may cause
      crashes.

sources:
  - query: |

        LET query_registry = SELECT *, OSPath.String + Data.value AS FullPath,
                                    expand(path=Data.value) AS Datavalue
                            FROM glob(globs=RegistryPath, accessor="registry") WHERE Data.value =~ RegistryData

        LET query_diff = SELECT *, commandline_split(command=Datavalue) as AbsolutePath
              FROM diff(query=query_registry, period=Period, key="FullPath")
              WHERE Diff = diff

        SELECT *,
            alert(name=AlertName, Key=OSPath, Value=Datavalue, RegistryValue=Diff) as AlertSent,
            if(condition=Calculate_hashes,
                then=hash(path=AbsolutePath[0], accessor="auto")) AS Hash,
            if(condition=CertificateInfo,
                then=authenticode(filename=AbsolutePath[0])) AS Certinfo
        FROM query_diff
        WHERE Diff = diff
              AND Hash.SHA256 =~ regex_sha256
              AND Certinfo.IssuerName=~regex_IssuerName
              AND NOT if(condition= UntrustedAuthenticode,
                        then= Certinfo.Trusted = 'trusted',
                        else= False )

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/server.utils.starthuntexample.md
======
---
title: Server.Utils.StartHuntExample
hidden: true
tags: [Server Artifact]
---

This example artifact shows how to create a utility artifact to
provide low privileged users with a controlled ability to perform
high privileged operations.

This server artifact launches a new `Generic.Client.Info` hunt, but
the parameters for the hunt are not determined by the initiating
user. This makes is safe for unprivileged users to schedule this
hunt whenever they want.

Usually to start a hunt, the user must have the `START_HUNT`
permission - usually granted by the `administrator` or
`investigator` roles. Additionally, in order to collect this
artifact, a user must have the `COLLECT_SERVER` permission - usually
only granted by the `administrator` role.

So by default this artifact does not give any additional permissions
and usually has to be collected by an `administrator` (which would
be able to schedule hunts anyway).

However, it is possible to mark the artifact as basic using the VQL

```vql
SELECT artifact_set_metadata(
    artifact="Server.Utils.StartHuntExample", basic=TRUE)
FROM scope()
```

This will allow users with the `COLLECT_BASIC` permission to also
collect it. Once collected the artifact specifies the impersonate
field to `admin` which will cause it to run under the `admin` user's
permissions.

This combination allows us to now grant the `COLLECT_BASIC`
permission to any user and they will be able to start the hunt via
this artifact, but have no additional permissions to start arbitrary
hunts or collections.


<pre><code class="language-yaml">
name: Server.Utils.StartHuntExample
description: |
  This example artifact shows how to create a utility artifact to
  provide low privileged users with a controlled ability to perform
  high privileged operations.

  This server artifact launches a new `Generic.Client.Info` hunt, but
  the parameters for the hunt are not determined by the initiating
  user. This makes is safe for unprivileged users to schedule this
  hunt whenever they want.

  Usually to start a hunt, the user must have the `START_HUNT`
  permission - usually granted by the `administrator` or
  `investigator` roles. Additionally, in order to collect this
  artifact, a user must have the `COLLECT_SERVER` permission - usually
  only granted by the `administrator` role.

  So by default this artifact does not give any additional permissions
  and usually has to be collected by an `administrator` (which would
  be able to schedule hunts anyway).

  However, it is possible to mark the artifact as basic using the VQL

  ```vql
  SELECT artifact_set_metadata(
      artifact="Server.Utils.StartHuntExample", basic=TRUE)
  FROM scope()
  ```

  This will allow users with the `COLLECT_BASIC` permission to also
  collect it. Once collected the artifact specifies the impersonate
  field to `admin` which will cause it to run under the `admin` user's
  permissions.

  This combination allows us to now grant the `COLLECT_BASIC`
  permission to any user and they will be able to start the hunt via
  this artifact, but have no additional permissions to start arbitrary
  hunts or collections.

type: SERVER

# Collect this artifact under the admin user permissions.
impersonate: admin

sources:
  - query: |
      -- This query will run with admin ACLs.
      SELECT hunt(
        description="A general hunt",
        artifacts='Generic.Client.Info')
      FROM scope()

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.eventlogs.powershellscriptblock.md
======
---
title: Windows.EventLogs.PowershellScriptblock
hidden: true
tags: [Client Artifact]
---

This Artifact will search and extract ScriptBlock events (Event ID 4104) from
Powershell-Operational Event Logs.

Powershell is commonly used by attackers across all stages of the attack
lifecycle. A valuable hunt is to search Scriptblock logs for signs of
malicious content.

There are several parameter's available for search leveraging regex.
  - DateAfter enables search for events after this date.
  - DateBefore enables search for events before this date.
  - SearchStrings enables regex search over scriptblock text field.
  - StringWhiteList enables a regex whitelist for scriptblock text field.
  - PathWhitelist enables a regex whitelist for path of scriptblock.
  - LogLevel enables searching on type of log. Default is Warning level which
  is logged even if ScriptBlock logging is turned off when suspicious keywords
  detected in Powershell interpreter. See second reference for list of keywords.
  - SearchVSS enables VSS search.


<pre><code class="language-yaml">
name: Windows.EventLogs.PowershellScriptblock
author: Matt Green - @mgreen27

description: |
  This Artifact will search and extract ScriptBlock events (Event ID 4104) from
  Powershell-Operational Event Logs.

  Powershell is commonly used by attackers across all stages of the attack
  lifecycle. A valuable hunt is to search Scriptblock logs for signs of
  malicious content.

  There are several parameter's available for search leveraging regex.
    - DateAfter enables search for events after this date.
    - DateBefore enables search for events before this date.
    - SearchStrings enables regex search over scriptblock text field.
    - StringWhiteList enables a regex whitelist for scriptblock text field.
    - PathWhitelist enables a regex whitelist for path of scriptblock.
    - LogLevel enables searching on type of log. Default is Warning level which
    is logged even if ScriptBlock logging is turned off when suspicious keywords
    detected in Powershell interpreter. See second reference for list of keywords.
    - SearchVSS enables VSS search.

reference:
  - https://attack.mitre.org/techniques/T1059/001/
  - https://github.com/PowerShell/PowerShell/blob/master/src/System.Management.Automation/engine/runtime/CompiledScriptBlock.cs#L1781-L1943

parameters:
  - name: EvtxGlob
    default: '%SystemRoot%\System32\winevt\logs\Microsoft-Windows-PowerShell%4Operational.evtx'
  - name: DateAfter
    description: "search for events after this date. YYYY-MM-DDTmm:hh:ss Z"
    type: timestamp
  - name: DateBefore
    description: "search for events before this date. YYYY-MM-DDTmm:hh:ss Z"
    type: timestamp
  - name: SearchStrings
    type: regex
    description: "regex search over scriptblock text field."
  - name: StringWhitelist
    description: "Regex of string to witelist"
    type: regex
  - name: PathWhitelist
    description: "Regex of path to whitelist."
    type: regex
  - name: LogLevel
    description: "Log level. Warning is Powershell default bad keyword list."
    type: choices
    default: Warning
    choices:
       - All
       - Warning
       - Verbose
  - name: LogLevelMap
    type: hidden
    default: |
      Choice,Regex
      All,"."
      Warning,"3"
      Verbose,"5"

  - name: VSSAnalysisAge
    type: int
    default: 0
    description: |
      If larger than zero we analyze VSS within this many days
      ago. (e.g 7 will analyze all VSS within the last week).  Note
      that when using VSS analysis we have to use the ntfs accessor
      for everything which will be much slower.

sources:
  - query: |
      LET VSS_MAX_AGE_DAYS &lt;= VSSAnalysisAge
      LET Accessor = if(condition=VSSAnalysisAge &gt; 0, then="ntfs_vss", else="auto")

      -- firstly set timebounds for performance
      LET DateAfterTime &lt;= if(condition=DateAfter,
        then=timestamp(epoch=DateAfter), else=timestamp(epoch="1600-01-01"))
      LET DateBeforeTime &lt;= if(condition=DateBefore,
        then=timestamp(epoch=DateBefore), else=timestamp(epoch="2200-01-01"))

      -- Parse Log level dropdown selection
      LET LogLevelRegex &lt;= SELECT format(format="%v", args=Regex) as value
        FROM parse_csv(filename=LogLevelMap, accessor="data")
        WHERE Choice=LogLevel LIMIT 1

      -- expand provided glob into a list of paths on the file system (fs)
      LET fspaths = SELECT OSPath
        FROM glob(globs=expand(path=EvtxGlob), accessor=Accessor)

      -- function returning IOC hits
      LET evtxsearch(PathList) = SELECT * FROM foreach(
            row=PathList,
            query={
                SELECT
                  timestamp(epoch=int(int=System.TimeCreated.SystemTime)) AS EventTime,
                  System.Computer as Computer,
                  System.Channel as Channel,
                  System.EventID.Value as EventID,
                  System.Security.UserID as SecurityID,
                  EventData.Path as Path,
                  EventData.ScriptBlockId as ScriptBlockId,
                  EventData.ScriptBlockText as ScriptBlockText,
                  get(field="Message") as Message,
                  System.EventRecordID as EventRecordID,
                  System.Level as Level,
                  System.Opcode as Opcode,
                  System.Task as Task,
                  OSPath
                FROM parse_evtx(filename=OSPath, accessor=Accessor)
                WHERE System.EventID.Value = 4104
                    AND EventTime &lt; DateBeforeTime
                    AND EventTime &gt; DateAfterTime
                    AND  format(format="%d", args=System.Level) =~ LogLevelRegex.value[0]
                    AND if(condition=SearchStrings,
                      then=ScriptBlockText =~ SearchStrings,
                      else=TRUE)
                    AND if(condition=StringWhitelist,
                      then= NOT ScriptBlockText =~ StringWhitelist,
                      else=TRUE)
                    AND if(condition=PathWhitelist,
                      then= NOT Path =~ PathWhitelist,
                      else=TRUE)
          })

        SELECT * FROM evtxsearch(PathList=fspaths)

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.triage.processmemory.md
======
---
title: Windows.Triage.ProcessMemory
hidden: true
tags: [Client Artifact]
---

Dump process memory and upload to the server


```yaml
name: Windows.Triage.ProcessMemory
description: |
  Dump process memory and upload to the server

precondition: SELECT OS From info() where OS = 'windows'

parameters:
  - name: processRegex
    default: notepad
    type: regex

sources:
  - query: |
        LET processes = SELECT Name as ProcessName, CommandLine, Pid
            FROM pslist()
            WHERE Name =~ processRegex

        SELECT * FROM foreach(
          row=processes,
          query={
            SELECT ProcessName, CommandLine, Pid, FullPath,
                   upload(file=FullPath) as CrashDump
            FROM proc_dump(pid=Pid)
          })

```

---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.system.vbscript.md
======
---
title: Windows.System.VBScript
hidden: true
tags: [Client Artifact]
---

This artifact allows running VBScript through cscript.exe.

This is a very powerful artifact since it allows for arbitrary command execution 
on the endpoints as SYSTEM. Therefore this artifact requires elevated permissions 
(specifically the EXECVE permission). Typically it is only available with the 
administrator role.

Note: Output is formatted to 1 row per line of Stdout. Ensure appropriately 
formatted scripts. Pasting scripts direct from word or webpages may lead to 
formatting issues when unicode characters are substituted. Copy script into 
a notepad, save as ASCII then try again.


<pre><code class="language-yaml">
name: Windows.System.VBScript
author: Matt Green - @mgreen27
description: |
  This artifact allows running VBScript through cscript.exe.
  
  This is a very powerful artifact since it allows for arbitrary command execution 
  on the endpoints as SYSTEM. Therefore this artifact requires elevated permissions 
  (specifically the EXECVE permission). Typically it is only available with the 
  administrator role.
  
  Note: Output is formatted to 1 row per line of Stdout. Ensure appropriately 
  formatted scripts. Pasting scripts direct from word or webpages may lead to 
  formatting issues when unicode characters are substituted. Copy script into 
  a notepad, save as ASCII then try again.
  
required_permissions:
  - EXECVE

precondition:
  SELECT OS From info() where OS = 'windows'

parameters:
  - name: Script
    default: Wscript.Echo "Hello world!"
       
sources:
  - query: |
      LET temp_script &lt;= tempfile(extension='.vbs', data=str(str=Script))
 
      SELECT Stdout 
      FROM execve(argv=['cscript.exe','//NoLogo','/E:vbs',temp_script], sep='\n')
</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/macos.system.tcc.md
======
---
title: MacOS.System.TCC
hidden: true
tags: [Client Artifact]
---

This artifact provides details around the TCC (Transparency,
Consent, and Control) database, and can help reveal when access to
system services has been added or modified for an application.

Note that this artifact has only been tested on macOS Big Sur, and
that the `allowed`, and `prompt_count` columns will need to be used
in place of the `auth_value`, `auth_reason`, and `auth_version`
columns for Catalina and prior.


<pre><code class="language-yaml">
name: MacOS.System.TCC
description: |
   This artifact provides details around the TCC (Transparency,
   Consent, and Control) database, and can help reveal when access to
   system services has been added or modified for an application.

   Note that this artifact has only been tested on macOS Big Sur, and
   that the `allowed`, and `prompt_count` columns will need to be used
   in place of the `auth_value`, `auth_reason`, and `auth_version`
   columns for Catalina and prior.

type: CLIENT

author: Wes Lambert - @therealwlambert

parameters:
- name: TCCGlob
  default: /Library/Application Support/com.apple.TCC/TCC.db,/Users/*/Library/Application Support/com.apple.TCC/TCC.db

precondition:
      SELECT OS From info() where OS = 'darwin'

sources:
  - query: |
      LET TCCList = SELECT OSPath
       FROM glob(globs=split(string=TCCGlob, sep=","))

      LET TCCAccess = SELECT *
       FROM sqlite(file=OSPath, query="SELECT * from access")

      LET TCCAccessDetails =
          SELECT * FROM foreach(
              row=TCCAccess,
              query={ SELECT
                    timestamp(epoch=last_modified) AS LastModified,
                    service AS Service,
                    client AS Client,
                    if(condition= client_type= 0, then="Console", else=if(condition= client_type= 1, then="Service/Script", else="Other")) AS ClientType,
                    if(condition= auth_value= 2, then="Yes", else="No") AS Allowed,
                    if(condition= OSPath =~ "Users", then=path_split(path=OSPath)[-5], else="System") AS User,
                    auth_reason AS _AuthReason,
                    auth_version AS _AuthVersion,
                    csreq AS _CSReq,
                    policy_id as _PolicyId,
                    indirect_object_identifier_type as _IndirectObjectIdentifierType,
                    indirect_object_identifier as IndirectObjectIdentifier,
                    indirect_object_code_identity as _IndirectObjectCodeIdentity,
                    flags as _Flags,
                    OSPath AS _OSPath
                 FROM scope()
              }
          )
      SELECT * FROM foreach(row=TCCList, query=TCCAccessDetails)

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/generic.applications.office.keywords.md
======
---
title: Generic.Applications.Office.Keywords
hidden: true
tags: [Client Artifact]
---

Microsoft Office documents among other document format (such as
LibraOffice) are actually stored in zip files. The zip file contain
the document encoded as XML in a number of zip members.

This makes it difficult to search for keywords within office
documents because the ZIP files are typically compressed.

This artifact searches for office documents by file extension and
glob then uses the zip filesystem accessor to launch a yara scan
again the uncompressed data of the document. Keywords are more
likely to match when scanning the decompressed XML data.

The artifact returns a context around the keyword hit.

NOTE: The InternalMtime column shows the creation time of the zip
member within the document which may represent when the document was
initially created.

See
https://en.wikipedia.org/wiki/List_of_Microsoft_Office_filename_extensions
https://wiki.openoffice.org/wiki/Documentation/OOo3_User_Guides/Getting_Started/File_formats


<pre><code class="language-yaml">
name: Generic.Applications.Office.Keywords
description: |
  Microsoft Office documents among other document format (such as
  LibraOffice) are actually stored in zip files. The zip file contain
  the document encoded as XML in a number of zip members.

  This makes it difficult to search for keywords within office
  documents because the ZIP files are typically compressed.

  This artifact searches for office documents by file extension and
  glob then uses the zip filesystem accessor to launch a yara scan
  again the uncompressed data of the document. Keywords are more
  likely to match when scanning the decompressed XML data.

  The artifact returns a context around the keyword hit.

  NOTE: The InternalMtime column shows the creation time of the zip
  member within the document which may represent when the document was
  initially created.

  See
  https://en.wikipedia.org/wiki/List_of_Microsoft_Office_filename_extensions
  https://wiki.openoffice.org/wiki/Documentation/OOo3_User_Guides/Getting_Started/File_formats

parameters:
  - name: documentGlobs
    default: /*.{docx,docm,dotx,dotm,docb,xlsx,xlsm,xltx,xltm,pptx,pptm,potx,potm,ppam,ppsx,ppsm,sldx,sldm,odt,ott,oth,odm}
  - name: searchGlob
    default: C:\Users\**
  - name: yaraRule
    type: yara
    default: |
      rule Hit {
        strings:
          $a = "secret" wide nocase
          $b = "secret" nocase

        condition:
          any of them
      }

sources:
  - query: |
        LET office_docs = SELECT OSPath AS OfficePath,
             Mtime as OfficeMtime,
             Size as OfficeSize
        FROM glob(globs=searchGlob + documentGlobs)

        // A list of zip members inside the doc that have some content.
        LET document_parts = SELECT OfficePath,
             OSPath AS ZipMemberPath
        FROM glob(
           globs="/**",
           root=pathspec(DelegatePath=OfficePath),
           accessor='zip')
        WHERE not IsDir and Size &gt; 0

        // For each document, scan all its parts for the keyword.
        SELECT OfficePath,
               OfficeMtime,
               OfficeSize,
               File.ModTime as InternalMtime,
               String.HexData as HexContext,
               File.OSPath AS OSPath
        FROM foreach(
           row=office_docs,
           query={
              SELECT File, String, OfficePath,
                     OfficeMtime, OfficeSize
              FROM yara(
                 rules=yaraRule,
                 files=document_parts.ZipMemberPath,
                 context=200,
                 accessor='zip')
        })

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/notebooks.vqlx2.md
======
---
title: Notebooks.VQLx2
hidden: true
tags: [notebook]
---

A notebook initialized with 2 VQL cells


<pre><code class="language-yaml">
name: Notebooks.VQLx2
description: |
  A notebook initialized with 2 VQL cells

type: NOTEBOOK

sources:
  - notebook:
    - type: vql
      name: First Cell
      output: |
        &lt;&lt; 1st cell: Click here to edit &gt;&gt;
      template: |
        SELECT * FROM orgs()
    - type: vql
      name: Second Cell
      output: |
        &lt;&lt; 2nd cell: Click here to edit &gt;&gt;
      template: |
        SELECT * FROM gui_users() WHERE name = whoami()

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.system.domainrole.md
======
---
title: Windows.System.DomainRole
hidden: true
tags: [Client Artifact]
---

This artifact will extract Domain Role per machine.


<pre><code class="language-yaml">
name: Windows.System.DomainRole
author: 'Matt Green - @mgreen27'
description: |
   This artifact will extract Domain Role per machine.

type: CLIENT

parameters:
   - name: HostNameRegex
     description: Regex filter by DNSHostName
     default: .
   - name: DomainRegex
     description: Regex filter by Domain
     default: .
   - name: RoleRegex
     description: Regex filter by Role
     default: .
     
sources:
  - precondition:
      SELECT OS From info() where OS =~ 'windows'

    query: |
        SELECT 
            Domain, 
            DNSHostName, 
            if(condition= DomainRole=0,
                then='Standalone Workstation',
                else=if(condition= DomainRole=1,
                    then='Member Workstation',
                    else=if(condition= DomainRole=2,
                        then='Standalone Server',
                        else=if(condition= DomainRole=3,
                            then='Member Server',
                            else=if(condition= DomainRole=4,
                                then='Backup Domain Controller',
                                else=if(condition= DomainRole=5,
                                    then= 'Primary Domain Controller',
                                    else= 'Unknown' )))))
                ) AS DomainRole
        FROM wmi(query='SELECT * FROM Win32_ComputerSystem',namespace='ROOT/cimv2')
        WHERE 
            DNSHostName =~ HostNameRegex
            AND Domain =~ DomainRegex
            AND DomainRole =~ RoleRegex
</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.forensics.useraccesslogs.md
======
---
title: Windows.Forensics.UserAccessLogs
hidden: true
tags: [Client Artifact]
---

Parse and collect the SUM database

UAL is a feature that can help server administrators quantify the
number of unique client requests of roles and services on a local
server.

The UAL only exists on Windows Server edition 2012 and above.

NOTE: Unlike other tools, Velociraptor DOES NOT use the JET API to
access the database because it has a builtin ESE parser. This means
that you **do not need to repair** the files using `eseutil.exe` as
is commonly explained in the references below. Velociraptor should
have no trouble parsing these files on the live system.


<pre><code class="language-yaml">
name: Windows.Forensics.UserAccessLogs
description: |
  Parse and collect the SUM database

  UAL is a feature that can help server administrators quantify the
  number of unique client requests of roles and services on a local
  server.

  The UAL only exists on Windows Server edition 2012 and above.

  NOTE: Unlike other tools, Velociraptor DOES NOT use the JET API to
  access the database because it has a builtin ESE parser. This means
  that you **do not need to repair** the files using `eseutil.exe` as
  is commonly explained in the references below. Velociraptor should
  have no trouble parsing these files on the live system.

reference:
  - https://advisory.kpmg.us/blog/2021/digital-forensics-incident-response.html
  - https://docs.microsoft.com/en-us/windows-server/administration/user-access-logging/manage-user-access-logging
  - https://www.crowdstrike.com/blog/user-access-logging-ual-overview/

export: |
    LET IPProfile = '''[
      ["IP4", 0, [
        ["A", 0, "uint8"],
        ["B", 1, "uint8"],
        ["C", 2, "uint8"],
        ["D", 3, "uint8"],
        ["IP", 0, "Value", {
           value: "x=&gt; format(format='%d.%d.%d.%d', args=[x.A, x.B, x.C, x.D])"
        }]
      ]],
     ["IP6", 0, [
        ["A", 0, "uint16be"],
        ["B", 2, "uint16be"],
        ["C", 4, "uint16be"],
        ["D", 6, "uint16be"],
        ["E", 8, "uint16be"],
        ["F", 10, "uint16be"],
        ["G", 12, "uint16be"],
        ["H", 14, "uint16be"],
        ["IP", 0, "Value", {
           value: "x=&gt; format(format='%04x:%04x:%04x:%04x:%04x:%04x:%04x:%04x', args=[x.A, x.B, x.C, x.D, x.E, x.F, x.G, x.H])"
        }]
      ]]
    ]'''

    -- Format the address - it can be IPv4, IPv6 or something else.
    LET FormatAddress(Address) = if(condition=len(list=Address) = 4,

         -- IPv4 address should be formatted in dot notation
         then=parse_binary(accessor="data",
                           filename=Address, struct="IP4",
                           profile=IPProfile).IP,

         else=if(condition=len(list=Address)=16,
           -- IPv6 addresses are usually shortened
           then=parse_binary(accessor="data",
                           filename=Address, struct="IP6",
                           profile=IPProfile).IP,

           -- We dont know what kind of address it is.
           else=format(format="%x", args=Address)))

    -- Get the Clients table from all snapshot files.
    LET SystemIdentity = SELECT OSPath FROM glob(globs=SUMGlob)
      WHERE Name =~ "SystemIdentity.mdb"

    -- Prepare a Role lookup to resolve the role GUID
    LET RoleLookup &lt;= memoize(key="RoleGuid", query={
      SELECT * FROM foreach(row=SystemIdentity, query={
         SELECT * FROM parse_ese(file=OSPath, table="ROLE_IDS")
         WHERE log(message="RoleGuid " + RoleGuid)
      })
    })

parameters:
    - name: SUMGlob
      type: glob
      default: C:/Windows/System32/LogFiles/Sum/*
      description: A glob to file all SUM ESE databases on the system.
    - name: AlsoUpload
      type: bool
      description: If set we also upload the raw files.

sources:
    - name: SystemIdentity
      description: Parse the SystemIdentity database.
      query: |
        SELECT * FROM foreach(row=SystemIdentity, query={
           SELECT *, OSPath AS _OSPath
           FROM parse_ese(file=OSPath, table="SYSTEM_IDENTITY")
        })

    - name: Chained Databases
      query: |
        SELECT * FROM foreach(row=SystemIdentity, query={
          SELECT *, OSPath AS _OSPath
          FROM parse_ese(file=OSPath, table="CHAINED_DATABASES")
        })

    - name: RoleIds
      query: |
        SELECT * FROM foreach(row=SystemIdentity, query={
           SELECT *, OSPath AS _OSPath
           FROM parse_ese(file=OSPath, table="ROLE_IDS")
        })

    - name: Clients
      description: Dump the clients database from all ESE files
      query: |
        LET ContentDatabases =  SELECT * FROM glob(globs=SUMGlob)
           WHERE Name =~ ".mdb" AND NOT Name =~ "SystemIdentity"

        -- The clients table has potentially 365 columns (1 per day) so we
        -- format it a bit better by putting the Day* columns in their own dict.
        LET GetClients(OSPath) = SELECT *, OSPath AS _OSPath
             FROM foreach(row={
            SELECT to_dict(item={
                   SELECT _key, _value FROM items(item=_value)
                   WHERE NOT _key =~ "Day"
               })  +
               dict(Days=to_dict(item={
                   SELECT _key, _value FROM items(item=_value)
                   WHERE _key =~ "Day"
               })) AS Value
            FROM items(item={
               SELECT *, get(item=RoleLookup, field=RoleGuid).RoleName AS RoleName,
                  Address AS RawAddress,
                  FormatAddress(Address=unhex(string=Address)) AS Address
               FROM parse_ese(file=OSPath, table="CLIENTS")
            })
        }, column="Value")

        -- Get the Clients table from all snapshot files.
        SELECT * FROM foreach(row=ContentDatabases, query={
          SELECT * FROM GetClients(OSPath=OSPath)
        })

    - name: VIRTUALMACHINES
      query: |
        SELECT * FROM foreach(row=ContentDatabases, query={
           SELECT *, OSPath AS _OSPath
           FROM parse_ese(file=OSPath, table="VIRTUALMACHINES")
        })

    - name: DNS
      query: |
        SELECT * FROM foreach(row=ContentDatabases, query={
           SELECT *, OSPath AS _OSPath
           FROM parse_ese(file=OSPath, table="DNS")
        })

    - name: Uploads
      query: |
        SELECT OSPath, if(condition=AlsoUpload, then=upload(file=OSPath))
        FROM glob(globs=SUMGlob)

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.remediation.quarantine.md
======
---
title: Windows.Remediation.Quarantine
hidden: true
tags: [Client Artifact]
---

**Apply quarantine via Windows local IPSec policy**

- By default the current client configuration is applied as an
  exclusion using resolved IP address at time of application.

- A configurable lookup table is also used to generate
  additional entries using the same syntax as netsh ipsec
  configuration.

  - DNS and DHCP are entires here allowed by default.

- An optional MessageBox may also be configured to alert all
  logged in users.

  - The message will be truncated to 256 characters.

- After policy application, connection back to the Velociraptor
  frontend is tested and the policy removed if connection
  unavailable.

- To remove policy, select the RemovePolicy checkbox.

- To update policy, simply rerun the artifact.

NOTE:

- Remember DNS resolution may change. It is highly recommended
  to plan policy accordingly and not rely on DNS lookups.

- Local IPSec policy can not be applied when Domain IPSec policy
  is already enforced. Please configure at GPO level in this case.

- This artifact deliberately does not support connecting back on
  plain http! We only support the https or wss protocols because
  this is the recommended connectivity mechanism between server
  and client.


<pre><code class="language-yaml">
name: Windows.Remediation.Quarantine
description: |
      **Apply quarantine via Windows local IPSec policy**

      - By default the current client configuration is applied as an
        exclusion using resolved IP address at time of application.

      - A configurable lookup table is also used to generate
        additional entries using the same syntax as netsh ipsec
        configuration.

        - DNS and DHCP are entires here allowed by default.

      - An optional MessageBox may also be configured to alert all
        logged in users.

        - The message will be truncated to 256 characters.

      - After policy application, connection back to the Velociraptor
        frontend is tested and the policy removed if connection
        unavailable.

      - To remove policy, select the RemovePolicy checkbox.

      - To update policy, simply rerun the artifact.

      NOTE:

      - Remember DNS resolution may change. It is highly recommended
        to plan policy accordingly and not rely on DNS lookups.

      - Local IPSec policy can not be applied when Domain IPSec policy
        is already enforced. Please configure at GPO level in this case.

      - This artifact deliberately does not support connecting back on
        plain http! We only support the https or wss protocols because
        this is the recommended connectivity mechanism between server
        and client.

author: Matt Green - @mgreen27

reference:
  - https://mgreen27.github.io/posts/2020/07/23/IPSEC.html

required_permissions:
  - EXECVE

precondition: SELECT OS From info() where OS = 'windows'

parameters:
  - name: PolicyName
    default: "VelociraptorQuarantine"
  - name: RuleLookupTable
    type: csv
    default: |
        Action,SrcAddr,SrcMask,SrcPort,DstAddr,DstMask,DstPort,Protocol,Mirrored,Description
        Permit,me,,0,any,,53,udp,yes,DNS
        Permit,me,,0,any,,53,tcp,yes,DNS TCP
        Permit,me,,68,any,,67,udp,yes,DHCP
        Block,any,,,any,,,,yes,All other traffic

  - name: MessageBox
    description: |
        Optional message box notification to send to logged in users. 256
        character limit.

  - name: RemovePolicy
    type: bool
    description: Tickbox to remove policy.

  - name: VelociraptorURL
    description: |
      A URL for allowing connections back to the
      Velociraptor server. If not specified we use the first URL in the
      client's configuration file.

sources:
    - query: |
        LET AllURLs &lt;= filter(list=config.server_urls + VelociraptorURL, regex='.+')

        // If a MessageBox configured truncate to 256 character limit
        LET MessageBox &lt;= parse_string_with_regex(
                  regex='^(?P&lt;Message&gt;.{0,255}).*',
                  string=MessageBox).Message

        // Normalise Action
        LET normalise_action(Action)=if(condition= lowcase(string=Action)= 'permit',
              then= 'Permit',
              else= if(condition= lowcase(string=Action)= 'block',
                  then= 'Block'))

        // extract configurable policy from lookuptable
        LET configurable_policy &lt;= SELECT
                  normalise_action(Action=Action) AS Action,
                  SrcAddr,SrcMask,SrcPort,
                  DstAddr,DstMask,DstPort,
                  Protocol,Mirrored,Description
              FROM RuleLookupTable

        // Parse a URL to get domain name.
        LET get_domain(URL) = split(string=url(parse=URL).Host, sep=":")[0]

        // Parse a URL to get the port or use 443. We deliberately do
        // not support plain http!
        LET get_port(URL) = if(condition=url(parse=URL).Host =~ ":",
            then=split(string=url(parse=URL).Host, sep=":")[1],
            else="443")

        // extract Velociraptor config for policy
        LET extracted_config &lt;= SELECT * FROM foreach(
                  row= AllURLs,
                  query={
                      SELECT
                          'Permit' AS Action,
                          'me' AS SrcAddr,
                          '' As SrcMask,
                          '0' AS SrcPort,
                          get_domain(URL=_value) AS DstAddr,
                          '' As DstMask,
                          get_port(URL=_value) AS DstPort,
                          'tcp' AS Protocol,
                          'yes' AS Mirrored,
                          'VelociraptorFrontEnd' AS Description,
                          _value AS URL
                      FROM scope()
                  })

        // build policy with extracted config and lookuptable
        LET policy &lt;= SELECT *
              FROM chain(
                  a=extracted_config,
                  b=configurable_policy
              )
              WHERE Action =~ '^(Permit|Block)$'

        // Removes empty options from the command line
        LET clean_cmdline(CMD) = filter(list=CMD, regex='^(\\w+|\\w+=.+)$')

        LET delete_cmdline = clean_cmdline(
             CMD=('netsh','ipsec','static','delete','policy', 'name=' + PolicyName))

        LET create_cmdline = clean_cmdline(
             CMD=('netsh','ipsec','static','add','policy', 'name=' + PolicyName))

        LET action_cmdline(Action) = clean_cmdline(
             CMD=('netsh','ipsec','static','add','filteraction',
                  'name=' + PolicyName + ' ' + Action + 'Action',
                  'action=' + Action))

        LET rule_cmdline(Action) = clean_cmdline(
             CMD=('netsh','ipsec','static','add','rule',
                  'name=' + PolicyName + ' ' + Action + 'Rule',
                  'policy=' + PolicyName,
                  'filterlist=' + PolicyName + ' ' + Action + 'FilterList',
                  'filteraction=' + PolicyName + ' ' + Action + 'Action'))

        LET enable_cmdline = clean_cmdline(
             CMD=('netsh','ipsec','static','set','policy',
                   'name=' + PolicyName, 'assign=y'))

        // Emit the message if no output is emitted, otherwise emit the output.
        LET combine_results(Stdout, Stderr, ReturnCode, Message) = if(
              condition=Stdout =~ "[^\\s]", then=Stdout,
              else= if(condition=Stderr =~ "[^\\s]", then=Stderr,
              else= if(condition= ReturnCode=0,
                    then=Message )))

        // delete old or unwanted policy
        LET delete_policy = SELECT
              timestamp(epoch=now()) as Time,
              PolicyName + ' IPSec policy removed.' AS Result
          FROM execve(argv=delete_cmdline, length=10000)

        // first step is creating IPSec policy
        LET create_policy = SELECT
              timestamp(epoch=now()) as Time,
              combine_results(Stdout=Stdout, Stderr=Stderr,
                  ReturnCode=ReturnCode,
                  Message=PolicyName + ' IPSec policy created.') AS Result
          FROM execve(argv=create_cmdline, length=10000)

        LET entry_cmdline(Action, SrcAddr, SrcPort, SrcMask,
                   DstAddr, DstPort, DstMask, Protocol,
                   Mirrored, Description) = clean_cmdline(
              CMD=('netsh','ipsec','static','add','filter',
                   format(format='filterlist=%s %sFilterList', args=[PolicyName, Action]),
                   format(format='srcaddr=%v', args=SrcAddr),
                   format(format='srcmask=%v', args=SrcMask),
                   format(format='srcport=%v', args=SrcPort),
                   format(format='dstaddr=%v', args=DstAddr),
                   format(format='dstmask=%v', args=DstMask),
                   format(format='dstport=%v', args=DstPort),
                   format(format='protocol=%v', args=Protocol),
                   format(format='mirrored=%v', args=Mirrored),
                   format(format='description=%v', args=Description)))

        // second step is to create policy filters
        LET create_filters = SELECT * FROM foreach(row=policy,
                  query={
                      SELECT
                          timestamp(epoch=now()) as Time,
                          combine_results(Stdout=Stdout, Stderr=Stderr,
                               ReturnCode=ReturnCode,
                               Message='Entry added: ' +
                                 join(array=entry_cmdline(Action=Action,
                                   SrcAddr=SrcAddr, SrcPort=SrcPort, SrcMask=SrcMask,
                                   DstAddr=DstAddr, DstPort=DstPort, DstMask=DstMask,
                                   Protocol=Protocol, Mirrored=Mirrored,
                                   Description=Description), sep=" ")) AS Result
                      FROM execve(argv=entry_cmdline(Action=Action,
                                   SrcAddr=SrcAddr, SrcPort=SrcPort, SrcMask=SrcMask,
                                   DstAddr=DstAddr, DstPort=DstPort, DstMask=DstMask,
                                   Protocol=Protocol, Mirrored=Mirrored,
                                   Description=Description), length=10000)
                  })

        // third step is to create policy filter actions
        LET create_actions = SELECT * FROM foreach(
                  row= {
                      SELECT Action
                      FROM policy
                      GROUP BY Action
                  },
                  query={
                      SELECT
                          timestamp(epoch=now()) as Time,
                          combine_results(Stdout=Stdout, Stderr=Stderr,
                               ReturnCode=ReturnCode,
                               Message='FilterAction added: ' +
                                 join(array=action_cmdline(Action=Action), sep=" ")) AS Result
                      FROM execve(argv=action_cmdline(Action=Action), length=10000)
                  })

        // fourth step combines action lists and actions in a Rule
        LET create_rules = SELECT * FROM foreach(
                  row= {
                      SELECT Action
                      FROM policy
                      GROUP BY Action
                  },
                  query={
                      SELECT
                          timestamp(epoch=now()) as Time,
                          combine_results(Stdout=Stdout, Stderr=Stderr,
                               ReturnCode=ReturnCode,
                               Message='Rule added: ' +
                                 join(array=rule_cmdline(Action=Action), sep=" ")) AS Result
                      FROM execve(argv=rule_cmdline(Action=Action), length=10000)
                  })

        // fith step is to enable our IPSec policy
        LET enable_policy = SELECT
              timestamp(epoch=now()) as Time,
              combine_results(Stdout=Stdout, Stderr=Stderr,
                  ReturnCode=ReturnCode,
                  Message=PolicyName + ' IPSec policy applied.') AS Result
              FROM execve(argv=enable_cmdline, length=10000)

        // test connection to a frontend server
        LET test_connection = SELECT * FROM foreach(
                  row={
                      SELECT * FROM policy
                      WHERE Description = 'VelociraptorFrontEnd'
                  },
                  query={
                      SELECT *
                          Url,
                          response
                      FROM
                          -- Always use https even when configured for wss
                          http_client(url=url(
                              scheme='https',
                              host=DstAddr + ':' + DstPort,
                              path='/server.pem').String)

                      WHERE Response = 200
                      LIMIT 1
                  })

        // final check to keep or remove policy
        LET final_check = SELECT * FROM if(condition= test_connection,
                  then={
                      SELECT
                          timestamp(epoch=now()) as Time,
                          if(condition=MessageBox,
                              then= PolicyName + ' connection test successful. MessageBox sent.',
                              else= PolicyName + ' connection test successful.'
                              ) AS Result
                      FROM if(condition=MessageBox,
                          then= {
                              SELECT * FROM execve(argv=['msg','*',MessageBox])
                          },
                          else={
                              SELECT * FROM scope()
                          })
                  },
                  else={
                      SELECT
                          timestamp(epoch=now()) as Time,
                          PolicyName + ' failed connection test. Removing IPSec policy.' AS Result
                      FROM delete_policy
                  })

        // Execute content
        SELECT * FROM if(condition=RemovePolicy,
                  then=delete_policy,
                  else={
                      SELECT * FROM chain(
                          a=delete_policy,
                          b=create_policy,
                          c=create_filters,
                          d=create_actions,
                          e=create_rules,
                          g=enable_policy,
                          h=final_check)
                  })

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/server.monitor.health.md
======
---
title: Server.Monitor.Health
hidden: true
tags: [Server Event Artifact]
---

This is the main server health dashboard. It is shown on the
homescreen and enabled by default on all new installs.

You may edit this artifact to customize your server dashboard.

Alternatively, edit the Welcome screen at the
`Server.Internal.Welcome` artifact.


<pre><code class="language-yaml">
name: Server.Monitor.Health
description: |
  This is the main server health dashboard. It is shown on the
  homescreen and enabled by default on all new installs.

  You may edit this artifact to customize your server dashboard.

  Alternatively, edit the Welcome screen at the
  `Server.Internal.Welcome` artifact.

type: SERVER_EVENT

sources:
  - name: Prometheus
    query: SELECT sleep(time=10000000) FROM scope()

reports:
  - type: SERVER_EVENT
    # Only allow the report to run for 10 seconds - this is plenty for
    # the GUI.
    timeout: 10
    parameters:
      - name: Sample
        default: "6"

    template: |
      {{ define "CPU" }}
        LET SampledData &lt;= SELECT * FROM sample(
             n=atoi(string=Sample),
             query={
              SELECT _ts as Timestamp,
                  CPUPercent,
                  int(int=MemoryUse / 1048576) AS MemoryUse_Mb,
                  TotalFrontends
              FROM source(source="Prometheus",
                  start_time=StartTime, end_time=EndTime,
                  artifact="Server.Monitor.Health")
        })

        LET Stats &lt;= SELECT count() AS Count,
            timestamp(epoch=min(item=Timestamp)) AS MinTime,
            timestamp(epoch=max(item=Timestamp)) AS MaxTime,
            timestamp(epoch=StartTime) AS StartTime
        FROM SampledData
        GROUP BY 1

        // Include a log for verification. Last data should always be
        // very recent and sample should be passed properly.
        LET _ &lt;= log(message="Graphs cover times from %v (%v). Actual data available from %v (%v) to %v (%v) with %v rows. Data is sampled every %v samples.", args=[
           Stats[0].StartTime.String, humanize(time=Stats[0].StartTime),
           Stats[0].MinTime.String, humanize(time=Stats[0].MinTime),
           Stats[0].MaxTime.String, humanize(time=Stats[0].MaxTime),
           Stats[0].Count, Sample])

        SELECT * FROM SampledData
      {{ end }}

      {{ define "CurrentConnections" }}
        SELECT * FROM sample(
             n=atoi(string=Sample),
             query={
               SELECT _ts as Timestamp,
                  client_comms_current_connections
               FROM source(source="Prometheus",
                           start_time=StartTime, end_time=EndTime,
                           artifact="Server.Monitor.Health")
        })
      {{ end }}

      {{ $time_rows := Query "SELECT timestamp(epoch=now()) AS Now FROM scope()" | Expand }}
      ## Server status @ {{ Render ( Get $time_rows "0.Now" ) }}

      &lt;p&gt;The following are total across all frontends.&lt;/p&gt;
          &lt;span class="container"&gt;
            &lt;span class="row"&gt;
              &lt;span class="col-sm panel"&gt;
               CPU and Memory Utilization
               {{- Query "CPU" | TimeChart "RSS.yaxis" 2 -}}
              &lt;/span&gt;
              &lt;span class="col-sm panel"&gt;
               Currently Connected Clients
               {{- Query "CurrentConnections" | TimeChart "RSS.yaxis" 2 -}}
              &lt;/span&gt;
            &lt;/span&gt;
          &lt;/span&gt;

      ## Current Orgs
      {{ define "OrgsTable" }}
         LET ColumnTypes &lt;= dict(ClientConfig='url')
         LET OrgsTable = SELECT Name, OrgId,
                         upload(accessor='data', file=_client_config,
                                name='client.'+OrgId+'.config.yaml') AS _Upload
         FROM orgs()

         SELECT Name, OrgId, link_to(upload=_Upload) AS ClientConfig
         FROM OrgsTable
      {{ end }}

      {{ Query "OrgsTable" | Table }}

      ## Disk Space

      {{ Query "SELECT * FROM Artifact.Generic.Client.DiskSpace()" | Table }}

      ## Users

      {{ define "UserPermissions" }}
        SELECT name, effective_policy AS _EffectivePolicy,
               join(array=roles, sep=", ") AS Roles
        FROM gui_users()
      {{ end }}

      {{ Query "UserPermissions" | Table }}

      ## Server version

      {{ Query "SELECT server_version FROM config" | Table }}

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/linux.sys.groups.md
======
---
title: Linux.Sys.Groups
hidden: true
tags: [Client Artifact]
---

Get system group IDs, names and memberships from /etc/group

<pre><code class="language-yaml">
name: Linux.Sys.Groups
author: Andreas Misje – @misje
description: Get system group IDs, names and memberships from /etc/group
parameters:
  - name: GroupFile
    default: /etc/group
    description: The location of the group file

sources:
  - precondition: |
      SELECT OS From info() where OS = 'linux'
    query: |
      SELECT Group, int(int=GID) AS GID, filter(regex='.+',
        list=split(sep_string=',', string=Members)) AS Members
      FROM split_records(
            filenames=GroupFile,
            regex=':', record_regex='\r?\n',
            columns=['Group', 'Password', 'GID', 'Members'])

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/server.utils.deletemanyflows.md
======
---
title: Server.Utils.DeleteManyFlows
hidden: true
tags: [Server Artifact]
---

Sometimes the Velociraptor server accumulates a lot of data that is
no longer needed.

This artifact will enumerate all flows from all clients and matches
them against some criteria. Flows that match are then removed.

**NOTE** This artifact will destroy all data irrevocably. Take
  care! You should always do a dry run first to see which flows
  will match before using the ReallyDoIt option.


<pre><code class="language-yaml">
name: Server.Utils.DeleteManyFlows
description: |
   Sometimes the Velociraptor server accumulates a lot of data that is
   no longer needed.

   This artifact will enumerate all flows from all clients and matches
   them against some criteria. Flows that match are then removed.

   **NOTE** This artifact will destroy all data irrevocably. Take
     care! You should always do a dry run first to see which flows
     will match before using the ReallyDoIt option.

type: SERVER

parameters:
   - name: ArtifactRegex
     default: Generic.Client.Info
     type: regex
   - name: HostnameRegex
     description: If specified only target these hosts
     type: regex
   - name: DateBefore
     description: Only select flows created before this date. If not set we choose all flows.
     type: timestamp
   - name: CreatorRegex
     default: "."
     type: regex
     description: |
       Match flows created by this user.
   - name: ReallyDoIt
     type: bool
     description: Does not delete until you press the ReallyDoIt button!

sources:
  - query: |
        LET DateBefore &lt;= DateBefore || timestamp(epoch=now())
        LET hits = SELECT * FROM foreach(row={
            SELECT client_id,
                   os_info.hostname AS hostname
            FROM clients()
            WHERE hostname =~ HostnameRegex
        },
        query={
          SELECT client_id, hostname,
                 session_id, request.creator AS creator,
                 request.artifacts as artifacts,
                 timestamp(epoch=create_time) AS created
          FROM flows(client_id=client_id)
          WHERE creator =~ CreatorRegex
             AND artifacts =~ ArtifactRegex
             AND created &lt; DateBefore
        }, workers=10)

        SELECT * FROM if(condition=ReallyDoIt,
        then={
            SELECT * FROM foreach(row=hits,
            query={
                SELECT client_id, hostname, creator,
                       session_id, artifacts, created, Type, Data, Error
                FROM delete_flow(client_id=client_id,
                        flow_id=session_id, really_do_it=ReallyDoIt)
                WHERE log(message=format(format="Deleting flow %v from %v",
                   args=[session_id, hostname]))
            }, workers=10)
        }, else={
            SELECT * FROM hits
        })

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.applications.chrome.history.md
======
---
title: Windows.Applications.Chrome.History
hidden: true
tags: [Client Artifact]
---

Enumerates a targets chrome history. Source based on Hindsight and
code review of
https://source.chromium.org/chromium/chromium/src/+/master:components/history/core/browser/history_types.h.

NOTE: Some research has shown that older browsers may not have this
table, then you should be treating it as you would in a traditional
investigation, this changes is aimed at taking advantage of the
newer tables to reduce false postitives.

## NOTES:

This artifact is deprecated in favor of
Generic.Forensic.SQLiteHunter and will be removed in future


<pre><code class="language-yaml">
name: Windows.Applications.Chrome.History
description: |
  Enumerates a targets chrome history. Source based on Hindsight and
  code review of
  https://source.chromium.org/chromium/chromium/src/+/master:components/history/core/browser/history_types.h.

  NOTE: Some research has shown that older browsers may not have this
  table, then you should be treating it as you would in a traditional
  investigation, this changes is aimed at taking advantage of the
  newer tables to reduce false postitives.

  ## NOTES:

  This artifact is deprecated in favor of
  Generic.Forensic.SQLiteHunter and will be removed in future


author: Angry-Bender @angry-bender
parameters:
  - name: historyGlobs
    default: \AppData\{Local,Roaming}\{Google\Chrome\User Data,Microsoft\Edge\User Data,BraveSoftware\Brave-Browser\User Data,Vivaldi\User Data,Opera Software\Opera*Stable}\*\History
  - name: urlSQLQuery
    default: |
      SELECT U.id AS id,
             U.url AS url,
             V.visit_time as visit_time,
             U.title AS title,
             U.visit_count,
             U.typed_count,
             U.last_visit_time, U.hidden,
             CASE VS.source
                WHEN 0 THEN 'Synced'
                WHEN 1 THEN 'Local'
                WHEN 2 THEN 'Extension'
                WHEN 3 THEN 'ImportFromFirefox'
                WHEN 4 THEN 'ImportFromSafari'
                WHEN 6 THEN 'ImportFromChrome/Edge'
                WHEN 7 THEN 'ImportFromEdgeHTML'
                ELSE 'Local'
             END Source,
             V.from_visit,
             strftime('%H:%M:%f',V.visit_duration/1000000.0, 'unixepoch') as visit_duration,
             V.transition
      FROM urls AS U
      JOIN visits AS V ON U.id = V.url
      LEFT JOIN visit_source AS VS on V.id = VS.id
  - name: userRegex
    default: .
    type: regex
  - name: URLRegex
    default: .
    type: regex

precondition: SELECT OS From info() where OS = 'windows'

sources:
  - query: |
        LET history_files = SELECT * from foreach(
          row={
             SELECT Uid, Name AS User,
                    expand(path=Directory) AS HomeDirectory
             FROM Artifact.Windows.Sys.Users()
             WHERE Name =~ userRegex
          },
          query={
             SELECT User, OSPath, Mtime
             FROM glob(globs=historyGlobs, root=HomeDirectory)
          })

        SELECT * FROM foreach(row=history_files,
          query={
            SELECT User,
                   id AS url_id,
                   timestamp(winfiletime=visit_time * 10) AS visit_time,
                   url as visited_url,
                   title,visit_count,typed_count,
                   timestamp(winfiletime=last_visit_time * 10) AS last_visit_time,
                   hidden,
                   from_visit AS from_url_id,
                   Source,
                   visit_duration,transition,
                   timestamp(winfiletime=last_visit_time * 10) as _SourceLastModificationTimestamp,
                   OSPath
            FROM sqlite(
              file=OSPath,
              query=urlSQLQuery)
          })
          WHERE visited_url =~ URLRegex

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/generic.client.stats.md
======
---
title: Generic.Client.Stats
hidden: true
tags: [Client Event Artifact]
---

An Event artifact which generates client's CPU and memory statistics.

<pre><code class="language-yaml">
name: Generic.Client.Stats
description: An Event artifact which generates client's CPU and memory statistics.
parameters:
  - name: Frequency
    description: Return stats every this many seconds.
    type: int
    default: "10"
type: CLIENT_EVENT

sources:
  - precondition: SELECT OS From info() where OS = 'windows'
    query: |
      SELECT *, rate(x=CPU, y=Timestamp) AS CPUPercent
      FROM foreach(
         row={
           SELECT UnixNano
           FROM clock(period=Frequency)
         },
         query={
           SELECT UnixNano / 1000000000 as Timestamp,
                  User + System as CPU,
                  Memory.WorkingSetSize as RSS
           FROM pslist(pid=getpid())
         })

    notebook:
      - type: vql_suggestion
        name: Graph CPU usage
        template: |
          /*
          # Events from Generic.Client.Stats
          */
          LET resources = SELECT Timestamp, rate(x=CPU, y=Timestamp) * 100 As CPUPercent,
               RSS / 1000000 AS MemoryUse
          FROM source(start_time=StartTime, end_time=EndTime)
          WHERE CPUPercent &gt;= 0
          /*
            {{ Query "SELECT * FROM resources" | LineChart "xaxis_mode" "time" "RSS.yaxis" 2 }}
          */
          SELECT * FROM resources
          LIMIT 50

  - precondition: SELECT OS From info() where OS != 'windows'
    query: |
      SELECT *, rate(x=CPU, y=Timestamp) AS CPUPercent
      FROM foreach(
         row={
           SELECT UnixNano
           FROM clock(period=Frequency)
         },
         query={
           SELECT UnixNano / 1000000000 as Timestamp,
                  Times.system + Times.user as CPU,
                  MemoryInfo.RSS as RSS
           FROM pslist(pid=getpid())
         })


reports:
  - type: SERVER_EVENT
    template: |
      {{ define "resources" }}
           SELECT Timestamp, rate(x=CPU, y=Timestamp) * 100 As CPUPercent,
                  RSS / 1000000 AS MemoryUse
           FROM source()
           WHERE CPUPercent &gt;= 0
      {{ end }}

      {{ Query "resources" | LineChart "xaxis_mode" "time" "RSS.yaxis" 2 }}

  - type: MONITORING_DAILY
    template: |
      {{ define "resources" }}
           SELECT Timestamp, rate(x=CPU, y=Timestamp) * 100 As CPUPercent,
                  RSS / 1000000 AS MemoryUse
           FROM source()
           WHERE CPUPercent &gt;= 0
      {{ end }}

      {{ $client_info := Query "SELECT * FROM clients(client_id=ClientId) LIMIT 1" }}

      # Client Footprint for {{ Get $client_info "0.os_info.fqdn" }}

      The client has a client ID of {{ Get $client_info "0.client_id" }}.
      Clients report the Velociraptor process footprint to the
      server every 10 seconds. The data includes the total CPU
      utilization, and the resident memory size used by the client.

      The following graph shows the total utilization. Memory
      utilization is meausred in `Mb` while CPU Utilization is
      measured by `Percent of one core`.

      We would expect the client to use around 1-5% of one core when
      idle, but if a heavy hunt is running this might climb
      substantially.

        &lt;div&gt;
        {{ Query "resources" | LineChart "xaxis_mode" "time" "RSS.yaxis" 2 }}
        &lt;/div&gt;

      ## VQL Query

      The following VQL query was used to plot the graph above.

      ```sql
      {{ template "resources" }}
      ```

      &gt; To learn about managing end point performance with Velociraptor see
        the [blog post](https://docs.velociraptor.velocidex.com/blog/html/2019/02/10/velociraptor_performance.html).

column_types:
  - name: Timestamp
    type: timestamp

  - name: ClientId
    type: client_id

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/elastic.flows.upload.md
======
---
title: Elastic.Flows.Upload
hidden: true
tags: [Server Event Artifact]
---

This server side event monitoring artifact waits for new artifacts
to be collected from endpoints and automatically uploads those to an
elastic server.

We use the artifact name as the name of the index. This allows users
to adjust the index size/lifetime according to the artifact it is
holding.

NOTE: Elastic is a database and still must have a stable
schema. This means that artifacts that produce inconsistant columns
and types will **NOT** work as expected. What will happen is that
the first row that is inserted will create the Elastic database
schema (In Elastic terminology "mapping") and then any subsequent
row with a different type for these fields will be rejected by
Elastic.

In particular this does not work with event logs because event logs
have a varied schema (The EventData field is a free form field
depending on the event log itself). Therefore forwarding event log
data to Elastic with this artifact will cause Elastic to drop many
events!! This artifact is not suitable for forwarding Windows Event
Logs!


<pre><code class="language-yaml">
name: Elastic.Flows.Upload
description: |
  This server side event monitoring artifact waits for new artifacts
  to be collected from endpoints and automatically uploads those to an
  elastic server.

  We use the artifact name as the name of the index. This allows users
  to adjust the index size/lifetime according to the artifact it is
  holding.

  NOTE: Elastic is a database and still must have a stable
  schema. This means that artifacts that produce inconsistant columns
  and types will **NOT** work as expected. What will happen is that
  the first row that is inserted will create the Elastic database
  schema (In Elastic terminology "mapping") and then any subsequent
  row with a different type for these fields will be rejected by
  Elastic.

  In particular this does not work with event logs because event logs
  have a varied schema (The EventData field is a free form field
  depending on the event log itself). Therefore forwarding event log
  data to Elastic with this artifact will cause Elastic to drop many
  events!! This artifact is not suitable for forwarding Windows Event
  Logs!

type: SERVER_EVENT

parameters:
  - name: ArtifactNameRegex
    default: .
    type: regex
    description: Only upload these artifacts to elastic
  - name: elasticAddresses
    default: http://127.0.0.1:9200/
  - name: Username
  - name: Password
  - name: APIKey
  - name: DisableSSLSecurity
    type: bool
    description: Disable SSL certificate verification
  - name: Threads
    type: int
    description: Number of threads to upload with
  - name: ChunkSize
    type: int
    description: Batch this many rows for each upload.
  - name: CloudID
    description: The cloud id if needed
  - name: RootCA
    description: |
      A root CA certificate in PEM for trusting TLS protected Elastic
      servers.

sources:
  - query: |
      LET completions = SELECT * FROM watch_monitoring(
             artifact="System.Flow.Completion")
             WHERE Flow.artifacts_with_results =~ ArtifactNameRegex
      LET organization &lt;= org().name

      LET documents = SELECT * FROM foreach(row=completions,
          query={
             SELECT * FROM foreach(
                 row=Flow.artifacts_with_results,
                 query={
                     SELECT *, _value AS Artifact,
                            client_info(client_id=ClientId).os_info.hostname AS Hostname,
                            timestamp(epoch=now()) AS timestamp,
                            ClientId, Flow.session_id AS FlowId,
                            "artifact_" + regex_replace(source=_value,
                               re='[/.]', replace='_') as _index,
                            organization as Organization
                     FROM source(
                        client_id=ClientId,
                        flow_id=Flow.session_id,
                        artifact=_value)
                 })
          })

      SELECT * FROM elastic_upload(
            query=documents,
            threads=Threads,
            chunk_size=ChunkSize,
            addresses=split(string=elasticAddresses, sep=","),
            index="velociraptor",
            password=Password,
            username=Username,
            cloud_id=CloudID,
            api_key=APIKey,
            root_ca=RootCA,
            disable_ssl_security=DisableSSLSecurity,
            type="artifact")

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/server.internal.huntupdate.md
======
---
title: Server.Internal.HuntUpdate
hidden: true
tags: [Internal Artifact]
---

An internal queue to notify hunt dispatchers on all minions that a
certain hunt has changed and should be updated from the internal
cache.


<pre><code class="language-yaml">
name: Server.Internal.HuntUpdate
description: |
  An internal queue to notify hunt dispatchers on all minions that a
  certain hunt has changed and should be updated from the internal
  cache.

type: INTERNAL

column_types:
  - name: HuntId
  - name: Hunt
    type: json

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.etw.kernelfile.md
======
---
title: Windows.ETW.KernelFile
hidden: true
tags: [Client Event Artifact]
---

This artifact follows the Microsoft-Windows-Kernel-File provider.

NOTE: We can only attach to this provider when running as
NT_USER/SYSTEM.


<pre><code class="language-yaml">
name: Windows.ETW.KernelFile
description: |
  This artifact follows the Microsoft-Windows-Kernel-File provider.

  NOTE: We can only attach to this provider when running as
  NT_USER/SYSTEM.

aliases:
  - Windows.ETW.FileCreation

type: CLIENT_EVENT

references:
  - https://github.com/repnz/etw-providers-docs/blob/master/Manifests-Win10-18990/Microsoft-Windows-Kernel-File.xml

parameters:
  - name: ProcessRegex
    type: regex
    description: View Processes with Executables matching this regex
    default: .

  - name: IgnoreProcessRegex
    type: regex
    description: Ignore Processes with Executables matching this regex

  - name: Events
    type: multichoice
    description: Events to view
    default: '["NameCreate", "NameDelete", "FileOpen", "Rename", "RenamePath", "CreateNewFile"]'
    choices:
      - NameCreate
      - NameDelete
      - FileOpen
      - Rename
      - RenamePath
      - CreateNewFile

sources:
  - query: |
      -- KERNEL_FILE_KEYWORD_FILENAME | KERNEL_FILE_KEYWORD_CREATE | KERNEL_FILE_KEYWORD_DELETE_PATH
      LET Keyword &lt;= 0x1490
      LET EIDLookup &lt;= dict(
        `10`="NameCreate", `11`="NameDelete", `12`="FileOpen",
        `19`="Rename", `27`="RenamePath",`30`="CreateNewFile")

      LET ETW = SELECT *
      FROM watch_etw(guid='{edd08927-9cc4-4e65-b970-c2560fb5c289}',
           description="Microsoft-Windows-Kernel-File", any=Keyword)

      SELECT System.ID AS EID,
         get(item=EIDLookup, field=str(str=System.ID)) AS EventType,
         process_tracker_get(id=System.ProcessID).Data AS ProcInfo,
         process_tracker_callchain(id=System.ProcessID).Data.Exe AS CallChain,
         EventData
      FROM delay(query=ETW, delay=3)
      WHERE EventType IN Events
        AND ProcInfo.Exe =~ ProcessRegex
        AND if(condition=IgnoreProcessRegex,
               then=NOT ProcInfo.Exe =~ IgnoreProcessRegex,
               else=TRUE)

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.etw.etwsessions.md
======
---
title: Windows.ETW.ETWSessions
hidden: true
tags: [Client Event Artifact]
---

Windows Event Tracing exposes a lot of low level system information
and events. It is normally employed by security tools to gather
telemetry, however may also be used maliciously.

This artifact monitors for all new ETW sessions and reports the
tracing process as well as the provider that is being traced.


<pre><code class="language-yaml">
name: Windows.ETW.ETWSessions
description: |
  Windows Event Tracing exposes a lot of low level system information
  and events. It is normally employed by security tools to gather
  telemetry, however may also be used maliciously.

  This artifact monitors for all new ETW sessions and reports the
  tracing process as well as the provider that is being traced.

type: CLIENT_EVENT

precondition: SELECT OS From info() where OS = 'windows'

sources:
  - query: |
      LET PublisherGlob = pathspec(
        Path='''HKEY_LOCAL_MACHINE\SOFTWARE\Microsoft\Windows\CurrentVersion\WINEVT\Publishers''',
        path_type="registry")

      LET GUIDLookup(GUID) = SELECT Data.value AS Provider
         FROM stat(accessor="registry", filename=PublisherGlob + ("/" + GUID + "/@"))

      SELECT System.TimeStamp AS Timestamp,
        if(condition=System.ID = 14, then="Installed", else="Removed") AS Action, {
           SELECT Name, CommandLine from pslist(pid=System.ProcessID)
        } AS ProcessInfo ,
        GUIDLookup(GUID=EventData.ProviderName)[0].Provider AS Provider,
        EventData.SessionName AS SessionName,
        System AS _System, EventData AS _EventData
      FROM watch_etw(
         description='Microsoft-Windows-Kernel-EventTracing',
         guid="{B675EC37-BDB6-4648-BC92-F3FDC74D3CA2}", all=0x400)
      WHERE System.ID IN (14, 15)

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.collectors.vss.md
======
---
title: Windows.Collectors.VSS
hidden: true
tags: [Client Artifact]
---

Collects files with VSS deduplication.

Volume shadow copies is a windows feature where file system
snapshots can be made at various times. When collecting files it is
useful to go back through the VSS to see older versions of critical
files.

At the same time we dont want to collect multiple copies of the
same data.

This artifact runs the provided globs over all the VSS and collects
the unique modified time + path combinations.

If a file was modified in a previous VSS copy, this artifact will
retrieve it at multiple shadow copies.


```yaml
name: Windows.Collectors.VSS
description: |
   Collects files with VSS deduplication.

   Volume shadow copies is a windows feature where file system
   snapshots can be made at various times. When collecting files it is
   useful to go back through the VSS to see older versions of critical
   files.

   At the same time we dont want to collect multiple copies of the
   same data.

   This artifact runs the provided globs over all the VSS and collects
   the unique modified time + path combinations.

   If a file was modified in a previous VSS copy, this artifact will
   retrieve it at multiple shadow copies.

parameters:
  - name: collectionSpec
    description: |
       A CSV file with a Glob column with all the globs to collect.
       NOTE: Globs must not have a leading device since the device
       will depend on the VSS.
    type: csv
    default: |
       Glob
       Users\*\NTUser.dat
  - name: RootDevice
    description: The device to apply all the glob on.
    default: "C:"
  - name: Accessor
    default: lazy_ntfs
  - name: VSSDateRegex
    default: .
    type: regex

sources:
   - name: All Matches Metadata
     query: |
      LET originating_machine <= SELECT Data.SystemName AS System
            FROM glob(globs="/*", accessor=Accessor)
            WHERE Name = "\\\\.\\" + RootDevice

      // Generate the collection globs for each device
      LET specs = SELECT Device + Glob AS Glob
            FROM collectionSpec
            WHERE log(message="Processing Device " + Device + " With " + Accessor)

      // Join all the collection rules into a single Glob plugin. This ensure we
      // only make one pass over the filesystem. We only want LFNs.
      LET hits = SELECT FullPath AS SourceFile, Size,
               Ctime AS Created,
               Mtime AS Modified,
               Atime AS LastAccessed,
               Device, strip(string=FullPath, prefix=Device) AS Path,
               Data.mft AS MFT, Data.name_type AS NameType
        FROM glob(globs=specs.Glob, accessor=Accessor)
        WHERE Mode.IsRegular

      // Get all volume shadows on this system.
      LET volume_shadows = SELECT Data.InstallDate AS InstallDate,
               Data.DeviceObject + "\\" AS Device
        FROM glob(globs='/*', accessor=Accessor)
        WHERE Device =~ 'VolumeShadowCopy' AND
              Data.OriginatingMachine =~ originating_machine.System[0] AND
              InstallDate =~ VSSDateRegex

      // The target devices are the root device and all the VSS
      LET target_devices = SELECT * FROM chain(
            a={SELECT "\\\\.\\" + RootDevice + "\\" AS Device from scope()},
            b=volume_shadows)

      // Get all the paths matching the collection globs.
      LET all_matching = SELECT * FROM foreach(row=target_devices, query=hits)

      // Create a unique key to group by - modification time and path name.
      // Order by device name so we get C:\ above the VSS device.
      LET all_results <= SELECT Created, LastAccessed, Path, MFT, NameType,
              Modified, Size, SourceFile, Device,
              format(format="%s:%v", args=[Modified, MFT]) AS Key
        FROM all_matching ORDER BY Device DESC

      SELECT * FROM all_results

   - name: Uploads
     query: |
      // Get all the unique versions of the sort key - that is unique instances of
      // mod time + path. If a path has several mod time (i.e. different times in each VSS
      // we will get them all). But if the same path has the same mod time in all VSS we only
      // take the first one which due to the sorting above will be the root device usually.
      LET unique_mtimes = SELECT * FROM all_results GROUP BY Key

      // Upload the files using the MFT accessor.
      LET uploaded_files = SELECT * FROM foreach(row=unique_mtimes,
        workers=30,
        query={
            SELECT Created, LastAccessed, Modified, MFT, SourceFile, Size,
               upload(file=Device+MFT,
                      name=pathspec(Path=SourceFile),
                      accessor="mft") AS Upload
            FROM scope()
        })

      // Seperate the hashes into their own column.
      SELECT now() AS CopiedOnTimestamp, SourceFile, Upload.Path AS DestinationFile,
               Size AS FileSize, Upload.sha256 AS SourceFileSha256,
               Created, Modified, LastAccessed, MFT
      FROM uploaded_files

```

---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.applications.outlook.pst.header.md
======
---
title: Windows.Applications.Outlook.PST.Header
hidden: true
tags: [Client Artifact]
---

This artifact fetch emails and header details such as SPF, DMARC and DKIM from outlook PST file.


<pre><code class="language-yaml">
name: Windows.Applications.Outlook.PST.Header
author: "Sikha Puthanveedu @SikhaMohan"
description: |
  This artifact fetch emails and header details such as SPF, DMARC and DKIM from outlook PST file.
parameters:
  - name: outlookPSTfile
    type: .pst
    description: Full path to the outlook .pst file (For example - D:/MyPST/MyOutlookDataFile.pst)

sources:
  - precondition:
      SELECT OS FROM info() WHERE OS = 'windows'
    query: |
        
            LET PSTInfo = SELECT Sender as Sender,
                 Receiver as Receiver,
                 Subject as Subject,
                 Message as Message,
                 DateandTime as DeliveryTime,
                 Attachments as AttachmentNames,
                 Body as Body
            from parse_pst(filename=outlookPSTfile)
          
            SELECT  
               Sender,
               Receiver,
               parse_string_with_regex(regex='spf=(\\w+)', string=Body).g1 AS SPF,
               parse_string_with_regex(regex='dkim=(\\w+)', string=Body).g1 AS DKIM,
               parse_string_with_regex(regex='dmarc=(\\w+)', string=Body).g1 AS DMARC,
               parse_string_with_regex(regex='Return-Path: &lt;(.*?)&gt;', string=Body).g1 AS ReturnPath,
               Subject,
               DeliveryTime,
               AttachmentNames,
               Message,
               parse_string_with_regex(regex='internet_message_id:"&lt;(.*?)&gt;"', string=Body).g1 AS msgId,
               parse_string_with_regex(regex='Content-Type:(.*?);', string=Body).g1 AS ContentType
            FROM PSTInfo 
</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/server.internal.clientinfo.md
======
---
title: Server.Internal.ClientInfo
hidden: true
tags: [Internal Artifact]
---

An internal artifact collecting client information. This is used to
update the client info indexes. Client send this automatically at
startup and then every day.


<pre><code class="language-yaml">
name: Server.Internal.ClientInfo
type: INTERNAL
description: |
  An internal artifact collecting client information. This is used to
  update the client info indexes. Client send this automatically at
  startup and then every day.

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/splunk.flows.upload.md
======
---
title: Splunk.Flows.Upload
hidden: true
tags: [Server Event Artifact]
---

This server side event monitoring artifact waits for new artifacts
to be collected from endpoints and automatically uploads those to a
Splunk server.
To configure the event collector properly a couple steps need to be
completed prior to setting up this event:
  1. Configure an index to ingest the data.
     * Go to Settings > Index.
     * New Index.
  2. Configure the collector.
     * Go to Settings > Data Inputs > HTTP Event Collector.
     * Add New.
     * Name does not matter, but ensure indexer acknowledgement is OFF.
     * Set `Selected Indexes` to the index configured in step 1.
     * Save API key for this event.
  3. Set Global settings.
     * Go to Settings > Data Inputs > HTTP Event Collector > Global Settings
     * Ensure `All Tokens` is set to ENABLED
     * Copy the HTTP Port Number for this event
  4. Configure your Splunk props.conf and tranforms.conf
     * Add the following to props.conf
      [vql]
      INDEXED_EXTRACTIONS = json
      DATETIME_CONFIG = CURRENT
      TZ = GMT
      category = Custom
      pulldown_type = 1
      TRANSFORMS-vql-sourcetype = vql-sourcetype,vql-timestamp
      TRUNCATE = 512000
     * Add the following to transforms.conf
      [vql-sourcetype]
      INGEST_EVAL = sourcetype=lower(src_artifact)
      [vql-timestamp]
      INGEST_EVAL = _time=case( \
                    src_artifact="artifact_Linux_Search_FileFinder",strptime(CTime,"%Y-%m-%dT%H:%M:%SZ"), \
                    src_artifact="artifact_System_VFS_ListDirectory",strptime(ctime,"%Y-%m-%dT%H:%M:%S.%NZ"), \
                    src_artifact="artifact_Windows_Timeline_MFT",strptime(event_time,"%Y-%m-%dT%H:%M:%S.%NZ"), \
                    src_artifact="artifact_Windows_NTFS_MFT",strptime(Created0x10,"%Y-%m-%dT%H:%M:%S.%NZ"), \
                    src_artifact="artifact_Windows_EventLogs_Evtx",strptime(TimeCreated,"%Y-%m-%dT%H:%M:%SZ"), \
                    src_artifact="artifact_Custom_Windows_EventLogs_System_7045",strptime(TimeCreated,"%Y-%m-%dT%H:%M:%SZ"), \
                    src_artifact="artifact_Windows_EventLogs_RDPAuth",strptime(EventTime,"%Y-%m-%dT%H:%M:%SZ"), \
                    src_artifact="artifact_Windows_Analysis_EvidenceOfExecution_UserAssist",strptime(LastExecution,"%Y-%m-%dT%H:%M:%SZ"), \
                    src_artifact="artifact_Windows_Analysis_EvidenceOfExecution_Amcache",strptime(KeyMTime,"%Y-%m-%dT%H:%M:%SZ"), \
                    src_artifact="artifact_Windows_System_Amcache_InventoryApplicationFile",strptime(LastModified,"%Y-%m-%dT%H:%M:%SZ"), \
                    src_artifact="artifact_Windows_Search_FileFinder",strptime(CTime,"%Y-%m-%dT%H:%M:%S.%NZ"), \
                    src_artifact="artifact_Windows_Applications_NirsoftBrowserViewer",strptime(Visited,"%Y-%m-%dT%H:%M:%SZ"), \
                    src_artifact="artifact_Windows_Registry_RecentDocs",strptime(LastWriteTime,"%Y-%m-%dT%H:%M:%SZ"), \
                    src_artifact="artifact_Windows_Forensics_UserAccessLogs_Clients",strptime(InsertDate,"%Y-%m-%dT%H:%M:%SZ"), \
                    src_artifact="artifact_Windows_Forensics_UserAccessLogs_DNS",strptime(LastSeen,"%Y-%m-%dT%H:%M:%SZ"), \
                    src_artifact="artifact_Windows_Forensics_UserAccessLogs_SystemIdentity",strptime(CreationTime,"%Y-%m-%dT%H:%M:%SZ"), \
                    src_artifact="artifact_Custom_Windows_Application_IIS_IISLogs",strptime(event_time,"%Y-%m-%dT%H:%M:%SZ"), \
                    src_artifact="artifact_MacOS_Applications_Chrome_History",strptime(last_visit_time,"%Y-%m-%dT%H:%M:%SZ"), \
                    src_artifact="artifact_Windows_Registry_UserAssist",strptime(LastExecution,"%Y-%m-%dT%H:%M:%SZ") \
                    )


     > Note: `Enable SSL` only works if SSL is properly configured on your
     Splunk server -- meaning you have proper certificates and DNS. If you are
     accessing your Splunk instance by IP, `Enable SSL` should be set to OFF.


<pre><code class="language-yaml">
name: Splunk.Flows.Upload

description: |
  This server side event monitoring artifact waits for new artifacts
  to be collected from endpoints and automatically uploads those to a
  Splunk server.
  To configure the event collector properly a couple steps need to be
  completed prior to setting up this event:
    1. Configure an index to ingest the data.
       * Go to Settings &gt; Index.
       * New Index.
    2. Configure the collector.
       * Go to Settings &gt; Data Inputs &gt; HTTP Event Collector.
       * Add New.
       * Name does not matter, but ensure indexer acknowledgement is OFF.
       * Set `Selected Indexes` to the index configured in step 1.
       * Save API key for this event.
    3. Set Global settings.
       * Go to Settings &gt; Data Inputs &gt; HTTP Event Collector &gt; Global Settings
       * Ensure `All Tokens` is set to ENABLED
       * Copy the HTTP Port Number for this event
    4. Configure your Splunk props.conf and tranforms.conf
       * Add the following to props.conf
        [vql]
        INDEXED_EXTRACTIONS = json
        DATETIME_CONFIG = CURRENT
        TZ = GMT
        category = Custom
        pulldown_type = 1
        TRANSFORMS-vql-sourcetype = vql-sourcetype,vql-timestamp
        TRUNCATE = 512000
       * Add the following to transforms.conf
        [vql-sourcetype]
        INGEST_EVAL = sourcetype=lower(src_artifact)
        [vql-timestamp]
        INGEST_EVAL = _time=case( \
                      src_artifact="artifact_Linux_Search_FileFinder",strptime(CTime,"%Y-%m-%dT%H:%M:%SZ"), \
                      src_artifact="artifact_System_VFS_ListDirectory",strptime(ctime,"%Y-%m-%dT%H:%M:%S.%NZ"), \
                      src_artifact="artifact_Windows_Timeline_MFT",strptime(event_time,"%Y-%m-%dT%H:%M:%S.%NZ"), \
                      src_artifact="artifact_Windows_NTFS_MFT",strptime(Created0x10,"%Y-%m-%dT%H:%M:%S.%NZ"), \
                      src_artifact="artifact_Windows_EventLogs_Evtx",strptime(TimeCreated,"%Y-%m-%dT%H:%M:%SZ"), \
                      src_artifact="artifact_Custom_Windows_EventLogs_System_7045",strptime(TimeCreated,"%Y-%m-%dT%H:%M:%SZ"), \
                      src_artifact="artifact_Windows_EventLogs_RDPAuth",strptime(EventTime,"%Y-%m-%dT%H:%M:%SZ"), \
                      src_artifact="artifact_Windows_Analysis_EvidenceOfExecution_UserAssist",strptime(LastExecution,"%Y-%m-%dT%H:%M:%SZ"), \
                      src_artifact="artifact_Windows_Analysis_EvidenceOfExecution_Amcache",strptime(KeyMTime,"%Y-%m-%dT%H:%M:%SZ"), \
                      src_artifact="artifact_Windows_System_Amcache_InventoryApplicationFile",strptime(LastModified,"%Y-%m-%dT%H:%M:%SZ"), \
                      src_artifact="artifact_Windows_Search_FileFinder",strptime(CTime,"%Y-%m-%dT%H:%M:%S.%NZ"), \
                      src_artifact="artifact_Windows_Applications_NirsoftBrowserViewer",strptime(Visited,"%Y-%m-%dT%H:%M:%SZ"), \
                      src_artifact="artifact_Windows_Registry_RecentDocs",strptime(LastWriteTime,"%Y-%m-%dT%H:%M:%SZ"), \
                      src_artifact="artifact_Windows_Forensics_UserAccessLogs_Clients",strptime(InsertDate,"%Y-%m-%dT%H:%M:%SZ"), \
                      src_artifact="artifact_Windows_Forensics_UserAccessLogs_DNS",strptime(LastSeen,"%Y-%m-%dT%H:%M:%SZ"), \
                      src_artifact="artifact_Windows_Forensics_UserAccessLogs_SystemIdentity",strptime(CreationTime,"%Y-%m-%dT%H:%M:%SZ"), \
                      src_artifact="artifact_Custom_Windows_Application_IIS_IISLogs",strptime(event_time,"%Y-%m-%dT%H:%M:%SZ"), \
                      src_artifact="artifact_MacOS_Applications_Chrome_History",strptime(last_visit_time,"%Y-%m-%dT%H:%M:%SZ"), \
                      src_artifact="artifact_Windows_Registry_UserAssist",strptime(LastExecution,"%Y-%m-%dT%H:%M:%SZ") \
                      )


       &gt; Note: `Enable SSL` only works if SSL is properly configured on your
       Splunk server -- meaning you have proper certificates and DNS. If you are
       accessing your Splunk instance by IP, `Enable SSL` should be set to OFF.
type: SERVER_EVENT

parameters:
   - name: ArtifactNameRegex
     default: "."
     type: regex
     description: Names of artifacts to upload to Splunk
   - name: url
     default: http://127.0.0.1:8088/services/collector
     description: |
      The Splunk collector url, this is typically the url of the Splunk
      server followed by :8088/services/collector.
   - name: token
     description: |
      API token given when the event collector is configured on Splunk.
   - name: index
     default: velociraptor
     description: |
      Index to ingest the data. This should be set up when configuring
      the event collector.
   - name: SkipVerify
     default: false
     type: bool
     description: |
      SSL configured with the event collector. This is false by default.
   - name: RootCerts
     description: |
       As a better alternative to skip_verify, allows root ca certs to
       be added here.

   - name: HostnameField
     description: Field to extract hostname from
     default: ClientId

   - name: TimestampField
     description: Field to extract timestamp from
     default: timestamp

sources:
  - query: |
        LET completions = SELECT * FROM watch_monitoring(
                     artifact="System.Flow.Completion")
                 WHERE Flow.artifacts_with_results =~ ArtifactNameRegex
                     AND log(message=Flow.artifacts_with_results)

        LET organization &lt;= org().name

        LET documents = SELECT * FROM foreach(row=completions,
                  query={
                     SELECT * FROM foreach(
                         row=Flow.artifacts_with_results,
                         query={
                             SELECT *, _value AS Artifact,
                                    timestamp(epoch=now()) AS timestamp,
                                    ClientId, Flow.session_id AS FlowId,
                                    "artifact_" + regex_replace(source=_value,
                                       re='[/.]', replace='_') as src_artifact,
                                       organization as org_name
                             FROM source(
                                client_id=ClientId,
                                flow_id=Flow.session_id,
                                artifact=_value)
                         })
                  })

        SELECT * FROM splunk_upload(
        query = documents,
        url = url,
        token = token,
        index = index,
        skip_verify = SkipVerify,
        root_ca = RootCerts,
        hostname_field=HostnameField,
        timestamp_field=TimestampField
        )

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/server.utils.adduser.md
======
---
title: Server.Utils.AddUser
hidden: true
tags: [Server Artifact]
---

This server artifact is used to add new user to the Velociraptor
GUI.

A new random password is generated for the user and stored in the
server metadata object (to ensure it can not be seen in the output
of the artifact itself). The Administrator can share this password
with the user later.

When using SSO (e.g. oauth) this password is not used and can be
ignored (Becuase the SSO provider will do the authentication).


<pre><code class="language-yaml">
name: Server.Utils.AddUser
description: |
  This server artifact is used to add new user to the Velociraptor
  GUI.

  A new random password is generated for the user and stored in the
  server metadata object (to ensure it can not be seen in the output
  of the artifact itself). The Administrator can share this password
  with the user later.

  When using SSO (e.g. oauth) this password is not used and can be
  ignored (Becuase the SSO provider will do the authentication).

type: SERVER

parameters:
  - name: UserName
    description: The new username to add

  - name: ResetPassword
    type: bool
    default: "Y"
    description: |
      Reset the user's password. This must be set when
      creating the user in the first place.

  - name: Role
    description: The role to grant the new user.
    type: choices
    default: reader
    choices:
      - reader
      - analyst
      - investigator
      - administrator

sources:
  - query: |
      LET Password &lt;= format(format="%02x", args=rand(range=0xffffffffffff))
      LET ServerMetadataKey &lt;= "User Password " + UserName

      LET DoIt = SELECT * FROM if(condition=ResetPassword,
      then={
        SELECT
          server_set_metadata(metadata=set(
             item=server_metadata(),
             field=ServerMetadataKey, value=Password)),
          user_create(roles=Role, user=UserName, password=Password)
        FROM scope()
        WHERE log(message="New password for user is stored in server metadata under key " + ServerMetadataKey)
      }, else={
        -- Just grant the user the specified role
        SELECT user_create(roles=Role, user=UserName)
        FROM scope()
      })

      SELECT * FROM if(condition=UserName,
      then={
        SELECT * FROM foreach(row=DoIt,
        query={
           SELECT * FROM gui_users()
           WHERE name =~ UserName
        })
      }, else={
        SELECT * FROM scope()
        WHERE log(message="A Username must be set") AND FALSE
      })

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/linux.applications.chrome.extensions.upload.md
======
---
title: Linux.Applications.Chrome.Extensions.Upload
hidden: true
tags: [Client Artifact]
---

Upload all users chrome extension.

We dont bother actually parsing anything here, we just grab all the
extension files in user's home directory.


<pre><code class="language-yaml">
name: Linux.Applications.Chrome.Extensions.Upload
description: |
  Upload all users chrome extension.

  We dont bother actually parsing anything here, we just grab all the
  extension files in user's home directory.

parameters:
  - name: extensionGlobs
    default: /.config/google-chrome/*/Extensions/**
sources:
  - precondition: |
      SELECT OS From info() where OS = 'linux'
    query: |
        -- For each user on the system, search for extension files
        -- in their home directory and upload them.
        SELECT * from foreach(
          row={
             SELECT Uid, User, Homedir from Artifact.Linux.Sys.Users()
          },
          query={
             SELECT OSPath, Mtime, Ctime, User, Uid,
                    upload(file=OSPath) as Upload
             FROM glob(globs=extensionGlobs, root=Homedir)
          })

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/linux.proc.modules.md
======
---
title: Linux.Proc.Modules
hidden: true
tags: [Client Artifact]
---

Module listing via /proc/modules.

<pre><code class="language-yaml">
name: Linux.Proc.Modules
description: Module listing via /proc/modules.
parameters:
  - name: ProcModules
    default: /proc/modules

sources:
  - precondition: |
      SELECT OS From info() where OS = 'linux'

    query: |
        SELECT Name,
          atoi(string=Size) As Size,
          atoi(string=UseCount) As UseCount,
          parse_string_with_regex(regex='''(?P&lt;UsedBy&gt;.*),''', string=UsedBy).UsedBy AS UsedBy,
          Status, 
          Address
        FROM split_records(
           filenames=ProcModules,
           regex='\\s+',
           columns=['Name', 'Size', 'UseCount', 'UsedBy', 'Status', 'Address'])

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.eventlogs.rdpauth.md
======
---
title: Windows.EventLogs.RDPAuth
hidden: true
tags: [Client Artifact]
---

This artifact will extract Event Logs related to Remote Desktop sessions,
logon and logoff.

Security channel - EventID in 4624,4634 AND LogonType 3, 7, or 10.
Security channel - EventID in 4778,4625,4779, or 4647.
System channel -  EventID 9009.
Microsoft-Windows-TerminalServices-RemoteConnectionManager/Operational - EventID 1149.
Microsoft-Windows-TerminalServices-LocalSessionManager/Operational - EventID 23,22,21,24,25,39, or 40.

Best use of this artifact is to collect RDP and Authentication events around
a timeframe of interest and order by EventTime to scope RDP activity.


<pre><code class="language-yaml">
name: Windows.EventLogs.RDPAuth
author: "Matt Green - @mgreen27"
description: |
    This artifact will extract Event Logs related to Remote Desktop sessions,
    logon and logoff.

    Security channel - EventID in 4624,4634 AND LogonType 3, 7, or 10.
    Security channel - EventID in 4778,4625,4779, or 4647.
    System channel -  EventID 9009.
    Microsoft-Windows-TerminalServices-RemoteConnectionManager/Operational - EventID 1149.
    Microsoft-Windows-TerminalServices-LocalSessionManager/Operational - EventID 23,22,21,24,25,39, or 40.

    Best use of this artifact is to collect RDP and Authentication events around
    a timeframe of interest and order by EventTime to scope RDP activity.

reference:
  - https://ponderthebits.com/2018/02/windows-rdp-related-event-logs-identification-tracking-and-investigation/

precondition: SELECT OS From info() where OS = 'windows'

parameters:
  - name: Security
    description: path to Security event log.
    default: '%SystemRoot%\System32\Winevt\Logs\Security.evtx'
  - name: System
    description: path to System event log.
    default: '%SystemRoot%\System32\Winevt\Logs\System.evtx'
  - name: LocalSessionManager
    description: path to TerminalServices-LocalSessionManager operational event log.
    default: '%SystemRoot%\System32\Winevt\Logs\Microsoft-Windows-TerminalServices-LocalSessionManager%4Operational.evtx'
  - name: RemoteConnectionManager
    description: path to TerminalServices-RemoteConnectionManager operational event log.
    default: '%SystemRoot%\System32\Winevt\Logs\Microsoft-Windows-TerminalServices-RemoteConnectionManager%4Operational.evtx'
  - name: DateAfter
    description: "search for events after this date. YYYY-MM-DDTmm:hh:ss Z"
    type: timestamp
  - name: DateBefore
    description: "search for events before this date. YYYY-MM-DDTmm:hh:ss Z"
    type: timestamp
  - name: SourceIPRegex
    default: ".+"
    type: regex
  - name: UserNameRegex
    default: ".+"
    type: regex
  - name: UserNameWhitelist
    default: '\$$'
    type: regex
  - name: VSSAnalysisAge
    type: int
    default: 0
    description: |
      If larger than zero we analyze VSS within this many days
      ago. (e.g 7 will analyze all VSS within the last week).  Note
      that when using VSS analysis we have to use the ntfs accessor
      for everything which will be much slower.

sources:
  - query: |
      LET VSS_MAX_AGE_DAYS &lt;= VSSAnalysisAge
      LET Accessor = if(condition=VSSAnalysisAge &gt; 0, then="ntfs_vss", else="auto")

      -- firstly set timebounds for performance
      LET DateAfterTime &lt;= if(condition=DateAfter,
        then=DateAfter, else=timestamp(epoch="1600-01-01"))
      LET DateBeforeTime &lt;= if(condition=DateBefore,
        then=DateBefore, else=timestamp(epoch="2200-01-01"))

      -- expand provided glob into a list of paths on the file system (fs)
      LET fspaths &lt;= SELECT OSPath
        FROM glob(globs=[
            expand(path=Security),
            expand(path=System),
            expand(path=LocalSessionManager),
            expand(path=RemoteConnectionManager)], accessor=Accessor)

      -- function returning query hits
      LET evtxsearch(PathList) = SELECT * FROM foreach(
            row=PathList,
            query={
                SELECT
                    timestamp(epoch=int(int=System.TimeCreated.SystemTime)) AS EventTime,
                    System.Computer as Computer,
                    System.Channel as Channel,
                    System.EventID.Value as EventID,
                    if(condition= System.Channel='Security',
                        then= EventData.TargetDomainName,
                        else= if(condition= UserData.EventXML.User,
                            then= split(string=UserData.EventXML.User,sep='\\\\')[0],
                            else= if(condition= UserData.EventXML.Param2,
                                then= UserData.EventXML.Param2,
                                else= 'null' ))) as DomainName,
                    if(condition= System.Channel='Security',
                        then= EventData.TargetUserName,
                        else= if(condition= UserData.EventXML.User,
                            then= split(string=UserData.EventXML.User,sep='\\\\')[1],
                            else= if(condition= UserData.EventXML.Param1,
                                then= UserData.EventXML.Param1,
                                else= 'null' ))) as UserName,
                    if(condition= System.Channel='Security',
                        then= if(condition= EventData.LogonType,
                            then= EventData.LogonType,
                            else= 'null' ),
                        else= 'null' ) as LogonType,
                    if(condition= System.Channel='Security',
                        then= if(condition= EventData.IpAddress,
                            then= EventData.IpAddress,
                            else= 'null' ),
                        else= if(condition= System.Channel=~'TerminalServices',
                            then= if(condition= UserData.EventXML.Address,
                                then= UserData.EventXML.Address,
                                else= if(condition= UserData.EventXML.Param3,
                                    then= UserData.EventXML.Param3,
                                    else= 'null')),
                            else= 'null' )) as SourceIP,
                    if(condition= System.Channel=~'TerminalServices|System',
                        then=
                            get(item=dict(
                                `21`='RDP_LOCAL_CONNECTED',
                                `22`='RDP_REMOTE_CONNECTED',
                                `23`='RDP_SESSION_LOGOFF',
                                `24`='RDP_LOCAL_DISCONNECTED',
                                `25`='RDP_REMOTE_RECONNECTION',
                                `39`='RDP_REMOTE_DISCONNECTED_FORMAL',
                                `40`='RDP_REMOTE_DISCONNECTED_REASON',
                                `1149`='RDP_INITIATION_SUCCESSFUL',
                                `9009`='DESKTOPWINDOWMANAGER_CLOSED'),
                                    member=str(str=System.EventID.Value)),
                        else=if(condition= System.EventID.Value = 4624 AND EventData.LogonType = 10,
                            then='RDP_LOGON_SUCCESSFUL_NEW',
                        else=if(condition= System.EventID.Value = 4624 AND EventData.LogonType = 3,
                            then='LOGON_SUCCESSFUL',
                        else=if(condition= System.EventID.Value = 4624 AND EventData.LogonType = 7,
                            then='LOGON_SUCCESSFUL_OLD',
                        else=if(condition= System.EventID.Value = 4625 AND EventData.LogonType = 3,
                            then='LOGON_FAILED',
                        else=if(condition= System.EventID.Value = 4625 AND EventData.LogonType = 10,
                            then='RDP_LOGON_FAILED',
                        else=
                            get(item=dict(
                                `4778`='LOGON_RECONNECT_EXISTING',
                                `4779`='SESSION_DISCONNECT',
                                `4647`='USER_INITIATED_LOGOFF',
                                `4634`='LOGOFF_DISCONNECT'),
                                    member=str(str=System.EventID.Value)
                        ))))))) as Description,
                    get(field="Message") as Message,
                    System.EventRecordID as EventRecordID,
                    OSPath
                FROM parse_evtx(filename=OSPath, accessor=Accessor)
                WHERE
                    ( Channel = 'Security'
                        AND ( (EventID in (4624,4634) AND LogonType in (3,10,7))
                            OR EventID in (4778,4625,4779,4647)))
                    OR ( Channel = 'System' AND EventID = 9009 )
                    OR ( Channel = 'Microsoft-Windows-TerminalServices-RemoteConnectionManager/Operational'
                        AND EventID = 1149 )
                    OR ( Channel = 'Microsoft-Windows-TerminalServices-LocalSessionManager/Operational'
                        AND EventID in (23,22,21,24,25,39,40))
                    AND EventTime &lt; DateBeforeTime
                    AND EventTime &gt; DateAfterTime
                    AND if(condition= UserNameWhitelist,
                        then= NOT UserName =~ UserNameWhitelist,
                        else= True)
                    AND UserName =~ UserNameRegex
                    AND SourceIP =~ SourceIPRegex
            }
          )

      SELECT * FROM if(condition=VSSAnalysisAge &gt; 0,
      then={
        SELECT * FROM evtxsearch(PathList=fspaths)
        GROUP BY EventRecordID, Channel
      }, else={
        SELECT * FROM evtxsearch(PathList=fspaths)
      })

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/server.internal.timelineadd.md
======
---
title: Server.Internal.TimelineAdd
hidden: true
tags: [Server Event Artifact]
---

This artifact will fire whenever a timeline is added to a super
timeline. You can use this to monitor for users adding timelines and
forward them to an external timeline system (e.g. TimeSketch)


<pre><code class="language-yaml">
name: Server.Internal.TimelineAdd
type: SERVER_EVENT
description: |
  This artifact will fire whenever a timeline is added to a super
  timeline. You can use this to monitor for users adding timelines and
  forward them to an external timeline system (e.g. TimeSketch)

column_types:
  - name: NotebookId
  - name: SuperTimelineName
  - name: Timeline

  # What type of event this is: can be Delete, AddTimeline
  - name: Action

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.memory.acquisition.md
======
---
title: Windows.Memory.Acquisition
hidden: true
tags: [Client Artifact]
---

Acquires a full memory image using the built in WinPmem driver.

NOTE: This artifact usually transfers a lot of data. You should
increase the default timeout to allow it to complete.

Memory images are typically susceptible to a lot of smear. To
minimize this we need to acquire memory as quickly as possible. This
artifact offers a few compression methods for the output
file. Reducing the size of the file will decrease time needed for IO
but will increase CPU requirements so this is a
tradeoff. Empirically we found that using S2 compression gives a
reasonable compression and very high speed reducing acquisition time
from the no compression options significantly.

To decompress the image you can use the [Go Winpmem binary](https://github.com/Velocidex/WinPmem/releases/download/v4.0.rc1/go-winpmem_amd64_1.0-rc1.exe)

```
go-winpmem.exe expand image.compressed image.raw
```


<pre><code class="language-yaml">
name: Windows.Memory.Acquisition
description: |
  Acquires a full memory image using the built in WinPmem driver.

  NOTE: This artifact usually transfers a lot of data. You should
  increase the default timeout to allow it to complete.

  Memory images are typically susceptible to a lot of smear. To
  minimize this we need to acquire memory as quickly as possible. This
  artifact offers a few compression methods for the output
  file. Reducing the size of the file will decrease time needed for IO
  but will increase CPU requirements so this is a
  tradeoff. Empirically we found that using S2 compression gives a
  reasonable compression and very high speed reducing acquisition time
  from the no compression options significantly.

  To decompress the image you can use the [Go Winpmem binary](https://github.com/Velocidex/WinPmem/releases/download/v4.0.rc1/go-winpmem_amd64_1.0-rc1.exe)

  ```
  go-winpmem.exe expand image.compressed image.raw
  ```

precondition: |
  SELECT OS FROM info()
  WHERE OS = 'windows'
    AND Architecture = "amd64"
    AND version(function='winpmem') &gt;= 0

parameters:
  - name: ServiceName
    description: Override the name of the driver service to install.
  - name: Compression
    default: None
    type: choices
    description: Type of compression to use (Recommended None, S2 or Snappy).
    choices:
      - None
      - S2
      - Snappy
      - Gzip

sources:
  - query: |
      LET Tempfile &lt;= tempfile(extension=".pmem")

      LET ImageInfo &lt;= winpmem(
         service=ServiceName,
         image_path=Tempfile,
         compression=Compression)

      SELECT ImageInfo, upload(file=Tempfile, name="PhysicalMemory.dd") AS Upload
      FROM stat(filename=Tempfile)
      WHERE log(message="Uploading %v bytes", args=Size)

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/triage.collection.uploadtable.md
======
---
title: Triage.Collection.UploadTable
hidden: true
tags: [Client Artifact]
---

A Generic uploader used by triaging artifacts. This is similar to
`Triage.Collection.Upload` but uses a CSV table to drive it.


<pre><code class="language-yaml">
name: Triage.Collection.UploadTable
description: |
  A Generic uploader used by triaging artifacts. This is similar to
  `Triage.Collection.Upload` but uses a CSV table to drive it.

parameters:
  - name: triageTable
    description: "A CSV table controlling upload. Must have the headers: Type, Accessor, Glob."
    type: csv
    default: |
      Type,Accessor,Glob

sources:
  - query: |
        LET results = SELECT OSPath, Size,
               Mtime As Modifed,
               Type,
               upload(file=OSPath,
                      mtime=Mtime,
                      ctime=Ctime,
                      accessor=Accessor) AS FileDetails
        FROM glob(globs=split(string=Glob, sep=","), accessor=Accessor)
        WHERE NOT IsDir

        SELECT * FROM foreach(
         row=triageTable,
         query={
           SELECT OSPath, Size, Modifed, Type,
               FileDetails.Path AS ZipPath,
               FileDetails.Md5 as Md5,
               FileDetails.Sha256 as SHA256
          FROM results
        })

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/generic.client.locallogsretrieve.md
======
---
title: Generic.Client.LocalLogsRetrieve
hidden: true
tags: [Client Artifact]
---

Retrives the locally written logs.


<pre><code class="language-yaml">
name: Generic.Client.LocalLogsRetrieve
description: |
  Retrives the locally written logs.

type: CLIENT

parameters:
- name: LocalFilename
  default: "%TEMP%/locallogs.log"
  description: The local filename that will be retrieved (Env variables will be expanded).

sources:
- query: |
    SELECT upload(file=expand(path=LocalFilename)) AS Upload
    FROM scope()
  notebook:
    - type: vql
      name: Decrypt logs
      template: |
        /*
        # Retrieved local logs from endpoint
        */

        SELECT * FROM foreach(row={
           SELECT * FROM uploads(client_id=ClientId, flow_id=FlowId)
        }, query={
           SELECT * FROM read_crypto_file(filename=vfs_path, accessor="fs")
        })

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/linux.utils.installdeb.md
======
---
title: Linux.Utils.InstallDeb
hidden: true
tags: [Client Artifact]
---

Install a deb package and configure it with debconf answers. The package
may either be specified by name, as an uploaded file or as a "tool". If the
package already exists, it may be optionally reconfigured with debconf
answers.

There are three ways to specify a package (listed in order of preference if
all are set):

  - DebFile: An uploaded deb package.

  - DebTool: A deb package provided as a tool, specified by tool name. Since
    this is a utility artifact meant to be called by other artifacts, the
    tool should be specified in the artifact calling this artifact.
    Alternatively, configure the tool using
    [VQL](https://docs.velociraptor.app/vql_reference/server/inventory_add/).

  - DebName: The name of the package to install, or an absolute path to a deb
    file to install. Each word is considered as a package name or file name.
    `apt-get` interprets the package name, and allows you to specify a
    specific version, architecture, or even install and remove packages in
    the same go:

    - "foo": installs foo
    - "foo bar- baz=1.0.0-1 qux:arm64": installs foo, removes bar, installs
      a specific version of baz and a specific architecture of qux


<pre><code class="language-yaml">
name: Linux.Utils.InstallDeb
author: Andreas Misje – @misje
description: |
   Install a deb package and configure it with debconf answers. The package
   may either be specified by name, as an uploaded file or as a "tool". If the
   package already exists, it may be optionally reconfigured with debconf
   answers.

   There are three ways to specify a package (listed in order of preference if
   all are set):

     - DebFile: An uploaded deb package.

     - DebTool: A deb package provided as a tool, specified by tool name. Since
       this is a utility artifact meant to be called by other artifacts, the
       tool should be specified in the artifact calling this artifact.
       Alternatively, configure the tool using
       [VQL](https://docs.velociraptor.app/vql_reference/server/inventory_add/).

     - DebName: The name of the package to install, or an absolute path to a deb
       file to install. Each word is considered as a package name or file name.
       `apt-get` interprets the package name, and allows you to specify a
       specific version, architecture, or even install and remove packages in
       the same go:

       - "foo": installs foo
       - "foo bar- baz=1.0.0-1 qux:arm64": installs foo, removes bar, installs
         a specific version of baz and a specific architecture of qux

type: CLIENT

required_permissions:
   - EXECVE

reference:
   - https://manpages.debian.org/bookworm/debconf-doc/debconf-devel.7.en.html#Type

parameters:
   - name: DebName
     description: |
        Package to install (by name). Ignored if DebFile or DebTool is set. An
        absolute path to a deb file that already exists on the system is also
        accepted.

   - name: DebFile
     description: |
        Package to install (by file). Remember to click "Upload"! When set,
        DebName and DebTool is ignored. Use DebName with an absolute file path
        if the file already exists on the system and does not need to be
        uploaded.
     type: upload_file

   - name: DebTool
     description: |
        Package to install as a tool (tool name). The tool must be configured
        manually by using VQL or in another artifact (calling this artifact).
        Ignored if DebFile is set.

   - name: ToolSleepDuration
     description: |
        Maximum number of seconds to sleep before downloading the package. Only
        relevant if DebTool is set.
     type: int
     default: 20

   - name: UpdateSources
     description: |
        Run `apt-get update` before installing the package. This is not necessary
        if the package has no dependencies, and it should be disabled if there
        is no Internet.
     type: bool
     default: True

   - name: ForceConfNew
     type: bool
     description: |
        Use the configuration delivered by the package instead of keeping the
        local changes.

   - name: Reinstall
     type: bool
     description: |
        Reinstall the package if it is already installed. This is only useful
        if you know or suspect that the package installation is broken. This
        also reconfigures the package.

   - name: UpgradeOnly
     type: bool
     description: |
        Do not install the package; only upgrade it if it is already installed.

   - name: ReconfigureIfInstalled
     type: bool
     description: |
        If the package is already installed, run pre-seed debconf and
        `dpkg-reconfigure` instead.

   - name: DebConfValues
     type: csv
     description: |
        debconf is a system used by many packages for interactive configuration.
        When using a non-interactive frontend (like this artifact), answers may
        by provided as a "pre-seed" file. Example line:

        "wireshark-common/install-setuid,boolean,false"
     default: |
        Key,Type,Value

column_types:
  - name: Stdout
    type: nobreak

  - name: Stderr
    type: nobreak

sources:
  - precondition:
      SELECT OS From info() where OS = 'linux'

    query: |
       LET Tool = SELECT OSPath
         FROM Artifact.Generic.Utils.FetchBinary(ToolName=DebTool,
                                                 TemporaryOnly=true,
                                                 SleepDuration=ToolSleepDuration)
       LET Package &lt;= if(
           condition=DebTool,
           then=Tool[0].OSPath,
           else=if(
             condition=DebFile,
             /* apt requires file names to end in an architecture name, so
                create a copy ending in "_amd64.deb". The architecture chosen
                here, amd64, does not need to match the architecture of neither
                the package or the system:
             */
             then=copy(dest=tempdir() + '/package_amd64.deb',
                       filename=DebFile),
                       else=DebName))

       /* The file name is lost from the uploaded file, so extract it from the
          package instead (apt has certain requirements for the file name):
       */
       LET PackageInfo = SELECT Stdout
         FROM execve(argv=['/usr/bin/dpkg-deb', '--field', Package, 'Package'])

       LET PackageName = if(condition=DebTool OR DebFile,
                            // remove "\n":
                            then=PackageInfo[0].Stdout[:-1], else=DebName)

       /* The file format is "package_name question type answer": */
       LET PreSeedLines = SELECT join(sep=' ',
           array=(PackageName, Key, Type, Value)) AS Line
         FROM DebConfValues

       LET PreSeedFile &lt;= tempfile(data=join(sep='\n', array=PreSeedLines.Line))

       LET AptEnv = dict(
           DEBIAN_FRONTEND='noninteractive',
           DEBCONF_NOWARNINGS='yes')

       LET AptOpts &lt;= ('-f', '-y', '-o', 'Debug::pkgProblemResolver=yes',
                       '--no-install-recommends') +
           if(condition=ForceConfNew,
              then=('-o', 'Dpkg::Options::=--force-confnew'), else=[]) +
           if(condition=Reinstall, then=('--reinstall', ), else=[]) +
           if(condition=UpgradeOnly, then=('--only-upgrade', ), else=[])

       LET PreSeed = SELECT 'Pre-seed debconf' AS Step, *
         FROM if(condition=DebConfValues, then={
             SELECT *
             FROM execve(argv=['/usr/bin/debconf-set-selections', PreSeedFile, ])
             WHERE log(message='Pre-seeding %v', dedup= -1,
                       args=PackageName,
                       level='INFO')
              AND (NOT ReturnCode OR log(level='ERROR',
                      message='%v failed: %v', args=(Step, Stderr)))
           })

       /* Install regardless of whether package is installed or not, handing all
          the (arch-specific) version comparison logic to apt:
        */
       LET Install &lt;= SELECT * FROM chain(
           a_update={
             SELECT 'Updating index' AS Step, *
             FROM if(condition=UpdateSources, then={
                 SELECT *
                 FROM execve(argv=['/usr/bin/apt-get', '-y', 'update'])
                 WHERE log(message='Updating package index before installing',
                           level='INFO')
               })
           },
           b_debconf=PreSeed,
           c_install={
             SELECT 'Installing package' AS Step, *
             FROM execve(
               argv=('/usr/bin/apt-get', ) + AptOpts +
               if(condition=Package = DebName,
                  then=('install', ) + split(sep='''\s+''', string=Package),
                  else=('install', Package)),
               env=AptEnv)
             WHERE log(message='Installing deb package %v',
                       args=PackageName,
                       dedup= -1,
                       level='INFO')
           })
         WHERE NOT ReturnCode OR log(level='ERROR',
                                     message='%v failed: %v',
                                     args=(Step, Stderr))

       SELECT * FROM chain(
         a_install=Install,
         b_reconfigure={
           SELECT * FROM if(
             condition=ReconfigureIfInstalled AND (
                Reinstall OR Install.Stdout =~ 'Skipping|already the newest version'),
             then={
               SELECT 'Reconfiguring package' AS Step, *
               FROM execve(argv=['/usr/sbin/dpkg-reconfigure', PackageName, ],
                           env=AptEnv)
               WHERE log(message='Reconfiguring deb package %v',
                         args=PackageName,
                         dedup= -1,
                         level='INFO')
                AND (NOT ReturnCode OR log(level='ERROR',
                                       message='%v failed: %v',
                                       args=(Step, Stderr)))
             })
         })

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/linux.suse.packages.md
======
---
title: Linux.SuSE.Packages
hidden: true
tags: [Client Artifact]
---

Parse list of installed packages from zypper output


<pre><code class="language-yaml">
name: Linux.SuSE.Packages
author: Hilko Bengen &lt;bengen@hilluzination.de&gt;
description: |
  Parse list of installed packages from zypper output

sources:
  - precondition: |
      SELECT OS From info() WHERE OS = 'linux'

    query: |
      LET zypper_output = SELECT *
        FROM execve(
          length=1000000,
          argv=["zypper", "--xmlout", "search", "--installed-only", "--details", "--type=package"])
      
      LET xml = parse_xml(
          file=str(str=zypper_output.Stdout),
          accessor="data")
      
      SELECT *
      FROM foreach(
        row=xml.stream.`search-result`.`solvable-list`.solvable,
        query={
          SELECT Attrname AS Package,
                 Attredition AS Version,
                 Attrarch AS Architecture,
                 Attrrepository AS Repository
          FROM _value
        })

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/macos.system.timemachine.md
======
---
title: MacOS.System.TimeMachine
hidden: true
tags: [Client Artifact]
---

This artifact collects information about MacOS Time Machine backups.


<pre><code class="language-yaml">
name: MacOS.System.TimeMachine
description: |
  This artifact collects information about MacOS Time Machine backups.

type: CLIENT

author: Wes Lambert - @therealwlambert

parameters:
  - name: TimeMachineGlob
    default: /Library/Preferences/com.apple.TimeMachine.plist

sources:
  - query: |
      LET TMPlist = SELECT OSPath FROM glob(globs=TimeMachineGlob)
      LET TMDetails =
            SELECT * FROM foreach(
                row=plist(file=OSPath),
                query={ SELECT
                    plist(file=OSPath).LocalizedDiskImageVolumeName AS VolumeName,
                    plist(file=OSPath).AutoBackup AS AutoBackup,
                    plist(file=OSPath).LastDestinationID AS LastDestination,
                    plist(file=OSPath).HostUUIDs[0] AS HostUUID,
                    plist(file=OSPath).Destinations AS Destinations
                    FROM scope()
                }
            )
      SELECT * FROM foreach(row=TMPlist, query=TMDetails)

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/macos.search.filefinder.md
======
---
title: MacOS.Search.FileFinder
hidden: true
tags: [Client Artifact]
---

Find files on the filesystem using the filename or content.


## Performance Note

This artifact can be quite expensive, especially if we search file
content. It will require opening each file and reading its entire
content. To minimize the impact on the endpoint we recommend this
artifact is collected with a rate limited way (about 20-50 ops per
second).

This artifact is useful in the following scenarios:

  * We need to locate all the places on our network where customer
    data has been copied.

  * We’ve identified malware in a data breach, named using short
    random strings in specific folders and need to search for other
    instances across the network.

  * We believe our user account credentials have been dumped and
    need to locate them.

  * We need to search for exposed credit card data to satisfy PCI
    requirements.

  * We have a sample of data that has been disclosed and need to
    locate other similar files


<pre><code class="language-yaml">
name: MacOS.Search.FileFinder
description: |
  Find files on the filesystem using the filename or content.


  ## Performance Note

  This artifact can be quite expensive, especially if we search file
  content. It will require opening each file and reading its entire
  content. To minimize the impact on the endpoint we recommend this
  artifact is collected with a rate limited way (about 20-50 ops per
  second).

  This artifact is useful in the following scenarios:

    * We need to locate all the places on our network where customer
      data has been copied.

    * We’ve identified malware in a data breach, named using short
      random strings in specific folders and need to search for other
      instances across the network.

    * We believe our user account credentials have been dumped and
      need to locate them.

    * We need to search for exposed credit card data to satisfy PCI
      requirements.

    * We have a sample of data that has been disclosed and need to
      locate other similar files


precondition:
  SELECT * FROM info() where OS = 'darwin'

parameters:
  - name: SearchFilesGlob
    default: /Users/*
    description: Use a glob to define the files that will be searched (Use ** for recursive).

  - name: SearchFilesGlobTable
    type: csv
    default: |
      Glob
      /Users/someuser/*
    description: Alternative specify multiple globs in a table

  - name: YaraRule
    type: yara
    default:
    description: A yara rule to search for matching files.

  - name: Upload_File
    default: N
    type: bool

  - name: Calculate_Hash
    default: N
    type: bool

  - name: MoreRecentThan
    default: ""
    type: timestamp

  - name: ModifiedBefore
    default: ""
    type: timestamp

  - name: DoNotFollowSymlinks
    type: bool
    default: Y
    description: If specified we are allowed to follow symlinks while globbing

sources:
- query: |
    LET file_search = SELECT OSPath,
               Sys.mft as Inode,
               Mode.String AS Mode, Size,
               Mtime AS MTime,
               Atime AS ATime,
               Ctime AS CTime,
               Btime AS BTime,
               IsDir, Mode
        FROM glob(globs=SearchFilesGlobTable.Glob + SearchFilesGlob,
                  accessor="file", nosymlink=DoNotFollowSymlinks)

    LET more_recent = SELECT * FROM if(
        condition=MoreRecentThan,
        then={
          SELECT * FROM file_search
          WHERE MTime &gt; MoreRecentThan
        },
        else={ SELECT * FROM file_search})

    LET modified_before = SELECT * FROM if(
        condition=ModifiedBefore,
        then={
          SELECT * FROM more_recent
          WHERE MTime &lt; ModifiedBefore
           AND  MTime &gt; MoreRecentThan
        },
        else={SELECT * FROM more_recent})

    LET keyword_search = SELECT * FROM if(
        condition=YaraRule,
        then={
          SELECT * FROM foreach(
            row={
               SELECT * FROM modified_before
               WHERE Mode.IsRegular
            },
            query={
               SELECT OSPath, Inode, Mode,
                      Size, ATime, MTime, CTime, BTime,
                      str(str=String.Data) As Keywords

               FROM yara(files=OSPath,
                         key="A",
                         rules=YaraRule,
                         accessor="file")
            })
        },
        else={SELECT * FROM modified_before})

    SELECT OSPath, Inode, Mode, Size, ATime,
             MTime, CTime, BTime, get(field='Keywords') AS Keywords,
               if(condition=Upload_File and Mode.IsRegular,
                  then=upload(file=OSPath,
                              accessor="file")) AS Upload,
               if(condition=Calculate_Hash and Mode.IsRegular,
                  then=hash(path=OSPath,
                            accessor="file")) AS Hash
    FROM keyword_search

column_types:
  - name: ATime
    type: timestamp
  - name: MTime
    type: timestamp
  - name: CTime
    type: timestamp
  - name: BTime
    type: timestamp
  - name: Upload
    type: preview_upload

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/server.import.artifactexchange.md
======
---
title: Server.Import.ArtifactExchange
hidden: true
tags: [Server Artifact]
---

This artifact will automatically import the latest artifact
exchange bundle into the current server.

## Security note

The artifact exchange is not officially supported by the
Velociraptor team and contains contributions from the
community. The quality, security and stability of artifacts from
the exchange is not guaranteed. Some artifacts from the exchange
will fetch external binaries and run them on your endpoints! These
binaries are not reviewed or endorsed by the Velociraptor team or
Rapid7!

Contributions to the exchange must meet a lower quality bar than
built in artifacts (for example lacking tests), which means that
they may break at any time or not work as described!

Collecting any of the artifacts in the exchange is purely at your
own risk!.

We strongly suggest users review exchange artifacts carefully
before deploying them on their network!


<pre><code class="language-yaml">
name: Server.Import.ArtifactExchange
description: |
   This artifact will automatically import the latest artifact
   exchange bundle into the current server.

   ## Security note

   The artifact exchange is not officially supported by the
   Velociraptor team and contains contributions from the
   community. The quality, security and stability of artifacts from
   the exchange is not guaranteed. Some artifacts from the exchange
   will fetch external binaries and run them on your endpoints! These
   binaries are not reviewed or endorsed by the Velociraptor team or
   Rapid7!

   Contributions to the exchange must meet a lower quality bar than
   built in artifacts (for example lacking tests), which means that
   they may break at any time or not work as described!

   Collecting any of the artifacts in the exchange is purely at your
   own risk!.

   We strongly suggest users review exchange artifacts carefully
   before deploying them on their network!

type: SERVER

required_permissions:
- SERVER_ADMIN

parameters:
   - name: ExchangeURL
     default: https://github.com/Velocidex/velociraptor-docs/raw/gh-pages/exchange/artifact_exchange_v2.zip
   - name: Prefix
     description: Add artifacts with this prefix
     default: Exchange.
   - name: ArchiveGlob
     default: "/**/*.{yaml,yml}"

sources:
  - query: |
        LET X = SELECT artifact_set(prefix=Prefix, definition=Definition) AS Definition
        FROM foreach(row={
          SELECT Content FROM http_client(
             remove_last=TRUE,
             tempfile_extension=".zip", url=ExchangeURL)
        }, query={
          SELECT read_file(accessor="zip", filename=OSPath) AS Definition
          FROM glob(
             globs=ArchiveGlob,
             root=pathspec(
                DelegateAccessor="auto",
                DelegatePath=Content),
             accessor="zip")
        })

        SELECT Definition.name AS Name,
               Definition.description AS Description,
               Definition.author AS Author
        FROM X

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/generic.collectors.file.md
======
---
title: Generic.Collectors.File
hidden: true
tags: [Client Artifact]
---

Collects files using a set of globs. All globs must be on the same
device. The globs will be searched in one pass - so you can provide
many globs at the same time.


<pre><code class="language-yaml">
name: Generic.Collectors.File
description: |
   Collects files using a set of globs. All globs must be on the same
   device. The globs will be searched in one pass - so you can provide
   many globs at the same time.

aliases:
  - Windows.Collectors.File

parameters:
  - name: collectionSpec
    description: |
       A CSV file with a Glob column with all the globs to collect.
       NOTE: Globs must not have a leading device.
    type: csv
    default: |
       Glob
       Users\*\NTUser.dat

  - name: Root
    description: |
      On Windows, this is the device to apply all the glob on
      (e.g. `C:`). On *NIX, this should be a path to a subdirectory or
      /.
    default: "C:"

  - name: Accessor
    default: auto
    description: |
      On Windows, this can be changed to `ntfs`.

  - name: NTFS_CACHE_TIME
    type: int
    description: How often to flush the NTFS cache. (Default is never).
    default: "1000000"


sources:
   - name: All Matches Metadata
     query: |
      LET RootPath &lt;= pathspec(Path=Root, accessor=Accessor)

      -- Generate the collection globs for each device
      LET specs = SELECT RootPath + Glob AS Glob
            FROM collectionSpec
            WHERE log(message=format(
               format="Processing Device %v with %v: glob is %v",
               args=[Root, Accessor, Glob]))

      -- Join all the collection rules into a single Glob plugin. This ensure we
      -- only make one pass over the filesystem. We only want LFNs.
      LET hits = SELECT OSPath AS SourceFile, Size,
               Btime AS Created,
               Ctime AS Changed,
               Mtime AS Modified,
               Atime AS LastAccessed
        FROM glob(globs=specs.Glob, accessor=Accessor)
        WHERE NOT IsDir AND log(message="Found " + SourceFile)

      -- Pass all the results to the next query. This will serialize
      -- to disk if there are too many results.
      LET all_results &lt;=
         SELECT Created, Changed, LastAccessed, Modified, Size, SourceFile
         FROM hits

      SELECT * FROM all_results

   - name: Uploads
     query: |
      -- Upload the files
      LET uploaded_files = SELECT * FROM foreach(row={
          SELECT * FROM all_results
        },
        workers=30,
        query={
          SELECT Created, Changed, LastAccessed, Modified, SourceFile, Size,
               upload(file=SourceFile,
                      accessor=Accessor,
                      mtime=Modified) AS Upload
            FROM scope()
        })

      -- Separate the hashes into their own column.
      SELECT now() AS CopiedOnTimestamp, SourceFile,
             Upload.Path AS DestinationFile,
               Size AS FileSize, Upload.sha256 AS SourceFileSha256,
               Created, Changed, Modified, LastAccessed
        FROM uploaded_files

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.sys.appcompatshims.md
======
---
title: Windows.Sys.AppcompatShims
hidden: true
tags: [Client Artifact]
---

Application Compatibility shims are a way to persist malware. This
table presents the AppCompat Shim information from the registry in a
nice format.


<pre><code class="language-yaml">
name: Windows.Sys.AppcompatShims
description: |
  Application Compatibility shims are a way to persist malware. This
  table presents the AppCompat Shim information from the registry in a
  nice format.

reference:
  - http://files.brucon.org/2015/Tomczak_and_Ballenthin_Shims_for_the_Win.pdf

parameters:
  - name: shimKeys
    default: &gt;-
      HKEY_LOCAL_MACHINE\SOFTWARE\Microsoft\Windows NT\CurrentVersion\AppCompatFlags\InstalledSDB\*
  - name: customKeys
    default: &gt;-
      HKEY_LOCAL_MACHINE\SOFTWARE\Microsoft\Windows NT\CurrentVersion\AppCompatFlags\Custom\*\*

sources:
  - precondition:
      SELECT OS From info() where OS = 'windows'
    query: |
        LET installed_sdb &lt;=
           SELECT Key, Key.Name as SdbGUID, DatabasePath,
                  DatabaseType, DatabaseDescription,
                  -- Convert windows file time to unix epoch.
                  (DatabaseInstallTimeStamp / 10000000) - 11644473600 AS DatabaseInstallTimeStamp
           FROM read_reg_key(
             globs=split(string=shimKeys, sep=",[\\s]*"),
             accessor="registry")

        LET result = SELECT * from foreach(
          row={
            SELECT regex_replace(
               source=OSPath,
               replace="$1",
               re="^.+\\\\([^\\\\]+)\\\\[^\\\\]+$") as Executable,
              regex_replace(
               source=Name,
               replace="$1",
               re="(\\{[^}]+\\}).*$") as SdbGUIDRef,
               Name as ExeName
            FROM glob(
              globs=split(string=customKeys, sep=",[\\s]*"),
              accessor="registry")
          },
          query={
            SELECT Executable, DatabasePath, DatabaseType,
                   DatabaseDescription, DatabaseInstallTimeStamp, SdbGUID
            FROM installed_sdb
            WHERE SdbGUID = SdbGUIDRef
          })

        SELECT * from result

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.system.taskscheduler.md
======
---
title: Windows.System.TaskScheduler
hidden: true
tags: [Client Artifact]
---

The Windows task scheduler is a common mechanism that malware uses
for persistence. It can be used to run arbitrary programs at a later
time. Commonly malware installs a scheduled task to run itself
periodically to achieve persistence.

This artifact enumerates all the task jobs (which are XML
files). The artifact uploads the original XML files and then
analyses them to provide an overview of the commands executed and
the user under which they will be run.


<pre><code class="language-yaml">
name: Windows.System.TaskScheduler
description: |
  The Windows task scheduler is a common mechanism that malware uses
  for persistence. It can be used to run arbitrary programs at a later
  time. Commonly malware installs a scheduled task to run itself
  periodically to achieve persistence.

  This artifact enumerates all the task jobs (which are XML
  files). The artifact uploads the original XML files and then
  analyses them to provide an overview of the commands executed and
  the user under which they will be run.

parameters:
  - name: TasksPath
    default: c:/Windows/System32/Tasks/**
  - name: AlsoUpload
    type: bool
    description: |
      If set we also upload the task XML files.
  - name: UploadCommands
    type: bool
    description: |
      If set we attempt to upload the commands that are
      mentioned in the scheduled tasks

sources:
  - name: Analysis
    query: |
      LET Uploads = SELECT Name, OSPath, if(
           condition=AlsoUpload='Y',
           then=upload(file=OSPath)) as Upload, Mtime
        FROM glob(globs=TasksPath)
        WHERE NOT IsDir

      // Job files contain invalid XML which confuses the parser - we
      // use regex to remove the invalid tags.
      LET parse_task = select OSPath, Mtime, parse_xml(
               accessor='data',
               file=regex_replace(
                    source=utf16(string=Data),
                    re='&lt;[?].+?&gt;',
                    replace='')) AS XML
        FROM read_file(filenames=OSPath)

      LET Results = SELECT OSPath, Mtime,
            XML.Task.Actions.Exec.Command as Command,
            expand(path=XML.Task.Actions.Exec.Command)  AS ExpandedCommand,
            XML.Task.Actions.Exec.Arguments as Arguments,
            XML.Task.Actions.ComHandler.ClassId as ComHandler,
            XML.Task.Principals.Principal.UserId as UserId,
            timestamp(epoch=XML.Task.Triggers.CalendarTrigger.StartBoundary) AS StartBoundary,
            XML as _XML
        FROM foreach(row=Uploads, query=parse_task)

      SELECT *,
         authenticode(filename=ExpandedCommand) AS Authenticode,
         if(condition=UploadCommands and ExpandedCommand,
            then=upload(file=ExpandedCommand)) AS Upload
      FROM Results

column_types:
- name: Upload
  type: upload_preview
- name: Authenticode
  type: collapsed

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/server.utils.createmsi.md
======
---
title: Server.Utils.CreateMSI
hidden: true
tags: [Server Artifact]
---

Build an MSI ready for deployment in the current org.

This artifact depends on the following tools:

* <velo-tool-viewer name="VelociraptorWindowsMSI" />
* <velo-tool-viewer name="VelociraptorWindows_x86MSI" />

You can replace those with suitable MSI builds.


<pre><code class="language-yaml">
name: Server.Utils.CreateMSI
description: |
  Build an MSI ready for deployment in the current org.

  This artifact depends on the following tools:

  * &lt;velo-tool-viewer name="VelociraptorWindowsMSI" /&gt;
  * &lt;velo-tool-viewer name="VelociraptorWindows_x86MSI" /&gt;

  You can replace those with suitable MSI builds.

type: SERVER

parameters:
  - name: CustomConfig
    description: Supply a custom client config instead of using the one from the current org
    type: yaml
  - name: AlsoBuild_x86
    description: Also build 32 bit MSI for deployment.
    type: bool

sources:
- query: |
    LET ValidateConfig(Config) = Config.Client.server_urls
          AND Config.Client.ca_certificate =~ "(?ms)-----BEGIN CERTIFICATE-----.+-----END CERTIFICATE-----"
          AND Config.Client.nonce

    LET client_config &lt;= if(condition=ValidateConfig(Config=CustomConfig),
                         then=CustomConfig,
                         else=org()._client_config)

    LET Build(Target) = repack(
        upload_name=format(
          format='Org_%v_%v',
          args=[org().name, inventory_get(tool=Target).Definition.filename]),
        target=Target,
        config=serialize(format='yaml', item=client_config))

    SELECT * FROM chain(a={
       SELECT Build(Target="VelociraptorWindowsMSI") FROM scope()
    }, b={
       SELECT Build(Target="VelociraptorWindows_x86MSI") FROM scope()
       WHERE AlsoBuild_x86
    })

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.events.processcreation.md
======
---
title: Windows.Events.ProcessCreation
hidden: true
tags: [Client Event Artifact]
---

Collect all process creation events.

This artifact relies on WMI to receive process start events. This
method is not as good as kernel mechanism used by Sysmon. It is more
reliable to use Sysmon instead via the
Windows.Sysinternals.SysmonLogForward artifact instead.


<pre><code class="language-yaml">
name: Windows.Events.ProcessCreation
description: |
  Collect all process creation events.

  This artifact relies on WMI to receive process start events. This
  method is not as good as kernel mechanism used by Sysmon. It is more
  reliable to use Sysmon instead via the
  Windows.Sysinternals.SysmonLogForward artifact instead.

type: CLIENT_EVENT

sources:
  - precondition:
      SELECT OS From info() where OS = 'windows'
    query: |
      -- Add a small delay to allow the process tracker to catch up
      -- for enrichments.
      LET Delayed = SELECT * FROM delay(query={
         SELECT * FROM wmi_events(
             query="SELECT * FROM Win32_ProcessStartTrace",
             wait=5000000,   // Do not time out.
             namespace="ROOT/CIMV2")
      }, delay=2)

      // Convert the timestamp from WinFileTime to Epoch.
      SELECT timestamp(winfiletime=atoi(string=Parse.TIME_CREATED)) as Timestamp,
          Parse.ParentProcessID as PPID,
          Parse.ProcessID as PID,
          Parse.ProcessName as Name,
          process_tracker_get(id=Parse.ProcessID).Data.CommandLine AS CommandLine,
          process_tracker_get(id=Parse.ParentProcessID).Data.CommandLine AS ParentCommandLine,
          join(array=process_tracker_callchain(id=Parse.ProcessID).Data.Name,
               sep=" &lt;- ") AS CallChain
      FROM Delayed

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.registry.wdigest.md
======
---
title: Windows.Registry.WDigest
hidden: true
tags: [Client Artifact]
---

Find WDigest registry values on the filesystem. The artifact will also use
GROUP BY to limit all ControlSet output to a single row.

In order to prevent a clear-text password from being placed in
LSASS, the following registry key needs to be set to “0” (Digest
Disabled):

 - HKEY_LOCAL_MACHINE\SYSTEM\CurrentControlSet\Control\SecurityProviders\WDigest
    “UseLogonCredential”(DWORD)
    “Negotiate”(DWORD)

These registry keys are worth monitoring in an environment as an
attacker may wish to set it to 1 to enable Digest password support
which forces “clear-text” passwords to be placed in LSASS on any
version of Windows from Windows 7 / 2008R2 up to Windows 10 /
2012R2. Furthermore, Windows 8.1 / 2012 R2 and newer do not have a
“UseLogonCredential” DWORD value, so the key needs to be
added. The existence of the key is suspicious, if not expected.

* ATT&CK tactic: Defense Evasion, Credential Access
* ATT&CK technique: T1112, T1003.001


<pre><code class="language-yaml">
name: Windows.Registry.WDigest
author: Eduardo Mattos - @eduardfir, Matt Green - @mgreen27
description: |
    Find WDigest registry values on the filesystem. The artifact will also use
    GROUP BY to limit all ControlSet output to a single row.

    In order to prevent a clear-text password from being placed in
    LSASS, the following registry key needs to be set to “0” (Digest
    Disabled):

     - HKEY_LOCAL_MACHINE\SYSTEM\CurrentControlSet\Control\SecurityProviders\WDigest
        “UseLogonCredential”(DWORD)
        “Negotiate”(DWORD)

    These registry keys are worth monitoring in an environment as an
    attacker may wish to set it to 1 to enable Digest password support
    which forces “clear-text” passwords to be placed in LSASS on any
    version of Windows from Windows 7 / 2008R2 up to Windows 10 /
    2012R2. Furthermore, Windows 8.1 / 2012 R2 and newer do not have a
    “UseLogonCredential” DWORD value, so the key needs to be
    added. The existence of the key is suspicious, if not expected.

    * ATT&amp;CK tactic: Defense Evasion, Credential Access
    * ATT&amp;CK technique: T1112, T1003.001

reference:
    - https://medium.com/blue-team/preventing-mimikatz-attacks-ed283e7ebdd5

type: CLIENT
precondition:
  SELECT * FROM info() where OS = 'windows'

parameters:
  - name: WDigestGlob
    default: HKEY_LOCAL_MACHINE\SYSTEM\*ControlSet*\Control\SecurityProviders\WDigest\**
    description: Use a glob to define the files that will be searched.
  - name: ShowAllValues
    type: bool
    description: Show all key values. It may be suspicious if these keys exist.


sources:
  - query: |
        SELECT
            ModTime as LastModified,
            OSPath as KeyPath,
            Name as KeyName,
            Data.type as KeyType,
            Data.value as KeyValue
        FROM glob(globs=WDigestGlob, accessor="registry")
        WHERE KeyType = "DWORD"
            AND KeyName =~ "UseLogonCredential|Negotiate"
            AND NOT if(condition= ShowAllValues,
                        then= False,
                        else= KeyValue = 0)
        GROUP BY LastModified, KeyName, KeyType, KeyValue,
            regex_replace(source=OSPath,
                re='''[^\\]+ControlSet[^\\]+''',replace='CurrentControlSet')

column_types:
  - name: LastModified
    type: timestamp

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/macos.applications.chrome.history.md
======
---
title: MacOS.Applications.Chrome.History
hidden: true
tags: [Client Artifact]
---

Read all User's chrome history.

## NOTES:

This artifact is deprecated in favor of
Generic.Forensic.SQLiteHunter and will be removed in future


<pre><code class="language-yaml">
name: MacOS.Applications.Chrome.History
description: |
  Read all User's chrome history.

  ## NOTES:

  This artifact is deprecated in favor of
  Generic.Forensic.SQLiteHunter and will be removed in future


parameters:
  - name: historyGlobs
    default: /Users/*/Library/Application Support/Google/Chrome/*/History
  - name: urlSQLQuery
    default: |
      SELECT url as visited_url, title, visit_count,
             typed_count, last_visit_time
      FROM urls
  - name: userRegex
    default: .

precondition: SELECT OS From info() where OS = 'darwin'

sources:
  - query: |
      LET history_files = SELECT
         parse_string_with_regex(regex="/Users/(?P&lt;User&gt;[^/]+)", string=OSPath).User AS User,
         OSPath, Mtime
      FROM glob(globs=historyGlobs)

      SELECT * FROM foreach(row=history_files,
        query={
           SELECT User, OSPath,
              Mtime,
              visited_url,
              title, visit_count, typed_count,
              timestamp(winfiletime=last_visit_time * 10) as last_visit_time
          FROM sqlite(
             file=OSPath,
             query=urlSQLQuery)
          })

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/server.orgs.listorgs.md
======
---
title: Server.Orgs.ListOrgs
hidden: true
tags: [Server Artifact]
---

This server artifact will list all currently configured orgs on the
server.

NOTE: This artifact is only available to users with the ORG_ADMIN
permission, normally only given to users with the administrator role
while using the root org (You might need to switch to the root org
in the GUI before collecting this artifact).


<pre><code class="language-yaml">
name: Server.Orgs.ListOrgs
description: |
  This server artifact will list all currently configured orgs on the
  server.

  NOTE: This artifact is only available to users with the ORG_ADMIN
  permission, normally only given to users with the administrator role
  while using the root org (You might need to switch to the root org
  in the GUI before collecting this artifact).

type: SERVER

parameters:
- name: AlsoDownloadClientConfigs
  type: bool
  description: When set also downloads client configs from each org

sources:
- query: |
    SELECT * FROM if(condition=AlsoDownloadClientConfigs,
    then={
      SELECT *, upload(file=_client_config,
         accessor="data",
         name=format(format="client.%s.config.yaml", args=OrgId || "RootOrg")) AS ClientConfig
      FROM orgs()
    }, else={
      SELECT * FROM orgs()
    })

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/reporting.default.md
======
---
title: Reporting.Default
hidden: true
tags: [Server Artifact]
---

A default template for HTML export.  This template will be used to
host html exports such as the notebook and the reporting
templates. Velociraptor will evaluate this template on the following
dict:

  - key main: contains a string with all the results of rendering
              the notebook inside.

## Notes

1. All html elements are allowed in a html template.

2. It is possible to run arbitrary VQL (and therefore arbitrary
   code) inside HTML templates. Therefore to modify this you will
   need the SERVER_ARTIFACT_WRITER permission.


<pre><code class="language-yaml">
name: Reporting.Default

type: SERVER

description: |
  A default template for HTML export.  This template will be used to
  host html exports such as the notebook and the reporting
  templates. Velociraptor will evaluate this template on the following
  dict:

    - key main: contains a string with all the results of rendering
                the notebook inside.

  ## Notes

  1. All html elements are allowed in a html template.

  2. It is possible to run arbitrary VQL (and therefore arbitrary
     code) inside HTML templates. Therefore to modify this you will
     need the SERVER_ARTIFACT_WRITER permission.

reports:
  - name: Templates
    type: TEMPLATES
    template: |
       {{ define "fold_start" }}
       &lt;div role="button" class="btn btn-primary btn-block row collapsible"&gt;View Details&lt;/div&gt;
       &lt;div class="collapse row"&gt;&lt;div class="card card-body overflow-auto"&gt;
       {{end}}
       {{ define "fold_end" }}
       &lt;/div&gt;&lt;/div&gt;
       {{ end }}

       {{ define "hidden_paragraph_start" }}
       {{- if .description -}}
       &lt;div&gt;&lt;a href="#" class="collapsible"&gt;{{ .description }} ...&lt;/a&gt;
       {{- else -}}
       &lt;div&gt;&lt;a href="#" class="collapsible"&gt;More ...&lt;/a&gt;
       {{- end -}}
       &lt;div class="collapse"&gt;
       {{end}}

       {{ define "hidden_paragraph_end" }}
       &lt;/div&gt;&lt;/div&gt;
       {{ end }}


  - type: HTML
    template: |
      {{ import "Reporting.Default" "Templates" }}

      &lt;!doctype html&gt;
       &lt;html lang="en-US"&gt;
         &lt;head&gt;
         {{ $hostinfo := Query "SELECT timestamp(epoch=now()).UTC.String AS Time, \
             OS, Fqdn FROM info()" | Expand }}

           &lt;meta charset="utf-8"&gt;
           &lt;meta http-equiv="X-UA-Compatible" content="IE=edge"&gt;
           &lt;meta name="viewport" content="width=device-width, initial-scale=1"&gt;

           &lt;!-- Name of the scan --&gt;
           &lt;title&gt;{{ Get $hostinfo "0.Fqdn" }} Artifact Collection&lt;/title&gt;
           &lt;style&gt;
             @charset "UTF-8";
           body {
             padding-top: 57px;
           }
           .btn-primary.btn {
              color: #00aa00;
              background-color: #fff;
              border-color: #fff;
           }
           .btn-primary.btn:hover {
              color: #fff;
              background-color: #00911e;
              border-color: #00911e;
           }
           .btn.btn-primary:not(:disabled):not(.disabled):active, .btn.btn-primary:not(:disabled):not(.disabled).active {
              color: #fff;
              background-color: #008773;
              border-color: #008773;
           }
           .btn.btn-primary:focus, .btn.btn-primary.focus {
             color: #fff;
              background-color: #00911e;
              border-color: #00911e;
             box-shadow: 0 0 0 0.2rem rgba(38, 143, 255, 0.5);
           }
           .header {
               background-color: black;
               border-bottom: 1px solid #00aa00;
           }
           .collapse {
             display: none;
           }
           .anchor {
             display: block;
             position: relative;
             top: -57px;
             visibility: hidden;
           }
           .logo {
             margin-top: -17px;
             margin-bottom: -10px;
             margin-left: 20px;
             height: 40px;
           }

           .section {
               color: #FFFFFF;
               font-size: 24px;
               background-color: #00aa00;
               font-family: Gotham, "Helvetica Neue", Helvetica, Arial, sans-serif;
               font-variant: normal;
               padding-top: 15px;
               padding-bottom: 15px;
               text-align: center;
           }
           .top-section {
               border-bottom-left-radius: 40px;
               border-bottom-right-radius: 40px;
           }

           /* Error */  .chromaerr { color: #a61717; background-color: #e3d2d2 }
           /* LineTableTD */  .chromalntd { vertical-align: top; padding: 0; margin: 0; border: 0; }
           /* LineTable */  .chromalntable { border-spacing: 0; padding: 0; margin: 0; border: 0; width: auto; overflow: auto; display: block; }
           /* LineHighlight */  .chromahl { display: block; width: 100%; }
           /* LineNumbersTable */  .chromalnt { margin-right: 0.4em; padding: 0 0.4em 0 0.4em; }
           /* LineNumbers */  .chromaln { display: none; margin-right: 0.4em; padding: 0 0.4em 0 0.4em; }
           /* Keyword */  .chromak { color: #000000; font-weight: bold }
           /* KeywordConstant */  .chromakc { color: #000000; font-weight: bold }
           /* KeywordDeclaration */  .chromakd { color: #000000; font-weight: bold }
           /* KeywordNamespace */  .chromakn { color: #000000; font-weight: bold }
           /* KeywordPseudo */  .chromakp { color: #000000; font-weight: bold }
           /* KeywordReserved */  .chromakr { color: #000000; font-weight: bold }
           /* KeywordType */  .chromakt { color: #445588; font-weight: bold }
           /* NameAttribute */  .chromana { color: #008080 }
           /* NameBuiltin */  .chromanb { color: #0086b3 }
           /* NameBuiltinPseudo */  .chromabp { color: #999999 }
           /* NameClass */  .chromanc { color: #445588; font-weight: bold }
           /* NameConstant */  .chromano { color: #008080 }
           /* NameDecorator */  .chromand { color: #3c5d5d; font-weight: bold }
           /* NameEntity */  .chromani { color: #800080 }
           /* NameException */  .chromane { color: #990000; font-weight: bold }
           /* NameFunction */  .chromanf { color: #990000; font-weight: bold }
           /* NameLabel */  .chromanl { color: #990000; font-weight: bold }
           /* NameNamespace */  .chromann { color: #555555 }
           /* NameTag */  .chromant { color: #000080 }
           /* NameVariable */  .chromanv { color: #008080 }
           /* NameVariableClass */  .chromavc { color: #008080 }
           /* NameVariableGlobal */  .chromavg { color: #008080 }
           /* NameVariableInstance */  .chromavi { color: #008080 }
           /* LiteralString */  .chromas { color: #dd1144 }
           /* LiteralStringAffix */  .chromasa { color: #dd1144 }
           /* LiteralStringBacktick */  .chromasb { color: #dd1144 }
           /* LiteralStringChar */  .chromasc { color: #dd1144 }
           /* LiteralStringDelimiter */  .chromadl { color: #dd1144 }
           /* LiteralStringDoc */  .chromasd { color: #dd1144 }
           /* LiteralStringDouble */  .chromas2 { color: #dd1144 }
           /* LiteralStringEscape */  .chromase { color: #dd1144 }
           /* LiteralStringHeredoc */  .chromash { color: #dd1144 }
           /* LiteralStringInterpol */  .chromasi { color: #dd1144 }
           /* LiteralStringOther */  .chromasx { color: #dd1144 }
           /* LiteralStringRegex */  .chromasr { color: #009926 }
           /* LiteralStringSingle */  .chromas1 { color: #dd1144 }
           /* LiteralStringSymbol */  .chromass { color: #990073 }
           /* LiteralNumber */  .chromam { color: #009999 }
           /* LiteralNumberBin */  .chromamb { color: #009999 }
           /* LiteralNumberFloat */  .chromamf { color: #009999 }
           /* LiteralNumberHex */  .chromamh { color: #009999 }
           /* LiteralNumberInteger */  .chromami { color: #009999 }
           /* LiteralNumberIntegerLong */  .chromail { color: #009999 }
           /* LiteralNumberOct */  .chromamo { color: #009999 }
           /* Operator */  .chromao { color: #000000; font-weight: bold }
           /* OperatorWord */  .chromaow { color: #000000; font-weight: bold }
           /* Comment */  .chromac { color: #999988; font-style: italic }
           /* CommentHashbang */  .chromach { color: #999988; font-style: italic }
           /* CommentMultiline */  .chromacm { color: #999988; font-style: italic }
           /* CommentSingle */  .chromac1 { color: #999988; font-style: italic }
           /* CommentSpecial */  .chromacs { color: #999999; font-weight: bold; font-style: italic }
           /* CommentPreproc */  .chromacp { color: #999999; font-weight: bold; font-style: italic }
           /* CommentPreprocFile */  .chromacpf { color: #999999; font-weight: bold; font-style: italic }
           /* GenericDeleted */  .chromagd { color: #000000; background-color: #ffdddd }
           /* GenericEmph */  .chromage { color: #000000; font-style: italic }
           /* GenericError */  .chromagr { color: #aa0000 }
           /* GenericHeading */  .chromagh { color: #999999 }
           /* GenericInserted */  .chromagi { color: #000000; background-color: #ddffdd }
           /* GenericOutput */  .chromago { color: #888888 }
           /* GenericPrompt */  .chromagp { color: #555555 }
           /* GenericStrong */  .chromags { font-weight: bold }
           /* GenericSubheading */  .chromagu { color: #aaaaaa }
           /* GenericTraceback */  .chromagt { color: #aa0000 }
           /* TextWhitespace */  .chromaw { color: #bbbbbb }

           &lt;/style&gt;
           &lt;meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"&gt;

           &lt;!-- Bootstrap core CSS --&gt;
           &lt;link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/css/bootstrap.min.css" integrity="sha384-Vkoo8x4CGsO3+Hhxv8T/Q5PaXtkKtu6ug5TOeNV6gBiFeWPGFN9MuhOf23Q9Ifjh" crossorigin="anonymous"&gt;
           &lt;link rel="stylesheet" href="https://cdn.datatables.net/1.10.21/css/jquery.dataTables.min.css" &gt;

           &lt;script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"&gt;&lt;/script&gt;
           &lt;script src="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/js/bootstrap.min.js" integrity="sha384-wfSDF2E50Y2D1uUdj0O3uMBJnjuUD4Ih7YwaYd1iqfktj0Uod8GCExl3Og8ifwB6" crossorigin="anonymous"&gt;&lt;/script&gt;
           &lt;script src="https://cdn.datatables.net/1.10.21/js/jquery.dataTables.min.js"&gt;&lt;/script&gt;
         &lt;/head&gt;
         &lt;body&gt;
           &lt;nav class="header navbar navbar-expand-lg navbar-dark fixed-top"&gt;
             &lt;a class="navbar-brand" href="#" aria-label="CyberCX"&gt;
               &lt;img src="https://www.velocidex.com/images/logos/velo_word_on_side.svg" class="logo"/&gt;
             &lt;/a&gt;
             &lt;button class="navbar-toggler" type="button"
                     data-toggle="collapse"
                     data-target="#navbarSupportedContent"
                     aria-controls="navbarSupportedContent"
                     aria-expanded="false" aria-label="Toggle navigation"&gt;
               &lt;span class="navbar-toggler-icon"&gt;&lt;/span&gt;
             &lt;/button&gt;
             &lt;div class="collapse navbar-collapse" id="navbarSupportedContent"&gt;
               &lt;ul class="navbar-nav mr-auto"&gt;
                 &lt;li class="nav-item active"&gt;
                   &lt;a class="nav-link" href="#"&gt;Top &lt;span class="sr-only"&gt;(top)&lt;/span&gt;&lt;/a&gt;
                 &lt;/li&gt;
                 &lt;li class="nav-item"&gt;
                   &lt;a class="nav-link" href="https://github.com/Velocidex/velociraptor"&gt;GitHub&lt;/a&gt;
                 &lt;/li&gt;
                 &lt;li class="nav-item"&gt;
                   &lt;a class="nav-link" href="#" id="print-button"&gt;Print&lt;/a&gt;
                 &lt;/li&gt;

                 &lt;li class="nav-item dropdown"&gt;
                   &lt;a class="nav-link dropdown-toggle" href="#"
                   id="navbarDropdown" role="button"
                   data-toggle="dropdown"
                   aria-haspopup="true" aria-expanded="false"&gt;
                     Artifacts Collected
                   &lt;/a&gt;
                   &lt;div class="dropdown-menu" aria-labelledby="navbarDropdown"&gt;
                     {{ range .parts }}
                     &lt;a class="dropdown-item" href="#{{- .Artifact.Name -}}"&gt;
                         {{ .Artifact.Name }}
                     &lt;/a&gt;
                     {{ end }}
                   &lt;/div&gt;
                 &lt;/li&gt;
               &lt;/ul&gt;
             &lt;/div&gt;
           &lt;/nav&gt;

           &lt;main role="main" class="container"&gt;
             &lt;div class="row section top-section"&gt;
               &lt;div class="col"&gt;
                 {{ $data := Query "SELECT timestamp(epoch=now()).UTC.String AS Time, OS, Fqdn FROM info()" | Expand }}
                 {{ Get $hostinfo "0.Fqdn" }} Artifact Collection
               &lt;/div&gt;
               &lt;div class="col"&gt;{{- Get $data "0" -}}&lt;/div&gt;
             &lt;/div&gt;

             {{ range .parts }}

             &lt;div class=""&gt;
               &lt;a class="anchor" name="{{- .Artifact.Name -}}"&gt;&lt;/a&gt;
               &lt;!-- If the artifact has its own report, just include it as is --&gt;
               {{ if .HTML }}
                 {{ .HTML }}
               {{ else }}
                 &lt;!-- Default report in case the artifact does not have one --&gt;
                 &lt;h1&gt;{{ .Artifact.Name }}
                     &lt;div class="btn btn-primary-outline float-right"&gt;{{ .Artifact.Author }}
                     &lt;/div&gt;
                 &lt;/h1&gt;

                 {{ $name := .Artifact.Name }}

                 {{ template "hidden_paragraph_start" dict "description" "View Artifact Description" }}
                   {{ Markdown .Artifact.Description }}

                   {{ if .Artifact.Reference }}
                     &lt;h3&gt;References&lt;/h3&gt;
                     &lt;ul&gt;
                       {{ range .Artifact.Reference }}
                       &lt;li&gt;&lt;a href="{{ . }}"&gt;{{ . }}&lt;/a&gt;&lt;/li&gt;
                       {{ end }}
                     &lt;/ul&gt;
                   {{ end }}
                 {{ template "hidden_paragraph_end" }}

                 {{ range .Artifact.Sources }}
                    {{ $source := print "source(\n  source='" .Name "', artifact='" $name "')" }}
                    {{ $query := print "SELECT * FROM " $source " \nLIMIT 100" }}

                    &lt;!-- There could be a huge number of rows just to get the count, so we cap at 10000 --&gt;
                    {{ $count := Get ( Query (print "LET X = SELECT * FROM " $source \
                       " LIMIT 10000 SELECT 1 AS ALL, count() AS Count FROM X Group BY ALL") | Expand ) \
                       "0.Count" }}

                    {{ if $count }}
                      {{ if .Name }}
                        &lt;h3&gt;Source {{ $name }}/{{ .Name }}&lt;/h3&gt;
                        {{ Markdown .Description }}
                      {{ end }}

                      &lt;!-- Show the artifact source if required. --&gt;
                      {{ template "hidden_paragraph_start" dict "description" "Source" }}
                      &lt;div class="row card card-body noprint"&gt;
                        {{ if .Query }}
                          {{ Markdown ( print "```vql\n" .Query  "```\n") }}
                        {{ else }}
                          {{ range .Queries }}
                            {{ Markdown ( print "```vql\n" .  "```\n") }}
                          {{ end }}
                        {{ end }}
                      &lt;/div&gt;
                      {{ template "hidden_paragraph_end" }}

                      &lt;!-- If this is a flow show the parameters. --&gt;
                      {{ $flow := Query "LET X = SELECT Request.Parameters.env AS Env FROM flows(client_id=ClientId, flow_id=FlowId)" \
                      "SELECT * FROM foreach(row=X[0].Env, query={ SELECT Key, Value FROM scope()})" | Expand }}
                      {{ if $flow }}
                        {{ template "hidden_paragraph_start" dict "description" "Parameters" }}
                        &lt;div class="row card card-body noprint"&gt;
                          &lt;h3&gt; Parameters &lt;/h3&gt;

                          &lt;table class="table"&gt;&lt;thead&gt;&lt;th&gt;Key&lt;/th&gt;&lt;th&gt;Value&lt;/th&gt;&lt;/thead&gt;
                            &lt;tbody&gt;
                              {{ range $flow }}
                                &lt;tr&gt;&lt;td&gt;{{ Get . "Key" }}&lt;/td&gt;&lt;td&gt;{{ Get . "Value" }}&lt;/td&gt;&lt;/tr&gt;
                              {{ end }}
                            &lt;/tbody&gt;
                          &lt;/table&gt;
                        &lt;/div&gt;
                        {{ template "hidden_paragraph_end" }}
                      {{ end }}

                      {{ if gt $count 9999 }}
                        &lt;p&gt;The source produced more than {{ $count }} rows.&lt;/p&gt;
                      {{ else }}
                        &lt;p&gt;The source retrieved a total of {{ $count }} rows.&lt;/p&gt;
                      {{ end }}

                      {{ template "fold_start" }}
                      &lt;div class="noprint"&gt;
                        &lt;p&gt; Below you will find a table of the first 100 rows, obtained by the VQL query:
                        &lt;/p&gt;
                        {{ Markdown (print "```vql\n" $query "\n```\n" ) }}
                      &lt;/div&gt;
                      {{ Query $query | Table }}
                      {{ template "fold_end" }}

                    {{ else }}
                      &lt;p&gt;No rows returned&lt;/p&gt;
                    {{ end }}
                 {{ end }}
               {{ end }}
             &lt;/div&gt;

           {{ end }}
           &lt;/main&gt;
           &lt;script&gt;
             $(".collapsible").click(function() {
               $(this).next().toggle("slow");
               try {
                 $("table.table-striped").DataTable().columns.adjust();
               } catch(e) {

               };
             });

             $("#print-button").click(function() {
                $(".collapse").removeClass("collapse");
                $('table.table-striped').DataTable().destroy();
                $(".collapsible").hide();
                $(".noprint").hide();
                setTimeout(function() {
                   window.print();
                   location.reload();
                }, 1000);
             });

             $(document).ready( function () {
                try {
                   $('table.table-striped').DataTable({
                      "scrollY": 400,
                      "scrollX": true,
                      "autoWidth": false,
                   });
                } catch(e) {};
             });
           &lt;/script&gt;
        &lt;/body&gt;
       &lt;/html&gt;

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.kapefiles.remapping.md
======
---
title: Windows.KapeFiles.Remapping
hidden: true
tags: [Client Artifact]
---

This artifact automates the rebuilding of remapping rules to be
able to easily post process the results of the
Windows.KapeFiles.Targets.

Use as follows in the flow notebook cell of a collection:

```vql
LET _ <=
   SELECT * FROM Artifact.Windows.KapeFiles.Remapping(ClientId=ClientId, FlowId=FlowId)

SELECT * FROM Artifact.Windows.System.TaskScheduler()
```

NOTE: Not all plugins are enabled in this mode for obvious reasons
(e.g. pslist, wmi etc).

See https://docs.velociraptor.app/blog/2022/2022-08-04-post-processing/


<pre><code class="language-yaml">
name: Windows.KapeFiles.Remapping
description: |
   This artifact automates the rebuilding of remapping rules to be
   able to easily post process the results of the
   Windows.KapeFiles.Targets.

   Use as follows in the flow notebook cell of a collection:

   ```vql
   LET _ &lt;=
      SELECT * FROM Artifact.Windows.KapeFiles.Remapping(ClientId=ClientId, FlowId=FlowId)

   SELECT * FROM Artifact.Windows.System.TaskScheduler()
   ```

   NOTE: Not all plugins are enabled in this mode for obvious reasons
   (e.g. pslist, wmi etc).

   See https://docs.velociraptor.app/blog/2022/2022-08-04-post-processing/

type: CLIENT

parameters:
   - name: ClientId
     description: The ClientID of the collection we need to remap
   - name: FlowId
     description: The FlowID of the collection

export: |
   -- Get the base path of files in the filestore for this client id
   -- and flow id
   LET GetBasePath(FlowId, ClientId) = regex_transform(
     source="/clients/ClientId/collections/FlowId/uploads",
     map=dict(FlowId=FlowId, ClientId=ClientId))

   -- Get the registry mount for the users
   LET HiveMount(BasePath, Target) = regex_transform(source='''
   - type: mount
     from:
       accessor: raw_reg
       prefix: |-
         {
           "Path": "/",
           "DelegateAccessor": "fs",
           "DelegatePath": "BasePath"
         }
       path_type: registry
     "on":
       accessor: registry
       prefix: Target
       path_type: registry
   ''', map=dict(BasePath=BasePath, Target=Target), key=Target)

   -- Map regular files from the fs accessor to the designated accessor
   LET AccessorMount(Accessor, BasePath) = regex_transform(source='''
   - type: mount
     from:
       accessor: fs
       prefix: "BasePath/AccessorName"
     "on":
       accessor: AccessorName
       prefix: ""
       path_type: AccessorName
   ''', map=dict(BasePath=BasePath, AccessorName=Accessor), key=Accessor)

   -- ShadowMount just copy accessors into the new remapped environment.
   LET ShadowMount(Accessor) = regex_transform(source='''
   - type: shadow
     from:
       accessor: AccessorName
     "on":
       accessor: AccessorName
   ''', map=dict(AccessorName=Accessor), key=Accessor)

   -- Common mounts that are used in all cases.
   LET CommonMount = '''remappings:
   - type: permissions
     permissions:
       - COLLECT_CLIENT
       - FILESYSTEM_READ
       - FILESYSTEM_WRITE
       - READ_RESULTS
       - MACHINE_STATE
       - SERVER_ADMIN
   - type: impersonation
     os: windows
     hostname: Virtual Host
     env:
       - key: SystemRoot
         value: C:\Windows
       - key: WinDir
         value: C:\Windows
     disabled_functions:
       - amsi
       - lookupSID
       - token
     disabled_plugins:
       - users
       - certificates
       - handles
       - pslist
       - interfaces
       - modules
       - netstat
       - partitions
       - proc_dump
       - proc_yara
       - vad
       - winobj
       - wmi
   '''

   -- Build remapping parts by searching for registry hives to mount.
   LET Parts(BasePath) = SELECT * FROM chain(
   a={

     -- Mount all ntuser.dat hives that were fetched. Username is
     -- taken to be containing directory.
     SELECT OSPath,
             HiveMount(BasePath=OSPath.String,
                       Target="HKEY_USERS/" + OSPath[-2]) AS Mount
     FROM glob(globs="*/C:/Users/*/ntuser.dat", accessor="fs", root=BasePath)
     WHERE NOT OSPath.Basename =~ "idx$"

   }, b={
     -- Mount the main system registry hives
     SELECT OSPath,
            HiveMount(BasePath=OSPath.String,
                      Target="HKEY_LOCAL_MACHINE/" + OSPath[-1]) AS Mount
     FROM glob(globs="*/C:/Windows/System32/Config/{SOFTWARE,SYSTEM}",
               accessor="fs", root=BasePath)
     WHERE NOT OSPath.Basename =~ "idx$"

   }, e={
     SELECT ShadowMount(Accessor=_value) AS Mount
     FROM foreach(row=["raw_reg", "zip", "data", "scope", "gzip"])
   })

   -- Mount all files to be accessible by auto, ntfs and file accessor.
   LET GetRemappingByBase(BasePath) = join(array=CommonMount +
       AccessorMount(BasePath=BasePath, Accessor="auto") +
       AccessorMount(BasePath=BasePath, Accessor="ntfs") +
       AccessorMount(BasePath=BasePath, Accessor="file") +
       Parts(BasePath=BasePath).Mount, sep="")

   LET GetRemapping(FlowId, ClientId) = GetRemappingByBase(
       BasePath=GetBasePath(FlowId=FlowId, ClientId=ClientId))

sources:
  - query: |
      SELECT remap(clear=TRUE, config=GetRemapping) AS Remapping
      FROM scope()

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/generic.detection.yara.glob.md
======
---
title: Generic.Detection.Yara.Glob
hidden: true
tags: [Client Artifact]
---

This artifact returns a list of target files then runs Yara over the target
list.

There are 2 kinds of Yara rules that can be deployed:

1. Url link to a yara rule.
2. or a Standard Yara rule attached as a parameter.

Only one method of Yara will be applied and search order is as above.

The artifact leverages Glob for search so relevant filters can be applied
including Glob, Size and date. Date filters will target files with a timestamp
before LatestTime and after EarliestTime. The artifact also has an option to
upload any files with Yara hits.

Some examples of path glob may include:

* Specific binary: `/usr/bin/ls`
* Wildcards: `/var/www/*.js`
* More wildcards: `/var/www/**/*.js`
* Multiple extentions: `/var/www/*\.{php,aspx,js,html}`
* Windows: `C:/Users/**/*.{exe,dll,ps1,bat}`
* Windows: `C:\Users\**\*.{exe,dll,ps1,bat}`

NOTE: this artifact runs the glob plugin with the nosymlink switch turned on.
This will NOT follow any symlinks and may cause unexpected results if
unknowingly targeting a folder with symlinks.
If upload is selected NumberOfHits is redundant and not advised as hits are
grouped by path to ensure files only downloaded once.


<pre><code class="language-yaml">
name: Generic.Detection.Yara.Glob
author: Matt Green - @mgreen27
description: |
  This artifact returns a list of target files then runs Yara over the target
  list.

  There are 2 kinds of Yara rules that can be deployed:

  1. Url link to a yara rule.
  2. or a Standard Yara rule attached as a parameter.

  Only one method of Yara will be applied and search order is as above.

  The artifact leverages Glob for search so relevant filters can be applied
  including Glob, Size and date. Date filters will target files with a timestamp
  before LatestTime and after EarliestTime. The artifact also has an option to
  upload any files with Yara hits.

  Some examples of path glob may include:

  * Specific binary: `/usr/bin/ls`
  * Wildcards: `/var/www/*.js`
  * More wildcards: `/var/www/**/*.js`
  * Multiple extentions: `/var/www/*\.{php,aspx,js,html}`
  * Windows: `C:/Users/**/*.{exe,dll,ps1,bat}`
  * Windows: `C:\Users\**\*.{exe,dll,ps1,bat}`

  NOTE: this artifact runs the glob plugin with the nosymlink switch turned on.
  This will NOT follow any symlinks and may cause unexpected results if
  unknowingly targeting a folder with symlinks.
  If upload is selected NumberOfHits is redundant and not advised as hits are
  grouped by path to ensure files only downloaded once.

aliases:
  - Windows.Detection.Yara.Glob
  - Linux.Detection.Yara.Glob
  - MacOS.Detection.Yara.Glob

type: CLIENT
parameters:
  - name: PathGlob
    description: Only file names that match this glob will be scanned.
    default: /usr/bin/ls
  - name: SizeMax
    description: maximum size of target file.
    type: int64
  - name: SizeMin
    description: minimum size of target file.
    type: int64
  - name: UploadHits
    type: bool
  - name: DateAfter
    type: timestamp
    description: "search for events after this date. YYYY-MM-DDTmm:hh:ssZ"
  - name: DateBefore
    type: timestamp
    description: "search for events before this date. YYYY-MM-DDTmm:hh:ssZ"
  - name: YaraUrl
    description: If configured will attempt to download Yara rules form Url
    type: upload
  - name: YaraRule
    type: yara
    description: Final Yara option and the default if no other options provided.
    default: |
        rule IsELF:TestRule {
           meta:
              author = "the internet"
              date = "2021-05-03"
              description = "A simple ELF rule to test yara features"
          condition:
             uint32(0) == 0x464c457f
        }
  - name: NumberOfHits
    description: This artifact will stop by default at one hit. This setting allows additional hits
    default: 1
    type: int
  - name: ContextBytes
    description: Include this amount of bytes around hit as context.
    default: 0
    type: int

sources:
  - query: |
      -- check which Yara to use
      LET yara_rules &lt;= YaraUrl || YaraRule

      -- time testing
      LET time_test(stamp) =
            if(condition= DateBefore AND DateAfter,
                then= stamp &lt; DateBefore AND stamp &gt; DateAfter,
                else=
            if(condition=DateBefore,
                then= stamp &lt; DateBefore,
                else=
            if(condition= DateAfter,
                then= stamp &gt; DateAfter,
                else= True
            )))

      -- first find all matching glob
      LET files = SELECT OSPath, Name, Size, Mtime, Atime, Ctime, Btime
        FROM glob(globs=PathGlob,nosymlink='True')
        WHERE
          NOT IsDir AND NOT IsLink
          AND if(condition=SizeMin,
            then= SizeMin &lt; Size,
            else= True)
          AND if(condition=SizeMax,
            then=SizeMax &gt; Size,
            else= True)
          AND
             ( time_test(stamp=Mtime)
            OR time_test(stamp=Atime)
            OR time_test(stamp=Ctime)
            OR time_test(stamp=Btime))

      -- scan files and prepare hit metadata
      LET hits = SELECT * FROM foreach(row=files,
            query={
                SELECT
                    OSPath,
                    File.Size as Size,
                    Mtime, Atime, Ctime, Btime,
                    Rule, Tags, Meta,
                    String.Name as YaraString,
                    String.Offset as HitOffset,
                    upload( accessor='scope',
                            file='String.Data',
                            name=format(format="%v-%v-%v",
                            args=[
                                OSPath,
                                if(condition= String.Offset - ContextBytes &lt; 0,
                                    then= 0,
                                    else= String.Offset - ContextBytes),
                                if(condition= String.Offset + ContextBytes &gt; Size,
                                    then= Size,
                                    else= String.Offset + ContextBytes) ]
                            )) as HitContext
                FROM yara(rules=yara_rules,files=OSPath,
                  context=ContextBytes,number=NumberOfHits)
            })

      -- upload files if selected
      LET upload_hits = SELECT *, upload(file=OSPath,name=OSPath) as Upload FROM hits

      -- return rows
      SELECT * FROM if(condition= UploadHits,
                        then= upload_hits,
                        else= hits )

column_types:
  - name: HitContext
    type: preview_upload
</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/macos.detection.yara.glob.md
======
---
title: MacOS.Detection.Yara.Glob
hidden: true
tags: [Client Artifact]
---

This artifact returns a list of target files then runs Yara over the target
list.

There are 2 kinds of Yara rules that can be deployed:

1. Url link to a yara rule.
2. or a Standard Yara rule attached as a parameter.

Only one method of Yara will be applied and search order is as above.

The artifact leverages Glob for search so relevant filters can be applied
including Glob, Size and date. Date filters will target files with a timestamp
before LatestTime and after EarliestTime. The artifact also has an option to
upload any files with Yara hits.

Some examples of path glob may include:

* Specific binary: `/usr/bin/ls`
* Wildcards: `/var/www/*.js`
* More wildcards: `/var/www/**/*.js`
* Multiple extentions: `/var/www/*\.{php,aspx,js,html}`
* Windows: `C:/Users/**/*.{exe,dll,ps1,bat}`
* Windows: `C:\Users\**\*.{exe,dll,ps1,bat}`

NOTE: this artifact runs the glob plugin with the nosymlink switch turned on.
This will NOT follow any symlinks and may cause unexpected results if
unknowingly targeting a folder with symlinks.
If upload is selected NumberOfHits is redundant and not advised as hits are
grouped by path to ensure files only downloaded once.


<pre><code class="language-yaml">
name: Generic.Detection.Yara.Glob
author: Matt Green - @mgreen27
description: |
  This artifact returns a list of target files then runs Yara over the target
  list.

  There are 2 kinds of Yara rules that can be deployed:

  1. Url link to a yara rule.
  2. or a Standard Yara rule attached as a parameter.

  Only one method of Yara will be applied and search order is as above.

  The artifact leverages Glob for search so relevant filters can be applied
  including Glob, Size and date. Date filters will target files with a timestamp
  before LatestTime and after EarliestTime. The artifact also has an option to
  upload any files with Yara hits.

  Some examples of path glob may include:

  * Specific binary: `/usr/bin/ls`
  * Wildcards: `/var/www/*.js`
  * More wildcards: `/var/www/**/*.js`
  * Multiple extentions: `/var/www/*\.{php,aspx,js,html}`
  * Windows: `C:/Users/**/*.{exe,dll,ps1,bat}`
  * Windows: `C:\Users\**\*.{exe,dll,ps1,bat}`

  NOTE: this artifact runs the glob plugin with the nosymlink switch turned on.
  This will NOT follow any symlinks and may cause unexpected results if
  unknowingly targeting a folder with symlinks.
  If upload is selected NumberOfHits is redundant and not advised as hits are
  grouped by path to ensure files only downloaded once.

aliases:
  - Windows.Detection.Yara.Glob
  - Linux.Detection.Yara.Glob
  - MacOS.Detection.Yara.Glob

type: CLIENT
parameters:
  - name: PathGlob
    description: Only file names that match this glob will be scanned.
    default: /usr/bin/ls
  - name: SizeMax
    description: maximum size of target file.
    type: int64
  - name: SizeMin
    description: minimum size of target file.
    type: int64
  - name: UploadHits
    type: bool
  - name: DateAfter
    type: timestamp
    description: "search for events after this date. YYYY-MM-DDTmm:hh:ssZ"
  - name: DateBefore
    type: timestamp
    description: "search for events before this date. YYYY-MM-DDTmm:hh:ssZ"
  - name: YaraUrl
    description: If configured will attempt to download Yara rules form Url
    type: upload
  - name: YaraRule
    type: yara
    description: Final Yara option and the default if no other options provided.
    default: |
        rule IsELF:TestRule {
           meta:
              author = "the internet"
              date = "2021-05-03"
              description = "A simple ELF rule to test yara features"
          condition:
             uint32(0) == 0x464c457f
        }
  - name: NumberOfHits
    description: This artifact will stop by default at one hit. This setting allows additional hits
    default: 1
    type: int
  - name: ContextBytes
    description: Include this amount of bytes around hit as context.
    default: 0
    type: int

sources:
  - query: |
      -- check which Yara to use
      LET yara_rules &lt;= YaraUrl || YaraRule

      -- time testing
      LET time_test(stamp) =
            if(condition= DateBefore AND DateAfter,
                then= stamp &lt; DateBefore AND stamp &gt; DateAfter,
                else=
            if(condition=DateBefore,
                then= stamp &lt; DateBefore,
                else=
            if(condition= DateAfter,
                then= stamp &gt; DateAfter,
                else= True
            )))

      -- first find all matching glob
      LET files = SELECT OSPath, Name, Size, Mtime, Atime, Ctime, Btime
        FROM glob(globs=PathGlob,nosymlink='True')
        WHERE
          NOT IsDir AND NOT IsLink
          AND if(condition=SizeMin,
            then= SizeMin &lt; Size,
            else= True)
          AND if(condition=SizeMax,
            then=SizeMax &gt; Size,
            else= True)
          AND
             ( time_test(stamp=Mtime)
            OR time_test(stamp=Atime)
            OR time_test(stamp=Ctime)
            OR time_test(stamp=Btime))

      -- scan files and prepare hit metadata
      LET hits = SELECT * FROM foreach(row=files,
            query={
                SELECT
                    OSPath,
                    File.Size as Size,
                    Mtime, Atime, Ctime, Btime,
                    Rule, Tags, Meta,
                    String.Name as YaraString,
                    String.Offset as HitOffset,
                    upload( accessor='scope',
                            file='String.Data',
                            name=format(format="%v-%v-%v",
                            args=[
                                OSPath,
                                if(condition= String.Offset - ContextBytes &lt; 0,
                                    then= 0,
                                    else= String.Offset - ContextBytes),
                                if(condition= String.Offset + ContextBytes &gt; Size,
                                    then= Size,
                                    else= String.Offset + ContextBytes) ]
                            )) as HitContext
                FROM yara(rules=yara_rules,files=OSPath,
                  context=ContextBytes,number=NumberOfHits)
            })

      -- upload files if selected
      LET upload_hits = SELECT *, upload(file=OSPath,name=OSPath) as Upload FROM hits

      -- return rows
      SELECT * FROM if(condition= UploadHits,
                        then= upload_hits,
                        else= hits )

column_types:
  - name: HitContext
    type: preview_upload
</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/demo.plugins.gui.md
======
---
title: Demo.Plugins.GUI
hidden: true
tags: [Client Artifact]
---

A demo plugin showing some GUI features.

This plugin is also used for tests.


<pre><code class="language-yaml">
name: Demo.Plugins.GUI
description: |
  A demo plugin showing some GUI features.

  This plugin is also used for tests.

resources:
  timeout: 20
  ops_per_second: 60
  max_rows: 213
  max_upload_bytes: 545454

parameters:
  - name: ChoiceSelector
    description: Choose one item from a selection
    type: choices
    default: First Choice
    choices:
      - First Choice
      - Second Choice
      - Third Choice

  - name: MultiChoiceSelector
    description: Choose one or more items from a selection
    type: multichoice
    default: '["Bananas"]'
    choices:
      - Apples
      - Bananas
      - Oranges
      - Grapes

  - name: Hashes
    validating_regex: '^\s*([A-F0-9]+\s*)+$'
    description: One or more hashes in hex separated by white space.

  - name: RegularExpression
    type: regex
    default: "."

  - name: MultipleRegularExpression
    type: regex_array
    default: '[".+"]'

  - name: YaraRule
    type: yara

  - name: Flag
    friendly_name: A Flag with a name
    type: bool
    default: True

  - name: Flag2
    type: bool
    default: Y

  - name: Flag3
    type: bool
    default: Y

  - name: OffFlag
    type: bool

  - name: StartDate
    type: timestamp

  - name: StartDate2
    type: timestamp

  - name: StartDate3
    type: timestamp

  - name: CSVData
    type: csv
    default: |
      Column1,Column2
      A,B
      C,D

  - name: CSVData2
    type: csv
    default: |
      Column1,Column2
      A,B
      C,D

  - name: JSONData
    type: json_array
    default: "[]"

  - name: JSONData2
    type: json_array
    default: |
      [{"foo": "bar"}]

  - name: FileUpload1
    type: upload
    description: |
      FileUpload1 can receive a file upload.

      The upload content will be available in this variable when
      executing on the client.

  - name: FileUpload2
    type: upload_file
    description: |
      FileUpload2 can receive a file upload.

      The upload content will be stored in a temp file which will be
      available in this variable when executing on the client.

  - name: ArtifactSelections
    type: artifactset
    description: A selection of artifact
    artifact_type: CLIENT_EVENT
    default: |
      Artifact
      Windows.Detection.PsexecService
      Windows.Events.ProcessCreation
      Windows.Events.ServiceCreation

column_types:
  - name: Base64Hex
    type: base64hex

sources:
  - query: |
      SELECT base64encode(string="This should popup in a hex editor") AS Base64Hex,
             ChoiceSelector, MultiChoiceSelector, Flag, Flag2, Flag3,
             OffFlag, StartDate, StartDate2, StartDate3,
             CSVData, CSVData2, JSONData, JSONData2,
             len(list=FileUpload1) AS FileUpload1Length,
             stat(filename=FileUpload2) AS FileUpload2Stats
      FROM scope()

    notebook:
      - type: vql_suggestion
        name: Test Suggestion
        template: |
          /*
          # This is a suggestion notebook cell.

          It should be available from the suggestions list.
          */
          SELECT * FROM info()

      - type: markdown
        name: Test Template
        template: |
          # GUI Notebook tests

          The following cells are testing the notebook in the flow. To
          run this test simply collect the `Demo.Plugins.GUI` artifact
          and check the output is correct.

          **Each of the below cells should have a H2 heading**

          ## Check that notebook environment variables are populated

          Some of these are populated from the artifact parameters.

          {{ $x := Query "LET X = scope() SELECT * FROM items(\
             item=dict(NotebookId=X.NotebookId, ClientId=X.ClientId,\
                       FlowId=X.FlowId, ArtifactName=X.ArtifactName, \
                       ChoiceSelector=X.ChoiceSelector, StartDate=X.StartDate, \
                       HuntId=X.HuntId))" | Expand }}

          {{ range $x }}
          * {{ Get . "_key" }} - {{ Get . "_value" }}
          {{- end -}}

      - type: markdown
        name: Test Code Highlighting
        template: |
          ## Code syntax highlighting for VQL

          ```vql
          SELECT * FROM info()
          ```

      - type: vql
        name: Test Markdown in VQL cell
        template: |
          /*
          ## A VQL cell with a heading.
          */
          LET ColumnTypes = dict(
            Time1="timestamp",
            Time2="timestamp",
            Time3="timestamp",
            Time4="timestamp",
            FlowId="flow",
            ClientId="client",
            Data="hex",
            URL="url",
            SafeURL="safe_url", // Present dialog before click.
            Base64Data="base64hex"
          )

          LET Base64Data = base64encode(string="\x00\x01\x20\x32\x12\x10")
          LET URL = "[Google](https://www.google.com)"

          SELECT 1628609690.1 AS Raw,

                 -- float
                 1628609690.1 AS Time1,

                 -- ms as a string
                 "1628609690100" AS Time2,

                 -- ns
                 1628609690100000 AS Time3,

                 -- Standard string form
                 "2021-08-10T15:34:50Z" AS Time4,

                 FlowId, ClientId, URL, URL AS SafeURL, Base64Data,

                 format(format="%02x", args="Hello") AS Data,
                 TRUE, 4, NULL
          FROM scope()

      - type: Markdown
        name: Scatter Chart
        template: |
          ## Scatter Chart with a named column

          {{ define "ScatterTest" }}
           SELECT X, Name, Y, Y3
          FROM parse_csv(accessor="data", filename='''
          X,Name,Y,Y3
          1,Bob,2,3
          2,Frank,4,6
          3,Mike,6,8
          4,Sally,3,2
           ''')
          {{ end }}
          {{ Query "ScatterTest" | ScatterChart "name_column" "Name" }}

          ## Stacked Bar Chart (Categories are first column)

          {{ define "Test" }}
          SELECT X, Y, Y3
          FROM parse_csv(accessor="data", filename='''
          X,Y,Y3
          Bob,2,3
          Bill,4,6
          Foo,6,8
          Bar,7,2
          ''')
          {{ end }}
          {{ Query "Test" | BarChart "type" "stacked" }}

          ## Time chart with timestamp in first column

          {{ define "TimeTest" }}
          SELECT Timestamp, Y, Y3
          FROM parse_csv(accessor="data", filename='''
          Timestamp,Y,Y3
          2021-10-09,2,3
          2021-10-10,4,6
          2021-10-11,6,8
          2021-10-12,7,2
          ''')
          {{ end }}
          {{ Query "TimeTest" | TimeChart }}

          ## Line chart

          {{ define "LineTest" }}
          SELECT X, Y, Y3
          FROM parse_csv(accessor="data", filename='''
          X,Y,Y3
          1,2,3
          2,4,6
          3,6,8
          4,7,2
          ''')
          {{ end }}
          {{ Query "LineTest" | LineChart }}

      - type: Markdown
        name: Line Chart
        template: |
          ## A Line Chart

          The following should show a CPU load chart of the last 10 min.

          {{ define "Q" }}
            SELECT _ts, CPUPercent
            FROM monitoring(
                  client_id="server",
                  artifact="Server.Monitor.Health/Prometheus",
                  start_time=now() - 10 * 60)
            LIMIT 100
          {{ end }}

          {{ Query "Q" | TimeChart }}

      - type: vql
        name: Test Timeline
        template: |
          /*
          ## Adding timelines

          Add a timeline from this time series data. (This only works
          for root org because it relies on server health events).

          */
          SELECT timestamp(epoch=_ts) AS Timestamp, CPUPercent
          FROM monitoring(
            client_id="server",
            source="Prometheus",
            artifact="Server.Monitor.Health",
            start_time=now() - 10 * 60)

          LET T1 = SELECT
               timestamp(epoch=_ts) AS Timestamp,
               dict(X=CPUPercent, Y=1) AS Dict
          FROM monitoring(
            client_id="server",
            source="Prometheus",
            artifact="Server.Monitor.Health",
            start_time=now() - 10 * 60)

          -- Add the time series into the timeline.
          SELECT timeline_add(
              key="Timestamp", name="Time 你好世界 'line' &amp;\" ",
              query=T1, timeline="Test \"Timeline 你好世界\""),
           timeline_add(
              key="Timestamp", name="2",
              query=T1, timeline="Test \"Timeline 你好世界\"")
          FROM scope()

      - type: Markdown
        name: Test Cell Environment
        env:
          - key: Timeline
            value: Test "Timeline 你好世界"
        template: |
          ## This super timeline should have two timelines.

          Add a timeline manually and hit refresh on this cell to
          check it is being updated.

          {{ Scope "Timeline" | Timeline }}

      - type: VQL
        name: Test Table Scrolling
        template: |
          /*
          # Test table scrolling.

          Check both expanded and contracted states of the cell
          */
          LET zalgo = "1̴̣̜̗̰͇͖͖̞̮͈͍̂͜.̸̢̧̨͙̻̜̰̼̔̿̓̄̀̅͌̈́͒͗̈́̒̕̚͜͠e̶̙̞̬̹̥͖̤̟͑͒̂̀̔͠x̵̛̱̠̳͍̦̘̤̙͚̙͈̬́̈́͂̎̽̇̀͝ę̵̯̦̫͖͖͍͈̟̠͉̥͒̑̐̏̕̚̕͜͠"
          LET Test = "Hellothereongline" + zalgo

          SELECT Test AS Test1, Test AS Test2, Test AS Test3,
                 Test AS Test4, Test AS Test5,
                 Test AS Test11, Test AS Test21,
                 Test AS Test13, Test AS Test14, Test AS Test15,
                 Test AS Test21, Test AS Test22,
                 Test AS Test23, Test AS Test24, Test AS Test25
          FROM range(start=0, end=100, step=1)

      - type: VQL
        name: Test Column Types
        template: |
          /*
          # Column types set in the artifact's `column_types` field

          These apply to notebooks automatically without needing to
          define them again.

          * Hash column should right click to VT
          * upload preview should show the uploaded file.

          */

          LET ColumnTypes = dict(`StartDate`='timestamp', Download='download',
                                 Hex='hex', Upload='preview_upload')
          LET Hex = "B0 EC 48 5F 18 77"

          SELECT Hex, StartDate, hash(accessor="data", path="Hello") AS Hash,
                 upload(accessor="data", file="Hello world",
                        name="test.txt") AS Upload,
                 upload(accessor="data", file="Hello world",
                        name="test.txt") AS Download
          FROM source()

      - type: VQL
        name: Test JSON renderer
        template: |
          /* Test the JSON renderer. */
          LET Strings = SELECT "Hello World" AS A FROM range(end=100)

          LET MultiColumn = SELECT * FROM chain(a={
            SELECT 1 AS A FROM range(end=10)
          }, b={
            SELECT 1 AS B FROM range(end=10)
          })

          SELECT dict(
            MultiColumn=MultiColumn,
            Strings=Strings.A,
            `NULL`=NULL,
            Bool=TRUE,
            BoolF=FALSE,
            BinaryData=base64encode(string="hello world"),
            Rows={
              SELECT count() AS Count,
                     rand() AS R
              FROM range(end=20)
            },
            Integer=1, Float=1.235,
            LongString="Hello world " * 100,
            MixedList=[1, 2, dict(A=3)],
            NestedDict=dict(
                Foo=dict(A=1,
                         B=dict(z=1,
                                nesting=dict(Foo="Hello world"))))) AS A
          FROM scope()

      - type: VQL
        name: Test Links
        template: |
          /*
          # Test the link_to() VQL Function
          */
          LET ColumnTypes &lt;= dict(
            LinkToFlow="url_internal",
            LinkToHunt="url_internal",
            LinkToArtifact="url_internal",
            Download="url_internal",
            LinkToClient="url_internal")

          LET s = scope()
          LET Uploaded &lt;= upload(accessor="data", file="Hello", name="test.txt")

          SELECT link_to(client_id=ClientId, flow_id=s.FlowId || "F.123") AS LinkToFlow,
                 link_to(client_id=ClientId) AS LinkToClient,
                 link_to(hunt_id=s.HuntId || "H.123") AS LinkToHunt,
                 link_to(artifact=ArtifactName) AS LinkToArtifact,
                 link_to(upload=Uploaded) AS Download
          FROM scope()

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.events.trackprocesses.md
======
---
title: Windows.Events.TrackProcesses
hidden: true
tags: [Client Event Artifact]
---

This artifact uses sysmon and pslist to keep track of running
processes using the Velociraptor process tracker.

The Process Tracker keeps track of exited processes, and resolves
process callchains from it in memory cache.

This event artifact enables the global process tracker and makes it
possible to run many other artifacts that depend on the process
tracker.


<pre><code class="language-yaml">
name: Windows.Events.TrackProcesses
description: |
  This artifact uses sysmon and pslist to keep track of running
  processes using the Velociraptor process tracker.

  The Process Tracker keeps track of exited processes, and resolves
  process callchains from it in memory cache.

  This event artifact enables the global process tracker and makes it
  possible to run many other artifacts that depend on the process
  tracker.

type: CLIENT_EVENT

tools:
  - name: SysmonBinary
    url: https://live.sysinternals.com/tools/sysmon64.exe
    serve_locally: true

  - name: SysmonConfig
    url: https://raw.githubusercontent.com/SwiftOnSecurity/sysmon-config/master/sysmonconfig-export.xml
    serve_locally: true

parameters:
  - name: AlsoForwardUpdates
    type: bool
    description: |
      If set we also send process tracker state updates to
      the server.
  - name: MaxSize
    type: int64
    description: Maximum size of the in memory process cache (default 10k)

  - name: SysmonFileLocation
    description: If set, we check this location first for sysmon installed.
    default: C:/Windows/sysmon64.exe

  - name: AddEnrichments
    type: bool
    description: Add process information enrichments (can use more resources)

sources:
  - precondition:
      SELECT OS From info() where OS = 'windows'

    query: |
      // Make sure sysmon is installed.
      LET _ &lt;= SELECT * FROM Artifact.Windows.Sysinternals.SysmonInstall(
         SysmonFileLocation=SysmonFileLocation)

      LET UpdateQuery =
            SELECT * FROM foreach(row={
              SELECT *,
                     get(member='EventData') AS EventData
              FROM watch_etw(
                guid='{5770385f-c22a-43e0-bf4c-06f5698ffbd9}',
                description='Microsoft-Windows-Sysmon/Operational')
            }, query={
              SELECT * FROM switch(
              start={
                SELECT EventData.ProcessId AS id,
                       EventData.ParentProcessId AS parent_id,
                       "start" AS update_type,

                       -- We need to manually build the dict here so
                       -- we can maintain column ordering.
                       dict(
                           Pid=EventData.ProcessId,
                           Ppid=EventData.ParentProcessId,
                           Name=split(sep_string="\\", string=EventData.Image)[-1],
                           StartTime=EventData.UtcTime,
                           EndTime=NULL,
                           Username=EventData.User,
                           Exe=EventData.Image,
                           CommandLine= EventData.CommandLine,
                           CurrentDirectory= EventData.CurrentDirectory,
                           FileVersion=EventData.FileVersion,
                           Description= EventData.Description,
                           Company= EventData.Company,
                           Product= EventData.Product,
                           ParentImage= EventData.ParentImage,
                           ParentCommandLine= EventData.ParentCommandLine,
                           TerminalSessionId= EventData.TerminalSessionId,
                           IntegrityLevel= EventData.IntegrityLevel,
                           Hashes=parse_string_with_regex(regex=[
                             "SHA256=(?P&lt;SHA256&gt;[^,]+)",
                             "MD5=(?P&lt;MD5&gt;[^,]+)",
                             "IMPHASH=(?P&lt;IMPHASH&gt;[^,]+)"],
                           string=EventData.Hashes)
                       ) AS data,
                       EventData.UtcTime AS start_time,
                       NULL AS end_time
                FROM scope()
                WHERE System.ID = 1
              },
              end={
                SELECT EventData.ProcessId AS id,
                       NULL AS parent_id,
                       "exit" AS update_type,
                       dict() AS data,
                       NULL AS start_time,
                       EventData.UtcTime AS end_time
                FROM scope()
                WHERE System.ID = 5
              })
            })

      LET SyncQuery =
              SELECT Pid AS id,
                 Ppid AS parent_id,
                 CreateTime AS start_time,
                 dict(
                   Name=Name,
                   Username=Username,
                   Exe=Exe,
                   CommandLine=CommandLine) AS data
              FROM pslist()

      LET Tracker &lt;= process_tracker(
         max_size=MaxSize,
         enrichments=if(condition=AddEnrichments, then=[
           '''x=&gt;if(
                condition=NOT x.Data.VersionInformation AND x.Data.Image,
                then=dict(VersionInformation=parse_pe(file=x.Data.Image).VersionInformation))
           ''',
           '''x=&gt;if(
                condition=NOT x.Data.OriginalFilename OR x.Data.OriginalFilename = '-',
                then=dict(OriginalFilename=x.Data.VersionInformation.OriginalFilename))
           '''], else=[]),
        sync_query=SyncQuery, update_query=UpdateQuery, sync_period=60000)

      SELECT * FROM process_tracker_updates()
      WHERE update_type = "stats" OR AlsoForwardUpdates

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/linux.network.packetcapture.md
======
---
title: Linux.Network.PacketCapture
hidden: true
tags: [Client Artifact]
---

This artifact leverages tcpdump to natively capture packets.

The `Duration` parameter is used to define how long (in seconds) the capture should be.  Specific interfaces can be defined using the `Interface` parameter, otherwise the artifact defaults to an interface assignment of `any`.

A `BPF` (Berkeley Packet Filter) expression can also be supplied to filter the captured traffic as desired.

Read more about BPF expressions here: https://biot.com/capstats/bpf.html


<pre><code class="language-yaml">
name: Linux.Network.PacketCapture
author: Wes Lambert, @therealwlambert
description: |
  This artifact leverages tcpdump to natively capture packets.

  The `Duration` parameter is used to define how long (in seconds) the capture should be.  Specific interfaces can be defined using the `Interface` parameter, otherwise the artifact defaults to an interface assignment of `any`.

  A `BPF` (Berkeley Packet Filter) expression can also be supplied to filter the captured traffic as desired.
  
  Read more about BPF expressions here: https://biot.com/capstats/bpf.html

required_permissions:
  - EXECVE

parameters:
  - name: Duration
    type: integer
    description: Duration (in seconds) of PCAP to be recorded.
    default: 10
  
  - name: Interface
    type: string
    default: any

  - name: BPF
    type: string
    default:
    
precondition:
  SELECT * FROM info() where OS = 'linux'

sources:
    - query: |
            LET pcap &lt;= tempfile(extension=".pcap")
            SELECT *, upload(file=pcap) AS PCAP
              FROM execve(argv=['bash', '-c', format(format='''(tcpdump -nni %v -w %v %v) &amp; sleep %v; kill $!''', args=[Interface, pcap, BPF, Duration])], length=1000000)

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/server.internal.huntmodification.md
======
---
title: Server.Internal.HuntModification
hidden: true
tags: [Internal Artifact]
---

An internal queue to watch modifications of hunts. The hunt
dispatcher from all nodes sends this mutation to the hunt manager
which applies it.


<pre><code class="language-yaml">
name: Server.Internal.HuntModification
description: |
  An internal queue to watch modifications of hunts. The hunt
  dispatcher from all nodes sends this mutation to the hunt manager
  which applies it.

type: INTERNAL

column_types:
  - name: HuntId
  - name: Mutation
    type: json

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/server.utils.timesketchupload.md
======
---
title: Server.Utils.TimesketchUpload
hidden: true
tags: [Server Artifact]
---

Timesketch is an interactive collaborative timeline analysis tool
that can be found at https://timesketch.org/

This artifact uploads Velociraptor's timelines to Timesketch using
the Timesketch client library. The artifact assumes the client
library is installed and configured on the server.

To install the Timesketch client library:
```
pip install timesketch-import-client timesketch-cli-client
```

To configure the client library to access your Timesketch instance
see instructions https://timesketch.org/guides/user/cli-client/ and
https://timesketch.org/guides/user/upload-data/

This artifact assumes that the timesketch CLI is preconfigured with
the correct credentials in the `.timesketchrc` file.


<pre><code class="language-yaml">
name: Server.Utils.TimesketchUpload
description: |
  Timesketch is an interactive collaborative timeline analysis tool
  that can be found at https://timesketch.org/

  This artifact uploads Velociraptor's timelines to Timesketch using
  the Timesketch client library. The artifact assumes the client
  library is installed and configured on the server.

  To install the Timesketch client library:
  ```
  pip install timesketch-import-client timesketch-cli-client
  ```

  To configure the client library to access your Timesketch instance
  see instructions https://timesketch.org/guides/user/cli-client/ and
  https://timesketch.org/guides/user/upload-data/

  This artifact assumes that the timesketch CLI is preconfigured with
  the correct credentials in the `.timesketchrc` file.

required_permissions:
  - EXECVE

parameters:
  - name: NotebookId
    description: The notebook ID that contains the super timeline
  - name: SuperTimeline
    description: The name of the super timeline
  - name: Timeline
    description: The name of the timeline within the super timeline.
  - name: TimesketchCLICommand
    default: "timesketch"
    description: |
      The path to the timesketch cli binary. If you installed in a
      virtual environment this will be inside that environment.

type: SERVER

export: |
  LET timesketch_import_command = TimesketchCLICommand + "_importer"

  -- The uploader tool can create a new "Sketch" but if we want to
  -- just add a timeline to an existing sketch we need to specify the
  -- ID. This function finds the ID for the specified Sketch if it
  -- exists. NOTE that you can have multiple Sketches with the same
  -- name! We pick the first.
  LET GetIdToSketch(Sketch) = SELECT * FROM foreach(row={
    SELECT Stdout
      FROM execve(
          argv=[TimesketchCLICommand, "--output-format",
              "json", "sketch", "list"], length=10000)
  }, query={
    SELECT * FROM parse_json_array(data=Stdout)
  })
  WHERE name = Sketch

  -- Enumerate all the timelines in a super timeline
  LET _GetAllTimelines(SuperTimelineName, NotebookId) = SELECT *
   FROM foreach(row={
     SELECT *
     FROM timelines(notebook_id=NotebookId)
     WHERE name = SuperTimelineName
  }, query={ SELECT * FROM timelines })

  LET _GetTimelineMetdata(SuperTimelineName, NotebookId, TimelineName) =
  SELECT * FROM _GetAllTimelines(
      SuperTimelineName=SuperTimelineName, NotebookId=NotebookId)
  WHERE Id = TimelineName

  -- Gets the metadata of a named timeline
  LET GetTimelineMetdata(SuperTimelineName, NotebookId, TimelineName) =
     _GetTimelineMetdata(SuperTimelineName= SuperTimelineName,
                         NotebookId = NotebookId,
                         TimelineName=TimelineName)[0]

  -- Timesketch insists the file have the .csv extension.
  LET tmp &lt;= tempfile(extension=".csv")

  -- We copy the timeline to a temp csv file then upload that. This
  -- might seem inefficient but timesketch is written in python so it
  -- is already very slow. The extra tempfile does not make much
  -- difference in practice.
  LET WriteTmpFile(NotebookId, SuperTimelineName, TimelineName) =
       SELECT count() AS Count
       FROM write_csv(filename=tmp, query={
          SELECT Timestamp as timestamp, Message as message, *
          FROM timeline(notebook_id=NotebookId, timeline=SuperTimelineName,
                        components=TimelineName)
       })
       GROUP BY 1

  LET ImportToTS(SuperTimelineName, NotebookId, TimelineName, SketchName) =
  SELECT * FROM chain(a={
     SELECT format(format="Exporting %v rows to %v", args=[WriteTmpFile(
       NotebookId=NotebookId, SuperTimelineName=SuperTimelineName,
       TimelineName=TimelineName)[0].Count, tmp]) AS Stdout
     FROM scope()
  }, c={
    SELECT * FROM foreach(row={

      -- This is unfortunately slow and unnecessary but Timesketch
      -- does not have a flag that just says - add timeline to
      -- existing sketch. So we have to type to find the sketch ID
      -- first.
      SELECT GetIdToSketch(Sketch=SketchName)[0].id || 0 AS SketchID
      FROM scope()

    }, query={

      -- Launch the import library and display the output.
      SELECT Stdout, Stderr, SketchID,
             SketchName, TimelineName
      FROM execve(argv=[timesketch_import_command, "--sketch_name",
                        SketchName, "--sketch_id", SketchID,
                        "--timeline_name", TimelineName,
                        tmp], sep="\n")
    })
  })

sources:
  - query: |
      SELECT * FROM ImportToTS(
         SuperTimelineName=SuperTimelineName,
         NotebookId=NotebookId,
         TimelineName=TimelineName,
         SketchName=SketchName)

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/server.import.updatedbuiltin.md
======
---
title: Server.Import.UpdatedBuiltin
hidden: true
tags: [Server Artifact]
---

This artifact allows importing updated versions of some common built
in artifacts. If you do not want to wait for the next full release
you can use this artifact to import a more recent version of some
select artifacts which might include later feature.

NOTE: There is no guarantees that the updated artifact will work on
an older version. Make sure to test properly.


<pre><code class="language-yaml">
name: Server.Import.UpdatedBuiltin
description: |
  This artifact allows importing updated versions of some common built
  in artifacts. If you do not want to wait for the next full release
  you can use this artifact to import a more recent version of some
  select artifacts which might include later feature.

  NOTE: There is no guarantees that the updated artifact will work on
  an older version. Make sure to test properly.

type: SERVER

required_permissions:
- SERVER_ADMIN

parameters:
  - name: PackageName
    type: choices
    default: Windows.KapeFiles.Targets
    choices:
      - Windows.KapeFiles.Targets
      - Generic.Forensic.SQLiteHunter

  - name: Prefix
    description: Add artifacts with this prefix
    default: Updated.

sources:
  - query: |
      LET URLlookup = dict(
        `Windows.KapeFiles.Targets`="https://raw.githubusercontent.com/Velocidex/velociraptor/master/artifacts/definitions/Windows/KapeFiles/Targets.yaml",
        `Generic.Forensic.SQLiteHunter`="https://raw.githubusercontent.com/Velocidex/SQLiteHunter/main/output/SQLiteHunter.yaml"
      )

      SELECT artifact_set(definition=Content, prefix="Updated.") AS Artifact
      FROM http_client(url=get(item=URLlookup, field=PackageName))
      WHERE Response = 200

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.system.powershell.psreadline.md
======
---
title: Windows.System.Powershell.PSReadline
hidden: true
tags: [Client Artifact]
---

This Artifact will search and extract lines from PSReadline history file.

Powershell is commonly used by attackers across all stages of the attack
lifecycle. The PSReadline module is responsible for command history and from
Powershell 5 on Windows 10 default configuration saves a copy of the console
history to disk.

There are several parameter's available for search leveraging regex.
- SearchStrings enables regex search over a PSReadline line.
- StringWhiteList enables a regex whitelist for results.
- UserRegex enables a regex search on Username
- UploadFiles enables upload ConsoleHost_history.txt in scope


<pre><code class="language-yaml">
name: Windows.System.Powershell.PSReadline
description: |
  This Artifact will search and extract lines from PSReadline history file.

  Powershell is commonly used by attackers across all stages of the attack
  lifecycle. The PSReadline module is responsible for command history and from
  Powershell 5 on Windows 10 default configuration saves a copy of the console
  history to disk.

  There are several parameter's available for search leveraging regex.
  - SearchStrings enables regex search over a PSReadline line.
  - StringWhiteList enables a regex whitelist for results.
  - UserRegex enables a regex search on Username
  - UploadFiles enables upload ConsoleHost_history.txt in scope


author: Matt Green - @mgreen27

reference:
  - https://attack.mitre.org/techniques/T1059/001/
  - https://0xdf.gitlab.io/2018/11/08/powershell-history-file.html

type: CLIENT

parameters:
  - name: ConsoleHostHistory
    default: \AppData\Roaming\Microsoft\Windows\PowerShell\PSReadLine\ConsoleHost_history.txt
  - name: SearchStrings
    default: .
    type: regex
  - name: StringWhiteList
    default:
    type: regex
  - name: UserRegex
    default: .
    type: regex
  - name: UploadFiles
    description: "Upload ConsoleHost_history.txt files in scope"
    type: bool

precondition:
  SELECT OS From info() where OS = 'windows'

sources:
  - query: |
        -- First extract target ConsoleHost_history path for each user
        LET targets = SELECT Name as Username,
           { SELECT Mtime, Atime, Ctime, Btime, Size, OSPath
             FROM stat(filename=expand(path=Directory) + ConsoleHostHistory)
           } AS Stat
        FROM Artifact.Windows.Sys.Users()
        WHERE Directory and Username =~ UserRegex AND Stat.OSPath

        -- Extract targets PSReadline entries
        SELECT * FROM foreach(
        row=targets,
        query={
            SELECT Stat, count() AS LineNum,
                   Line,
                   Username,
                   Stat.OSPath AS OSPath
            FROM parse_lines(filename=Stat.OSPath)
            WHERE LineNum
             AND Line =~ SearchStrings
             AND NOT if(condition=StringWhiteList,
                        then=Line =~ StringWhiteList,
                        else=FALSE)
        })

  - name: Upload
    query: |
        -- if configured upload ConsoleHost_history.txt in results
        SELECT * FROM if(condition=UploadFiles,
            then={
                SELECT
                    Username,
                    upload(file=Stat.OSPath) as ConsoleHost_history
                FROM targets
            })

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/linux.sys.bashhistory.md
======
---
title: Linux.Sys.BashHistory
hidden: true
tags: [Client Artifact]
---

This artifact enables grep of Bash and alternate shell history files.

It can also be used to target other files located in the user profile such as
*_profile and *rc files.
shell history: /{root,home/*}/.*_history
profile: /{root,home/*}/.*_profile
*rc file: /{root,home/*}/.*rc

tags: .bash_history .bash_profile .bashrc


<pre><code class="language-yaml">
name: Linux.Sys.BashHistory
author: "Matt Green - @mgreen27"
description: |
  This artifact enables grep of Bash and alternate shell history files.

  It can also be used to target other files located in the user profile such as
  *_profile and *rc files.
  shell history: /{root,home/*}/.*_history
  profile: /{root,home/*}/.*_profile
  *rc file: /{root,home/*}/.*rc

  tags: .bash_history .bash_profile .bashrc


parameters:
  - name: TargetGlob
    default: /{root,home/*}/.*_history
  - name: SearchRegex
    type: regex
    description: "Regex of strings to search in line."
    default: '.'
  - name: WhitelistRegex
    type: regex
    description: "Regex of strings to leave out of output."
    default:

sources:
  - query: |
      LET files = SELECT OSPath FROM glob(globs=TargetGlob)

      SELECT * FROM foreach(row=files,
          query={
              SELECT Line, OSPath FROM parse_lines(filename=OSPath)
              WHERE
                Line =~ SearchRegex
                AND NOT if(condition= WhitelistRegex,
                    then= Line =~ WhitelistRegex,
                    else= FALSE)
          })

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.eventlogs.telerik.md
======
---
title: Windows.EventLogs.Telerik
hidden: true
tags: [Client Artifact]
---

This Artifact will hunt for evidence of Telerik exploitation in the Application
Event Log.

Telerik is a commonly exploited component of IIS web pages that has been
actively targeted by actors via several CVEs. Several tools and attack
capabilities exist making exploitation of vulnerable services trivial. Due to
the nature of the software and typical deployments the patches may require
manual application.

IocRegex enables searching for regex in the whole EventData field.
Output of this artifact is targeted fields from EventID 1309 to provide
context for the hit.

This Artifact will hunt for evidence of Telerik exploitation in the Application Event Log.


<pre><code class="language-yaml">
name: Windows.EventLogs.Telerik
description: |
  This Artifact will hunt for evidence of Telerik exploitation in the Application
  Event Log.

  Telerik is a commonly exploited component of IIS web pages that has been
  actively targeted by actors via several CVEs. Several tools and attack
  capabilities exist making exploitation of vulnerable services trivial. Due to
  the nature of the software and typical deployments the patches may require
  manual application.

  IocRegex enables searching for regex in the whole EventData field.
  Output of this artifact is targeted fields from EventID 1309 to provide
  context for the hit.

  This Artifact will hunt for evidence of Telerik exploitation in the Application Event Log.

author: Matt Green - @mgreen27

reference:
  - https://www.cyber.gov.au/acsc/view-all-content/advisories/advisory-2020-004-remote-code-execution-vulnerability-being-actively-exploited-vulnerable-versions-telerik-ui-sophisticated-actors
  - https://attack.mitre.org/techniques/T1190/

parameters:
  - name: EvtxGlob
    default: '%SystemRoot%\System32\Winevt\Logs\Application.evtx'
  - name: IocRegex
    description: "IOC Regex"
    default: telerik.*\\?type=rau
    type: regex
  - name: WhitelistRegex
    description: "Regex of string to witelist"
    type: regex
  - name: VSSAnalysisAge
    type: int
    default: 0
    description: |
      If larger than zero we analyze VSS within this many days
      ago. (e.g 7 will analyze all VSS within the last week).  Note
      that when using VSS analysis we have to use the ntfs accessor
      for everything which will be much slower.
  - name: DateAfter
    type: timestamp
    description: "search for events after this date. YYYY-MM-DDTmm:hh:ssZ"
  - name: DateBefore
    type: timestamp
    description: "search for events before this date. YYYY-MM-DDTmm:hh:ssZ"

sources:
  - precondition: SELECT OS From info() where OS = 'windows'

    query: |
      LET VSS_MAX_AGE_DAYS &lt;= VSSAnalysisAge
      LET Accessor = if(condition=VSSAnalysisAge &gt; 0, then="ntfs_vss", else="auto")

      -- firstly set timebounds for performance
      LET DateAfterTime &lt;= if(condition=DateAfter,
        then = DateAfter, else = "1600-01-01" )
      LET DateBeforeTime &lt;= if(condition=DateBefore,
        then = DateBefore, else = "2200-01-01" )

      -- expand provided glob into a list of paths on the file system (fs)
      LET fspaths = SELECT OSPath
        FROM glob(globs=expand(path=EvtxGlob), accessor=Accessor)

      -- function returning IOC hits
      LET evtxsearch(PathList) = SELECT * FROM foreach(
            row=PathList,
            query={
                SELECT
                    timestamp(epoch=int(int=System.TimeCreated.SystemTime)) AS EventTime,
                    System.Computer as Computer,
                    System.Channel as Channel,
                    System.EventID.Value as EventID,
                    System.EventRecordID as EventRecordID,
                    EventData.Data[17] as Exception,
                    EventData.Data[16] as User,
                    EventData.Data[15] as Process,
                    EventData.Data[14] as Pid,
                    EventData.Data[21] as SourceIP,
                    EventData.Data[19] as Uri,
                    EventData.Data[11] as SitePath,
                    OSPath
                FROM parse_evtx(filename=OSPath, accessor=Accessor)
                WHERE EventID = 1309
                    AND format(format='%v',args=EventData.Data) =~ IocRegex
                    AND NOT if(condition=WhitelistRegex,
                        then= format(format='%v',args=EventData.Data) =~ WhitelistRegex,
                        else= FALSE )
                    AND EventTime &gt;= DateAfterTime AND EventTime &lt;= DateBeforeTime
            }
          )

        SELECT * FROM evtxsearch(PathList=fspaths)

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.detection.thumbdrives.list.md
======
---
title: Windows.Detection.Thumbdrives.List
hidden: true
tags: [Client Event Artifact]
---

Users inserting Thumb drives or other Removable drive pose a
constant security risk. The external drive may contain malware or
other undesirable content. Additionally thumb drives are an easy way
for users to exfiltrate documents.

This artifact watches for any removable drives and provides a
complete file listing to the server for any new drive inserted. It
also provides information about any addition to the thumb drive
(e.g. a new file copied onto the drive).

We exclude very large removable drives since they might have too
many files.


<pre><code class="language-yaml">
name: Windows.Detection.Thumbdrives.List
description: |
  Users inserting Thumb drives or other Removable drive pose a
  constant security risk. The external drive may contain malware or
  other undesirable content. Additionally thumb drives are an easy way
  for users to exfiltrate documents.

  This artifact watches for any removable drives and provides a
  complete file listing to the server for any new drive inserted. It
  also provides information about any addition to the thumb drive
  (e.g. a new file copied onto the drive).

  We exclude very large removable drives since they might have too
  many files.

type: CLIENT_EVENT

parameters:
  - name: maxDriveSize
    type: int
    description: We ignore removable drives larger than this size in bytes.
    default: "32000000000"


sources:
  - query: |
        LET removable_disks = SELECT Name AS Drive,
            atoi(string=Data.Size) AS Size
        FROM glob(globs="/*", accessor="file")
        WHERE Data.Description =~ "Removable" AND Size &lt; atoi(string=maxDriveSize)

        LET file_listing = SELECT OSPath,
            Mtime As Modified,
            Size
        FROM glob(globs=Drive+"\\**", accessor="file")
        LIMIT 1000

        SELECT * FROM diff(
          query={
             SELECT * FROM foreach(
                 row=removable_disks,
                 query=file_listing)
          },
          key="OSPath",
          period=10)
          WHERE Diff = "added"

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.system.powershell.md
======
---
title: Windows.System.PowerShell
hidden: true
tags: [Client Artifact]
---

This artifact allows running arbitrary commands through the system
powershell.

Since Velociraptor typically runs as system, the commands will also
run as System.

This is a very powerful artifact since it allows for arbitrary
command execution on the endpoints. Therefore this artifact requires
elevated permissions (specifically the `EXECVE`
permission). Typically it is only available with the `administrator`
role.

Note that in addition to running PowerShell cmdlets and scripts, the
Windows.System.PowerShell artifact can also be used to launch
Windows command-line executables with their parameters. This can be
difficult to achieve with the Windows.System.CmdShell artifact due
to complications with spaces in paths and other special character
issues. This PowerShell artifact is able to avoid most of these
problems by encoding the command in Base64.

As an example, the following command initiates a Windows Defender AV
quick-scan from the default location, which includes a path with
spaces in it:

```
  & 'C:\Program Files\Windows Defender\MpCmdRun.exe' -Scan -ScanType 1
```


<pre><code class="language-yaml">
name: Windows.System.PowerShell
description: |
  This artifact allows running arbitrary commands through the system
  powershell.

  Since Velociraptor typically runs as system, the commands will also
  run as System.

  This is a very powerful artifact since it allows for arbitrary
  command execution on the endpoints. Therefore this artifact requires
  elevated permissions (specifically the `EXECVE`
  permission). Typically it is only available with the `administrator`
  role.

  Note that in addition to running PowerShell cmdlets and scripts, the
  Windows.System.PowerShell artifact can also be used to launch
  Windows command-line executables with their parameters. This can be
  difficult to achieve with the Windows.System.CmdShell artifact due
  to complications with spaces in paths and other special character
  issues. This PowerShell artifact is able to avoid most of these
  problems by encoding the command in Base64.

  As an example, the following command initiates a Windows Defender AV
  quick-scan from the default location, which includes a path with
  spaces in it:

  ```
    &amp; 'C:\Program Files\Windows Defender\MpCmdRun.exe' -Scan -ScanType 1
  ```

required_permissions:
  - EXECVE

precondition:
  SELECT OS From info() where OS = 'windows'

parameters:
  - name: Command
    default: "dir C:/"
  - name: PowerShellExe
    default: "C:\\Windows\\System32\\WindowsPowerShell\\v1.0\\powershell.exe"

sources:
  - query: |
      SELECT * FROM execve(argv=[PowerShellExe,
        "-ExecutionPolicy", "Unrestricted", "-encodedCommand",
        base64encode(string=utf16_encode(string=Command))
      ])

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/server.utils.backupdirectory.md
======
---
title: Server.Utils.BackupDirectory
hidden: true
tags: [Server Event Artifact]
---

This server monitoring artifact will automatically export and
backup selected collected artifacts to a directory on the server.


<pre><code class="language-yaml">
name: Server.Utils.BackupDirectory
description: |
   This server monitoring artifact will automatically export and
   backup selected collected artifacts to a directory on the server.

type: SERVER_EVENT

parameters:
   - name: ArtifactNameRegex
     default: "."
     description: A regular expression to select which artifacts to upload
     type: regex

   - name: BackupDirectoryPath
     description: A directory on the server to receive the uploaded files.

   - name: RemoveDownloads
     type: bool
     description: If set, remove the flow export files after upload

required_permissions:
  - SERVER_ADMIN

sources:
  - query: |
      LET completions = SELECT *,
         client_info(client_id=ClientId).os_info.fqdn AS Fqdn,
         create_flow_download(client_id=ClientId,
             flow_id=FlowId, wait=TRUE) AS FlowDownload
      FROM watch_monitoring(artifact="System.Flow.Completion")
      WHERE Flow.artifacts_with_results =~ ArtifactNameRegex

      SELECT upload_directory(
         output=BackupDirectoryPath,
         name=format(format="Host %v %v %v.zip",
                     args=[Fqdn, FlowId, timestamp(epoch=now())]),
         accessor="fs",
         file=FlowDownload) AS Upload
      FROM completions
      WHERE Upload OR
        if(condition=RemoveDownloads,
           then=rm(filename=file_store(path=FlowDownload)))

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.system.pslist.md
======
---
title: Windows.System.Pslist
hidden: true
tags: [Client Artifact]
---

List processes and their running binaries.


<pre><code class="language-yaml">
name: Windows.System.Pslist
description: |
  List processes and their running binaries.

parameters:
  - name: ProcessRegex
    default: .
    type: regex
  - name: PidRegex
    default: .
    type: regex
  - name: ExePathRegex
    default: .
    type: regex
  - name: CommandLineRegex
    default: .
    type: regex
  - name: UsernameRegex
    default: .
    type: regex
  - name: UntrustedAuthenticode
    description: Show only Executables that are not trusted by Authenticode.
    type: bool
  - name: UseTracker
    type: bool
    description: If set we use the process tracker.
  - name: DISABLE_DANGEROUS_API_CALLS
    type: bool
    description: |
      Enable this to disable potentially flakey APIs which may cause
      crashes.

sources:
  - precondition: SELECT OS From info() where OS = 'windows'

    query: |
        LET ProcList = SELECT * FROM if(condition=UseTracker,
        then={
          SELECT Pid, Ppid, NULL AS TokenIsElevated,
                 Username, Name, CommandLine, Exe, NULL AS Memory
          FROM process_tracker_pslist()
        }, else={
          SELECT * FROM pslist()
        })

        SELECT Pid, Ppid, TokenIsElevated, Name, CommandLine, Exe,
            token(pid=int(int=Pid)) as TokenInfo,
            hash(path=Exe) as Hash,
            authenticode(filename=Exe) AS Authenticode,
            Username, Memory.WorkingSetSize AS WorkingSetSize
        FROM ProcList
        WHERE Name =~ ProcessRegex
            AND Pid =~ PidRegex
            AND Exe =~ ExePathRegex
            AND CommandLine =~ CommandLineRegex
            AND Username =~ UsernameRegex
            AND NOT if(condition= UntrustedAuthenticode,
                        then= Authenticode.Trusted = 'trusted' OR NOT Exe,
                        else= False )

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.detection.yara.uefi.md
======
---
title: Windows.Detection.Yara.UEFI
hidden: true
tags: [Client Artifact]
---

This artifact enables running yara over files in an EFI System Partition (ESP).


<pre><code class="language-yaml">
name: Windows.Detection.Yara.UEFI
author: Matt Green - @mgreen27
description: |
  This artifact enables running yara over files in an EFI System Partition (ESP).
  

parameters:
  - name: ImagePath
    default: \\.\PhysicalDrive0
    description: Raw Device for main disk containing partition table to parse.
  - name: SectorSize
    type: int
    default: 512
  - name: TargetGlob
    default: "**/*.efi"
  - name: SizeMax
    description: maximum size of target file.
    type: int64
  - name: SizeMin
    description: minimum size of target file.
    type: int64
  - name: UploadHits
    type: bool
  - name: DateAfter
    type: timestamp
    description: "search for events after this date. YYYY-MM-DDTmm:hh:ssZ"
  - name: DateBefore
    type: timestamp
    description: "search for events before this date. YYYY-MM-DDTmm:hh:ssZ"
  - name: YaraUrl
    description: If configured will attempt to download Yara rules form Url
    type: upload
  - name: YaraRule
    type: yara
    description: Final Yara option and the default if no other options provided.
    default: |
            rule win_blacklotus_auto {
                meta:
                    author = "Felix Bilstein - yara-signator at cocacoding dot com"
                    date = "2023-07-11"
                    description = "Detects win.blacklotus."
                strings:
                    $sequence_0 = { 498bcf e8???????? 448bc0 498bd7 4d03c0 488bce }
                    $sequence_1 = { 4c897020 55 488d68c8 4881ec30010000 4c8bd1 }
                    $sequence_2 = { 488b0d???????? 4c8d054e140100 488bd7 488bd8 e8???????? 488b05???????? 488bcb }
                    $sequence_3 = { 8b0c91 498bd2 4903c9 e8???????? }
                    $sequence_4 = { 4585d2 743f 8b05???????? 4103c1 }
                    $sequence_5 = { 4883ec20 488d7910 8bea 488b1f 33f6 }
                    $sequence_6 = { 488bd9 b10e e8???????? 8a4b02 40b70d }
                    $sequence_7 = { 410f47f7 8bc6 488b742460 4883c430 415f }
                    $sequence_8 = { 4923d3 4803d1 440fb74a0c 440fb7520e }
                    $sequence_9 = { 6642837cc11010 0f859d000000 428b54c114 41bbffffff7f 4923d3 }
                condition:
                    7 of them and filesize &lt; 181248
            }
            rule MAL_Rootkit_CosmicStrand
            {
                meta:
                	author = "Natalie Zargarov @ Rapid7"
                    description = "CosmicStrand UEFI rootkit detection rule. Detects the compromised .efi driver "
                    targeting = "process,efi"
                    tags ="Rootkit"
                strings:
                    $trait_0 = {89 C6 53 89 D8 BB 3F B8 11 03}
                    $trait_1 = {8B 3D 18 10 01 00 33 DB 8D 45 F8 50 53 53 6A 0B}
                    $trait_2= {83 EC 4C 53 57 68 A0 10 01 00 8D 45 F8}
                    $trait_3= {53 81 C7 FF 0F 00 00 68 54 44 55 00 81 E7 00 F0 FF FF 57 6A 01}
                    $trait_4= {50 68 08 08 08 08 68 D0 43 DE DE 68 1F 96 00 00 BF E4 10 01 00}
                    $string_0 = "winlogon.exe" 
                condition:
                    1 of ($trait_*) and 
                    1 of ($string_*)
            }
  - name: NumberOfHits
    description: This artifact will stop by default at one hit. This setting allows additional hits
    default: 1
    type: int
  - name: ContextBytes
    description: Include this amount of bytes around hit as context.
    default: 0
    type: int

sources:
- query: |
      -- check which Yara to use
      LET yara_rules &lt;= YaraUrl || YaraRule

      -- time testing
      LET time_test(stamp) =
            if(condition= DateBefore AND DateAfter,
                then= stamp &lt; DateBefore AND stamp &gt; DateAfter,
                else=
            if(condition=DateBefore,
                then= stamp &lt; DateBefore,
                else=
            if(condition= DateAfter,
                then= stamp &gt; DateAfter,
                else= True
            )))
            
      LET find_efi = SELECT StartOffset,EndOffset,
            Size AS PartitionSize,
            name AS PartitionName
       FROM Artifact.Windows.Forensics.PartitionTable(
          ImagePath=ImagePath, SectorSize=SectorSize)
      WHERE PartitionName =~ "EFI"
      
      LET find_files = SELECT * FROM foreach(row=find_efi, 
        query={
            SELECT *,
                StartOffset,EndOffset,
                PartitionSize,
                PartitionName
            FROM glob(globs=TargetGlob,
                accessor="fat",
                root=pathspec(
                    DelegateAccessor="offset",
                    DelegatePath=pathspec(
                        DelegateAccessor="raw_file",
                        DelegatePath=ImagePath,
                        Path=format(format="%d", args=StartOffset))))
        })
      
      LET target_files = SELECT 
            StartOffset as PartitionOffset, PartitionSize,
            OSPath,
            Size, Mtime, Atime, Ctime, Btime,
            Data.first_cluster as FirstCluster,
            Data.attr AS Attr,
            Data.deleted as IsDeleted,
            Data.short_name AS ShortName
        FROM find_files
        WHERE NOT IsDir
            AND if(condition=SizeMin,
                        then= SizeMin &lt; Size,
                        else= True)
            AND if(condition=SizeMax,
                        then= SizeMax &gt; Size,
                        else= True)
            AND ( time_test(stamp=Mtime)
                    OR time_test(stamp=Atime)
                    OR time_test(stamp=Ctime)
                    OR time_test(stamp=Btime))
        
      -- scan files and prepare hit metadata
      LET hits = SELECT * FROM foreach(row=target_files,
        query={
            SELECT 
                OSPath as _OSPath,
                OSPath.Path as OSPath,
                File.Size as Size,
                Mtime, Atime, Ctime, Btime,
                Rule, Tags, Meta,
                String.Name as YaraString,
                String.Offset as HitOffset,
                upload( accessor='scope',
                        file='String.Data',
                        name=format(format="%v-%v-%v",
                        args=[
                            OSPath.Path,
                            if(condition= String.Offset - ContextBytes &lt; 0,
                                then= 0,
                                else= String.Offset - ContextBytes),
                            if(condition= String.Offset + ContextBytes &gt; Size,
                                then= Size,
                                else= String.Offset + ContextBytes) ]
                        )) as HitContext
            FROM yara( accessor='fat', rules=yara_rules,files=OSPath,
                    context=ContextBytes,number=NumberOfHits )
        })
      
      -- upload files if selected
      LET upload_hits = SELECT *, 
            upload(accessor='fat',file=_OSPath,name=_OSPath.Path) as Upload 
        FROM hits

      -- return rows
      SELECT * FROM if(condition= UploadHits,
                        then= upload_hits,
                        else= hits )

column_types:
  - name: HitContext
    type: preview_upload
</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.analysis.evidenceofexecution.md
======
---
title: Windows.Analysis.EvidenceOfExecution
hidden: true
tags: [Client Artifact]
---

In many investigations it is useful to find evidence of program execution.

This artifact combines the findings of several other collectors into
an overview of all program execution artifacts. The associated
report walks the user through the analysis of the findings.


<pre><code class="language-yaml">
name: Windows.Analysis.EvidenceOfExecution
description: |
  In many investigations it is useful to find evidence of program execution.

  This artifact combines the findings of several other collectors into
  an overview of all program execution artifacts. The associated
  report walks the user through the analysis of the findings.

sources:
  - name: UserAssist
    query: |
      SELECT * FROM Artifact.Windows.Registry.UserAssist()

  - name: Amcache
    query: |
      SELECT * FROM Artifact.Windows.Detection.Amcache()

  - name: Timeline
    query: |
      SELECT * FROM Artifact.Windows.Forensics.Timeline()

  - name: ShimCache
    query: |
      SELECT * FROM Artifact.Windows.Registry.AppCompatCache()

  - name: Prefetch
    query: |
      SELECT * FROM Artifact.Windows.Forensics.Prefetch()

  - name: Recent Apps
    query: |
      SELECT * FROM Artifact.Windows.Forensics.RecentApps()

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/server.internal.clienttasks.md
======
---
title: Server.Internal.ClientTasks
hidden: true
tags: [Internal Artifact]
---

This event will be fired when a client has new tasks scheduled.


<pre><code class="language-yaml">
name: Server.Internal.ClientTasks
description: |
  This event will be fired when a client has new tasks scheduled.

type: INTERNAL
column_types:
  - name: ClientId

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.applications.firefox.downloads.md
======
---
title: Windows.Applications.Firefox.Downloads
hidden: true
tags: [Client Artifact]
---

Enumerate the users Firefox downloads.

## NOTES:

This artifact is deprecated in favor of
Generic.Forensic.SQLiteHunter and will be removed in future


<pre><code class="language-yaml">
name: Windows.Applications.Firefox.Downloads
description: |
  Enumerate the users Firefox downloads.

  ## NOTES:

  This artifact is deprecated in favor of
  Generic.Forensic.SQLiteHunter and will be removed in future

author: |
  Angry-Bender @angry-bender, based on
  Custom.Windows.Application.Firefox.History by Zach Stanford @svch0st

parameters:
  - name: placesGlobs
    default: \AppData\Roaming\Mozilla\Firefox\Profiles\*\places.sqlite
  - name: urlSQLQuery
    default: |
        SELECT * FROM moz_annos,moz_anno_attributes,moz_places WHERE moz_annos.place_id=moz_places.id AND moz_annos.anno_attribute_id=moz_anno_attributes.id
  - name: userRegex
    default: .
    type: regex
  - name: URLRegex
    default: .
    type: regex

precondition: SELECT OS From info() where OS = 'windows'

sources:
  - query: |
        LET places_files = SELECT * from foreach(
          row={
             SELECT Uid, Name AS User,
                    expand(path=Directory) AS HomeDirectory
             FROM Artifact.Windows.Sys.Users()
             WHERE Name =~ userRegex
          },
          query={
             SELECT User, OSPath, Mtime
             FROM glob(root=HomeDirectory, globs=placesGlobs)
          })

        LET metadata = SELECT * FROM foreach(row=places_files,
          query={
            SELECT parse_json(data=content)
            FROM sqlite(
              file=OSPath,
              query=urlSQLQuery)
             WHERE name = 'downloads/metaData'
          })

        SELECT * FROM foreach(row=places_files,
          query={
            SELECT User,
                   timestamp(epoch=dateAdded) as startTime,
                   if(condition=name=~'metaData',
                    then=timestamp(epoch=parse_json(data=content).endTime)
                    ) AS endTime,
                   timestamp(epoch=lastModified) as last_modified,
                   id,
                   name,
                   url,
                   place_id,
                   if(condition=name=~'metaData',
                    then=parse_json(data=content).fileSize
                    ) AS fileSize,
                   if(condition=name=~'metaData',
                    then=parse_json(data=content).state
                    ) AS state,
                   if(condition=name=~'destinationFileURI',
                    then=content
                    ) AS localDirectory,
                   flags,
                   expiration,
                   type
            FROM sqlite(
              file=OSPath,
              query=urlSQLQuery)
            ORDER BY last_modified DESC
          })
          WHERE url =~ URLRegex

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/server.utils.addtimeline.md
======
---
title: Server.Utils.AddTimeline
hidden: true
tags: [Server Artifact]
---

Adds a new timeline to a super timeline.


<pre><code class="language-yaml">
name: Server.Utils.AddTimeline
description: |
  Adds a new timeline to a super timeline.

type: SERVER

parameters:
  - name: NotebookId
  - name: Timeline
    description: SuperTimeline name
  - name: ChildName
    description: Name of child timeline
  - name: Query
    description: A query that will be parsed and run.
  - name: Key
    description: Sort column for time
  - name: MessageColumn
    description: The name of the column to appear as the message
  - name: RemoveLimit
    description: If specified, we remove the limit clause before adding to the timeline.
    type: bool
  - name: Env
    type: json

sources:
  - query: |
      SELECT timeline_add(
         notebook_id=NotebookId,
         timeline=Timeline,
         name=ChildName,
         message_column=MessageColumn,
         query={
           SELECT * FROM query(query=if(condition=RemoveLimit,
             then=regex_replace(re="(?i)LIMIT [0-9]+", replace="", source=Query),
             else=Query), env=Env)
         },
         key=Key), RemoveLimit
      FROM scope()

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/generic.forensic.localhashes.glob.md
======
---
title: Generic.Forensic.LocalHashes.Glob
hidden: true
tags: [Client Artifact]
---

This artifact maintains a local (client side) database of file
hashes. It is then possible to query this database using the
Generic.Forensic.LocalHashes.Query artifact

Maintaining hashes client side allows Velociraptor to answer the
query - which machine has this hash on our network extremely
quickly. Velociraptor only needs to lookup the each client's local
database of file hashes.

Maintaining this database case be done using this artifact or using
the Windows.Forensics.LocalHashes.Usn artifact.

This artifact simply crawls the filesystem hashing files as
specified by the glob expression, and adds them to the local hash
database. You can rate limit this artifact using the ops/sec setting
to perform a slow update of the local file hash database.


<pre><code class="language-yaml">
name: Generic.Forensic.LocalHashes.Glob
description: |
  This artifact maintains a local (client side) database of file
  hashes. It is then possible to query this database using the
  Generic.Forensic.LocalHashes.Query artifact

  Maintaining hashes client side allows Velociraptor to answer the
  query - which machine has this hash on our network extremely
  quickly. Velociraptor only needs to lookup the each client's local
  database of file hashes.

  Maintaining this database case be done using this artifact or using
  the Windows.Forensics.LocalHashes.Usn artifact.

  This artifact simply crawls the filesystem hashing files as
  specified by the glob expression, and adds them to the local hash
  database. You can rate limit this artifact using the ops/sec setting
  to perform a slow update of the local file hash database.

parameters:
  - name: HashGlob
    description: Search for files according to this glob and hash them.
    default: C:/Users/**/*.exe

  - name: HashDb
    description: Name of the local hash database
    default: hashdb.sqlite

  - name: SuppressOutput
    description: If this is set, the artifact does not return any rows to the server but will still update the local database.
    type: bool

sources:
  - query: |
      LET hash_db &lt;= SELECT OSPath
      FROM Artifact.Generic.Forensic.LocalHashes.Init(HashDb=HashDb)

      LET path &lt;= hash_db[0].OSPath

      LET _ &lt;= log(message="Will use local hash database " + path)

      // Crawl the files and calculate their hashes
      LET files = SELECT OSPath, Size, hash(path=OSPath).MD5 AS Hash
      FROM glob(globs=HashGlob)
      WHERE Mode.IsRegular

      LET insertion = SELECT OSPath, Hash, Size, {
         SELECT * FROM sqlite(file=path,
            query="INSERT into hashes (path, md5, timestamp, size) values (?,?,?,?)",
            args=[OSPath.String, Hash, now(), Size])
      } AS Insert
      FROM files
      WHERE Insert OR TRUE

      SELECT OSPath, Hash, Size
      FROM insertion
      WHERE NOT SuppressOutput

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.detection.impersonation.md
======
---
title: Windows.Detection.Impersonation
hidden: true
tags: [Client Artifact]
---

An access token is an object that describes the security context of
a process or thread. The information in a token includes the
identity and privileges of the user account associated with the
process or thread. When a user logs on, the system verifies the
user's password by comparing it with information stored in a
security database.

Every process has a primary token that describes the security
context of the user account associated with the process. By default,
the system uses the primary token when a thread of the process
interacts with a securable object. Moreover, a thread can
impersonate a client account. Impersonation allows the thread to
interact with securable objects using the client's security
context. A thread that is impersonating a client has both a primary
token and an impersonation token.

This artfiact enumerates all threads on the system which have an
impersonation token. I.e. they are operating with a different token
then the token the entire process has. For example mimikatz has a
command called `token::elevate` to do just such a thing:

```
mimikatz # privilege::debug
Privilege '20' OK

mimikatz # token::elevate
Token Id  : 0
User name :
SID name  : NT AUTHORITY\SYSTEM

688     {0;000003e7} 1 D 42171          NT AUTHORITY\SYSTEM     S-1-5-18        (04g,21p)       Primary
-> Impersonated !
* Process Token : {0;000195ad} 1 F 757658339   DESKTOP-NHNHT65\mic     S-1-5-21-2310288903-2791442386-3035081252-1001  (15g,24p)       Primary
* Thread Token  : {0;000003e7} 1 D 759094260   NT AUTHORITY\SYSTEM     S-1-5-18        (04g,21p)       Impersonation (Delegation)
```


<pre><code class="language-yaml">
name: Windows.Detection.Impersonation
description: |
  An access token is an object that describes the security context of
  a process or thread. The information in a token includes the
  identity and privileges of the user account associated with the
  process or thread. When a user logs on, the system verifies the
  user's password by comparing it with information stored in a
  security database.

  Every process has a primary token that describes the security
  context of the user account associated with the process. By default,
  the system uses the primary token when a thread of the process
  interacts with a securable object. Moreover, a thread can
  impersonate a client account. Impersonation allows the thread to
  interact with securable objects using the client's security
  context. A thread that is impersonating a client has both a primary
  token and an impersonation token.

  This artfiact enumerates all threads on the system which have an
  impersonation token. I.e. they are operating with a different token
  then the token the entire process has. For example mimikatz has a
  command called `token::elevate` to do just such a thing:

  ```
  mimikatz # privilege::debug
  Privilege '20' OK

  mimikatz # token::elevate
  Token Id  : 0
  User name :
  SID name  : NT AUTHORITY\SYSTEM

  688     {0;000003e7} 1 D 42171          NT AUTHORITY\SYSTEM     S-1-5-18        (04g,21p)       Primary
  -&gt; Impersonated !
  * Process Token : {0;000195ad} 1 F 757658339   DESKTOP-NHNHT65\mic     S-1-5-21-2310288903-2791442386-3035081252-1001  (15g,24p)       Primary
  * Thread Token  : {0;000003e7} 1 D 759094260   NT AUTHORITY\SYSTEM     S-1-5-18        (04g,21p)       Impersonation (Delegation)
  ```
reference:
  - https://github.com/kslgroup/TokenImp-Token_Impersonation_Detection/blob/master/TokenImp%20documentation.pdf


precondition: SELECT OS From info() where OS = 'windows'

sources:
  - query: |
      LET processes = SELECT Pid AS ProcPid, Name AS ProcName,
               Username, OwnerSid, TokenIsElevated,
               CommandLine, Exe
        FROM pslist()
        WHERE log(message=format(format="Inspecting %s (%v)", args=[ProcName, Pid]))

      SELECT * FROM foreach(row=processes,
          query={
             // List all the threads and check that their tokens are the
             // same as the process token.
             SELECT ProcPid, ProcName, Username, OwnerSid, TokenIsElevated,
               CommandLine, Exe, ThreadInfo.TokenInfo AS ImpersonationToken
             FROM handles(pid=ProcPid, types='Thread')
             WHERE ImpersonationToken.User AND ImpersonationToken.User != OwnerSid
          })

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.persistence.permanentwmievents.md
======
---
title: Windows.Persistence.PermanentWMIEvents
hidden: true
tags: [Client Artifact]
---

This artifact reports currently deployed permanent WMI Event Consumers. The 
artifact collects Binding information, then presents associated Filters 
and Consumers.

NOTE: the artifact does not report on individual eventing classes. A seperate 
wmi query will need to be made for unlinked components that may reside in the 
WMI datastore.  

WMI Eventing components:  

- __FilterToConsumerBinding - ties together Filter + Consumer
- __EventFilter - trigger condition
- __EventConsumer - payload


<pre><code class="language-yaml">
name: Windows.Persistence.PermanentWMIEvents
author: Matt Green - @mgreen27
description: |
    This artifact reports currently deployed permanent WMI Event Consumers. The 
    artifact collects Binding information, then presents associated Filters 
    and Consumers.
    
    NOTE: the artifact does not report on individual eventing classes. A seperate 
    wmi query will need to be made for unlinked components that may reside in the 
    WMI datastore.  

    WMI Eventing components:  
    
    - __FilterToConsumerBinding - ties together Filter + Consumer
    - __EventFilter - trigger condition
    - __EventConsumer - payload

reference:
  - https://attack.mitre.org/techniques/T1546/003/

parameters:
  - name: AllRootNamespaces
    description: Select to scan all ROOT namespaces. This setting over rides specific namespaces configured below.
    type: bool
  - name: Namespaces
    description: Add a list of target namespaces.
    type: csv
    default: |
       namespace
       root/subscription
       root/default

sources:
  - precondition:
      SELECT OS From info() where OS = 'windows'

    query: |
      LET namespaces &lt;= SELECT * FROM if(condition=AllRootNamespaces, 
            then= { 
                SELECT 'root/' + Name as namespace 
                FROM wmi(namespace='ROOT',query='SELECT * FROM __namespace' )
                WHERE namespace
            },
            else= Namespaces )
    
      LET FilterToConsumerBinding &lt;= SELECT * FROM foreach(
            row=namespaces,
            query={
                SELECT parse_string_with_regex(string=Consumer,
                    regex=['((?P&lt;namespace&gt;^[^:]+):)?(?P&lt;Type&gt;.+?)\\.Name="(?P&lt;Name&gt;.+)"']) as Consumer,
                    parse_string_with_regex(string=Filter,regex=['((?P&lt;namespace&gt;^[^:]+):)?(?P&lt;Type&gt;.+?)\\.Name="(?P&lt;Name&gt;.+)"']) as Filter
                FROM wmi(
                    query="SELECT * FROM __FilterToConsumerBinding",namespace=namespace)
        },workers=len(list=namespaces))
        
      SELECT * FROM foreach(
            row=namespaces,
            query={
                 SELECT {
                     SELECT * FROM wmi(
                       query="SELECT * FROM " + Consumer.Type,
                       namespace=if(condition=Consumer.namespace,
                          then=Consumer.namespace,
                          else=namespace)) WHERE Name = Consumer.Name
                   } AS ConsumerDetails,
                   {
                     SELECT * FROM wmi(
                       query="SELECT * FROM " + Filter.Type,
                       namespace=if(condition=Filter.namespace,
                          then=Filter.namespace,
                          else=namespace)) WHERE Name = Filter.Name
                   } AS FilterDetails,
                   namespace as Namespace
                 FROM FilterToConsumerBinding
                 WHERE (FilterDetails OR ConsumerDetails)
            },workers=len(list=namespaces))
</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/server.internal.interrogate.md
======
---
title: Server.Internal.Interrogate
hidden: true
tags: [Server Event Artifact]
---

An internal artifact used track new client interrogations by the
Interrogation service.


<pre><code class="language-yaml">
name: Server.Internal.Interrogate
description: |
  An internal artifact used track new client interrogations by the
  Interrogation service.

type: SERVER_EVENT

sources:
  - query: |
      SELECT * FROM foreach(
          row={
             SELECT ClientId, Flow, FlowId
             FROM watch_monitoring(artifact='System.Flow.Completion')
             WHERE Flow.artifacts_with_results =~ 'Generic.Client.Info'
          },
          query={
            SELECT * FROM switch(
              a={
                  SELECT ClientId,
                    FlowId,
                    Architecture,
                    BuildTime,
                    Fqdn,
                    Hostname,
                    KernelVersion,
                    Labels,
                    Name,
                    OS,
                    Platform,
                    PlatformVersion
                 FROM source(
                    client_id=ClientId,
                    flow_id=FlowId,
                    source="BasicInformation",
                    artifact="Custom.Generic.Client.Info")
               },
            b={
                SELECT ClientId,
                  FlowId,
                  Architecture,
                  BuildTime,
                  Fqdn,
                  Hostname,
                  KernelVersion,
                  Labels,
                  Name,
                  OS,
                  Platform,
                  PlatformVersion
               FROM source(
                  client_id=ClientId,
                  flow_id=FlowId,
                  source="BasicInformation",
                  artifact="Generic.Client.Info")
            })
          })

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/notebooks.timelines.md
======
---
title: Notebooks.Timelines
hidden: true
tags: [notebook]
---

The notebook creates a default Super-Timeline.

Timelines are used to visualize time series data from other
collections in the same place. This notebook template creates an
initial timeline.

Once this timeline is created, you can add any time series table in
other notebooks (e.g. Collection or Hunt notebooks) to this super
timeline.


<pre><code class="language-yaml">
name: Notebooks.Timelines
description: |
  The notebook creates a default Super-Timeline.

  Timelines are used to visualize time series data from other
  collections in the same place. This notebook template creates an
  initial timeline.

  Once this timeline is created, you can add any time series table in
  other notebooks (e.g. Collection or Hunt notebooks) to this super
  timeline.

type: NOTEBOOK

parameters:
  - name: TimelineName
    description: The name of the super timeline to create.
    default: Supertimeline

sources:
  - notebook:
      - type: markdown
        name: Timeline Description
        template: |
          # {{ Scope "TimelineName" }}

          Add to this timeline any time-series data from any other
          notebooks:

          1. Click the `Add Timeline` button at the top of any table.
          2. Switch to global notebook timelines and select this timeline.
          3. Select the timestamp and message columns to add a timeline.

          {{ Scope "TimelineName" | Timeline }}

      - type: vql
        name: Timeline Interactive Cell
        template: |
          /*
          # Timeline Annotations

          Refresh this to list all timeline annotations as a table.
          */
          SELECT *
          FROM timeline(notebook_id=NotebookId,
                        components="Annotation",
                        timeline=TimelineName)
          ORDER BY Timestamp

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/linux.triage.processmemory.md
======
---
title: Linux.Triage.ProcessMemory
hidden: true
tags: [Client Artifact]
---

Dump process memory and upload to the server


<pre><code class="language-yaml">
name: Linux.Triage.ProcessMemory
description: |
  Dump process memory and upload to the server

precondition: SELECT OS From info() where OS = 'linux'

parameters:
  - name: processPid
    type: int
    default: 2215

column_types:
  - name: CrashDump
    type: preview_upload

sources:
  - query: |
      SELECT Name as ProcessName, CommandLine, Pid,
             upload(file=format(format="/%d", args=processPid),
                    accessor="process") as CrashDump
      FROM pslist(pid=processPid)

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/server.internal.usermanager.md
======
---
title: Server.Internal.UserManager
hidden: true
tags: [Internal Artifact]
---

An internal artifact notifying when user accounts are modified.


<pre><code class="language-yaml">
name: Server.Internal.UserManager
type: INTERNAL
description: |
  An internal artifact notifying when user accounts are modified.

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/generic.client.trace.md
======
---
title: Generic.Client.Trace
hidden: true
tags: [Client Artifact]
---

This artifact collects profiling information about the running
client. The artifact is automatically added when the GUI selects a
non zero Trace frequency.

NOTE: You can also add the artifact directly, but then you will need
to cancel the collection manually since it will continue to run
until the timeout is reached.

Minimum Version: 0.6.8


<pre><code class="language-yaml">
name: Generic.Client.Trace
description: |
  This artifact collects profiling information about the running
  client. The artifact is automatically added when the GUI selects a
  non zero Trace frequency.

  NOTE: You can also add the artifact directly, but then you will need
  to cancel the collection manually since it will continue to run
  until the timeout is reached.

  Minimum Version: 0.6.8

parameters:
- name: FrequencySec
  type: int
  default: 10

sources:
- query: |
    SELECT * FROM if(condition=version(function="trace"),
    then={
       SELECT trace() AS TraceFile
       FROM clock(start=0, period=FrequencySec)
    })

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.eventlogs.servicecreationcomspec.md
======
---
title: Windows.EventLogs.ServiceCreationComspec
hidden: true
tags: [Client Artifact]
---


This Detection hts on the string "COMSPEC" (nocase) in Windows Service
Creation events. That is: EventID 7045 from the System event log.

This detects many hack tools that leverage SCM based lateral movement
including smbexec.

SearchVSS allows querying VSS instances of EventLog Path with event
deduplication.


<pre><code class="language-yaml">
name: Windows.EventLogs.ServiceCreationComspec
description: |

  This Detection hts on the string "COMSPEC" (nocase) in Windows Service
  Creation events. That is: EventID 7045 from the System event log.

  This detects many hack tools that leverage SCM based lateral movement
  including smbexec.

  SearchVSS allows querying VSS instances of EventLog Path with event
  deduplication.

author: Matt Green - @mgreen27

parameters:
  - name: EventLog
    default: C:\Windows\system32\winevt\logs\System.evtx
  - name: ComspecRegex
    default: "(COMSPEC|cmd.exe|ADMIN\\$)"
    type: regex

  - name: VSSAnalysisAge
    type: int
    default: 0
    description: |
      If larger than zero we analyze VSS within this many days
      ago. (e.g 7 will analyze all VSS within the last week).  Note
      that when using VSS analysis we have to use the ntfs accessor
      for everything which will be much slower.

sources:
  - name: ServiceCreation
    query: |
      LET VSS_MAX_AGE_DAYS &lt;= VSSAnalysisAge
      LET Accessor = if(condition=VSSAnalysisAge &gt; 0, then="ntfs_vss", else="auto")

      // Extract all target paths from glob
      LET files = SELECT OSPath
      FROM glob(globs=EventLog, accessor=Accessor)

      // Parse all target files, order by source and add dedupe string
      LET hits = SELECT * FROM foreach(
              row=files,
              query={
                SELECT timestamp(epoch=System.TimeCreated.SystemTime) as EventTime,
                  System.EventID.Value as EventID,
                  System.Computer as Computer,
                  System.Security.UserID as SecurityID,
                  EventData.AccountName as ServiceAccount,
                  EventData.ServiceName as ServiceName,
                  EventData.ImagePath as ImagePath,
                  EventData.ServiceType as ServiceType,
                  EventData.StartType as StartType,
                  System.EventRecordID as EventRecordID,
                  System.Level as Level,
                  System.Opcode as Opcode,
                  System.Task as Task,
                  OSPath AS Source
                FROM parse_evtx(filename=OSPath, accessor=Accessor)
                WHERE System.EventID.Value = 7045 and
                  EventData.ImagePath =~ ComspecRegex
            })
            ORDER BY Source DESC

      SELECT
            EventTime,
            EventID,
            Computer,
            SecurityID,
            ServiceAccount,
            ServiceName,
            ImagePath,
            ServiceType,
            StartType,
            EventRecordID,
            Source
        FROM hits

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.persistence.wow64cpu.md
======
---
title: Windows.Persistence.Wow64cpu
hidden: true
tags: [Client Artifact]
---

Checks for wow64cpu.dll replacement Autorun in Windows 10.
http://www.hexacorn.com/blog/2019/07/11/beyond-good-ol-run-key-part-108-2/


<pre><code class="language-yaml">
name: Windows.Persistence.Wow64cpu
description: |
  Checks for wow64cpu.dll replacement Autorun in Windows 10.
  http://www.hexacorn.com/blog/2019/07/11/beyond-good-ol-run-key-part-108-2/

author: Matt Green - @mgreen27

parameters:
   - name: TargetRegKey
     default: HKEY_LOCAL_MACHINE\Software\Microsoft\Wow64\**
sources:
  - precondition:
      SELECT OS From info() where OS = 'windows'

    query: |
      SELECT OSPath.Dirname as KeyPath,
        Name as KeyName,
        Data.value as Value,
        Mtime AS LastModified
      FROM glob(globs=split(string=TargetRegKey, sep=","), accessor="registry")
      WHERE Data.value and
        not (Name = "@" and (Data.value =~ "(wow64cpu.dll|wowarmhw.dll|xtajit.dll)"))

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.persistence.powershellregistry.md
======
---
title: Windows.Persistence.PowershellRegistry
hidden: true
tags: [Client Artifact]
---

A common way of persistence is to install a hook into a user profile
registry hive, using powershell. When the user logs in, the
powershell script downloads a payload and executes it.

This artifact searches the user's profile registry hive for
signatures related to general Powershell execution. We use a yara
signature specifically targeting the user's profile which we extract
using raw NTFS parsing (in case the user is currently logged on and
the registry hive is locked).


<pre><code class="language-yaml">
name: Windows.Persistence.PowershellRegistry
description: |
  A common way of persistence is to install a hook into a user profile
  registry hive, using powershell. When the user logs in, the
  powershell script downloads a payload and executes it.

  This artifact searches the user's profile registry hive for
  signatures related to general Powershell execution. We use a yara
  signature specifically targeting the user's profile which we extract
  using raw NTFS parsing (in case the user is currently logged on and
  the registry hive is locked).

parameters:
  - name: yaraRule
    type: yara
    default: |
      rule PowerShell {
        strings:
          $a = /ActiveXObject.{,500}eval/ wide nocase

        condition:
          any of them
      }
  - name: userRegex
    default: .
    type: regex

sources:
  - precondition:
      SELECT OS From info() where OS = 'windows'
    query: |
        SELECT * from foreach(
        row={
          SELECT Name,
                 expand(path=Directory) AS HomeDir
          FROM Artifact.Windows.Sys.Users()
          WHERE HomeDir and Gid AND Name =~ userRegex
        },
        query={
          SELECT File.OSPath As OSPath,
                 String.Offset AS Off,
                 String.HexData As Hex,
                 upload(file=File.FullPath, accessor="auto") AS Upload
              FROM yara(
              files=HomeDir + "\\ntuser.dat",
              rules=yaraRule, context=50)
        })

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.search.vss.md
======
---
title: Windows.Search.VSS
hidden: true
tags: [Client Artifact]
---

This artifact will find all relevant files in the VSS. Typically
used to out deduplicated paths for processing by other artifacts.

NOTE: This used to be more complicated but now delegates to the
"ntfs_vss" accessor to do all the work.


<pre><code class="language-yaml">
name: Windows.Search.VSS
description: |
  This artifact will find all relevant files in the VSS. Typically
  used to out deduplicated paths for processing by other artifacts.

  NOTE: This used to be more complicated but now delegates to the
  "ntfs_vss" accessor to do all the work.

author: Matt Green - @mgreen27

precondition: SELECT * FROM info() where OS = 'windows'

parameters:
  - name: SearchFilesGlob
    default: C:\Windows\System32\winevt\Logs\Security.evtx
    description: Use a glob to define the files that will be searched.

  - name: VSS_MAX_AGE_DAYS
    type: int
    description: |
      If larger than 0 we restrict VSS age to this many days
      ago. Otherwise we find all VSS.

sources:
  - query: |
      SELECT * FROM glob(globs=SearchFilesGlob, accessor="ntfs_vss")
      ORDER BY OSPath

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.timeline.prefetch.md
======
---
title: Windows.Timeline.Prefetch
hidden: true
tags: [Client Artifact]
---

Windows keeps a cache of prefetch files. When an executable is run,
the system records properties about the executable to make it faster
to run next time. By parsing this information we are able to
determine when binaries are run in the past. On Windows10 we can see
the last 8 execution times and creation time (9 potential executions).

This artifact is a timelined output version of the standard Prefetch
artifact. There are several parameter's availible.
  - dateAfter enables search for prefetch evidence after this date.
  - dateBefore enables search for prefetch evidence before this date.
  - binaryRegex enables to filter on binary name, e.g evil.exe.
  - hashRegex enables to filter on prefetch hash.


<pre><code class="language-yaml">
name: Windows.Timeline.Prefetch
author: Matt Green - @mgreen27
description: |
  Windows keeps a cache of prefetch files. When an executable is run,
  the system records properties about the executable to make it faster
  to run next time. By parsing this information we are able to
  determine when binaries are run in the past. On Windows10 we can see
  the last 8 execution times and creation time (9 potential executions).

  This artifact is a timelined output version of the standard Prefetch
  artifact. There are several parameter's availible.
    - dateAfter enables search for prefetch evidence after this date.
    - dateBefore enables search for prefetch evidence before this date.
    - binaryRegex enables to filter on binary name, e.g evil.exe.
    - hashRegex enables to filter on prefetch hash.

reference:
  - https://www.forensicswiki.org/wiki/Prefetch

parameters:
    - name: prefetchGlobs
      default: C:\Windows\Prefetch\*.pf
    - name: dateAfter
      description: "search for events after this date. YYYY-MM-DDTmm:hh:ssZ"
      type: timestamp
    - name: dateBefore
      description: "search for events before this date. YYYY-MM-DDTmm:hh:ssZ"
      type: timestamp
    - name: binaryRegex
      description: "Regex of executable name."
      type: regex
    - name: hashRegex
      description: "Regex of prefetch hash."
      type: regex

precondition: SELECT OS From info() where OS = 'windows'

sources:
  - query: |
      LET hostname &lt;= SELECT Fqdn FROM info()

      SELECT  LastRunTimes as event_time,
              hostname.Fqdn[0] as hostname,
              "Prefetch" as parser,
              message,
              OSPath as source,
              Executable as file_name,
              CreationTime as prefetch_ctime,
              ModificationTime as prefetch_mtime,
              FileSize as prefetch_size,
              Hash as prefetch_hash,
              Version as prefetch_version,
              PrefetchFileName as prefetch_file,
              RunCount as prefetch_count
      FROM foreach(
      row={
        SELECT *
        FROM Artifact.Windows.Forensics.Prefetch(
          prefetchGlobs=prefetchGlobs,
          dateAfter=dateAfter,
          dateBefore=dateBefore,
          binaryRegex=binaryRegex,
          hashRegex=hashRegex)
      },
      query={
        SELECT *
        FROM chain(a1={
           SELECT *
           FROM flatten(query={
            SELECT Executable,
                   FileSize,
                   Hash,
                   Version,
                   LastRunTimes,
                   "Evidence of Execution: " + Executable + format(
                      format=" Prefetch run count %v", args=RunCount) as message,
                   RunCount,
                   OSPath,
                   PrefetchFileName,
                   CreationTime,
                   ModificationTime,
                   Binary
            FROM scope()
          })
        }, b1={
            -- One more row for creation time
            SELECT Executable,
                   FileSize,
                   Hash,
                   Version,
                   CreationTime AS LastRunTimes,
                   "Evidence of Execution (Btime): " + Executable + format(
                      format=" Prefetch run count %v", args=RunCount) as message,
                   RunCount,
                   OSPath,
                   PrefetchFileName,
                   CreationTime,
                   ModificationTime,
                   Binary
            FROM scope()
        })
        -- This group by applies on only a single prefetch file to
        -- remove duplication with CreationTime
        GROUP BY LastRunTimes
      })
      ORDER BY event_time

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.timeline.registry.runmru.md
======
---
title: Windows.Timeline.Registry.RunMRU
hidden: true
tags: [Client Artifact]
---

# Output all available RunMRU registry keys in timeline format.

RunMRU is when a user enters a command into the START > Run prompt.
Entries will be logged in the user hive under:    Software\Microsoft\Windows\CurrentVersion\Explorer\RunMRU

The artifact numbers all entries with the most recent at
reg_mtime starting at 0. Second recent 1, Third recent 2 etc.

Default output enables a line per MRU entry.
A tickbox enables Grouped results with order in a single line.

Note: This artifact will collect RunMRU from ntuser.dat files and
may exclude very recent entries in transaction (HKCU).  Future
versions of this content will address this gap.


<pre><code class="language-yaml">
name: Windows.Timeline.Registry.RunMRU
description: |
    # Output all available RunMRU registry keys in timeline format.

    RunMRU is when a user enters a command into the START &gt; Run prompt.
    Entries will be logged in the user hive under:    Software\Microsoft\Windows\CurrentVersion\Explorer\RunMRU

    The artifact numbers all entries with the most recent at
    reg_mtime starting at 0. Second recent 1, Third recent 2 etc.

    Default output enables a line per MRU entry.
    A tickbox enables Grouped results with order in a single line.

    Note: This artifact will collect RunMRU from ntuser.dat files and
    may exclude very recent entries in transaction (HKCU).  Future
    versions of this content will address this gap.

author: Matt Green - @mgreen27

precondition: SELECT OS From info() where OS = 'windows'

parameters:
  - name: KeyGlob
    type: hidden
    default: Software\Microsoft\Windows\CurrentVersion\Explorer\RunMRU\MRUList
  - name: dateAfter
    description: "search for events after this date. YYYY-MM-DDTmm:hh:ss Z"
    type: timestamp
  - name: dateBefore
    description: "search for events before this date. YYYY-MM-DDTmm:hh:ss Z"
    type: timestamp
  - name: targetUser
    description: "target user regex"
    type: regex
  - name: regexValue
    description: "regex search over RunMRU values."
    type: regex
  - name: groupResults
    description: "groups MRU entries to one message line"
    type: bool

sources:
 - query: |
        LET hostname_lu &lt;= SELECT Fqdn FROM info()
        LET HKEY_USERS &lt;= pathspec(parse="HKEY_USERS", path_type="registry")

        // First we need to extract populated RunMRU
        LET MRUList &lt;= SELECT OSPath,
           Data.value as RunMruOrder,
           len(list=Data.value) as RunMruLength,
           Username,
           UUID
        FROM Artifact.Windows.Registry.NTUser(KeyGlob=KeyGlob)

        // Now extract RunMRU entries and order
        LET results &lt;= SELECT * FROM foreach(
           row=MRUList,
           query={
             SELECT
                OSPath.DelegatePath as source,
                Username,
                Mtime as reg_mtime,
                OSPath.Basename as reg_name,
                HKEY_USERS + UUID + OSPath.Dirname.Path as reg_key,

                -- Value data is similar to 'cmd.exe\1' so we just need the bit before the \
                regex_replace(source=Data.value, re="\\\\1$", replace="") as reg_value,
                Data.type as reg_type,
                RunMruLength - 1 - len(list=regex_replace(
                   source=RunMruOrder,
                   re="^.*" + OSPath.Basename,
                   replace="")) as mru_order,
                RunMruOrder
             FROM glob(globs='*', root=OSPath.Dirname, accessor="raw_reg")
             WHERE not reg_name = "MRUList" AND
                    if(condition=targetUser, then=Username =~ targetUser,
                        else=TRUE) AND
                    if(condition=dateAfter, then=reg_mtime &gt; timestamp(string=dateAfter),
                        else=TRUE) AND
                    if(condition=dateBefore, then=reg_mtime &lt; timestamp(string=dateBefore),
                        else=TRUE)
                    AND log(message=UUID)
             ORDER BY mru_order
          })

        // join mru values and order for presentation
        LET usercommands &lt;= SELECT Username as user, mru_order,
                format(format="MRU%v: %v", args=[mru_order,reg_value]) as mru_grouped
        FROM results

        // Prepare join use case
        LET joinOut = SELECT
                reg_mtime as event_time,
                hostname_lu[0].Fqdn as hostname,
                "RunMRU" as parser,
                "RunMRU evidence user: " + Username + ", " +
                  join(array=mru_grouped, sep=" | ")  + "'" as message,
                source,
                Username as user
        FROM foreach(row=usercommands,
            query={
                SELECT *, Username,
                    {
                        SELECT mru_grouped
                        FROM usercommands
                        WHERE user = Username
                        ORDER BY mru_grouped
                    } as mru_grouped
                FROM results
                ORDER BY mru_grouped
            })
        GROUP BY source

        // Prepare split use case
        LET splitOut = SELECT
                    reg_mtime as event_time,
                    hostname_lu.Fqdn[0] as hostname,
                    "RunMRU" as parser,
                    "RunMRU evidence user: " + Username +
                        format(format=", order: %v, command: %v", args=[mru_order,reg_value])
                            + "'" as message,
                    source,
                    Username as user,
                    reg_key,
                    reg_mtime,
                    reg_name,
                    reg_value,
                    reg_type
            FROM results

        // Print out chosen usecase
        SELECT *
        FROM if(condition=groupResults,
            then={ SELECT * FROM joinOut},
            else={ SELECT * FROM splitOut})
        WHERE if(condition=regexValue, then=message =~ regexValue, else=TRUE)

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/linux.events.trackprocesses.md
======
---
title: Linux.Events.TrackProcesses
hidden: true
tags: [Client Event Artifact]
---

This artifact uses ebpf and pslist to keep track of running
processes using the Velociraptor process tracker.

The process tracker keeps track of exited processes, and resolves
process call chains from it in memory cache.

This event artifact enables the global process tracker and makes it
possible to run many other artifacts that depend on the process
tracker.

NOTE: Unlike Windows.Events.TrackProcesses, the eBPF program is
already built into Velociraptor so this artifact does not depend on
external tools.


<pre><code class="language-yaml">
name: Linux.Events.TrackProcesses
description: |
  This artifact uses ebpf and pslist to keep track of running
  processes using the Velociraptor process tracker.

  The process tracker keeps track of exited processes, and resolves
  process call chains from it in memory cache.

  This event artifact enables the global process tracker and makes it
  possible to run many other artifacts that depend on the process
  tracker.

  NOTE: Unlike Windows.Events.TrackProcesses, the eBPF program is
  already built into Velociraptor so this artifact does not depend on
  external tools.

precondition: |
  SELECT OS From info() where OS = 'linux'

type: CLIENT_EVENT

parameters:
  - name: AlsoForwardUpdates
    type: bool
    description: Upload all tracker state updates to the server
  - name: MaxSize
    type: int64
    description: Maximum size of the in-memory process cache (default 10k)

sources:
  - query: |
      LET SyncQuery = SELECT
         Pid AS id,
         Ppid AS parent_id,
         CreateTime AS start_time,
         dict(Name=Name,
              Username=Username,
              Exe=Exe,
              CreateTime=CreateTime,
              CommandLine=CommandLine) AS data
      FROM pslist()

      LET UpdateQuery = SELECT * FROM foreach(
        row={
          SELECT * FROM watch_ebpf(events=["sched_process_exit", "sched_process_exec"])
        }, query={
          SELECT * FROM switch(a={
            SELECT System.ProcessID AS id,
                    System.ParentProcessID AS parent_id,
                    "start" AS update_type,
                    dict(Pid=System.ProcessID,
                         Ppid=System.ParentProcessID,
                         Name=System.ProcessName,
                         Username=System.UserID,
                         Exe=EventData.cmdpath,
                         CommandLine=join(array=EventData.argv, sep=" ")) AS data,

                    System.Timestamp AS start_time,
                    NULL AS end_time
            FROM scope()
            WHERE System.EventName =~ "exec"
          }, end={
            SELECT System.ProcessID AS id,
                   NULL AS parent_id,
                   "exit" AS update_type,
                   dict() AS data,
                   NULL AS start_time,
                   System.Timestamp AS end_time
            FROM scope()
            WHERE System.EventName =~ "exit"
          })
        })

        LET Tracker &lt;= process_tracker(max_size=MaxSize,
           sync_query=SyncQuery, update_query=UpdateQuery, sync_period=60000)

        SELECT * FROM process_tracker_updates()
        WHERE update_type = "stats"  OR AlsoForwardUpdates

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/generic.client.diskusage.md
======
---
title: Generic.Client.DiskUsage
hidden: true
tags: [Client Artifact]
---

This artifact reports the amount of space used by each directory
recursively (Similar to the `du` command).

Unlike the `du` command, this artifact can filter only certain file
name patterns.

If you change the `TopLevelDirectory` to the drive letter
(e.g. `C:\\`) it may take a while to complete as it will need to
examine every file on the drive.


<pre><code class="language-yaml">
name: Generic.Client.DiskUsage
description: |
  This artifact reports the amount of space used by each directory
  recursively (Similar to the `du` command).

  Unlike the `du` command, this artifact can filter only certain file
  name patterns.

  If you change the `TopLevelDirectory` to the drive letter
  (e.g. `C:\\`) it may take a while to complete as it will need to
  examine every file on the drive.

parameters:
  - name: TopLevelDirectory
    default: C:/Program Files
    description: The top level directory to start calculating disk usage.

  - name: FilenameGlob
    default: '*'
    description: A Glob expression for considering files

  - name: DirectoryGlob
    default: '*'
    description: A Glob expression for considering directories to recurse into.

sources:
  - query: |
      LET Res &lt;= dict()

      LET _DirInfo(DirPath) = SELECT DirPath, Size, sum(item=Size) AS TotalSize
      FROM chain(a={
        SELECT Size FROM glob(globs=FilenameGlob, root=DirPath)
        WHERE NOT IsDir
      }, b={
        SELECT * FROM foreach(row={
          SELECT OSPath FROM glob(globs=DirectoryGlob, root=DirPath)
          WHERE IsDir
        },
        query={
           SELECT TotalSize AS Size FROM DirInfo(DirPath=OSPath)
        })
      })
      GROUP BY 1 -- Needed for sum()

      LET DirInfo(DirPath) = SELECT * FROM _DirInfo(DirPath=DirPath)
      WHERE set(item=Res, field=DirPath,
                value=dict(DirPath=DirPath, TotalSize=TotalSize))

      -- Recurse into the TopLevelDirectory and rely on the set()
      -- above to store the results.
      LET _ &lt;= SELECT * FROM DirInfo(DirPath=TopLevelDirectory)

      SELECT *, humanize(bytes=TotalSize) AS TotalSizeHuman
      FROM foreach(row={
        SELECT * FROM items(item=Res)
      }, column="_value")
      ORDER BY TotalSize DESC

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.events.eventlogmodifications.md
======
---
title: Windows.Events.EventLogModifications
hidden: true
tags: [Client Event Artifact]
---

It is possible to disable windows event logs on a per channel or per
provider basis. Attackers may disable ciritcal log sources to
prevent detections.

This artifact monitors the state of the event log system from the
registry and attempts to detect when event logs were disabled.


<pre><code class="language-yaml">
name: Windows.Events.EventLogModifications
description: |
  It is possible to disable windows event logs on a per channel or per
  provider basis. Attackers may disable ciritcal log sources to
  prevent detections.

  This artifact monitors the state of the event log system from the
  registry and attempts to detect when event logs were disabled.

type: CLIENT_EVENT

precondition:
  SELECT * FROM info() WHERE OS =~ "windows"

parameters:
  - name: Period
    type: int
    default: 60

sources:
  - query: |
      LET Publishers = "HKEY_LOCAL_MACHINE\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\WINEVT\\Publishers\\*\\@"

      LET ProviderNames &lt;= memoize(key="GUID", query={
        SELECT OSPath.Components[-2] AS GUID,
               Data.value AS Name
        FROM glob(globs=Publishers, accessor="registry")
      })

      LET Key = "HKEY_LOCAL_MACHINE\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\WINEVT\\Channels\\*"

      LET Query = SELECT Key.Mtime AS Mtime,
           Key.OSPath[-1] AS ChannelName,
           format(format="%s/%v", args=[Key.OSPath[-1], Enabled]) AS QueryKey ,
           Key.OSPath AS _Key,
           get(item=ProviderNames, field=OwningPublisher).Name AS Publisher, Enabled
      FROM read_reg_key(globs=Key)

      SELECT * FROM diff(query=Query, period=Period, key="QueryKey")
      WHERE Diff =~ "added"

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.attack.unexpectedimagepath.md
======
---
title: Windows.Attack.UnexpectedImagePath
hidden: true
tags: [Client Artifact]
---

Some malware are hiding in plain text by masqurading a legitimate
executable name.

This artifact looks for processes with known names that are being
loaded from unexpected locations.


<pre><code class="language-yaml">
name: Windows.Attack.UnexpectedImagePath

description: |
  Some malware are hiding in plain text by masqurading a legitimate
  executable name.

  This artifact looks for processes with known names that are being
  loaded from unexpected locations.

reference:
  - https://www.sans.org/posters/hunt-evil/
  - https://github.com/teoseller/osquery-attck/blob/master/windows-incorrect_path_process.conf

author: Amged Wageh

parameters:
   - name: expected_paths
     type: csv
     default: |
        ProcName,ExpectedPath
        csrss.exe,c:\windows\system32\csrss.exe
        smss.exe,c:\windows\system32\smss.exe
        services.exe,c:\windows\system32\services.exe
        wininit.exe,c:\windows\system32\wininit.exe
        svchost.exe,c:\windows\system32\svchost.exe
        svchost.exe,c:\windows\syswow64\svchost.exe
        runtimebroker.exe,c:\windows\system32\runtimebroker.exe
        lsaiso.exe,c:\windows\system32\lsaiso.exe
        taskhostw.exe,c:\windows\system32\taskhostw.exe
        lsass.exe,c:\windows\system32\lsass.exe
        winlogon.exe,c:\windows\system32\winlogon.exe
        explorer.exe,c:\windows\explorer.exe
        explorer.exe,c:\windows\syswow64\explorer.exe
        conhost.exe,c:\windows\system32\conhost.exe
        dllhost.exe,c:\windows\system32\dllhost.exe
        dllhost.exe,c:\windows\syswow64\dllhost.exe
        wmiprvse.exe,c:\windows\system32\wbem\wmiprvse.exe
        wmiprvse.exe,c:\windows\syswow64\wbem\wmiprvse.exe

sources:
  - precondition:
      SELECT OS From info() where OS = 'windows'

    query: |
      LET expected_paths_lookup &lt;= memoize(key="ProcName", query={
        SELECT ProcName, enumerate(items=ExpectedPath) AS Path
        FROM expected_paths
        GROUP BY ProcName
      })

      LET suspicious_processes = SELECT Pid AS PID, Name AS ProcessName, Ppid AS PPID,
        Exe AS ImagePath, CommandLine, Username, StartTime,
        if(condition=EndTime&lt;StartTime, then="", else=EndTime) AS EndTime,
        get(item=expected_paths_lookup, field=Name).Path AS ExpectedPaths,
        process_tracker_callchain(id=Pid) AS CallChain,
        process_tracker_get(id=Ppid) AS Parent
      FROM process_tracker_pslist()
      WHERE ImagePath != "" AND ExpectedPaths AND
        NOT lowcase(string=ImagePath) IN ExpectedPaths

      SELECT PID, ProcessName, ImagePath, CommandLine, Username, StartTime, EndTime,
        PPID, Parent.Data.Name As ParentProcessName,
        Parent.Data.Exe As ParentImagePath,
        Parent.Data.CommandLine As ParentCommandLine,
        Parent.Data.Username As ParentUsername,
        Parent.StartTime As ParentStartTime,
        if(condition=Parent.EndTime&lt;Parent.StartTime, then=NULL, else=EndTime) AS ParentEndTime,
        CallChain.Data AS _CallChain,
        { SELECT Pid, Name, Ppid, Exe,
                 CommandLine, Username, StartTime, EndTime
          FROM
          foreach(row=process_tracker_children(id=PID).Data)
        } AS SubProcesses
        FROM suspicious_processes

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/server.monitor.velometrics.md
======
---
title: Server.Monitor.VeloMetrics
hidden: true
tags: [Server Artifact]
---

Get Velociraptor server metrics.


<pre><code class="language-yaml">
name: Server.Monitor.VeloMetrics
description: |
  Get Velociraptor server metrics.

type: SERVER

parameters:
  - name: MetricsURL
    default: http://localhost:8003/metrics

sources:
  - query: |
        LET stats = SELECT parse_string_with_regex(string=Content,
           regex=[
             'client_comms_concurrency (?P&lt;client_comms_concurrency&gt;[^\\s]+)',
             'client_comms_current_connections (?P&lt;client_comms_current_connections&gt;[^\\s]+)',
             'flow_completion (?P&lt;flow_completion&gt;[^\\s]+)',
             'process_open_fds (?P&lt;process_open_fds&gt;[^\\s]+)',
             'uploaded_bytes (?P&lt;uploaded_bytes&gt;[^\\s]+)',
             'uploaded_files (?P&lt;uploaded_files&gt;[^\\s]+)',
             'stats_client_one_day_actives{version="[^"]+"} (?P&lt;one_day_active&gt;[^\\s]+)',
             'stats_client_seven_day_actives{version="[^"]+"} (?P&lt;seven_day_active&gt;[^\\s]+)'
           ]) AS Stat, {
              // On Windows Prometheus does not provide these so we get our own.
              SELECT Times.user + Times.system as CPU,
                     MemoryInfo.RSS as RSS
              FROM pslist(pid=getpid())
           } AS PslistStats
        FROM  http_client(url=MetricsURL, chunk_size=50000)

        SELECT now() AS Timestamp,
               PslistStats.RSS AS process_resident_memory_bytes,
               parse_float(string=Stat.client_comms_concurrency)
                      AS client_comms_concurrency,
               parse_float(string=Stat.client_comms_current_connections)
                      AS client_comms_current_connections,
               parse_float(string=Stat.flow_completion) AS flow_completion,
               parse_float(string=Stat.uploaded_bytes) AS uploaded_bytes,
               parse_float(string=Stat.uploaded_files) AS uploaded_files,
               parse_float(string=Stat.process_open_fds)
                     AS process_open_fds,
               PslistStats.CPU AS process_cpu_seconds_total,
               parse_float(string=Stat.one_day_active)
                     AS one_day_active,
               parse_float(string=Stat.seven_day_active)
                     AS seven_day_active
        FROM stats

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/server.utils.deleteclient.md
======
---
title: Server.Utils.DeleteClient
hidden: true
tags: [Server Artifact]
---

This artifact completely removes a client from the data store.

Be careful with this one: there is no way to recover old
data. However, if the client still exists, it will just
automatically re-enrol when it next connects. You will still be able
to talk to it, it is just that old collected data is deleted.


<pre><code class="language-yaml">
name: Server.Utils.DeleteClient
description: |
  This artifact completely removes a client from the data store.

  Be careful with this one: there is no way to recover old
  data. However, if the client still exists, it will just
  automatically re-enrol when it next connects. You will still be able
  to talk to it, it is just that old collected data is deleted.

type: SERVER

parameters:
  - name: ClientIdList
    description: A list of client ids to delete.
    default:

  - name: ReallyDoIt
    description: If you really want to delete the client, check this.
    type: bool

sources:
  - query: |
      let clients_list = SELECT ClientId
      FROM parse_records_with_regex(
          accessor="data", file=ClientIdList,
          regex="(?P&lt;ClientId&gt;C\\.[0-9a-z-]+)")
      WHERE log(message="Deleting client " + ClientId)

      SELECT * FROM foreach(row=clients_list,
      query={
         SELECT * FROM client_delete(client_id=ClientId,
            really_do_it=ReallyDoIt)
      })

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.events.servicecreation.md
======
---
title: Windows.Events.ServiceCreation
hidden: true
tags: [Client Event Artifact]
---

Monitor for creation of new services.

New services are typically created by installing new software or
kernel drivers. Attackers will sometimes install a new service to
either insert a malicious kernel driver or as a persistence
mechanism.

This event monitor extracts the service creation events from the
event log and records them on the server.


<pre><code class="language-yaml">
name: Windows.Events.ServiceCreation
description: |
  Monitor for creation of new services.

  New services are typically created by installing new software or
  kernel drivers. Attackers will sometimes install a new service to
  either insert a malicious kernel driver or as a persistence
  mechanism.

  This event monitor extracts the service creation events from the
  event log and records them on the server.
type: CLIENT_EVENT

parameters:
  - name: systemLogFile
    default: &gt;-
      C:/Windows/System32/Winevt/Logs/System.evtx

sources:
 - precondition:
     SELECT OS from info() where OS = "windows"

   query: |
        SELECT System.TimeCreated.SystemTime as Timestamp,
               System.EventID.Value as EventID,
               EventData.ImagePath as ImagePath,
               EventData.ServiceName as ServiceName,
               EventData.ServiceType as Type,
               System.Security.UserID as UserSID,
               EventData as _EventData,
               System as _System
        FROM watch_evtx(filename=systemLogFile) WHERE EventID = 7045

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.packs.lateralmovement.md
======
---
title: Windows.Packs.LateralMovement
hidden: true
tags: [Client Artifact]
---

Detect evidence of lateral movement.


<pre><code class="language-yaml">
name: Windows.Packs.LateralMovement
description: |
  Detect evidence of lateral movement.

precondition: SELECT OS From info() where OS = 'windows'

reference:
  - https://digital-forensics.sans.org/media/SANS_Poster_2018_Hunt_Evil_FINAL.pdf

sources:
  - name: AlternateLogon
    query: |
      SELECT * FROM Artifact.Windows.EventLogs.AlternateLogon()

  - name: WMIC
    query: |
      SELECT * FROM Artifact.Windows.Forensics.Prefetch()
      WHERE Executable =~ "wmic.exe"
  - name: ShimCache
    query: |
      SELECT * FROM Artifact.Windows.Registry.AppCompatCache()
      WHERE Name =~ "wmic.exe"
  - name: BAM
    query: |
      SELECT * FROM Artifact.Windows.Forensics.Bam()
      WHERE Binary =~ "wmic.exe"
  - name: AmCache
    query: |
      SELECT * FROM Artifact.Windows.System.Amcache()
      WHERE Binary =~ "wmic.exe"

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/server.monitoring.timesketchupload.md
======
---
title: Server.Monitoring.TimesketchUpload
hidden: true
tags: [Server Event Artifact]
---

This artifact will automatically upload any Velociraptor timelines to Timesketch.


<pre><code class="language-yaml">
name: Server.Monitoring.TimesketchUpload
description: |
  This artifact will automatically upload any Velociraptor timelines to Timesketch.


type: SERVER_EVENT

parameters:
  - name: SketchRegex
    description: |
      Only upload Super timelines matching this regex to their
      corresponding Sketches.
    default: .

  - name: TimelineRegex
    default: .
    description: |
      Only upload Timelines with a name matching this regex to
      Timesketch.

  - name: TimesketchCLICommand
    default: "timesketch"
    description: |
      The path to the timesketch cli binary. If you installed in a
      virtual environment this will be inside that environment.

required_permissions:
  - EXECVE

imports:
  - Server.Utils.TimesketchUpload

sources:
  - query: |
      SELECT * FROM foreach(row={
         SELECT NotebookId, SuperTimelineName, Timeline
         FROM watch_monitoring(artifact="Server.Internal.TimelineAdd")
         WHERE Action = "AddTimeline"
           AND SuperTimelineName =~ SketchRegex
           AND Timeline =~ TimelineRegex
      }, query={
         SELECT * FROM ImportToTS(
             SuperTimelineName=SuperTimelineName,
             NotebookId=NotebookId,
             TimelineName=Timeline,
             SketchName=SuperTimelineName)
      })

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/macos.system.wifi.md
======
---
title: MacOS.System.Wifi
hidden: true
tags: [Client Artifact]
---

This artifact looks for all Wifi networks to which a host has
joined.  This can be useful in determining where a machine has
been, or if a user has joined an illegitimate or unauthorized
wireless network.


<pre><code class="language-yaml">
name: MacOS.System.Wifi
description: |
   This artifact looks for all Wifi networks to which a host has
   joined.  This can be useful in determining where a machine has
   been, or if a user has joined an illegitimate or unauthorized
   wireless network.

type: CLIENT

author: Wes Lambert - @therealwlambert

parameters:
  - name: WifiGlob
    default: /Library/Preferences/SystemConfiguration/com.apple.airport.preferences.plist

precondition:
      SELECT OS From info() where OS = 'darwin'

sources:
  - query: |
      LET WifiPlist = SELECT OSPath from glob(globs=WifiGlob)
      LET KnownNetworksQuery = SELECT get(member="KnownNetworks") as KN
         FROM plist(file=WifiPlist.OSPath)
         WHERE KN

      LET EachNetwork = SELECT * from foreach(
         row=KnownNetworksQuery,
         query={
            SELECT _key AS Network, _value AS Value
            FROM items(item=KN)
         })
      SELECT Network,
             Value.SSIDString AS SSID,
             Value.SecurityType AS SecurityType,
             Value.HiddenNetwork AS HiddenNetwork,
             Value.PersonalHotspot AS PersonalHotspot,
             Value.AddedAt AS AddedAt,
             Value.LastAutoJoinAt AS LastAutoJoinAt,
             Value.LastManualJoinAt AS LastManualJoinAt,
             Value AS _Data
      FROM EachNetwork

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.persistence.powershellprofile.md
======
---
title: Windows.Persistence.PowershellProfile
hidden: true
tags: [Client Artifact]
---

This Artifact will search and parse Powershell profile scripts.

PowerShell supports several profiles depending on the user or host program.
Adversaries may create or modify these profiles to include arbitrary commands,
functions, modules, and/or PowerShell drives to gain persistence. When a
backdoored PowerShell session is opened the modified script will be executed
unless the -NoProfile flag is used when it is launched.

The artifact will by default search both User profiles and System-wide
configured profiles. The user can also targert and exclude specific content
with relevant regex filters


<pre><code class="language-yaml">
name: Windows.Persistence.PowershellProfile
author: Matt Green - @mgreen27
description: |
  This Artifact will search and parse Powershell profile scripts.

  PowerShell supports several profiles depending on the user or host program.
  Adversaries may create or modify these profiles to include arbitrary commands,
  functions, modules, and/or PowerShell drives to gain persistence. When a
  backdoored PowerShell session is opened the modified script will be executed
  unless the -NoProfile flag is used when it is launched.

  The artifact will by default search both User profiles and System-wide
  configured profiles. The user can also targert and exclude specific content
  with relevant regex filters

reference:
  - https://attack.mitre.org/techniques/T1546/013/

type: CLIENT

parameters:
  - name: UserProfileGlob
    default: '\Documents\{WindowsPowerShell,Powershell}\{Profile,Microsoft.*_profile}.ps1'
    description: Glob for Powershell user profiles.
  - name: PSHomeProfileGlob
    default: 'C:\Windows\System32\{WindowsPowerShell,Powershell}\v1.0\{Profile,Microsoft.*_profile}.ps1'
    description: Glob for Powershell PSHome profiles.
  - name: SearchStrings
    default: .
    type: regex
    description: regex to filter for in profile content
  - name: StringWhiteList
    default:
    type: regex
    description: regex to filter out in profile content

sources:
  - precondition:
      SELECT OS From info() where OS = 'windows'

    query: |
        -- First extract potential glob path for each user
        LET UserTargets = SELECT Name as Username,
            expand(path=Directory) + UserProfileGlob as ProfileGlob
        FROM Artifact.Windows.Sys.Users()
        WHERE Directory

        -- Search for both Powershell System and User profiles.
        SELECT OSPath, Size,
            read_file(filename=OSPath) as Content,
            dict(   Mtime=Mtime,
                    Atime=Atime,
                    Ctime=Ctime,
                    Btime=Btime ) as Timestamps,
            hash(path=OSPath) as Hash
        FROM glob(globs=UserTargets.ProfileGlob + PSHomeProfileGlob)
        WHERE
            Content =~ SearchStrings
            AND NOT if(condition=StringWhiteList,
                        then= Content=~StringWhiteList,
                        else= False)

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/linux.remediation.quarantine.md
======
---
title: Linux.Remediation.Quarantine
hidden: true
tags: [Client Artifact]
---

This artifact applies quarantine to Linux systems via nftables.
It expects the target system to have nftables installed, and
hence the availability of nft CLI.

This artifact will create a table, with the default name
*vrr_quarantine_table*, which contains three chains. One
for inbound traffic, one for outbound traffic, and the other
for forwarding traffic. The chains will cut off all traffics
except those for DNS lookup and velociraptor itself.

To unquarantine the system, set the *RemovePolicy* parameter to *True*.


<pre><code class="language-yaml">
name: Linux.Remediation.Quarantine
description: |
  This artifact applies quarantine to Linux systems via nftables.
  It expects the target system to have nftables installed, and
  hence the availability of nft CLI.

  This artifact will create a table, with the default name
  *vrr_quarantine_table*, which contains three chains. One
  for inbound traffic, one for outbound traffic, and the other
  for forwarding traffic. The chains will cut off all traffics
  except those for DNS lookup and velociraptor itself.

  To unquarantine the system, set the *RemovePolicy* parameter to *True*.

precondition: SELECT OS From info() where OS = 'linux'

type: CLIENT

required_permissions:
  - EXECVE

parameters:
  - name: pathToNFT
    default: /usr/sbin/nft
    description: We depend on nft to manage the tables, chains, and rules.

  - name: TableName
    default: vrr_quarantine_table
    description: Name of the quarantine table

  - name: MessageBox
    description: |
        Optional message box notification to send to logged in users. 256
        character limit.

  - name: RemovePolicy
    type: bool
    description: Tickbox to remove policy.

sources:
  - query: |
     LET run_command(Cmd, Message) = SELECT timestamp(epoch=now()) as Time,
       format(format="Running %v: %v, Returned %v %v",
              args=[Cmd, Stdout || Stderr,
                    ReturnCode, Message || ""]) AS Result
     FROM  execve(argv=Cmd, length=10000)

     // If a MessageBox configured truncate to 256 character limit
     LET MessageBox &lt;= parse_string_with_regex(
               regex='^(?P&lt;Message&gt;.{0,255}).*',
               string=MessageBox).Message

     // Parse a URL to get domain name.
     LET get_domain(URL) = split(string=url(parse=URL).Host, sep=":")[0]
     LET get_port(URL) = if(condition=url(parse=URL).Host =~ ":",
         then=split(string=url(parse=URL).Host, sep=":")[1],
         else=if(condition=url(parse=URL).Scheme = "https",
                 then="443", else="80"))

     // extract Velociraptor config for policy
     LET extracted_config &lt;= SELECT * FROM foreach(
               row=config.server_urls,
               query={
                   SELECT
                       get_domain(URL=_value) AS DstAddr,
                       get_port(URL=_value) AS DstPort,
                       'VelociraptorFrontEnd' AS Description,
                       _value AS URL
                   FROM scope()
               })

     // delete table
     LET delete_table_cmd = (pathToNFT, 'delete', 'table', 'inet', TableName)

     // add table
     LET add_table_cmd = (pathToNFT, 'add', 'table', 'inet', TableName)

     // add inbound chain
     LET add_inbound_chain_cmd = (
          pathToNFT, 'add', 'chain', 'inet', TableName, 'inbound_chain',
          '{', 'type', 'filter', 'hook', 'input', 'priority', '0\;', 'policy', 'drop\;', '}')

     // add udp rule inbound chain to allow DNS lookups
     LET add_udp_rule_to_inbound_chain_cmd = (
          pathToNFT,'add','rule','inet', TableName, 'inbound_chain',
          'udp', 'sport', 'domain',
          'ct', 'state', 'established', 'accept')

     // add outbound chain
     LET add_outbound_chain_cmd = (
          pathToNFT, 'add', 'chain', 'inet', TableName, 'outbound_chain',
          '{', 'type', 'filter', 'hook', 'output', 'priority', '0\;', 'policy', 'drop\;', '}')

     // add tcp rule outbound chain to allow DNS traffics
     LET add_tcp_rule_to_outbound_chain_cmd = (
          pathToNFT, 'add', 'rule', 'inet', TableName, 'outbound_chain',
          'tcp', 'dport', '{', '53', '}',
          'ct', 'state', 'new,established', 'accept')

     // add udp rule outbound chain to allow DNS and DHCP traffics
     LET add_udp_rule_to_outbound_chain_cmd = (
          pathToNFT,'add','rule','inet', TableName, 'outbound_chain',
          'udp', 'dport', '{', '53,67,68', '}',
          'ct', 'state', 'new,established', 'accept')

     // add forward chain
     LET add_forward_chain_cmd = (
          pathToNFT, 'add', 'chain', 'inet', TableName, 'forward_chain',
          '{', 'type', 'filter', 'hook', 'forward', 'priority', '0\;', 'policy', 'drop\;', '}')


     // delete quarantine table
     LET delete_quarantine_table = SELECT
          timestamp(epoch=now()) as Time,
          TableName + ' table removed.' AS Result
       FROM execve(argv=delete_table_cmd, length=10000)

     // add tcp rule to inbound_chain to allow connections from Velociraptor
     // FIXME(gye): may need to add IPv6 rules if DstAddr is an IPv6 address
     LET add_velociraptor_rule_to_inbound_chain = SELECT * FROM foreach(
          row={
              SELECT DstAddr, DstPort, (
                  pathToNFT, 'add', 'rule', 'inet', TableName, 'inbound_chain',

                  'ip', 'saddr', DstAddr, 'tcp', 'sport', '{', DstPort, '}',
                  'ct', 'state', 'established',
                  'accept') AS add_velociraptor_rule_to_inbound_chain_cmd
              FROM extracted_config
          },
          query={
            SELECT * FROM run_command(Cmd=add_velociraptor_rule_to_inbound_chain_cmd,
                Message='Added tcp rule to inbound_chain in ' +  TableName + ' table.')
        })

     // add tcp rule to inbound_chain to allow connections from Velociraptor
     // FIXME(gye): may need to add IPv6 rules if DstAddr is an IPv6 address
     LET add_velociraptor_rule_to_outbound_chain = SELECT * FROM foreach(
          row={
              SELECT DstAddr, DstPort, (
                  pathToNFT, 'add', 'rule', 'inet', TableName, 'outbound_chain',
                  'ip', 'daddr', DstAddr, 'tcp', 'dport', '{', DstPort, '}',
                  'ct', 'state', 'established,new',
                  'accept') AS add_velociraptor_rule_to_outbound_chain_cmd
              FROM extracted_config
          },
          query={
              SELECT * FROM run_command(
                 Cmd=add_velociraptor_rule_to_outbound_chain_cmd,
                 Message='Added tcp rule to inbound_chain in ' +
                    TableName + ' table.')
          })

     // test connection to a frontend server
     LET test_connection = SELECT * FROM foreach(
         row={
             SELECT DstAddr, DstPort, URL + 'server.pem' AS pem_url
             FROM extracted_config
             WHERE log(message="Will check connectivity with " + pem_url)
         },
         query={
             SELECT format(format="Testing connectivity with %v: %v", args=[Url, Response]) AS Result
             FROM http_client(url=pem_url, disable_ssl_security='TRUE')
             WHERE Response = 200
             LIMIT 1
         })

     // final check to keep or remove policy
     // TODO(gyee): for now we are using the wall commmand to send the message.
     // Will need to look into using libnotify instead.
     LET final_check = SELECT * FROM if(condition= test_connection,
               then={
                   SELECT
                       timestamp(epoch=now()) as Time,
                       if(condition=MessageBox,
                           then= TableName + ' connection test successful. MessageBox sent.',
                           else= TableName + ' connection test successful.'
                       ) AS Result
                    FROM if(condition=MessageBox,
                        then= {
                            SELECT * FROM execve(argv=['wall', MessageBox])
                        },
                        else={
                            SELECT * FROM scope()
                        })
               },
               else=run_command(
                      Cmd=delete_table_cmd,
                      Message= TableName + ' failed connection test. Removing quarantine table.'))

     LET check_nft_cmd = (pathToNFT, "--version")

     // Execute content
     LET doit = SELECT * FROM if(condition=RemovePolicy,
               then=delete_quarantine_table,
               else={
                   SELECT * FROM chain(
                       a=delete_quarantine_table,
                       b=run_command(Cmd=add_table_cmd, Message=TableName + ' added.'),
                       c=run_command(Cmd=add_inbound_chain_cmd,
                           Message='Added inbound_chain to ' +
                                    TableName + ' table.'),
                       d=add_velociraptor_rule_to_inbound_chain,
                       e=run_command(Cmd=add_udp_rule_to_inbound_chain_cmd,
                           Message='Added udp rule to inbound_chain in ' +
                                     TableName + ' table.'),
                       f=run_command(Cmd=add_outbound_chain_cmd,
                           Message='Added outbound_chain to ' +
                                     TableName + ' table.'),
                       g=add_velociraptor_rule_to_outbound_chain,
                       h=run_command(Cmd=add_tcp_rule_to_outbound_chain_cmd,
                           Message='Added tcp rule to outbound_chain in ' +
                                     TableName + ' table.'),
                       i=run_command(Cmd=add_udp_rule_to_outbound_chain_cmd,
                           Message='Added udp rule to outbound_chain in ' +
                                     TableName + ' table.'),
                       j=run_command(Cmd=add_forward_chain_cmd,
                           Message='Added forward_chain to ' +
                                     TableName + ' table.'),
                       k=final_check)
               })

     SELECT * FROM if(condition={
        SELECT * FROM run_command(
           Cmd=check_nft_cmd, Message='Check for ' + pathToNFT)
        WHERE Result =~ "nftables"
     }, then=doit,
     else={
       SELECT * FROM scope() WHERE log(level="ERROR",
            message="nftables is not installed - quarantine not supported")
            AND FALSE
       })

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.ntfs.adshunter.md
======
---
title: Windows.NTFS.ADSHunter
hidden: true
tags: [Client Artifact]
---

This artifact hunts
for Alternate Data Streams on NTFS file systems. 
Adversaries may use NTFS file attributes for covert storage in order to evade 
detection. 
Alternate Data Streams (ADS) are additional $DATA attributes for an MFT entry in 
NTFS file systems. In NTFS, the primary $DATA attribute is 
never named but subsequent $DATA attributes must be named.

Targeting is via mix of path globs and include / exclude regex. 

- TargetGlob is a glob to target for ADS. NOTE **\* is recursive. To hit C drive we need to search for C:\*
- AdsName is name in glob format: e.g *, Zone.Identifier or Zone.*. 
- AdsNameExclusion - A regex value, common ADS added to exclusions have been 
added by default. The artifact also excludes NTFS system files by default.


<pre><code class="language-yaml">
name: Windows.NTFS.ADSHunter
author: "Matt Green - @mgreen27"
description: |
   This artifact hunts
   for Alternate Data Streams on NTFS file systems. 
   Adversaries may use NTFS file attributes for covert storage in order to evade 
   detection. 
   Alternate Data Streams (ADS) are additional $DATA attributes for an MFT entry in 
   NTFS file systems. In NTFS, the primary $DATA attribute is 
   never named but subsequent $DATA attributes must be named.
   
   Targeting is via mix of path globs and include / exclude regex. 
   
   - TargetGlob is a glob to target for ADS. NOTE **\* is recursive. To hit C drive we need to search for C:\*
   - AdsName is name in glob format: e.g *, Zone.Identifier or Zone.*. 
   - AdsNameExclusion - A regex value, common ADS added to exclusions have been 
   added by default. The artifact also excludes NTFS system files by default.

reference:
  - https://attack.mitre.org/techniques/T1564/004/
  
type: CLIENT

parameters:
 - name: TargetGlob
   description: A Glob to search for target files. **\* is recursive. To hit C drive we need to search for C:\*
   default: C:\{*,**\*}
 - name: AdsNameGlob
   description: AdsName in glob format. e.g *, Zone.Identifier or Zone.*
   default: '*'
 - name: AdsNameExclusion
   description: Regex of ADS name to exclude.
   default: 'SmartScreen|WofCompressedData|encryptable|favicon|AFP_AfpInfo|OECustomProperty|Win32App_1|com\.dropbox|icasource|\{\w{8}-\w{4}-\w{4}-\w{4}-\w{12}\}\.(MetaData|SyncRootIdentity)'
   type: regex
 - name: AdsContentRegex
   description: ADS content to search for by regex.
   default: .
   type: regex
 - name: AdsContentExclusion
   description: ADS content to exclude by regex.
   type: regex
 - name: MinSize
   description: Optional - only include alternate data streams above this size in bytes.
   type: int
 - name: MaxSize
   description: Optional - only include alternate data streams below this size in bytes.
   type: int
 - name: UploadDataStream
   description: If selected wil upload non-resident data streams.
   type: bool
   
sources:
 - query: |
      -- Collect ADS entries using glob but exclude ntfs objects that contain ads
      LET ads_entries = SELECT OSPath,
            split(string=Name,sep=':')[1] as AdsName,
            Data.mft as Inode,
            Size,
            OSPath.Dirname + split(string=Name,sep=':')[0] as HostObject,
            dict(Mtime=Mtime,Atime=Atime,Ctime=Ctime,Btime=Btime) as HostTimestampsSI
        FROM glob(globs=TargetGlob + ":" + AdsNameGlob, 
                  accessor="ntfs",
                  nosymlink='Y')
        WHERE
            NOT OSPath =~ '''[a-z]:\\(\$Extend\\|\$Secure|\$UpCase|\$BadClus|\$Bitmap|\$Repair)'''
            AND if(condition=MinSize,
                    then= Size &gt; MinSize,
                    else= True )
            AND if(condition= MaxSize,
                    then= Size &lt; MaxSize,
                    else= True )
            AND NOT if(condition=AdsNameExclusion,
                        then= AdsName =~ AdsNameExclusion,
                        else= False )
      
      -- Extract content and filter
      LET hits = SELECT *,
            read_file(filename=OSPath[0]+Inode, accessor="mft",offset=0,length=1024) as AdsContent -- only upload first 1k of each hit
        FROM ads_entries
        WHERE AdsContent =~ AdsContentRegex
            AND NOT if(condition=AdsContentExclusion,
                    then= AdsContent =~ AdsContentExclusion,
                    else= False )
                    
      -- upload hits
      LET upload_hits = SELECT *, 
            upload(file=OSPath,accessor='ntfs') as Upload
        FROM hits
      
      -- output rows 
      SELECT * FROM if(condition=UploadDataStream,
                        then= upload_hits,
                        else= hits)
</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.system.localadmins.md
======
---
title: Windows.System.LocalAdmins
hidden: true
tags: [Client Artifact]
---

Gets a list of local admin accounts.


<pre><code class="language-yaml">
name: Windows.System.LocalAdmins
description: |
   Gets a list of local admin accounts.

reference:
- https://docs.microsoft.com/en-us/powershell/module/microsoft.powershell.localaccounts/get-localgroupmember?view=powershell-5.1

type: CLIENT

required_permissions:
  - EXECVE

parameters:
 - name: PowerShellExe
   default: "C:\\Windows\\System32\\WindowsPowerShell\\v1.0\\powershell.exe"

sources:
  - precondition:
      SELECT OS From info() where OS = 'windows'

    query: |
      LET script &lt;= 'Get-LocalGroupMember -SID S-1-5-32-544 | select -ExpandProperty SID -Property Name, PrincipalSource | select Name, Value, PrincipalSource | ConvertTo-Json'

      LET out = SELECT parse_json_array(data=Stdout) AS Output
          FROM execve(argv=[PowerShellExe,
               "-ExecutionPolicy", "Unrestricted", "-encodedCommand",
                  base64encode(string=utf16_encode(
                  string=script))
            ], length=1000000)
      SELECT * FROM foreach(row=out.Output[0],
      query={
          SELECT Name, Value AS SID, if(condition=PrincipalSource=1,
            then="Local", else=if(condition=PrincipalSource=2,
            then="Domain", else=PrincipalSource)) AS PrincipalSource
          FROM scope()
      })

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/server.utils.savefavoriteflow.md
======
---
title: Server.Utils.SaveFavoriteFlow
hidden: true
tags: [Server Artifact]
---

Users may collect various artifacts from hosts. Sometimes it might
take a bit of effort to setup and configure just the perfect
combination of parameters and artifacts to collect.

This artifact allows the user to save the collection into a
Favorites section, which may be used in future.

An example of a Spec is
```json
[{"artifact":"Windows.KapeFiles.Targets", "parameters":{"env":[{"key":"EventLogs", "value":"Y"}]}}]
```


<pre><code class="language-yaml">
name: Server.Utils.SaveFavoriteFlow
description: |
  Users may collect various artifacts from hosts. Sometimes it might
  take a bit of effort to setup and configure just the perfect
  combination of parameters and artifacts to collect.

  This artifact allows the user to save the collection into a
  Favorites section, which may be used in future.

  An example of a Spec is
  ```json
  [{"artifact":"Windows.KapeFiles.Targets", "parameters":{"env":[{"key":"EventLogs", "value":"Y"}]}}]
  ```

type: SERVER

parameters:
  - name: Specs
    type: json_array
    description: The collection request that will be recreated.
  - name: Name
    description: A name for this collection template
  - name: Description
    description: A description for the template.
  - name: Type
    description: The type of favorites to save.
    type: choices
    default: CLIENT
    choices:
      - CLIENT
      - SERVER
      - CLIENT_EVENT
      - SERVER_EVENT
  - name: AllUsers
    type: bool
    description: If set, add the favorite to all users in all orgs.

sources:
  - query: |
      LET AddToAllOrgs = SELECT * FROM foreach(
      row={
        SELECT name, org_id
        FROM gui_users(all_orgs=TRUE)
      }, query={
        SELECT * FROM query(query={
             SELECT favorites_save(type=Type,
               description=Description,
               name=Name,
               specs=Specs)
             FROM scope()
           },
           org_id=org_id,
           runas=name,
           env=dict(
             Specs=Specs,
             Name=Name, Type=Type,
             Description=Description))
      })

      LET AddToOneUser = SELECT favorites_save(
         name=Name,
         description=Description,
         specs=Specs,
         type=Type)
      FROM scope()

      SELECT * FROM if(condition=AllUsers,
         then=AddToAllOrgs, else=AddToOneUser)

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/server.utils.listusers.md
======
---
title: Server.Utils.ListUsers
hidden: true
tags: [Server Artifact]
---

This server artifact is used to list all current users and their
permissions and org access.

NOTE: When collected in an org context only users belonging to the
current org are visible. When collected in the context of the root
org, all users in all orgs are visible.


<pre><code class="language-yaml">
name: Server.Utils.ListUsers
description: |
  This server artifact is used to list all current users and their
  permissions and org access.

  NOTE: When collected in an org context only users belonging to the
  current org are visible. When collected in the context of the root
  org, all users in all orgs are visible.

type: SERVER

sources:
  - query: |
      SELECT * FROM gui_users(all_orgs=TRUE)

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/generic.forensic.hashlookup.md
======
---
title: Generic.Forensic.HashLookup
hidden: true
tags: [Server Event Artifact]
---

This artifact is a server event artifact that collects hashes from
various sources into a central location. It is possible to follow
this artifact (e.g. with an external program using the API) to
lookup the hashes with an external service.

You can also send hashes to this artifact yourself using the
`send_event()` vql Function. For example, the following will add
hashes from the results of another artifact.

```vql
SELECT *, send_event(
    artifact="Generic.Forensic.HashLookup",
    row=dict(SHA256=Sha256, ClientId=ClientId))
FROM source()
```


<pre><code class="language-yaml">
name: Generic.Forensic.HashLookup
description: |
  This artifact is a server event artifact that collects hashes from
  various sources into a central location. It is possible to follow
  this artifact (e.g. with an external program using the API) to
  lookup the hashes with an external service.

  You can also send hashes to this artifact yourself using the
  `send_event()` vql Function. For example, the following will add
  hashes from the results of another artifact.

  ```vql
  SELECT *, send_event(
      artifact="Generic.Forensic.HashLookup",
      row=dict(SHA256=Sha256, ClientId=ClientId))
  FROM source()
  ```

type: SERVER_EVENT

sources:
  - query: |
      // You can add more queries to this chain to automatically
      // collect more hashes.
      SELECT ClientId, SHA256 FROM chain(
      a={
        SELECT * FROM foreach(
          row={
            SELECT ClientId, FlowId
            FROM watch_monitoring(artifact="System.Flow.Completion")
            WHERE Flow.artifacts_with_results =~ "System.VFS.DownloadFile"
          }, query={
            SELECT ClientId, Sha256 AS SHA256
            FROM source(
              artifact="System.VFS.DownloadFile",
              client_id=ClientId, flow_id=FlowId)
         })
      }, async=TRUE)

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/server.hunts.results.md
======
---
title: Server.Hunts.Results
hidden: true
tags: [Server Artifact]
---

Show the results from each artifact collection hunt.


<pre><code class="language-yaml">
name: Server.Hunts.Results
description: |
  Show the results from each artifact collection hunt.
parameters:
  - name: huntId
    default: H.d05b2482
  - name: ArtifactName
    default: Linux.Mounts

type: SERVER

sources:
  - query: |
      SELECT * FROM hunt_results(hunt_id=huntId, artifact=ArtifactName)

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/server.utils.deletefavoriteflow.md
======
---
title: Server.Utils.DeleteFavoriteFlow
hidden: true
tags: [Client Artifact]
---

This artifact allows the user to delete a previously saved
favorite. It will only addect the current user.


<pre><code class="language-yaml">
name: Server.Utils.DeleteFavoriteFlow
description: |
  This artifact allows the user to delete a previously saved
  favorite. It will only addect the current user.

parameters:
  - name: Name
    description: A name for this collection template
  - name: Type
    description: The type of favorites to delete.
    type: choices
    default: CLIENT
    choices:
      - CLIENT
      - SERVER
      - CLIENT_EVENT
      - SERVER_EVENT

sources:
  - query: |
      SELECT favorites_delete(name=Name, type=Type)
      FROM scope()

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.registry.rdp.md
======
---
title: Windows.Registry.RDP
hidden: true
tags: [Client Artifact]
---

This artifact will collect historical RDP server names and MRU items stored 
in each users NTUser.dat

1. Servers - list of all RDP connections that have ever been established by 
this user.   
 UsernameHint shows the username used to connect to the RDP/RDS host.  
 CertHash variable contains the RDP server SSL certificate thumbprint.

2. MRU 10 - Most recently used RDP connections 

UserRegex and SidRegex can be used to target a specific user.


<pre><code class="language-yaml">
name: Windows.Registry.RDP
author: Matt Green - @mgreen27
description: |
   This artifact will collect historical RDP server names and MRU items stored 
   in each users NTUser.dat
   
   1. Servers - list of all RDP connections that have ever been established by 
   this user.   
    UsernameHint shows the username used to connect to the RDP/RDS host.  
    CertHash variable contains the RDP server SSL certificate thumbprint.

   2. MRU 10 - Most recently used RDP connections 
   
   UserRegex and SidRegex can be used to target a specific user.

type: CLIENT

parameters:
   - name: KeyGlob
     default: Software\Microsoft\Terminal Server Client\{Default,Servers}\**
   - name: UserRegex
     default: .
     description: Regex filter to select a target username
     type: regex
   - name: SidRegex
     default: .
     description: Regex filter to select a target SID
     type: regex
     

precondition: SELECT OS From info() where OS = 'windows'
      
sources:
  - name: Servers
    query: |
      LET servers &lt;= SELECT 
            Mtime as LastWriteTime,
            basename(path=OSPath.Dirname) as Server,
            OSPath.Basename as KeyName,
            Data.value as KeyValue,
            Data.data_len as ValueLength,
            OSPath.Dirname.Path as Key,
            OSPath.DelegatePath as HiveName,
            OSPath,
            Username,
            UUID as SID
        FROM Artifact.Windows.Registry.NTUser(KeyGlob=KeyGlob)
        WHERE NOT Data.type = 'Key'
            AND OSPath =~ '''Terminal Server Client\\\\Servers\\'''

      LET find_value(path, sid, keyname ) = SELECT KeyValue,
            format(format='%x',args=read_file(accessor='data',filename=KeyValue,length=ValueLength)) as CertHash
        FROM servers 
        WHERE KeyName = keyname AND Key=path AND SID=sid
        
      LET results = SELECT 
            Username || dirname(path=HiveName).Basename as Username,  
            SID,
            HiveName,
            Key,  
            LastWriteTime,
            Server
        FROM servers
        WHERE Username =~ UserRegex AND SID =~ SidRegex
        GROUP BY SID,Key,HiveName,LastWriteTime
            
      
      SELECT *
        find_value(path=Key,sid=SID,keyname='UsernameHint')[0].KeyValue as UsernameHint,
        find_value(path=Key,sid=SID,keyname='CertHash')[0].CertHash as CertHash
      FROM results

  - name: Mru
    query: |
      LET mru &lt;= SELECT 
            Mtime as LastWriteTime,
            OSPath.Basename as KeyName,
            Data.value as KeyValue,
            OSPath.Dirname.Path as Key,
            OSPath.DelegatePath as HiveName,
            Username,
            UUID as SID
        FROM Artifact.Windows.Registry.NTUser(KeyGlob=KeyGlob)
        WHERE NOT Data.type = 'Key'
            AND OSPath =~ '''Terminal Server Client\\\\Default\\\\MRU'''
    
      LET find_mru(sid) = SELECT KeyValue FROM mru 
        WHERE SID=sid
        
      LET results = SELECT *,
            Username || dirname(path=HiveName).Basename as Username
        FROM mru 
        WHERE Username =~ UserRegex AND SID =~ SidRegex
        GROUP BY Sid,HiveName
      
      SELECT 
        Username,
        SID,  
        HiveName,
        Key,
        LastWriteTime,
        find_mru(sid=SID).KeyValue as Mru
      FROM results
</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/linux.sys.services.md
======
---
title: Linux.Sys.Services
hidden: true
tags: [Client Artifact]
---

Parse services from systemctl

<pre><code class="language-yaml">
name: Linux.Sys.Services
description: Parse services from systemctl 

sources:
  - precondition: |
      SELECT OS From info() where OS = 'linux'
    queries:
      - |
        LET services = SELECT Stdout FROM execve(argv=['systemctl', 'list-units',  '--type=service'])
        
        LET all_services = SELECT grok(grok="%{NOTSPACE:Unit}%{SPACE}%{NOTSPACE:Load}%{SPACE}%{NOTSPACE:Active}%{SPACE}%{NOTSPACE:Sub}%{SPACE}%{GREEDYDATA:Description}", data=Line) AS Parsed
        FROM parse_lines(accessor="data", filename=services.Stdout)
        
        SELECT * FROM foreach(row=all_services, column="Parsed") WHERE Unit =~ ".service"
        
        
</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.registry.appcompatcache.md
======
---
title: Windows.Registry.AppCompatCache
hidden: true
tags: [Client Artifact]
---

This artifact parses AppCompatCache (shimcache) from target hives.

AppCompatCache, also known as Shimcache, is a component of the Application
Compatibility Database, which was created by Microsoft and used by the Windows
operating system to identify application compatibility issues. This helps
developers troubleshoot legacy functions and contains data related to Windows
features.

Note: 

- Windows 10+ systems Execution flag of 1 indicates execution.
- The appcompatcache artifact does not currently support execution flag in
Windows 7 and 8 / 8.1 Systems.


<pre><code class="language-yaml">
name: Windows.Registry.AppCompatCache
author: Matt Green - @mgreen27
description: |
  This artifact parses AppCompatCache (shimcache) from target hives.

  AppCompatCache, also known as Shimcache, is a component of the Application
  Compatibility Database, which was created by Microsoft and used by the Windows
  operating system to identify application compatibility issues. This helps
  developers troubleshoot legacy functions and contains data related to Windows
  features.

  Note: 
  
  - Windows 10+ systems Execution flag of 1 indicates execution.
  - The appcompatcache artifact does not currently support execution flag in
  Windows 7 and 8 / 8.1 Systems.
 

reference:
  - https://www.mandiant.com/resources/caching-out-the-val

parameters:
  - name: AppCompatCacheKey
    default: HKEY_LOCAL_MACHINE/System/ControlSet*/Control/Session Manager/AppCompatCache/AppCompatCache

precondition: SELECT OS From info() where OS = 'windows'

export: |
    LET AppCompatCacheParser &lt;= '''[
    ["HeaderWin10", "x=&gt;x.HeaderSize", [
      ["HeaderSize", 0, "unsigned int"],
      ["Entries", "x=&gt;x.HeaderSize", Array, {
          type: "Entry",
          sentinel: "x=&gt;x.Size = 0",
          count: 10000,
      }]
    ]],
    ["HeaderWin8", 128, [
      ["Entries", 128, Array, {
          type: "EntryWin8",
          sentinel: "x=&gt;x.EntrySize = 0",
          count: 10000,
      }]
    ]],

    ["EntryWin8", "x=&gt;x.EntrySize + 12", [
      ["Signature", 0, "String", {
         length: 4,
      }],
      ["EntrySize", 8, "unsigned int"],
      ["PathSize", 12, "uint16"],
      ["Path", 14, "String", {
          length: "x=&gt;x.PathSize",
          encoding: "utf16",
      }],
      ["LastMod", "x=&gt;x.PathSize + 14 + 10", "WinFileTime"],
      ["Execution", 0, "Value",{"value":"N/A"}],
    ]],

    ["Entry", "x=&gt;x.Size + 12", [
      ["Signature", 0, "String", {
         length: 4,
      }],
      ["Size", 8, "unsigned int"],
      ["PathSize", 12, "uint16"],
      ["Path", 14, "String", {
          length: "x=&gt;x.PathSize",
          encoding: "utf16",
      }],
      ["LastMod", "x=&gt;x.PathSize + 14", "WinFileTime"],
      ["DataSize", "x=&gt;x.PathSize + 14 + 8", "uint32"],
      ["Data", "x=&gt;x.PathSize + 14 + 8 + 4" , "String", {
          length: "x=&gt;x.DataSize",
      }],

      # The last byte of the Data block is 1 for execution
      ["Execution", "x=&gt;x.PathSize + 14 + 8 + 4 + x.DataSize - 4", "uint32"]
    ]],

    # This is the Win7 parser but we dont use it right now.
    ["HeaderWin7x64", 128, [
      ["Signature", 0, "uint32"],
      ["Entries", 128, "Array", {
          count: 10000,
          sentinel: "x=&gt;x.PathSize = 0",
          type: EntryWin7x64,
      }]
    ]],
    ["EntryWin7x64", 48, [
      ["PathSize", 0, "uint16"],
      ["PathOffset", 8, "uint32"],
      ["Path", "x=&gt;x.PathOffset - x.StartOf", "String", {
          encoding: "utf16",
          length: "x=&gt;x.PathSize",
      }],
      ["LastMod", 16, "WinFileTime"],
      ["Execution", 0, "Value",{"value":"N/A"}],

    ]]

    ]'''

    LET AppCompatCacheWin10(Blob) = parse_binary(
        accessor="data",
        filename=Blob,
        profile=AppCompatCacheParser,
        struct="HeaderWin10")

    LET AppCompatCacheWin8(Blob) = parse_binary(
        accessor="data",
        filename=Blob,
        profile=AppCompatCacheParser,
        struct="HeaderWin8")

    LET AppCompatCache(Blob) = SELECT *
    FROM foreach(
      row=if(
        condition=AppCompatCacheWin10(Blob=Blob).HeaderSize IN (52, 48),
        then=AppCompatCacheWin10(Blob=Blob).Entries,
        else=AppCompatCacheWin8(Blob=Blob).Entries))


sources:
  - query: |
      -- first find all ControlSet Keys in scope
      LET AppCompatKeys &lt;= SELECT OSPath FROM glob(globs=AppCompatCacheKey, accessor='registry')

      -- when greater than one key we need to extract results and order later
      LET results &lt;= SELECT
            ModificationTime,
            Name as Path,
            ExecutionFlag,
            ControlSet,
            Key
          FROM foreach(
              row={
                 SELECT OSPath FROM glob(accessor='registry',
                     globs=AppCompatCacheKey)
              }, query={
                  SELECT OSPath AS Key, Path AS Name,
                     LastMod AS ModificationTime,
                     Execution as ExecutionFlag,
                     OSPath[2] as ControlSet
                  FROM AppCompatCache(Blob=read_file(
                      accessor='registry', filename=OSPath))
            })

      -- find position of entry for each ControlSet. Lower numbers more recent
      LET ControlSetPosition(cs) = SELECT *, count() - 1 as Position
        FROM results WHERE ControlSet = cs
      LET position = SELECT ControlSetPosition(cs=ControlSet) as Results
            FROM foreach(
                row={
                    SELECT ControlSet, count(items=ControlSet) as Entries
                    FROM results GROUP BY ControlSet
                })

      LET mutli_controlset = SELECT *
        FROM foreach(
                row=position.Results,
                query={
                    SELECT * FROM foreach(row=_value)
                })

      -- output results
      SELECT 
        Position,
        ModificationTime,
        Path,
        ExecutionFlag,
        ControlSet,
        Key
      FROM if(condition= len(list=AppCompatKeys.OSPath)=1,
        then={
            SELECT *, count() - 1 as Position FROM results
        },
        else= mutli_controlset )
</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.eventlogs.kerberoasting.md
======
---
title: Windows.EventLogs.Kerberoasting
hidden: true
tags: [Client Artifact]
---

This Artifact will return all successful Kerberos TGS Ticket events for
Service Accounts (SPN attribute) implemented with weak encryption. These
tickets are vulnerable to brute force attack and this event is an indicator
of a Kerberoasting attack.

Typical attacker methodology is to firstly request accounts in the domain
with SPN attributes, then request an insecure TGS ticket for brute forcing.
This attack is particularly effective as any domain credentials can be used
to implement the attack and service accounts often have elevated privileges.
Kerberoasting can be used for privilege escalation or persistence by adding a
SPN attribute to an unexpected account.

Log Source: Windows Security Event Log (Domain Controllers).
Event ID: 4769
Status: 0x0 (Audit Success)
Ticket Encryption: 0x17 (RC4)
Service Name: NOT krbtgt or NOT a system account (account name ends in $)
TargetUserName: NOT a system account (*$@*)

Monitor and alert on unusual events with these conditions from an unexpected
IP.
Note: There are potential false positives so whitelist normal source IPs and
manage risk of insecure ticket generation.


<pre><code class="language-yaml">
name: Windows.EventLogs.Kerberoasting
author: Matt Green - @mgreen27

description: |
  This Artifact will return all successful Kerberos TGS Ticket events for
  Service Accounts (SPN attribute) implemented with weak encryption. These
  tickets are vulnerable to brute force attack and this event is an indicator
  of a Kerberoasting attack.

  Typical attacker methodology is to firstly request accounts in the domain
  with SPN attributes, then request an insecure TGS ticket for brute forcing.
  This attack is particularly effective as any domain credentials can be used
  to implement the attack and service accounts often have elevated privileges.
  Kerberoasting can be used for privilege escalation or persistence by adding a
  SPN attribute to an unexpected account.

  Log Source: Windows Security Event Log (Domain Controllers).
  Event ID: 4769
  Status: 0x0 (Audit Success)
  Ticket Encryption: 0x17 (RC4)
  Service Name: NOT krbtgt or NOT a system account (account name ends in $)
  TargetUserName: NOT a system account (*$@*)

  Monitor and alert on unusual events with these conditions from an unexpected
  IP.
  Note: There are potential false positives so whitelist normal source IPs and
  manage risk of insecure ticket generation.

reference:
  - https://attack.mitre.org/techniques/T1208/
  - https://www.trustedsec.com/blog/art_of_kerberoast/

parameters:
  - name: EvtxGlob
    default: '%SystemRoot%\System32\winevt\logs\Security.evtx'
  - name: VSSAnalysisAge
    type: int
    default: 0
    description: |
      If larger than zero we analyze VSS within this many days
      ago. (e.g 7 will analyze all VSS within the last week).  Note
      that when using VSS analysis we have to use the ntfs accessor
      for everything which will be much slower.

sources:
  - query: |
      LET VSS_MAX_AGE_DAYS &lt;= VSSAnalysisAge
      LET Accessor = if(condition=VSSAnalysisAge &gt; 0, then="ntfs_vss", else="auto")

      -- expand provided glob into a list of paths on the file system (fs)
      LET fspaths = SELECT OSPath
        FROM glob(globs=expand(path=EvtxGlob))

      -- function returning IOC hits
      LET evtxsearch(PathList) = SELECT * FROM foreach(
            row=PathList,
            query={
                SELECT
                    timestamp(epoch=int(int=System.TimeCreated.SystemTime)) AS EventTime,
                    System.EventID.Value as EventID,
                    System.Computer as Computer,
                    EventData.ServiceName as ServiceName,
                    EventData.ServiceSid as ServiceSid,
                    EventData.TargetUserName as TargetUserName,
                    format(format="0x%x", args=EventData.Status) as Status,
                    EventData.TargetDomainName as TargetDomainName,
                    format(format="0x%x", args=EventData.TicketEncryptionType) as TicketEncryptionType,
                    format(format="0x%x", args=EventData.TicketOptions) as TicketOptions,
                    EventData.TransmittedServices as TransmittedServices,
                    EventData.IpAddress as IpAddress,
                    EventData.IpPort as IpPort,
                    OSPath
                FROM parse_evtx(filename=OSPath, accessor=Accessor)
                WHERE
                    System.EventID.Value = 4769
                    AND EventData.TicketEncryptionType = 23
                    AND EventData.Status = 0
                    AND NOT EventData.ServiceName =~ "krbtgt|\\$$"
                    AND NOT EventData.TargetUserName =~ "\\$@"
          })


        SELECT * FROM evtxsearch(PathList=fspaths)

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/generic.system.processsiblings.md
======
---
title: Generic.System.ProcessSiblings
hidden: true
tags: [Client Artifact]
---

This artifact queries the process tracker to display all known
sibling processes of the target process (i.e. all other processes
from the same parent).

This is useful to reveal the complete interaction that included
the process in question (e.g. previous shell commands etc).

Minimum Version: 0.6.6


<pre><code class="language-yaml">
name: Generic.System.ProcessSiblings
description: |
  This artifact queries the process tracker to display all known
  sibling processes of the target process (i.e. all other processes
  from the same parent).

  This is useful to reveal the complete interaction that included
  the process in question (e.g. previous shell commands etc).

  Minimum Version: 0.6.6

parameters:
  - name: CommandlineRegex
    default: .
    description: Target process by this command line
    type: regex

  - name: PidFilter
    description: Filter pids by this regex
    default: .
    type: regex

  - name: IncludePstree
    type: bool

sources:
  - query: |
        LET GetDetails(Records) = SELECT
            Id AS ChildPid,
            Data.CommandLine AS CommandLine,
            Data.Username AS Username,
            StartTime, EndTime
          FROM Records
          ORDER BY StartTime

        SELECT * FROM foreach(row={
          SELECT Pid, Ppid, Name
          FROM process_tracker_pslist()
          WHERE CommandLine =~  CommandlineRegex
            AND Pid =~ PidFilter
        }, query={
          SELECT Pid,Ppid, Name, ChildPid,
                 CommandLine, Username, StartTime, EndTime,
                 if(condition=IncludePstree, then=process_tracker_tree(id=Ppid)) AS ParentTree
          FROM foreach(row=GetDetails(
              Records=process_tracker_children(id=Ppid)))
        })

column_types:
  - name: ParentTree
    type: tree

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/linux.events.sshbruteforce.md
======
---
title: Linux.Events.SSHBruteforce
hidden: true
tags: [Client Event Artifact]
---

This is a monitoring artifact which detects a successful SSH login
preceded by some failed attempts within the last hour.

This is particularly important in the case of ssh brute forcers. If
one of the brute force password attempts succeeded the password
guessing program will likely report the success and move on. This
alert might provide sufficient time for admins to lock down the
account before attackers can exploit the weak password.


<pre><code class="language-yaml">
name: Linux.Events.SSHBruteforce
description: |
  This is a monitoring artifact which detects a successful SSH login
  preceded by some failed attempts within the last hour.

  This is particularly important in the case of ssh brute forcers. If
  one of the brute force password attempts succeeded the password
  guessing program will likely report the success and move on. This
  alert might provide sufficient time for admins to lock down the
  account before attackers can exploit the weak password.

reference:
  - https://www.elastic.co/blog/grokking-the-linux-authorization-logs

type: CLIENT_EVENT

parameters:
  - name: syslogAuthLogPath
    default: /var/log/auth.log

  - name: SSHGrok
    description: A Grok expression for parsing SSH auth lines.
    default: &gt;-
      %{SYSLOGTIMESTAMP:timestamp} (?:%{SYSLOGFACILITY} )?%{SYSLOGHOST:logsource} %{SYSLOGPROG}: %{DATA:event} %{DATA:method} for (invalid user )?%{DATA:user} from %{IPORHOST:ip} port %{NUMBER:port} ssh2(: %{GREEDYDATA:system.auth.ssh.signature})?

  - name: MinimumFailedLogins
    description: Minimum number of failed logins before a successful login.
    default: 2

sources:
  - query: |
      -- Basic syslog parsing via GROK expressions.
      LET failed_login = SELECT grok(grok=SSHGrok, data=Line) AS FailedEvent,
            Line as FailedLine
        FROM watch_syslog(filename=syslogAuthLogPath)
        WHERE FailedEvent.program = "sshd" AND FailedEvent.event = "Failed"
              AND FailedEvent.method = "password"

      LET last_failed_events = SELECT * FROM fifo(
              query=failed_login, max_rows=50, max_age=3600)

      LET _ &lt;= SELECT * FROM last_failed_events

      LET success_login = SELECT grok(grok=SSHGrok, data=Line) AS Event, Line
        FROM watch_syslog(filename=syslogAuthLogPath)
        WHERE Event.program = "sshd" AND Event.event = "Accepted"
              AND Event.method = "password"

      SELECT Event, Line, {
           SELECT FailedLine FROM last_failed_events
           WHERE Event.user = FailedEvent.user
        } AS Failures
        FROM success_login
        WHERE len(list=Failures) &gt; int(int=MinimumFailedLogins)

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/server.internal.enrollment.md
======
---
title: Server.Internal.Enrollment
hidden: true
tags: [Internal Artifact]
---

This event artifact is an internal event stream over which client
enrollments are sent. You can watch this event queue to be notified
on any new clients enrolling for the first time.

Note: This is an automated system artifact. You do not need to start it.


<pre><code class="language-yaml">
name: Server.Internal.Enrollment
description: |
  This event artifact is an internal event stream over which client
  enrollments are sent. You can watch this event queue to be notified
  on any new clients enrolling for the first time.

  Note: This is an automated system artifact. You do not need to start it.

type: INTERNAL

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.system.dnscache.md
======
---
title: Windows.System.DNSCache
hidden: true
tags: [Client Artifact]
---

Windows maintains DNS lookups for a short time in the DNS cache.

This artifact collects DNS cache entries using the WMI class MSFT_DNSClientCache.


<pre><code class="language-yaml">
name: Windows.System.DNSCache
description: |
  Windows maintains DNS lookups for a short time in the DNS cache.

  This artifact collects DNS cache entries using the WMI class MSFT_DNSClientCache.

parameters:
  - name: kMapOfRecordType
    description: |
      Mapping of decimal DNS record types to human-readable types
    type: hidden
    default: |
      {
      "0": "Reserved",
      "1": "A",
      "2": "NS",
      "3": "MD",
      "4": "MF",
      "5": "CNAME",
      "6": "SOA",
      "7": "MB",
      "8": "MG",
      "9": "MR",
      "10": "NULL",
      "11": "WKS",
      "12": "PTR",
      "13": "HINFO",
      "14": "MINFO",
      "15": "MX",
      "16": "TXT",
      "17": "RP",
      "18": "AFSDB",
      "19": "X25",
      "20": "ISDN",
      "21": "RT",
      "22": "NSAP",
      "23": "NSAP-PTR",
      "24": "SIG",
      "25": "KEY",
      "26": "PX",
      "27": "GPOS",
      "28": "AAAA",
      "29": "LOC",
      "30": "NXT",
      "31": "EID",
      "32": "NIMLOC",
      "33": "SRV",
      "34": "ATMA",
      "35": "NAPTR",
      "36": "KX",
      "37": "CERT",
      "38": "A6",
      "39": "DNAME",
      "40": "SINK",
      "41": "OPT",
      "42": "APL",
      "43": "DS",
      "44": "SSHFP",
      "45": "IPSECKEY",
      "46": "RRSIG",
      "47": "NSEC",
      "48": "DNSKEY",
      "49": "DHCID",
      "50": "NSEC3",
      "51": "NSEC3PARAM",
      "52": "TLSA",
      "53": "SMIMEA",
      "54": "Unassigned",
      "55": "HIP",
      "56": "NINFO",
      "57": "RKEY",
      "58": "TALINK",
      "59": "CDS",
      "60": "CDNSKEY",
      "61": "OPENPGPKEY",
      "62": "CSYNC",
      "63": "ZONEMD",
      "64": "SVCB",
      "65": "HTTPS",
      "99": "SPF",
      "100": "UINFO",
      "101": "UID",
      "102": "GID",
      "103": "UNSPEC",
      "104": "NID",
      "105": "L32",
      "106": "L64",
      "107": "LP",
      "108": "EUI48",
      "109": "EUI64",
      "249": "TKEY",
      "250": "TSIG",
      "251": "IXFR",
      "252": "AXFR",
      "253": "MAILB",
      "254": "MAILA",
      "255": "*",
      "256": "URI",
      "257": "CAA",
      "258": "AVC",
      "259": "DOA",
      "260": "AMTRELAY",
      "32768": "TA",
      "32769": "DLV",
      "65535": "Reserved"
      }

  - name: kMapOfStatus
    description: |
      Mapping of decimal status to human-readable status
    type: hidden
    default: |
      {
      "0": "Success",
      "9003": "NotExist",
      "9701": "NoRecords"
      }

  - name: kMapOfSection
    description: |
      Mapping of decimal section to human-readable section
    type: hidden
    default: |
      {
      "1": "Answer",
      "2": "Authority",
      "3": "Additional"
      }

sources:
  - precondition: |
      SELECT OS from info() where OS = "windows"
    query: |
      LET wmiQuery &lt;= '''
         SELECT Data, Entry, Status, TimeToLive, Type, Section
         FROM MSFT_DNSClientCache
      '''
      LET wmiNamespace &lt;= "root/StandardCimv2"
      LET MapOfRecordType &lt;= parse_json(data=kMapOfRecordType)
      LET MapOfStatus &lt;= parse_json(data=kMapOfStatus)
      LET MapOfSection &lt;= parse_json(data=kMapOfSection)

      LET dns_cache_entries = SELECT
          Entry AS Name,
          Data AS Record,
          get(item=MapOfRecordType,
              member=str(str=Type), default=Type) AS RecordType,
          Type AS _RecordType,
          atoi(string=TimeToLive) AS TTL,
          get(item=MapOfStatus,
              member=str(str=Status), default=Status) AS QueryStatus,
          Status AS _QueryStatus,
          get(item=MapOfSection,
              member=str(str=Section), default=Section) AS SectionType,
          Section AS _SectionType
      FROM wmi(query=wmiQuery, namespace=wmiNamespace)

      SELECT * FROM dns_cache_entries

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/generic.client.diskspace.md
======
---
title: Generic.Client.DiskSpace
hidden: true
tags: [Client Artifact]
---

This artifact reports the amount of free disk space. It is designed
to work equally on all architectures:

  1. On Linux and MacOS we call `df -h`.
  2. On Windows we use WMI


<pre><code class="language-yaml">
name: Generic.Client.DiskSpace
description: |
  This artifact reports the amount of free disk space. It is designed
  to work equally on all architectures:

    1. On Linux and MacOS we call `df -h`.
    2. On Windows we use WMI

sources:
- query: |
    LET NonWindows = SELECT * FROM foreach(row={
      SELECT regex_replace(source=Stdout, re="( on| +)", replace=" ") AS Stdout
      FROM execve(argv=["df", "-h"], length=10000)
    }, query={
      SELECT * FROM parse_csv(accessor="data", filename=Stdout, separator=" ")
    })

    -- WMI returns these as strings, we need to convert to ints
    LET wmi_query = SELECT *,
         int(int=FreeSpace) AS FreeSpace,
         int(int=Size) AS Size
      FROM wmi(query="SELECT * FROM Win32_LogicalDisk")

    LET Windows = SELECT DeviceID, Description,
           VolumeName, VolumeSerialNumber,
           humanize(bytes=Size) AS Size,
           humanize(bytes=FreeSpace) AS FreeSpace,
           int(int=FreeSpace / Size * 100) AS `Free%`
    FROM wmi_query

    SELECT * FROM if(condition={
      SELECT OS FROM info() WHERE OS =~ "windows"
    },
    then={ SELECT * FROM Windows},
    else={ SELECT * FROM NonWindows})

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.forensics.recentapps.md
======
---
title: Windows.Forensics.RecentApps
hidden: true
tags: [Client Artifact]
---

GUI Program execution launched on the Win10 system is tracked in the
RecentApps key.

NOTE: This artifact is available up from Windows 10 1607 to 1709.
After that, the RecentApps key is no longer populated in the referenced location. Previously existing data is not removed.


<pre><code class="language-yaml">
name: Windows.Forensics.RecentApps
description: |
  GUI Program execution launched on the Win10 system is tracked in the
  RecentApps key.

  NOTE: This artifact is available up from Windows 10 1607 to 1709.
  After that, the RecentApps key is no longer populated in the referenced location. Previously existing data is not removed.

reference:
  - https://www.sans.org/security-resources/posters/windows-forensics-evidence-of/75/download
  - https://www.forensicfocus.com/forums/general/forensics-windows-registry-program-launch-history/
  - https://thinkdfir.com/2020/10/23/when-did-recentapps-go/

precondition: SELECT OS From info() where OS = 'windows'

parameters:
  - name: UserFilter
    default: ""
    description: If specified we filter by this user ID.
    type: regex

  - name: ExecutionTimeAfter
    default: ""
    type: timestamp
    description: If specified only show executions after this time.

  - name: RecentAppsKey
    default: Software\Microsoft\Windows\CurrentVersion\Search\RecentApps\*

  - name: UserHomes
    default: C:\Users\*\NTUSER.DAT

sources:
  - query: |
      LET TMP = SELECT * FROM foreach(
         row={
            SELECT OSPath FROM glob(globs=UserHomes)
         },
         query={
            SELECT AppId, AppPath, LaunchCount,
                   timestamp(winfiletime=LastAccessedTime) AS LastExecution,
                   timestamp(winfiletime=LastAccessedTime).Unix AS LastExecutionTS,
                   parse_string_with_regex(
                      string=Key.OSPath,
                      regex="/Users/(?P&lt;User&gt;[^/]+)/ntuser.dat").User AS User
            FROM read_reg_key(
               globs=RecentAppsKey,
               root=pathspec(
                 DelegateAccessor="ntfs",
                 DelegatePath=OSPath),
               accessor="raw_reg")
         })

      LET A1 = SELECT * FROM if(
          condition=UserFilter,
          then={
            SELECT * FROM TMP WHERE User =~ UserFilter
          }, else={ SELECT * FROM TMP})

      SELECT * FROM if(
          condition=ExecutionTimeAfter,
          then={
            SELECT * FROM A1 WHERE LastExecutionTS &gt; ExecutionTimeAfter
          }, else={ SELECT * FROM A1})

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/server.monitor.profile.md
======
---
title: Server.Monitor.Profile
hidden: true
tags: [Server Artifact]
---

This artifact collects profiling information from the running
server. This is useful when you notice a high CPU load in the server
and want to know why.

The following options are most useful:

1. Goroutines: This shows the backtraces of all currently running
   goroutines. It will generally show most of the code working in the
   current running set of queries.

2. Heap: This shows all allocations currently in use and where they
   are allocated from. This is useful if the server is taking too
   much memory.

3. Profile: This takes a CPU profile of the running process for the
   number of seconds specified in the Duration parameter. You can
   read profiles using:

```
go tool pprof -callgrind -output=profile.grind profile.bin
kcachegrind profile.grind
```

NOTE: As of 0.7.0 release, this artifact will also collect
goroutines and heap profiles as distinct sources in a more readable
way.


<pre><code class="language-yaml">
name: Server.Monitor.Profile
description: |
  This artifact collects profiling information from the running
  server. This is useful when you notice a high CPU load in the server
  and want to know why.

  The following options are most useful:

  1. Goroutines: This shows the backtraces of all currently running
     goroutines. It will generally show most of the code working in the
     current running set of queries.

  2. Heap: This shows all allocations currently in use and where they
     are allocated from. This is useful if the server is taking too
     much memory.

  3. Profile: This takes a CPU profile of the running process for the
     number of seconds specified in the Duration parameter. You can
     read profiles using:

  ```
  go tool pprof -callgrind -output=profile.grind profile.bin
  kcachegrind profile.grind
  ```

  NOTE: As of 0.7.0 release, this artifact will also collect
  goroutines and heap profiles as distinct sources in a more readable
  way.

type: SERVER

parameters:
  - name: Allocs
    description: A sampling of all past memory allocations
    type: bool
    default: Y
  - name: Block
    description: Stack traces that led to blocking on synchronization primitives
    type: bool
  - name: Goroutine
    description: Stack traces of all current goroutines
    type: bool
    default: Y
  - name: Heap
    description: A sampling of memory allocations of live objects
    type: bool
  - name: Mutex
    description: Stack traces of holders of contended mutexes
    type: bool
  - name: Profile
    description: CPU profile
    type: bool
  - name: Trace
    description: CPU trace
    type: bool
  - name: Logs
    description: Get logs
    type: bool
  - name: QueryLogs
    description: Get recent queries logs
    type: bool
  - name: Metrics
    description: Get server metrics
    type: bool
  - name: Verbose
    description: Print more detail
    type: bool
  - name: Duration
    description: Duration of sampling for Profile and Trace.
    default: "30"

export: |
    LET CleanUp(Name) = regex_replace(
        re="www.velocidex.com/golang/velociraptor/",
        replace="", source=Name)

sources:
  - query: |
      SELECT Type,
             if(condition=get(field="OSPath"),
             then=upload(name=Type + ".bin", file=OSPath)) AS File,
             get(member="Line") AS Line
      FROM profile(allocs=Allocs, block=Block, goroutine=Goroutine,
                   heap=Heap, mutex=Mutex, profile=Profile, trace=Trace,
                   logs=Logs, queries=QueryLogs, metrics=Metrics,
                   debug=if(condition=Verbose, then=2, else=1),
                   duration=atoi(string=Duration))

  - name: Goroutines
    query: |
      SELECT *, {
         SELECT format(format="%v (%v:%v)",
             args=[CleanUp(Name=Name), basename(path=File), Line])
         FROM CallStack
         WHERE File =~ 'velociraptor|vfilter|go-ntfs'
         LIMIT 10
      } AS CallStack
      FROM profile_goroutines()
      WHERE CallStack

  - name: Memory
    query: |
      SELECT InUseBytes, InUseObjects, {
          SELECT format(format="%v (%v:%v)",
            args=[CleanUp(Name=Name), basename(path=File), Line])
          FROM CallStack
          WHERE File =~ 'velociraptor|vfilter|go-ntfs'
          LIMIT 10
      } AS CallStack
      FROM profile_memory()
      ORDER BY InUseBytes DESC

  - name: Logs
    query: |
      SELECT * FROM profile(logs=TRUE)

  - name: RunningQueries
    query: |
      SELECT Line.Start AS Timestamp, Line.Query AS Query
      FROM profile(queries=TRUE)
      WHERE NOT Line.Duration

  - name: AllQueries
    query: |
      SELECT Line.Start AS Timestamp, int(int = Line.Duration / 1000000) AS DurationSec, Line.Query AS Query
      FROM profile(queries=TRUE)

  - name: Metrics
    query: |
      SELECT Line.name AS Name, Line.value as value
      FROM profile(metrics=TRUE)

  - name: Everything
    query: SELECT * FROM profile(type='.+')

column_types:
  - name: InUseBytes
    type: mb

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/server.internal.masterregistrations.md
======
---
title: Server.Internal.MasterRegistrations
hidden: true
tags: [Internal Artifact]
---

The master will advertise to the minions the events it is interested
in.


<pre><code class="language-yaml">
name: Server.Internal.MasterRegistrations
description: |
  The master will advertise to the minions the events it is interested
  in.

type: INTERNAL
column_types:
  - name: Events
    type: json_array

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/macos.network.netstat.md
======
---
title: MacOS.Network.Netstat
hidden: true
tags: [Client Artifact]
---

Report network connections, and enrich with process information.


<pre><code class="language-yaml">
name: MacOS.Network.Netstat
description: |
  Report network connections, and enrich with process information.

type: CLIENT

precondition:
  SELECT OS From info() where OS = 'darwin'

parameters:
  - name: IPRegex
    description: "regex search over IP address fields."
    default:  "."
    type: regex
  - name: PortRegex
    description: "regex search over port fields."
    default: "."
    type: regex
  - name: ProcessNameRegex
    description: "regex search over source process name"
    default: "."
    type: regex
  - name: UsernameRegex
    description: "regex search over source process user context"
    default: "."
    type: regex
  - name: ConnectionStatusRegex
    description: "regex search over connection status"
    default: "LISTEN|ESTAB"
    type: regex
  - name: ProcessPathRegex
    description: "regex search over source process path"
    default: "."
    type: regex
  - name: CommandLineRegex
    description: "regex search over source process commandline"
    default: "."
    type: regex
  - name: CallChainRegex
    description: "regex search over the process callchain"
    default: "."
    type: regex
  - name: AlsoCollectFullProcessTree
    type: bool

sources:
  - query: |
      SELECT Laddr.IP AS Laddr,
             Laddr.Port AS Lport,
             Raddr.IP AS Raddr,
             Raddr.Port AS Rport,
             Pid,
             Status, TypeString AS Type,
             process_tracker_get(id=Pid).Data AS ProcInfo,
             join(array=process_tracker_callchain(id=Pid).Data.Name,
                  sep=" -&gt; ") AS CallChain,
             if(condition=AlsoCollectFullProcessTree,
                then=process_tracker_tree(id=Pid)) AS ChildrenTree
      FROM netstat()
      WHERE Status =~ ConnectionStatusRegex
       AND  Raddr =~ IPRegex
       AND  ( Lport =~ PortRegex OR Rport =~ PortRegex )
       AND ProcInfo.Name =~ ProcessNameRegex
       AND ProcInfo.Username =~ UsernameRegex
       AND ProcInfo.Exe =~ ProcessPathRegex
       AND ProcInfo.CommandLine =~ CommandLineRegex
       AND CallChain =~ CallChainRegex

column_types:
  - name: ChildrenTree
    type: tree

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/linux.osquery.generic.md
======
---
title: Linux.OSQuery.Generic
hidden: true
tags: [Client Artifact]
---

OSQuery is an excellent tool for querying system state across the
three supported Velociraptor platform (Windows/Linux/MacOS).

You can read more about OSQuery on https://osquery.io/


<pre><code class="language-yaml">
name: Linux.OSQuery.Generic
description: |
  OSQuery is an excellent tool for querying system state across the
  three supported Velociraptor platform (Windows/Linux/MacOS).

  You can read more about OSQuery on https://osquery.io/

reference:
  - https://osquery.io/
  - https://github.com/osquery/osquery

# I am not actually sure if OSQuery allows arbitrary command execution via SQL?
required_permissions:
  - EXECVE

precondition: SELECT OS From info() where OS = 'linux'

tools:
  - name: OSQueryLinux
    github_project: Velocidex/OSQuery-Releases
    github_asset_regex: linux-amd64

parameters:
  - name: Query
    default: "SELECT * FROM osquery_info"

sources:
  - query: |
      LET binary &lt;= SELECT OSPath
      FROM Artifact.Generic.Utils.FetchBinary(ToolName="OSQueryLinux")

      LET result = SELECT * FROM execve(
         argv=[binary[0].OSPath, "--json", Query],
         length=1000000)

      SELECT * FROM foreach(row=result,
      query={
         SELECT * FROM parse_json_array(data=Stdout)
      })

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.eventlogs.powershellmodule.md
======
---
title: Windows.EventLogs.PowershellModule
hidden: true
tags: [Client Artifact]
---

This Artifact will search and extract Module events (Event ID 4103) from
Powershell-Operational Event Logs.

Powershell is commonly used by attackers across all stages of the attack
lifecycle. Although quite noisy Module logging can provide valuable insight.

There are several parameter's available for search leveraging regex.
  - DateAfter enables search for events after this date.
  - DateBefore enables search for events before this date.
  - ContextRegex enables regex search over ContextInfo text field.
  - PayloadRegex enables a regex search over Payload text field.
  - SearchVSS enables VSS search


<pre><code class="language-yaml">
name: Windows.EventLogs.PowershellModule
description: |
  This Artifact will search and extract Module events (Event ID 4103) from
  Powershell-Operational Event Logs.

  Powershell is commonly used by attackers across all stages of the attack
  lifecycle. Although quite noisy Module logging can provide valuable insight.

  There are several parameter's available for search leveraging regex.
    - DateAfter enables search for events after this date.
    - DateBefore enables search for events before this date.
    - ContextRegex enables regex search over ContextInfo text field.
    - PayloadRegex enables a regex search over Payload text field.
    - SearchVSS enables VSS search


author: Matt Green - @mgreen27

reference:
  - https://attack.mitre.org/techniques/T1059/001/
  - https://www.fireeye.com/blog/threat-research/2016/02/greater_visibilityt.html

parameters:
  - name: EventLog
    default: C:\Windows\system32\winevt\logs\Microsoft-Windows-PowerShell%4Operational.evtx
  - name: DateAfter
    description: "search for events after this date. YYYY-MM-DDTmm:hh:ss Z"
    type: timestamp
  - name: DateBefore
    description: "search for events before this date. YYYY-MM-DDTmm:hh:ss Z"
    type: timestamp
  - name: ContextRegex
    description: "regex search over Payload text field."
    type: regex
  - name: PayloadRegex
    description: "regex search over Payload text field."
    type: regex

  - name: VSSAnalysisAge
    type: int
    default: 0
    description: |
      If larger than zero we analyze VSS within this many days
      ago. (e.g 7 will analyze all VSS within the last week).  Note
      that when using VSS analysis we have to use the ntfs accessor
      for everything which will be much slower.

sources:
  - query: |
        LET VSS_MAX_AGE_DAYS &lt;= VSSAnalysisAge
        LET Accessor &lt;= if(condition=VSSAnalysisAge &gt; 0, then="ntfs_vss", else="auto")

        -- Build time bounds
        LET DateAfterTime &lt;= if(condition=DateAfter,
            then=timestamp(epoch=DateAfter), else=timestamp(epoch="1600-01-01"))
        LET DateBeforeTime &lt;= if(condition=DateBefore,
            then=timestamp(epoch=DateBefore), else=timestamp(epoch="2200-01-01"))

        -- Determine target files
        LET files =
              SELECT *, OSPath as Source
              FROM glob(globs=EventLog, accessor=Accessor)

        -- Main query
        LET hits = SELECT * FROM foreach(
            row=files,
            query={
              SELECT
                timestamp(epoch=System.TimeCreated.SystemTime) As EventTime,
                System.EventID.Value as EventID,
                System.Computer as Computer,
                System.Security.UserID as SecurityID,
                EventData.ContextInfo as ContextInfo,
                EventData.Payload as Payload,
                Message,
                System.EventRecordID as EventRecordID,
                System.Level as Level,
                System.Opcode as Opcode,
                System.Task as Task,
                Source
              FROM parse_evtx(filename=OSPath, accessor=Accessor)
              WHERE EventID = 4103
                AND EventTime &gt; DateAfterTime
                AND EventTime &lt; DateBeforeTime
                AND if(condition=ContextRegex,
                    then=ContextInfo=~ContextRegex,else=TRUE)
                AND if(condition=PayloadRegex,
                    then=ContextInfo=~PayloadRegex,else=TRUE)
            })
          ORDER BY Source DESC

        -- Output results
        SELECT
            EventTime,
            EventID,
            Computer,
            SecurityID,
            ContextInfo,
            Payload,
            Message,
            EventRecordID,
            Level,
            Opcode,
            Task,
            Source
        FROM hits

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.events.kerbroasting.md
======
---
title: Windows.Events.Kerbroasting
hidden: true
tags: [Client Event Artifact]
---

**Description**:
This Artifact will monitor all successful Kerberos TGS Ticket events for
Service Accounts (SPN attribute) implemented with weak encryption. These
tickets are vulnerable to brute force attack and this event is an indicator
of a Kerbroasting attack.

**ATT&CK**: [T1208 - Kerbroasting](https://attack.mitre.org/techniques/T1208/)
Typical attacker methodology is to firstly request accounts in the domain
with SPN attributes, then request an insecure TGS ticket for brute forcing.
This attack is particularly effective as any domain credentials can be used
to implement the attack and service accounts often have elevated privileges.
Kerbroasting can be used for privilege escalation or persistence by adding a
SPN attribute to an unexpected account.

**Reference**: [The Art of Detecting Kerberoast Attacks](https://www.trustedsec.com/2018/05/art_of_kerberoast/)
**Log Source**: Windows Security Event Log (Domain Controllers)
**Event ID**: 4769
**Status**: 0x0 (Audit Success)
**Ticket Encryption**: 0x17 (RC4)
**Service Name**: NOT krbtgt or NOT a system account (account name ends in $)
**TargetUserName**: NOT a system account (*$@*)


Monitor and alert on unusual events from an unexpected IP.
Note: There are potential false positives so whitelist normal source IPs and
manage risk of insecure ticket generation.


```yaml
name: Windows.Events.Kerbroasting
description: |
  **Description**:
  This Artifact will monitor all successful Kerberos TGS Ticket events for
  Service Accounts (SPN attribute) implemented with weak encryption. These
  tickets are vulnerable to brute force attack and this event is an indicator
  of a Kerbroasting attack.

  **ATT&CK**: [T1208 - Kerbroasting](https://attack.mitre.org/techniques/T1208/)
  Typical attacker methodology is to firstly request accounts in the domain
  with SPN attributes, then request an insecure TGS ticket for brute forcing.
  This attack is particularly effective as any domain credentials can be used
  to implement the attack and service accounts often have elevated privileges.
  Kerbroasting can be used for privilege escalation or persistence by adding a
  SPN attribute to an unexpected account.

  **Reference**: [The Art of Detecting Kerberoast Attacks](https://www.trustedsec.com/2018/05/art_of_kerberoast/)
  **Log Source**: Windows Security Event Log (Domain Controllers)
  **Event ID**: 4769
  **Status**: 0x0 (Audit Success)
  **Ticket Encryption**: 0x17 (RC4)
  **Service Name**: NOT krbtgt or NOT a system account (account name ends in $)
  **TargetUserName**: NOT a system account (*$@*)


  Monitor and alert on unusual events from an unexpected IP.
  Note: There are potential false positives so whitelist normal source IPs and
  manage risk of insecure ticket generation.


author: Matt Green - @mgreen27

type: CLIENT_EVENT

parameters:
  - name: eventLog
    default: C:\Windows\system32\winevt\logs\Security.evtx

sources:
  - name: Kerbroasting
    query: |
      LET files = SELECT * FROM glob(globs=eventLog)

      SELECT timestamp(epoch=System.TimeCreated.SystemTime) As EventTime,
              System.EventID.Value as EventID,
              System.Computer as Computer,
              EventData.ServiceName as ServiceName,
              EventData.ServiceSid as ServiceSid,
              EventData.TargetUserName as TargetUserName,
              "0x" + format(format="%x", args=EventData.Status) as Status,
              EventData.TargetDomainName as TargetDomainName,
              "0x" + format(format="%x", args=EventData.TicketEncryptionType) as TicketEncryptionType,
              "0x" + format(format="%x", args=EventData.TicketOptions) as TicketOptions,
              EventData.TransmittedServices as TransmittedServices,
              EventData.IpAddress as IpAddress,
              EventData.IpPort as IpPort
        FROM foreach(
          row=files,
          async=TRUE,
          query={
            SELECT *
            FROM watch_evtx(filename=FullPath)
            WHERE System.EventID.Value = 4769
                AND EventData.TicketEncryptionType = 23
                AND EventData.Status = 0
                AND NOT EventData.ServiceName =~ "krbtgt|\\$$"
                AND NOT EventData.TargetUserName =~ "\\$@"
        })

```

---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.sys.users.md
======
---
title: Windows.Sys.Users
hidden: true
tags: [Client Artifact]
---

List User accounts by inspecting registry keys. This method is a
reliable indicator for users who have physically logged into the
system and thereby created local profiles.

This will not include domain users or the output from `NetUserEnum`
- you should collect the `Windows.Sys.AllUsers` artifact to get all
possible users on the system.


<pre><code class="language-yaml">
name: Windows.Sys.Users
description: |
  List User accounts by inspecting registry keys. This method is a
  reliable indicator for users who have physically logged into the
  system and thereby created local profiles.

  This will not include domain users or the output from `NetUserEnum`
  - you should collect the `Windows.Sys.AllUsers` artifact to get all
  possible users on the system.

parameters:
  - name: remoteRegKey
    default: HKEY_LOCAL_MACHINE\SOFTWARE\Microsoft\Windows NT\CurrentVersion\ProfileList\*

imports:
  - Windows.Sys.AllUsers

sources:
  - precondition:
      SELECT OS From info() where OS = 'windows'

    query: |
        LET GetTimestamp(High, Low) = if(condition=High,
                then=timestamp(winfiletime=High * 4294967296 + Low))

        -- lookupSID() may not be available on deaddisk analysis
        SELECT split(string=Key.OSPath.Basename, sep="-")[-1] as Uid,
           "" AS Gid,
           LookupSIDCache(SID=Key.OSPath.Basename || "") AS Name,
           Key.OSPath as Description,
           ProfileImagePath as Directory,
           Key.OSPath.Basename as UUID,
           Key.Mtime as Mtime,
           {
                SELECT Mtime
                FROM stat(filename=expand(path=ProfileImagePath))
            } AS HomedirMtime,
           dict(ProfileLoadTime=GetTimestamp(
                   High=LocalProfileLoadTimeHigh, Low=LocalProfileLoadTimeLow),
                ProfileUnloadTime=GetTimestamp(
                   High=LocalProfileUnloadTimeHigh, Low=LocalProfileUnloadTimeLow)
           ) AS Data
        FROM read_reg_key(globs=remoteRegKey, accessor="registry")

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.system.shares.md
======
---
title: Windows.System.Shares
hidden: true
tags: [Client Artifact]
---

This artifact will extract network shares per machine.


<pre><code class="language-yaml">
name: Windows.System.Shares
author: 'Matt Green - @mgreen27'
description: |
   This artifact will extract network shares per machine.

type: CLIENT

parameters:
  - name: NameRegex
    description: Regex filter for share name. e.g Admin\$ for Admin$
    default: .
    type: regex
  - name: PathRegex
    description: Regex filter for local path. e.g C:\\Windows$ for Admin$
    default: .
    type: regex

sources:
  - precondition:
      SELECT OS From info() where OS = 'windows'

    query: |
        SELECT Name, Path, Caption, Status,MaximumAllowed,AllowMaximum,InstallDate
        FROM wmi(query='SELECT * FROM Win32_Share',namespace='root/cimv2')
        WHERE Name =~ NameRegex AND Path =~ PathRegex
</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/system.vfs.downloadfile.md
======
---
title: System.VFS.DownloadFile
hidden: true
tags: [Client Artifact]
---

This is an internal artifact used by the GUI to populate the
VFS. You may run it manually if you like, but typically it is
launched by the GUI when the user clicks the "Collect from client"
button at the file "Stats" tab.

If you run it yourself (or via the API) the results will also be
shown in the VFS view.


<pre><code class="language-yaml">
name: System.VFS.DownloadFile
description: |
  This is an internal artifact used by the GUI to populate the
  VFS. You may run it manually if you like, but typically it is
  launched by the GUI when the user clicks the "Collect from client"
  button at the file "Stats" tab.

  If you run it yourself (or via the API) the results will also be
  shown in the VFS view.

parameters:
  - name: Path
    description: The path of the file to download.
    default: /
  - name: Components
    type: json_array
    description: Alternatively, this is an explicit list of components.
  - name: Accessor
    default: file
  - name: Recursively
    type: bool
    description: |
      If specified, Path is interpreted as a directory and
      we download all files below it.

sources:
  - query: |
      LET download_one_file = if(
         condition=version(plugin="stat") &gt; 1,
         then= {
           SELECT OSPath AS Path, Accessor,
              Size, upload(file=OSPath, accessor=Accessor) AS Upload
           FROM stat(filename=Components, accessor=Accessor)
        },
        else= {
           SELECT OSPath AS Path, Accessor,
              Size, upload(file=OSPath, accessor=Accessor) AS Upload
          FROM stat(filename=Path, accessor=Accessor)
        })

      LET download_recursive = if(
         condition=version(plugin="stat") &gt; 1,
         then= {
           SELECT OSPath AS Path, Accessor,
              Size, upload(file=OSPath, accessor=Accessor) AS Upload
           FROM glob(globs="**", root=Components,
                     accessor=Accessor, nosymlink=TRUE)
           WHERE Mode.IsRegular
        },
        else={
          SELECT OSPath AS Path, Accessor,
            Size, upload(file=OSPath, accessor=Accessor) AS Upload
          FROM glob(globs="**", root=Path, accessor=Accessor)
          WHERE Mode.IsRegular
       })

      SELECT Path, Accessor,
             Upload.Size AS Size,
             Upload.StoredSize AS StoredSize,
             Upload.Sha256 AS Sha256,
             Upload.Md5 AS Md5,
             Upload.Error AS Error,
             Path.Components AS _Components
      FROM if(condition=Recursively,
        then={ SELECT * FROM download_recursive},
        else={ SELECT * FROM download_one_file})

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.search.filefinder.md
======
---
title: Windows.Search.FileFinder
hidden: true
tags: [Client Artifact]
---

Find files on the filesystem using the filename or content.


## Performance Note

This artifact can be quite expensive, especially if we search file
content. It will require opening each file and reading its entire
content. To minimize the impact on the endpoint we recommend this
artifact is collected with a rate limited way (about 20-50 ops per
second).

This artifact is useful in the following scenarios:

  * We need to locate all the places on our network where customer
    data has been copied.

  * We’ve identified malware in a data breach, named using short
    random strings in specific folders and need to search for other
    instances across the network.

  * We believe our user account credentials have been dumped and
    need to locate them.

  * We need to search for exposed credit card data to satisfy PCI
    requirements.

  * We have a sample of data that has been disclosed and need to
    locate other similar files


<pre><code class="language-yaml">
name: Windows.Search.FileFinder
description: |
  Find files on the filesystem using the filename or content.


  ## Performance Note

  This artifact can be quite expensive, especially if we search file
  content. It will require opening each file and reading its entire
  content. To minimize the impact on the endpoint we recommend this
  artifact is collected with a rate limited way (about 20-50 ops per
  second).

  This artifact is useful in the following scenarios:

    * We need to locate all the places on our network where customer
      data has been copied.

    * We’ve identified malware in a data breach, named using short
      random strings in specific folders and need to search for other
      instances across the network.

    * We believe our user account credentials have been dumped and
      need to locate them.

    * We need to search for exposed credit card data to satisfy PCI
      requirements.

    * We have a sample of data that has been disclosed and need to
      locate other similar files


precondition:
  SELECT * FROM info() where OS = 'windows'

parameters:
  - name: SearchFilesGlobTable
    type: csv
    default: |
      Glob
      C:/Users/SomeUser/*
    description: Specify multiple globs to search for.

  - name: Accessor
    default: auto
    description: The accessor to use
    type: choices
    choices:
      - auto
      - registry
      - file
      - ntfs
      - ntfs_vss

  - name: YaraRule
    type: yara
    default:
    description: A yara rule to search for matching files.

  - name: Upload_File
    default: N
    type: bool

  - name: Calculate_Hash
    default: N
    type: bool

  - name: MoreRecentThan
    default: ""
    type: timestamp

  - name: ModifiedBefore
    default: ""
    type: timestamp

  - name: VSS_MAX_AGE_DAYS
    type: int
    description: |
      If larger than 0 we restrict VSS age to this many days
      ago. Otherwise we find all VSS.

sources:
  - query: |
      LET file_search = SELECT OSPath,
               get(item=Data, field="mft") as Inode,
               Mode.String AS Mode, Size,
               Mtime AS MTime,
               Atime AS ATime,
               Btime AS BTime,
               Ctime AS CTime, "" AS Keywords,
               IsDir, Data
        FROM glob(globs=SearchFilesGlobTable.Glob,
                  accessor=Accessor)

      LET more_recent = SELECT * FROM if(
        condition=MoreRecentThan,
        then={
          SELECT * FROM file_search
          WHERE MTime &gt; MoreRecentThan
        }, else=file_search)

      LET modified_before = SELECT * FROM if(
        condition=ModifiedBefore,
        then={
          SELECT * FROM more_recent
          WHERE MTime &lt; ModifiedBefore
           AND  MTime &gt; MoreRecentThan
        }, else=more_recent)

      LET keyword_search = SELECT * FROM if(
        condition=YaraRule,
        then={
          SELECT * FROM foreach(
            row={
               SELECT * FROM modified_before
               WHERE NOT IsDir
            },
            query={
               SELECT OSPath, Inode, Mode,
                      Size, MTime, ATime, CTime, BTime,
                      str(str=String.Data) As Keywords, IsDir, Data

               FROM yara(files=OSPath,
                         key="A",
                         rules=YaraRule,
                         accessor=Accessor)
            })
        }, else=modified_before)

      SELECT OSPath, Inode, Mode, Size, MTime, ATime,
             CTime, BTime, Keywords, IsDir,
               if(condition=Upload_File and NOT IsDir,
                  then=upload(file=OSPath, accessor=Accessor)) AS Upload,
               if(condition=Calculate_Hash and NOT IsDir,
                  then=hash(path=OSPath, accessor=Accessor)) AS Hash,
            Data
      FROM keyword_search

column_types:
  - name: Modified
    type: timestamp
  - name: ATime
    type: timestamp
  - name: MTime
    type: timestamp
  - name: CTime
    type: timestamp
  - name: Upload
    type: preview_upload

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/linux.applications.docker.info.md
======
---
title: Linux.Applications.Docker.Info
hidden: true
tags: [Client Artifact]
---

Get Dockers info by connecting to its socket.

<pre><code class="language-yaml">
name: Linux.Applications.Docker.Info
description: Get Dockers info by connecting to its socket.
parameters:
  - name: dockerSocket
    description: |
      Docker server socket. You will normally need to be root to connect.
    default: /var/run/docker.sock
sources:
  - precondition: |
      SELECT OS From info() where OS = 'linux'
    query: |
        LET data = SELECT parse_json(data=Content) as JSON
        FROM http_client(url=dockerSocket + ":unix/info")

        SELECT JSON.ID as ID,
               JSON.Containers as Containers,
               JSON.ContainersRunning as ContainersRunning,
               JSON.ContainersPaused as ContainersPaused,
               JSON.ContainersStopped as ContainersStopped,
               JSON.Images as Images,
               JSON.Driver as Driver,
               JSON.MemoryLimit as MemoryLimit,
               JSON.SwapLimit as SwapLimit,
               JSON.KernelMemory as KernelMemory,
               JSON.CpuCfsPeriod as CpuCfsPeriod,
               JSON.CpuCfsQuota as CpuCfsQuota,
               JSON.CPUShares as CPUShares,
               JSON.CPUSet as CPUSet,
               JSON.IPv4Forwarding as IPv4Forwarding,
               JSON.BridgeNfIptables as BridgeNfIptables,
               JSON.BridgeNfIp6tables as BridgeNfIp6tables,
               JSON.OomKillDisable as OomKillDisable,
               JSON.LoggingDriver as LoggingDriver,
               JSON.CgroupDriver as CgroupDriver,
               JSON.KernelVersion as KernelVersion,
               JSON.OperatingSystem as OperatingSystem,
               JSON.OSType as OSType,
               JSON.Architecture as Architecture,
               JSON.NCPU as NCPU,
               JSON.MemTotal as MemTotal,
               JSON.HttpProxy as HttpProxy,
               JSON.HttpsProxy as HttpsProxy,
               JSON.NoProxy as NoProxy,
               JSON.Name as Name,
               JSON.ServerVersion as ServerVersion,
               JSON.DockerRootDir as DockerRootDir
        FROM data

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/custom.server.enrichment.virustotal.md
======
---
title: Custom.Server.Enrichment.Virustotal
hidden: true
tags: [Server Artifact]
---

Submit a file hash or IP to Virustotal for details. Default Public API restriction is 4 requests/min.

This artifact can be called from within another artifact (such as one looking for files) to enrich the data made available by that artifact.

Ex.

  `SELECT * from Artifact.Server.Enrichment.Virustotal(Hash=$YOURHASH)`
  `SELECT * from Artifact.Server.Enrichment.Virustotal(IP=$YOURIP,QueryType='ip')`

`TO-DO`: Implement a timer to spread out requests


<pre><code class="language-yaml">
name: Custom.Server.Enrichment.Virustotal
author: Wes Lambert -- @therealwlambert, Whitney Champion -- @shortxstack
description: |
  Submit a file hash or IP to Virustotal for details. Default Public API restriction is 4 requests/min.

  This artifact can be called from within another artifact (such as one looking for files) to enrich the data made available by that artifact.

  Ex.

    `SELECT * from Artifact.Server.Enrichment.Virustotal(Hash=$YOURHASH)`
    `SELECT * from Artifact.Server.Enrichment.Virustotal(IP=$YOURIP,QueryType='ip')`

  `TO-DO`: Implement a timer to spread out requests

type: SERVER

parameters:
    - name: QueryType
      type: choices 
      description: The type of query--hash or IP
      default: hash
      choices:
         - hash
         - ip

    - name: Hash
      type: string
      description: The file hash to submit to Hybrid Analysis (MD5, SHA1, SHA256).
      default:

    - name: IP
      type: string
      description: The IP address to submit to Hybrid Analysis.
      default:

    - name: VirustotalKey
      type: string
      description: API key for Virustotal. Leave blank here if using server metadata store.
      default:

sources:
  - query: |
        LET Creds = if(
           condition=VirustotalKey,
           then=VirustotalKey,
           else=server_metadata().VirustotalKey)

        LET URL = if(
           condition= QueryType='hash',
           then= 'https://www.virustotal.com/api/v3/files/' + Hash,
           else= 'https://www.virustotal.com/api/v3/ip_addresses/' + IP)

        LET Data = SELECT parse_json(data=Content) AS VTData
        FROM http_client(url=URL, headers=dict(`x-apikey`=Creds))

        SELECT format(format='%v/%v',
             args=[VTData.data.attributes.last_analysis_stats.malicious,
                   VTData.data.attributes.last_analysis_stats.malicious +
                   VTData.data.attributes.last_analysis_stats.undetected]) As VTRating,
            timestamp(epoch=VTData.data.attributes.first_seen_itw_date) AS FirstSeen,
            timestamp(epoch=VTData.data.attributes.first_submission_date) AS FirstSubmitted,
            timestamp(epoch=VTData.data.attributes.last_analysis_date) AS LastAnalysis,
            VTData.data.attributes.as_owner AS Owner, 
            VTData.data.attributes.whois AS WhoIs,
            VTData.data.attributes.crowdsourced_yara_results AS YARAResults,
            VTData AS _Data
        FROM Data

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.detection.yara.glob.md
======
---
title: Windows.Detection.Yara.Glob
hidden: true
tags: [Client Artifact]
---

This artifact returns a list of target files then runs Yara over the target
list.

There are 2 kinds of Yara rules that can be deployed:

1. Url link to a yara rule.
2. or a Standard Yara rule attached as a parameter.

Only one method of Yara will be applied and search order is as above.

The artifact leverages Glob for search so relevant filters can be applied
including Glob, Size and date. Date filters will target files with a timestamp
before LatestTime and after EarliestTime. The artifact also has an option to
upload any files with Yara hits.

Some examples of path glob may include:

* Specific binary: `/usr/bin/ls`
* Wildcards: `/var/www/*.js`
* More wildcards: `/var/www/**/*.js`
* Multiple extentions: `/var/www/*\.{php,aspx,js,html}`
* Windows: `C:/Users/**/*.{exe,dll,ps1,bat}`
* Windows: `C:\Users\**\*.{exe,dll,ps1,bat}`

NOTE: this artifact runs the glob plugin with the nosymlink switch turned on.
This will NOT follow any symlinks and may cause unexpected results if
unknowingly targeting a folder with symlinks.
If upload is selected NumberOfHits is redundant and not advised as hits are
grouped by path to ensure files only downloaded once.


<pre><code class="language-yaml">
name: Generic.Detection.Yara.Glob
author: Matt Green - @mgreen27
description: |
  This artifact returns a list of target files then runs Yara over the target
  list.

  There are 2 kinds of Yara rules that can be deployed:

  1. Url link to a yara rule.
  2. or a Standard Yara rule attached as a parameter.

  Only one method of Yara will be applied and search order is as above.

  The artifact leverages Glob for search so relevant filters can be applied
  including Glob, Size and date. Date filters will target files with a timestamp
  before LatestTime and after EarliestTime. The artifact also has an option to
  upload any files with Yara hits.

  Some examples of path glob may include:

  * Specific binary: `/usr/bin/ls`
  * Wildcards: `/var/www/*.js`
  * More wildcards: `/var/www/**/*.js`
  * Multiple extentions: `/var/www/*\.{php,aspx,js,html}`
  * Windows: `C:/Users/**/*.{exe,dll,ps1,bat}`
  * Windows: `C:\Users\**\*.{exe,dll,ps1,bat}`

  NOTE: this artifact runs the glob plugin with the nosymlink switch turned on.
  This will NOT follow any symlinks and may cause unexpected results if
  unknowingly targeting a folder with symlinks.
  If upload is selected NumberOfHits is redundant and not advised as hits are
  grouped by path to ensure files only downloaded once.

aliases:
  - Windows.Detection.Yara.Glob
  - Linux.Detection.Yara.Glob
  - MacOS.Detection.Yara.Glob

type: CLIENT
parameters:
  - name: PathGlob
    description: Only file names that match this glob will be scanned.
    default: /usr/bin/ls
  - name: SizeMax
    description: maximum size of target file.
    type: int64
  - name: SizeMin
    description: minimum size of target file.
    type: int64
  - name: UploadHits
    type: bool
  - name: DateAfter
    type: timestamp
    description: "search for events after this date. YYYY-MM-DDTmm:hh:ssZ"
  - name: DateBefore
    type: timestamp
    description: "search for events before this date. YYYY-MM-DDTmm:hh:ssZ"
  - name: YaraUrl
    description: If configured will attempt to download Yara rules form Url
    type: upload
  - name: YaraRule
    type: yara
    description: Final Yara option and the default if no other options provided.
    default: |
        rule IsELF:TestRule {
           meta:
              author = "the internet"
              date = "2021-05-03"
              description = "A simple ELF rule to test yara features"
          condition:
             uint32(0) == 0x464c457f
        }
  - name: NumberOfHits
    description: This artifact will stop by default at one hit. This setting allows additional hits
    default: 1
    type: int
  - name: ContextBytes
    description: Include this amount of bytes around hit as context.
    default: 0
    type: int

sources:
  - query: |
      -- check which Yara to use
      LET yara_rules &lt;= YaraUrl || YaraRule

      -- time testing
      LET time_test(stamp) =
            if(condition= DateBefore AND DateAfter,
                then= stamp &lt; DateBefore AND stamp &gt; DateAfter,
                else=
            if(condition=DateBefore,
                then= stamp &lt; DateBefore,
                else=
            if(condition= DateAfter,
                then= stamp &gt; DateAfter,
                else= True
            )))

      -- first find all matching glob
      LET files = SELECT OSPath, Name, Size, Mtime, Atime, Ctime, Btime
        FROM glob(globs=PathGlob,nosymlink='True')
        WHERE
          NOT IsDir AND NOT IsLink
          AND if(condition=SizeMin,
            then= SizeMin &lt; Size,
            else= True)
          AND if(condition=SizeMax,
            then=SizeMax &gt; Size,
            else= True)
          AND
             ( time_test(stamp=Mtime)
            OR time_test(stamp=Atime)
            OR time_test(stamp=Ctime)
            OR time_test(stamp=Btime))

      -- scan files and prepare hit metadata
      LET hits = SELECT * FROM foreach(row=files,
            query={
                SELECT
                    OSPath,
                    File.Size as Size,
                    Mtime, Atime, Ctime, Btime,
                    Rule, Tags, Meta,
                    String.Name as YaraString,
                    String.Offset as HitOffset,
                    upload( accessor='scope',
                            file='String.Data',
                            name=format(format="%v-%v-%v",
                            args=[
                                OSPath,
                                if(condition= String.Offset - ContextBytes &lt; 0,
                                    then= 0,
                                    else= String.Offset - ContextBytes),
                                if(condition= String.Offset + ContextBytes &gt; Size,
                                    then= Size,
                                    else= String.Offset + ContextBytes) ]
                            )) as HitContext
                FROM yara(rules=yara_rules,files=OSPath,
                  context=ContextBytes,number=NumberOfHits)
            })

      -- upload files if selected
      LET upload_hits = SELECT *, upload(file=OSPath,name=OSPath) as Upload FROM hits

      -- return rows
      SELECT * FROM if(condition= UploadHits,
                        then= upload_hits,
                        else= hits )

column_types:
  - name: HitContext
    type: preview_upload
</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.forensics.processinfo.md
======
---
title: Windows.Forensics.ProcessInfo
hidden: true
tags: [Client Artifact]
---

Extract information about processes.


```yaml
name: Windows.Forensics.ProcessInfo
description: |
   Extract information about processes.

parameters:
  - name: ProcessNameRegex
    default: .
    type: regex

sources:
- query: |
       LET profile = '''[
       ["PEB",0 , [
           # https://docs.microsoft.com/en-us/windows/win32/api/winternl/ns-winternl-peb
           ["ProcessParameters", 32, "Pointer", {
                "type": "ProcessParameters",
           }],
       ]],
       ["ProcessParameters", 0, [
          ["ImagePathName", 96, "UNICODE_STRING"],
          ["CommandLine", 112, "UNICODE_STRING"],
          ["CurrentDirectory", 56, "CURDIR"],
          ["EnvironmentSize", 1008, "uint64"],
          ["Environment", 128, "Pointer", {
              "type": "String",
              "type_options": {
                 "length": "x=>x.EnvironmentSize",
                 "encoding": "utf16",
                 "max_length": 10000,
                 "term": "",
              }}]
       ]],
       ["CURDIR", 0, [
         ["DosPath", 0, "UNICODE_STRING"],
       ]],
       ["UNICODE_STRING", 16, [
          ["Length", 0, "uint16"],
          ["Buffer", 8, "Pointer", {
              "type": "String",
              "type_options": {
                "encoding": "utf16",
                "length": "x=>x.Length",
                "term": "",
              }}],
       ]]
       ]'''

       LET ParsePeb(PID) = SELECT Name,
           format(format="%0#x", args=PebBaseAddress) AS PebBaseAddress, Pid,
           parse_binary(accessor="process",
                        filename=format(format="/%v", args=PID),
                        profile=profile,
                        struct="PEB",
                        offset=PebBaseAddress) AS Data
       FROM pslist(pid=PID)

       -- The Environment string consists of null terminated
       -- lines. Each line contains the variable name followed by an =
       -- sign and then the variable value.
       LET SplitEnv(EnvString) =  SELECT parse_string_with_regex(
          string=_value, regex="^(?P<Name>[^=]*)=(?P<Value>.+)") AS Line
       FROM foreach(row=split(string=EnvString, sep="\x00"))
       WHERE Line

       -- Massage the parsed data into a structured table
       LET Calculate(PID) = SELECT Name, PebBaseAddress, Pid,
              Data.ProcessParameters.ImagePathName.Buffer AS ImagePathName,
              Data.ProcessParameters.CommandLine.Buffer AS CommandLine,
              Data.ProcessParameters.CurrentDirectory.DosPath.Buffer AS CurrentDirectory,
              -- Build an Env dict out of the parsed string.
              to_dict(item={
                 SELECT Line.Name AS _key, Line.Value AS _value
                 FROM SplitEnv(EnvString=Data.ProcessParameters.Environment)
              }) AS Env
        FROM ParsePeb(PID=PID)

        SELECT * FROM foreach(row={
           SELECT Pid FROM pslist()
           WHERE Name =~ ProcessNameRegex
        }, query={
           SELECT * FROM Calculate(PID=Pid)
        })

```

---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.eventlogs.scheduledtasks.md
======
---
title: Windows.EventLogs.ScheduledTasks
hidden: true
tags: [Client Artifact]
---

This artifact will extract Event Logs related to ScheduledTasks and provide
a nice format for simplified review.

Adversaries may abuse tasks for execution, persistence, lateral movement or
privilege escalation. This artifact collates all events from
Microsoft-Windows-TaskScheduler/Operational event log channel and scheduled
task events from the Security log if configured.

A common hunting use case may be collection all deleted scheduled tasks (EID 141),
all modified scheduled tasks (EID 140) then run frequency analysis and chase
down any abnormalities for the environment. Similarly task execution (EID 129)
and registration (EID 106) can be a good collection hunting for unusual paths.

Pivoting can be via either: TaskSchedulerEventRegex, TaskName or IOC Regex
(e.g taskname|delete|created|update)

Note: Audit Other Object Access Events is required to be implemented to record
scheduled tasks being registered, modified or disabled in the Security event
log channel.
See: Computer Configuration\Policies\Windows Settings\Security Settings\Advanced Audit Policy Configuration\Object Access


<pre><code class="language-yaml">
name: Windows.EventLogs.ScheduledTasks
description: |
  This artifact will extract Event Logs related to ScheduledTasks and provide
  a nice format for simplified review.

  Adversaries may abuse tasks for execution, persistence, lateral movement or
  privilege escalation. This artifact collates all events from
  Microsoft-Windows-TaskScheduler/Operational event log channel and scheduled
  task events from the Security log if configured.

  A common hunting use case may be collection all deleted scheduled tasks (EID 141),
  all modified scheduled tasks (EID 140) then run frequency analysis and chase
  down any abnormalities for the environment. Similarly task execution (EID 129)
  and registration (EID 106) can be a good collection hunting for unusual paths.

  Pivoting can be via either: TaskSchedulerEventRegex, TaskName or IOC Regex
  (e.g taskname|delete|created|update)

  Note: Audit Other Object Access Events is required to be implemented to record
  scheduled tasks being registered, modified or disabled in the Security event
  log channel.
  See: Computer Configuration\Policies\Windows Settings\Security Settings\Advanced Audit Policy Configuration\Object Access

author: "@mgreen27 - Matt Green"

precondition: SELECT OS From info() where OS = 'windows'

reference:
  - https://attack.mitre.org/techniques/T1053/005/
  - https://mnaoumov.wordpress.com/2014/05/15/task-scheduler-event-ids/

parameters:
  - name: Security
    description: path to Security event log.
    default: '%SystemRoot%\System32\Winevt\Logs\Security.evtx'
  - name: TaskScheduler
    description: path to the TaskScheduler/Operational event log
    default: '%SystemRoot%\System32\Winevt\Logs\Microsoft-Windows-TaskScheduler%4Operational.evtx'
  - name: DateAfter
    description: "search for events after this date. YYYY-MM-DDTmm:hh:ss Z"
    type: timestamp
  - name: DateBefore
    description: "search for events before this date. YYYY-MM-DDTmm:hh:ss Z"
    type: timestamp
  - name: TaskSchedulerEventRegex
    description: Regex of TaskScheduler log event ids.
    type: regex
    default: .
  - name: SecurityEventRegex
    description: regex of Security log event ids.
    type: regex
    default: '^(4698|4699|4700|4701|4702)$'
  - name: TaskNameRegex
    description: regex of target task name.
    default: .
    type: regex
  - name: TaskNameWhitelist
    description: regex of task names to exclude from results.
    default:
    type: regex
  - name: TaskActionRegex
    description: regex of target task execution process / path.
    default: .
    type: regex
  - name: TaskActionWhitelist
    description: regex of task processes to exclude from results.
    default:
    type: regex
  - name: UserNameRegex
    description: regex of target user name.
    default: .
    type: regex
  - name: IocRegex
    description: IOC regex to search for.
    default: .
    type: regex

  - name: VSSAnalysisAge
    type: int
    default: 0
    description: |
      If larger than zero we analyze VSS within this many days
      ago. (e.g 7 will analyze all VSS within the last week).  Note
      that when using VSS analysis we have to use the ntfs accessor
      for everything which will be much slower.


sources:
  - query: |
      LET VSS_MAX_AGE_DAYS &lt;= VSSAnalysisAge
      LET Accessor = if(condition=VSSAnalysisAge &gt; 0, then="ntfs_vss", else="auto")

      -- firstly set timebounds for performance
      LET DateAfterTime &lt;= if(condition=DateAfter,
        then=DateAfter, else=timestamp(epoch="1600-01-01"))
      LET DateBeforeTime &lt;= if(condition=DateBefore,
        then=DateBefore, else=timestamp(epoch="2200-01-01"))

      -- Lookup what each task ID means (sadly dict keys are always strings).
      LET TaskIDLookup &lt;= dict(
        `4698`="A scheduled task was created.",
        `4699`="A scheduled task was deleted.",
        `4700`="A scheduled task was enabled.",
        `4701`="A scheduled task was disabled.",
        `4702`="A scheduled task was updated.")

      -- expand provided glob into a list of paths on the file system (fs)
      LET fspaths = SELECT OSPath
        FROM glob(globs=[expand(path=Security), expand(path=TaskScheduler)],
        accessor=Accessor)

      -- function to parse task content and replace xml in EventData
      LET parse_task(data) = dict(
         SubjectUserSid=data.SubjectUserSid,
         SubjectUserName=data.SubjectUserName,
         SubjectDomainName=data.SubjectDomainName,
         SubjectLogonId=data.SubjectLogonId,
         TaskName=data.TaskName,
         TaskContent=parse_xml(
            accessor='data',
            file=regex_replace(
              source= if(condition= data.TaskContentNew,
                 then= data.TaskContentNew,
                 else= if(condition= data.TaskContent,
                    then= data.TaskContent)),
                       re='&lt;[?].+?&gt;',
                       replace='')).Task,

         ClientProcessStartKey=data.ClientProcessStartKey,
         ClientProcessId=data.ClientProcessId,
         ParentProcessId=data.ParentProcessId,
         RpcCallClientLocality=data.RpcCallClientLocality,
         FQDN=data.FQDN)


      -- function returning query hits
      LET evtxsearch(PathList) = SELECT * FROM foreach(
            row=PathList,
            query={
                SELECT
                    timestamp(epoch=int(int=System.TimeCreated.SystemTime)) AS EventTime,
                    System.Computer as Computer,
                    System.Channel as Channel,
                    System.EventID.Value as EventID,
                    System.EventRecordID as EventRecordID,
                    if(condition=EventData.UserName,
                        then= EventData.UserName,
                        else= if(condition=EventData.UserContext,
                            then=EventData.UserContext,
                            else= if(condition=EventData.SubjectUserName,
                                then= EventData.SubjectDomainName + '\\' + EventData.SubjectUserName,
                                else= 'N/A' ))) as UserName,
                    if(condition=EventData.TaskName,
                        then= EventData.TaskName) as TaskName,
                    if(condition=EventData.ActionName,
                        then= EventData.ActionName,
                        else= if(condition=EventData.Path,
                            then= EventData.Path,
                            else= 'N/A' )) as TaskAction,
                    if(condition=EventData.TaskContent OR EventData.TaskContentNew,
                            then= parse_task(data=EventData),
                            else= EventData) as EventData,
                    get(field="Message") as Message,
                    OSPath
                FROM parse_evtx(filename=OSPath, accessor=Accessor)
                WHERE
                    (( Channel = 'Microsoft-Windows-TaskScheduler/Operational'
                        AND str(str=EventID) =~ TaskSchedulerEventRegex )
                    OR ( Channel = 'Security'
                        AND str(str=EventID) =~ SecurityEventRegex ))
                    AND TaskName =~ TaskNameRegex
                    AND NOT if(condition= TaskNameWhitelist,
                        then= TaskName =~ TaskNameWhitelist,
                        else= False)
                    AND TaskAction =~ TaskActionRegex
                    AND NOT if(condition= TaskActionWhitelist,
                        then= TaskName =~ TaskActionWhitelist,
                        else= False)
                    AND UserName =~ UserNameRegex
                    AND format(format='%v %v %v %v', args=[
                            EventData, UserData, Message, System]) =~ IocRegex
                    AND EventTime &gt;= DateAfterTime AND EventTime &lt;= DateBeforeTime
            }
          )

      SELECT
        EventTime,
        Computer,
        Channel,
        EventID,
        EventRecordID,
        UserName,
        TaskName,
        if(condition= Channel = 'Microsoft-Windows-TaskScheduler/Operational',
            then= Message,
            else=get(item=TaskIDLookup, member=str(str=EventID))) as Message,
        if(condition= EventID =~'^(4698|4699|4700|4701|4702)$',
        then= if(condition= EventData.TaskContent.Actions,
            then= if(condition= EventData.TaskContent.Actions.Exec,
                then= if(condition= EventData.TaskContent.Actions.Exec.Arguments,
                    then= EventData.TaskContent.Actions.Exec.Command + ' ' + EventData.TaskContent.Actions.Exec.Arguments,
                    else=  EventData.TaskContent.Actions.Exec.Command),
                else= if(condition=EventData.TaskContent.Actions.ComHandler.ClassId,
                    then= 'ClassId: ' + EventData.TaskContent.Actions.ComHandler.ClassId))),
            else= TaskAction) as TaskAction,
        EventData,
        OSPath
      FROM evtxsearch(PathList=fspaths)

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/logscale.flows.upload.md
======
---
title: LogScale.Flows.Upload
hidden: true
tags: [Server Event Artifact]
---

This server side event monitoring artifact waits for new artifacts
to be collected from endpoints and automatically posts those to a
LogScale (formerly Humio) ingestion endpoint.


<pre><code class="language-yaml">
name: LogScale.Flows.Upload
description: |
  This server side event monitoring artifact waits for new artifacts
  to be collected from endpoints and automatically posts those to a
  LogScale (formerly Humio) ingestion endpoint.

type: SERVER_EVENT

parameters:
  - name: ingestApiBase
    description: API Base Url for LogScale server
    type: string
    default: https://cloud.community.humio.com/api
  - name: ingestToken
    description: Ingest token for API
    type: string
  - name: tagFields
    description: Comma-separated list of field names to use as tags in the message; Can be renamed with &lt;oldname&gt;=&lt;newname&gt;.
    default:
    type: string
  - name: numThreads
    description: Number of threads to start up to post events
    type: int
    default: 1
  - name: httpTimeout
    description: Timeout (in seconds) for http connection attempts
    type: int
    default: 10
  - name: batchingTimeoutMs
    description: Timeout to batch events prior to sending
    type: int
    default: 30000
  - name: eventBatchSize
    description: Count of events to batch prior to sending
    type: int
    default: 2000
  - name: statsInterval
    description: Interval to post statistics to log (in seconds, 0 to disable)
    type: int
    default: 600
  - name: debug
    description: Enable verbose logging
    type: bool
    default: false
  - name: ArtifactNameRegex
    default: .
    type: regex
    description: Only upload these artifacts to elastic

sources:
  - query: |
      LET completions = SELECT * FROM watch_monitoring(
             artifact="System.Flow.Completion")
             WHERE Flow.artifacts_with_results =~ ArtifactNameRegex

      LET documents = SELECT * FROM foreach(row=completions,
          query={
             SELECT * FROM foreach(
                 row=Flow.artifacts_with_results,
                 query={
                     SELECT *, _value AS Artifact,
                            timestamp(epoch=now()) AS timestamp,
                            ClientId, Flow.session_id AS FlowId
                     FROM source(
                        client_id=ClientId,
                        flow_id=Flow.session_id,
                        artifact=_value)
                 })
          })

      SELECT * FROM logscale_upload(
          query=documents,
          apibaseurl=ingestApiBase,
          ingest_token=ingestToken,
          threads=numThreads,
          tag_fields=split(string=tagFields, sep=","),
          batching_timeout_ms=batchingTimeoutMs,
          event_batch_size=eventBatchSize,
          http_timeout=httpTimeout,
          debug=debug,
          stats_interval=statsInterval)

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.ntfs.mft.md
======
---
title: Windows.NTFS.MFT
hidden: true
tags: [Client Artifact]
---

This artifact parses $MFT files and returns rows of each in scope  MFT record.
This artifact can be used as the basis for other artifacts where the MFT needs
to be queried or for deleted file recovery.

For deleted file recovery: Take the MFT ID of a file of interest and provide
it to the Windows.NTFS.Recover artifact.

To query all attached ntfs drives: check the AllDrives switch.

I have added several filters to uplift search capabilities from the original
MFT artifact. Due to the multi-drive features, the MFTPath will output the MFT
path of the entry.

Available filters include:

- PathRegex (OSPath): e.g `^C:\\folder\\file\.ext$` or partial `\\folder\\folder2\\` or `string|string2|string3`
- Fileregex: `^filename.ext$` or partial `string1|string2`
- Time bounds to select files with a timestamp within time ranges
- FileSize bounds
- MFTDrive: drive to target collection and show as source in results during offline pricessing.
- MFTPath: optional filter for offline MFT processing.

NOTE: Generally more efficient to filter on filename.
Multiple filters are cumulative.
OSPath output now uses expected Windows backslash "`\`".


<pre><code class="language-yaml">
name: Windows.NTFS.MFT
author: "Matt Green - @mgreen27"
description: |
  This artifact parses $MFT files and returns rows of each in scope  MFT record.
  This artifact can be used as the basis for other artifacts where the MFT needs
  to be queried or for deleted file recovery.

  For deleted file recovery: Take the MFT ID of a file of interest and provide
  it to the Windows.NTFS.Recover artifact.

  To query all attached ntfs drives: check the AllDrives switch.

  I have added several filters to uplift search capabilities from the original
  MFT artifact. Due to the multi-drive features, the MFTPath will output the MFT
  path of the entry.

  Available filters include:

  - PathRegex (OSPath): e.g `^C:\\folder\\file\.ext$` or partial `\\folder\\folder2\\` or `string|string2|string3`
  - Fileregex: `^filename.ext$` or partial `string1|string2`
  - Time bounds to select files with a timestamp within time ranges
  - FileSize bounds
  - MFTDrive: drive to target collection and show as source in results during offline pricessing.
  - MFTPath: optional filter for offline MFT processing.

  NOTE: Generally more efficient to filter on filename.
  Multiple filters are cumulative.
  OSPath output now uses expected Windows backslash "`\`".

parameters:
  - name: MFTDrive
    description: |
      The path to to the drive that holds the MFT file (can be a pathspec). This
      drive is also used for results for offline processing.
    default: "C:"
  - name: MFTPath
    description: Optional path to MFT file for offline processing.
    default:
  - name: Accessor
    default: ntfs
  - name: AllNtfs
    type: bool
    description: "Return all NTFS metadata with results."
  - name: PathRegex
    description: "Regex search over OSPath."
    default: "."
    type: regex
  - name: FileRegex
    description: "Regex search over File Name"
    default: "."
    type: regex
  - name: DateAfter
    type: timestamp
    description: "search for events after this date. YYYY-MM-DDTmm:hh:ssZ"
  - name: DateBefore
    type: timestamp
    description: "search for events before this date. YYYY-MM-DDTmm:hh:ssZ"
  - name: SizeMax
    type: int64
    description: "Entries in the MFT under this size in bytes."
  - name: SizeMin
    type: int64
    description: "Entries in the MFT over this size in bytes."
  - name: AllDrives
    type: bool
    description: "Select MFT search on all attached ntfs drives."
  - name: NTFS_INCLUDE_SHORT_NAMES
    description: See all names referencing the file including short names.
    type: bool

sources:
  - query: |
      -- Cater for older clients which do not have the Links column.
      LET parse_mft_version(filename, accessor, prefix) = SELECT *
      FROM if(condition=version(plugin="parse_mft") &gt; 1,
              then={ SELECT *
                     FROM parse_mft(
                         filename=filename, accessor=accessor, prefix=prefix)
              },

              -- Older versions do not have the prefix parameter in
              -- the plugin and need the prefix prepended to the
              -- OSPath
              else={ SELECT *,
                            prefix + OSPath AS Links,
                            prefix + OSPath AS OSPath
                     FROM parse_mft(
                         filename=filename, accessor=accessor)
              })

      -- The path to to the drive that holds the MFT file (can be a pathspec)
      LET Drive &lt;= pathspec(parse=MFTDrive, path_type="ntfs")

      -- time testing
      LET time_test(stamp) =
            if(condition= DateBefore AND DateAfter,
                then= stamp &lt; DateBefore AND stamp &gt; DateAfter,
                else=
            if(condition=DateBefore,
                then= stamp &lt; DateBefore,
                else=
            if(condition= DateAfter,
                then= stamp &gt; DateAfter,
                else= True
            )))

      -- find all ntfs drives
      LET ntfs_drives = SELECT
        OSPath AS Drive,
        OSPath + '$MFT' AS MFTFilename
      FROM glob(globs="/*", accessor="ntfs")
      WHERE log(message="Processing " + MFTFilename)

      -- function returning MFT entries
      -- Only check the filename - should be very quick
      LET mftsearch_with_filename(Drive, MFTPath) =
        SELECT EntryNumber, InUse, ParentEntryNumber,
            OSPath,
            Links AS _Links,
            FileName, FileSize, ReferenceCount, IsDir,
            Created0x10, Created0x30,
            LastModified0x10, LastModified0x30,
            LastRecordChange0x10, LastRecordChange0x30,
            LastAccess0x10,LastAccess0x30,
            HasADS, SI_Lt_FN, USecZeros, Copied,
            FileNames, FileNameTypes
        FROM parse_mft_version(filename=MFTPath,
                       accessor=Accessor, prefix=Drive)
        WHERE FileName =~ FileRegex
          AND Links =~ PathRegex

      -- Check only one date bound
      LET mftsearch_after_date(Drive, MFTPath) =
        SELECT
            EntryNumber, InUse, ParentEntryNumber,
            OSPath,
            Links AS _Links,
            FileName, FileSize, ReferenceCount, IsDir,
            Created0x10, Created0x30,
            LastModified0x10, LastModified0x30,
            LastRecordChange0x10, LastRecordChange0x30,
            LastAccess0x10,LastAccess0x30,
            HasADS, SI_Lt_FN, USecZeros, Copied,
            FileNames, FileNameTypes
        FROM parse_mft_version(filename=MFTPath,
                       accessor=Accessor, prefix=Drive)
        WHERE
             ( Created0x10 &gt; DateAfter
              OR Created0x30 &gt; DateAfter
              OR LastModified0x10 &gt; DateAfter
              OR LastModified0x30 &gt; DateAfter
              OR LastRecordChange0x10 &gt; DateAfter
              OR LastRecordChange0x30 &gt; DateAfter)
            AND FileName =~ FileRegex
            AND Links =~ PathRegex

      LET mftsearch_before_date(Drive, MFTPath) =
        SELECT EntryNumber, InUse, ParentEntryNumber,
            OSPath,
            Links AS _Links,
            FileName, FileSize, ReferenceCount, IsDir,
            Created0x10, Created0x30,
            LastModified0x10, LastModified0x30,
            LastRecordChange0x10, LastRecordChange0x30,
            LastAccess0x10,LastAccess0x30,
            HasADS, SI_Lt_FN, USecZeros, Copied,
            FileNames, FileNameTypes
        FROM parse_mft_version(filename=MFTPath,
                       accessor=Accessor, prefix=Drive)
        WHERE
             ( Created0x10 &lt; DateBefore
              OR Created0x30 &lt; DateBefore
              OR LastModified0x10 &lt; DateBefore
              OR LastModified0x30 &lt; DateBefore
              OR LastRecordChange0x10 &lt; DateBefore
              OR LastRecordChange0x30 &lt; DateBefore)
            AND FileName =~ FileRegex
            AND Links =~ PathRegex

      -- Check everything can be slow.
      LET mftsearch_full(Drive, MFTPath) =
        SELECT EntryNumber, InUse, ParentEntryNumber,
            OSPath,
            Links AS _Links,
            FileName, FileSize, ReferenceCount, IsDir,
            Created0x10, Created0x30,
            LastModified0x10, LastModified0x30,
            LastRecordChange0x10, LastRecordChange0x30,
            LastAccess0x10,LastAccess0x30,
            HasADS, SI_Lt_FN, USecZeros, Copied,
            FileNames, FileNameTypes
        FROM parse_mft_version(filename=MFTPath,
                       accessor=Accessor, prefix=Drive)
        WHERE FileName =~ FileRegex
            AND Links =~ PathRegex
            AND if(condition=SizeMax,
                then=FileSize &lt; atoi(string=SizeMax),
                else=TRUE)
            AND if(condition=SizeMin,
                then=FileSize &gt; atoi(string=SizeMin),
                else=TRUE)
            AND
             ( time_test(stamp=Created0x10)
            OR time_test(stamp=Created0x30)
            OR time_test(stamp=LastModified0x10)
            OR time_test(stamp=LastModified0x30)
            OR time_test(stamp=LastRecordChange0x10)
            OR time_test(stamp=LastRecordChange0x30)
            OR time_test(stamp=LastAccess0x10)
            OR time_test(stamp=LastAccess0x30))

      -- Choose a query to run depending on the user's choices.
      LET mftsearch(Drive, MFTPath) = SELECT * FROM if(
       -- only need to do a filename comparison
       condition=NOT DateAfter AND NOT DateBefore AND NOT SizeMin AND NOT SizeMax,
       then={ SELECT *
              FROM mftsearch_with_filename(Drive=Drive, MFTPath=MFTPath) },
       else={ SELECT * FROM if(

          -- Only DateAfter is set
          condition=NOT DateBefore AND NOT SizeMin AND NOT SizeMax,
          then={ SELECT *
                 FROM mftsearch_after_date(Drive=Drive, MFTPath=MFTPath)},
          else={ SELECT * FROM if(

             -- Only Date Before is set
             condition=NOT DateAfter AND NOT SizeMin AND NOT SizeMax,
             then={ SELECT *
                    FROM mftsearch_before_date(Drive=Drive, MFTPath=MFTPath)},
             else={ SELECT *
                    FROM mftsearch_full(Drive=Drive, MFTPath=MFTPath)})
          })
       })

      -- include all attached drives
      LET all_drives = SELECT * FROM foreach(row={
           SELECT * FROM ntfs_drives
        },
        query={
           SELECT *, Drive
           FROM mftsearch(
              Drive=Drive,
              MFTPath=MFTFilename)
        })

      -- return results
      LET results = SELECT *
          FROM if(condition=AllDrives,
            then={
              SELECT * FROM all_drives
            },
            else={
              SELECT * FROM mftsearch(Drive=Drive,
                                MFTPath=if(condition= MFTPath ,
                                            then= MFTPath,
                                            else= Drive + "$MFT"))
            })
      -- enrich results with NtfsMetadata is requests
      LET enriched_results = SELECT *,
            parse_ntfs(mft=EntryNumber, device=Drive ) as NtfsMetadata
        FROM results

      -- return rows
      SELECT * FROM if(condition=AllNtfs,
        then= enriched_results,
        else= results)

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/linux.ssh.privatekeys.md
======
---
title: Linux.Ssh.PrivateKeys
hidden: true
tags: [Client Artifact]
---

SSH Private keys can be either encrypted or unencrypted. Unencrypted
private keys are more risky because an attacker can use them without
needing to unlock them with a password.

In particular, AWS instances are usually accessed by way of an SSH
key pair generated by the AWS console. This key is not encrypted by
default and it is possible that administrators simply save the key
on their systems without encrypting it.

This artifact searches for private keys in the usual locations and
also records if they are encrypted or not. Not all key types are
supported

NOTE: In order to encrypt your private key run:

```
ssh-keygen -p -f my_private_key
```

Change the glob to /** if you would like to search the entire filesystem.
Be aware, this is an expensive operation.


<pre><code class="language-yaml">
name: Linux.Ssh.PrivateKeys
description: |
  SSH Private keys can be either encrypted or unencrypted. Unencrypted
  private keys are more risky because an attacker can use them without
  needing to unlock them with a password.

  In particular, AWS instances are usually accessed by way of an SSH
  key pair generated by the AWS console. This key is not encrypted by
  default and it is possible that administrators simply save the key
  on their systems without encrypting it.

  This artifact searches for private keys in the usual locations and
  also records if they are encrypted or not. Not all key types are
  supported

  NOTE: In order to encrypt your private key run:

  ```
  ssh-keygen -p -f my_private_key
  ```

  Change the glob to /** if you would like to search the entire filesystem.
  Be aware, this is an expensive operation.

reference:
  - https://attack.mitre.org/techniques/T1145/
  - https://coolaj86.com/articles/the-openssh-private-key-format/
  - https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-key-pairs.html

precondition: SELECT OS From info() where OS = 'linux'

parameters:
  - name: KeyGlobs
    default: /home/*/.ssh/{*.pem,id_rsa,id_dsa}

  - name: ExcludePathRegex
    default: "^/(proc|sys|run|snap)"
    type: regex
    description: If this regex matches the path of any directory we do not even descend inside of it.
    
  - name: LocalFilesystemOnly
    default: Y
    type: bool
    description:  |
      When set, we stay on local attached filesystems including loop, attached disk, cdrom, device mapper, and excluding proc, nfs etc.
      When set, it can miss keys in some Linux distros. If not sure, or run accross multiple distros, it is recommended to not set it.

sources:
  - query: |
      -- For new OpenSSH format
      LET SSHProfile = '''[
        ["Header", 0, [
        ["Magic", 0, "String", {
            "length": 100,
        }],
        ["cipher_length", 15, "uint32b"],
        ["cipher", 19, "String", {
            "length": "x=&gt;x.cipher_length",
        }]
      ]]]
      '''

      -- Device major numbers considered local. See Linux.Search.FileFinder
      LET LocalDeviceMajor &lt;= (NULL,
          253, 7, 8, 9, 11, 65, 66, 67, 68, 69, 70,
          71, 128, 129, 130, 131, 132, 133, 134, 135, 202, 253, 254, 259)

      -- By default set to 'True', to only search local filesystems.
      LET RecursionCallback = if(
       condition=LocalFilesystemOnly,
         then=if(condition=ExcludePathRegex,
                 then="x=&gt;x.Data.DevMajor IN LocalDeviceMajor AND NOT x.OSPath =~ ExcludePathRegex",
                 else="x=&gt;x.Data.DevMajor IN LocalDeviceMajor"),
         else=if(condition=ExcludePathRegex,
                 then="x=&gt;NOT x.OSPath =~ ExcludePathRegex",
                 else=""))

      LET _Hits = SELECT OSPath,
           read_file(filename=OSPath, length=20240) AS Data
        FROM glob(globs=KeyGlobs, recursion_callback=RecursionCallback)
        WHERE Size &lt; 20000

      LET Hits = SELECT OSPath, Data,
             base64decode(
                string=parse_string_with_regex(
                    string=Data,
                    regex="(?sm)KEY-----(.+)-----END").g1) || "" AS Decoded,
            parse_string_with_regex(
               string=Data,
               regex="(BEGIN.* PRIVATE KEY)").g1 AS Header,
            read_file(filename=OSPath.Dirname + (OSPath.Basename + ".pub") ) AS PublicKey
      FROM _Hits
      WHERE Header

      LET OpenSSHKeyParser(OSPath, Decoded) = SELECT OSPath,
         parse_binary(accessor="data", filename=Decoded,
                      profile=SSHProfile, struct="Header") AS Parsed
         FROM scope()

      -- Support both types of ssh keys dependingg on the header
      SELECT * FROM foreach(row={SELECT * FROM Hits},
      query={
        SELECT * FROM switch(
          a={
             -- new format
             SELECT OSPath,
                    Parsed.Magic AS KeyType,
                    Parsed.cipher AS Cipher,
                    Header, PublicKey
             FROM OpenSSHKeyParser(OSPath= OSPath, Decoded=Decoded)
             WHERE Header =~ "BEGIN OPENSSH PRIVATE KEY"
          },
          a2={
             -- encrypted rsa key from e.g. putty
             SELECT OSPath,
                    "PKCS8" AS KeyType,
                    parse_string_with_regex(string=Data,
                      regex="DEK-Info: ([-a-zA-Z0-9]+)").g1 AS Cipher,
                    Header, PublicKey
             FROM scope()
             WHERE Header =~ "BEGIN RSA PRIVATE KEY"
               AND "Proc-Type: 4,ENCRYPTED" in Data
          },
          b={
             -- unencrypted rsa key from e.g. AWS
             SELECT OSPath,
                    "PKCS8" AS KeyType,
                    "none" AS Cipher,
                    Header, PublicKey
             FROM scope()
             WHERE Header =~ "BEGIN (RSA )?PRIVATE KEY"
          },
          c={
             -- old format encrypted
             SELECT OSPath,
                    "PKCS8" AS KeyType,
                    "PKCS#5" AS Cipher,
                    Header, PublicKey
             FROM scope()
             WHERE Header =~ "BEGIN ENCRYPTED PRIVATE KEY"
          },
          d={
             -- catch all for unknown keys
             SELECT OSPath,
                    "Unknown" AS KeyType,
                    "Unknown" AS Cipher,
                    Header, PublicKey
             FROM scope()
          })
      })

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/elastic.events.upload.md
======
---
title: Elastic.Events.Upload
hidden: true
tags: [Server Event Artifact]
---

This server monitoring artifact will watch a selection of client or
server monitoring artifacts for new events and push those to an
elastic index.

NOTE: You must ensure you are collecting these artifacts from the
clients by adding them to the "Client Events" GUI, or for server
artifacts, the "Server Events" GUI.


<pre><code class="language-yaml">
name: Elastic.Events.Upload
aliases:
- Elastic.Events.Clients

description: |
  This server monitoring artifact will watch a selection of client or
  server monitoring artifacts for new events and push those to an
  elastic index.

  NOTE: You must ensure you are collecting these artifacts from the
  clients by adding them to the "Client Events" GUI, or for server
  artifacts, the "Server Events" GUI.

type: SERVER_EVENT

parameters:
  - name: ElasticAddresses
    default: http://127.0.0.1:9200/
  - name: Username
  - name: Password
  - name: APIKey
  - name: ClientArtifactsToWatch
    type: artifactset
    artifact_type: CLIENT_EVENT
    default: |
      Artifact
      Windows.Detection.PsexecService
      Windows.Events.ProcessCreation
      Windows.Events.ServiceCreation
  - name: ServerArtifactsToWatch
    type: artifactset
    artifact_type: SERVER_EVENT
    default: |
      Artifact
      Server.Audit.Logs
  - name: DisableSSLSecurity
    type: bool
    description: Disable SSL certificate verification
  - name: Threads
    type: int
    description: Number of threads to upload with
  - name: ChunkSize
    type: int
    description: Batch this many rows for each upload.
  - name: CloudID
    description: The cloud id if needed
  - name: RootCA
    description: |
      A root CA certificate in PEM for trusting TLS protected Elastic
      servers.

sources:
  - query: |
      LET artifacts_to_watch = SELECT * FROM chain(
        a={SELECT Artifact FROM ClientArtifactsToWatch},
        b={SELECT Artifact FROM ServerArtifactsToWatch})
      WHERE NOT Artifact =~ "Elastic.Events.Upload"
        AND log(message="Uploading artifact " + Artifact + " to Elastic")

      LET s = scope()

      LET events = SELECT * FROM foreach(
          row=artifacts_to_watch,
          async=TRUE,   // Required for event queries in foreach()
          query={
             SELECT *, "Artifact_" + Artifact as _index,
                    Artifact,
                    client_info(client_id=s.ClientId || "server").os_info.hostname AS Hostname,
                    timestamp(epoch=now()) AS timestamp
             FROM watch_monitoring(artifact=Artifact)
          })

      SELECT * FROM elastic_upload(
          query=events,
          threads=Threads,
          chunk_size=ChunkSize,
          addresses=split(string=ElasticAddresses, sep=","),
          index="velociraptor",
          password=Password,
          username=Username,
          cloud_id=CloudID,
          api_key=APIKey,
          root_ca=RootCA,
          disable_ssl_security=DisableSSLSecurity,
          type="ClientEvents")

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.memory.intezer.md
======
---
title: Windows.Memory.Intezer
hidden: true
tags: [Client Artifact]
---

This artifact will trigger an intezer agent scan on the endpoint.

Scan: The scanner collects running code from memory and sends it to Intezer Analyze.
Scans take approximately five to ten minutes. The first scan may take additional time.
Please note: The scanner only collects executable code, not documents or any other
data that is not binary code.
Analyze: The collected modules are analyzed using Genetic Malware Analysis technology.
View results: https://analyze.intezer.com/ endpoint analysis report.


<pre><code class="language-yaml">
name: Windows.Memory.Intezer
description: |
   This artifact will trigger an intezer agent scan on the endpoint.

   Scan: The scanner collects running code from memory and sends it to Intezer Analyze.
   Scans take approximately five to ten minutes. The first scan may take additional time.
   Please note: The scanner only collects executable code, not documents or any other
   data that is not binary code.
   Analyze: The collected modules are analyzed using Genetic Malware Analysis technology.
   View results: https://analyze.intezer.com/ endpoint analysis report.

author: Matt Green - @mgreen27

required_permissions:
  - EXECVE

tools:
  - name: Intezer
    url: https://analyze.intezer.com/api/scans/download

type: CLIENT

parameters:
   - name: ApiKey
     description: Intezer API key to scan with
     default:

sources:
  - precondition:
      SELECT OS From info() where OS = 'windows'

    query: |
      -- first get context on target binary
      LET bin &lt;= SELECT *
        FROM Artifact.Generic.Utils.FetchBinary(
            ToolName="Intezer")

      -- execute payload
      SELECT * FROM execve(argv=[ bin.OSPath[0], '-k', ApiKey ])

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/generic.forensic.localhashes.query.md
======
---
title: Generic.Forensic.LocalHashes.Query
hidden: true
tags: [Client Artifact]
---

This artifact maintains a local (client side) database of file
hashes. It is then possible to query this database using the
Generic.Forensic.LocalHashes.Query artifact.

NOTE: This artifact expects a CSV file with one hash per line. On
the command line you can encode carriage return using powershell
like this:

```
.\velociraptor.exe -v artifacts collect Generic.Forensic.LocalHashes.Query --args "Hashes=Hash`ne6c1ce56e6729a0b077c0f2384726b30"
```


<pre><code class="language-yaml">
name: Generic.Forensic.LocalHashes.Query
description: |
  This artifact maintains a local (client side) database of file
  hashes. It is then possible to query this database using the
  Generic.Forensic.LocalHashes.Query artifact.

  NOTE: This artifact expects a CSV file with one hash per line. On
  the command line you can encode carriage return using powershell
  like this:

  ```
  .\velociraptor.exe -v artifacts collect Generic.Forensic.LocalHashes.Query --args "Hashes=Hash`ne6c1ce56e6729a0b077c0f2384726b30"
  ```

parameters:
  - name: Hashes
    description: The hash to query for.
    type: csv
    default: |
      Hash
      XXX

  - name: CommaDelimitedHashes
    description: A set of comma delimited hashes
    default:

  - name: HashDb
    description: Name of the local hash database
    default: hashdb.sqlite

sources:
  - query: |
      LET hash_db &lt;= SELECT OSPath
      FROM Artifact.Generic.Forensic.LocalHashes.Init(HashDb=HashDb)

      -- Check hashes from the CSV or comma delimited input
      LET hashes = SELECT Hash FROM chain(
      a={
        SELECT lowcase(string=strip(string=Hash)) AS Hash
        FROM Hashes
      }, b={
        SELECT * FROM foreach(row=split(string=CommaDelimitedHashes, sep=","),
        query={
           SELECT lowcase(string=strip(string=_value)) AS Hash FROM scope()
        })
      })

      SELECT * FROM foreach(row=hashes,
      query={
         SELECT path AS Path, md5 AS MD5, size AS Size,
                timestamp(epoch=time) AS Timestamp
         FROM sqlite(file=hash_db[0].OSPath,
                     query="SELECT path, md5, size, timestamp AS time FROM hashes WHERE md5 = ?",
                     args=Hash)
      })

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/generic.system.pstree.md
======
---
title: Generic.System.Pstree
hidden: true
tags: [Client Artifact]
---

This artifact displays the call chain for every process on the
system by traversing the process's parent ID.

It is useful for establishing where a process came from - for
example, if a powershell process is spawned from Winword (event via
a number of intemediary processes) it could mean word was
compromised.

This artifact uses the process tracker which was introduced in
release 0.6.5. (Import an older version of this artifact using the
Server.Import.PreviousReleases if your client is older than this).

A more accurate call chain will be available when the
Windows.Events.TrackProcesses artifact is collected (required
Sysmon) or Windows.Events.TrackProcessesBasic (does not require
Sysmon)

Minimum Version: 0.6.6


<pre><code class="language-yaml">
name: Generic.System.Pstree
description: |
  This artifact displays the call chain for every process on the
  system by traversing the process's parent ID.

  It is useful for establishing where a process came from - for
  example, if a powershell process is spawned from Winword (event via
  a number of intemediary processes) it could mean word was
  compromised.

  This artifact uses the process tracker which was introduced in
  release 0.6.5. (Import an older version of this artifact using the
  Server.Import.PreviousReleases if your client is older than this).

  A more accurate call chain will be available when the
  Windows.Events.TrackProcesses artifact is collected (required
  Sysmon) or Windows.Events.TrackProcessesBasic (does not require
  Sysmon)

  Minimum Version: 0.6.6

parameters:
  - name: CommandlineRegex
    default: .
    type: regex

  - name: PidFilter
    description: Filter pids by this regex
    default: .
    type: regex

  - name: CallChainFilter
    default: .
    type: regex

  - name: CallChainSep
    default: " -&gt; "

  - name: IncludePstree
    type: bool

sources:
  - query: |
      SELECT Pid, Ppid, Name, Username, Exe, CommandLine, StartTime, EndTime,
          join(array=process_tracker_callchain(id=Pid).Data.Name, sep=CallChainSep) AS CallChain,
          if(condition=IncludePstree, then=process_tracker_tree(id=Pid)) AS PSTree
      FROM process_tracker_pslist()
      WHERE CommandLine =~ CommandlineRegex
        AND CallChain =~ CallChainFilter
        AND Pid =~ PidFilter

column_types:
  - name: PSTree
    type: tree

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.timeline.mft.md
======
---
title: Windows.Timeline.MFT
hidden: true
tags: [Client Artifact]
---

# Output all filtered MFT records.

This Artifact enables querying the MFT with advanced filters
such as time, path or other ntfs attributes.

Output is to Timeline field format to enable simple review across Timeline
queries. The TimeOutput paramater enables configuring which NTFS attribute
timestamps are in focus as event_time. for example:
  STANDARD_INFORMATION (4), FILE_NAME (4) or ALL (8)

This artifact also has the same anomaly logic as AnalyzeMFT added to
each row to assist analysis.


<pre><code class="language-yaml">
name: Windows.Timeline.MFT
description: |
  # Output all filtered MFT records.

  This Artifact enables querying the MFT with advanced filters
  such as time, path or other ntfs attributes.

  Output is to Timeline field format to enable simple review across Timeline
  queries. The TimeOutput paramater enables configuring which NTFS attribute
  timestamps are in focus as event_time. for example:
    STANDARD_INFORMATION (4), FILE_NAME (4) or ALL (8)

  This artifact also has the same anomaly logic as AnalyzeMFT added to
  each row to assist analysis.

author: Matt Green - @mgreen27

precondition: SELECT OS From info() where OS = 'windows'

parameters:
  - name: MFTFilename
    default: "C:/$MFT"
  - name: Accessor
    default: ntfs
  - name: PathRegex
    description: "regex search over OSPath."
    type: regex
  - name: NameRegex
    default: .
    type: regex
    description: "regex search over File Name"
  - name: Inode
    type: int64
    description: "search for inode"
  - name: DateAfter
    type: timestamp
    description: "search for events after this date. YYYY-MM-DDTmm:hh:ssZ"
  - name: DateBefore
    type: timestamp
    description: "search for events before this date. YYYY-MM-DDTmm:hh:ssZ"
  - name: SizeMax
    type: int64
    description: "Entries in the MFT over this size in bytes."
  - name: SizeMin
    type: int64
    description: "Entries in the MFT under this size in bytes."
  - name: EntryType
    description: |
        Type of entry. File, Directory or Both.
    type: choices
    default: Both
    choices:
       - File
       - Directory
       - Both
  - name: AllocatedType
    description: |
        Type of entry. Allocated, Unallocated or Both.
    type: choices
    default: Both
    choices:
       - Allocated
       - Unallocated
       - Both
  - name: TimeOutput
    description: |
        Timestamps to output as event_time. SI, FN or both.
        NOTE: both will output 8 rows per MFT entry.
    type: choices
    default: STANDARD_INFORMATION
    choices:
       - STANDARD_INFORMATION
       - FILE_NAME
       - ALL

sources:
  - query: |
        LET hostname &lt;= SELECT Fqdn FROM info()
        LET DateAfterTime &lt;= if(condition=DateAfter,
             then=DateAfter, else=timestamp(epoch="1600-01-01"))
        LET DateBeforeTime &lt;= if(condition=DateBefore,
             then=DateBefore, else=timestamp(epoch="2200-01-01"))
        LET records = SELECT *,
                Created0x10 &lt; Created0x30 as FNCreatedShift,
                Created0x10.Unix * 1000000000 = Created0x10.UnixNano as USecZero,
                Created0x10 &gt; LastModified0x10 as PossibleCopy,
                ( LastAccess0x10 &gt; LastModified0x10 AND LastAccess0x10 &gt; Created0x10 ) as VolumeCopy
            FROM parse_mft(filename=MFTFilename, accessor=Accessor)
            WHERE
                FileName =~ NameRegex AND
                OSPath =~ PathRegex AND
                if(condition=Inode, then= EntryNumber=atoi(string=Inode)
                    OR ParentEntryNumber=atoi(string=Inode),
                    else=TRUE) AND
                if(condition=SizeMax, then=FileSize &lt; SizeMax,
                    else=TRUE) AND
                if(condition=SizeMin, then=FileSize &gt; SizeMin,
                    else=TRUE) AND
                if(condition= EntryType="Both", then=TRUE,
                    else= if(condition= EntryType="File",
                        then= IsDir=False,
                    else= if(condition= EntryType="Directory",
                        then= IsDir=True))) AND
                if(condition= AllocatedType="Both", then=TRUE,
                    else= if(condition= AllocatedType="Allocated",
                        then= InUse=True,
                    else= if(condition= AllocatedType="Unallocated",
                        then= InUse=False))) AND
                (((Created0x10 &gt; DateAfterTime) AND (Created0x10 &lt; DateBeforeTime)) OR
                ((Created0x30 &gt; DateAfterTime) AND (Created0x30 &lt; DateBeforeTime)) OR
                ((LastModified0x10 &gt; DateAfterTime) AND (LastModified0x10 &lt; DateBeforeTime)) OR
                ((LastModified0x30 &gt; DateAfterTime) AND (LastModified0x30 &lt; DateBeforeTime)) OR
                ((LastRecordChange0x10 &gt; DateAfterTime) AND (LastRecordChange0x10 &lt; DateBeforeTime)) OR
                ((LastRecordChange0x30 &gt; DateAfterTime) AND (LastRecordChange0x30 &lt; DateBeforeTime)) OR
                ((LastAccess0x10 &gt; DateAfterTime) AND (LastAccess0x10 &lt; DateBeforeTime)) OR
                ((LastAccess0x30 &gt; DateAfterTime) AND (LastAccess0x30 &lt; DateBeforeTime)))

        LET common_fields = SELECT EntryNumber, ParentEntryNumber,
                OSPath, FileName, FileSize, IsDir,InUse,
                Created0x10, Created0x30,
                LastModified0x10, LastModified0x30,
                LastRecordChange0x10, LastRecordChange0x30,
                LastAccess0x10, LastAccess0x30,
                FNCreatedShift, USecZero, PossibleCopy, VolumeCopy
            FROM scope()

        LET standard_information_rows = SELECT * FROM chain(
            si_modified = {
                SELECT *,
                    LastModified0x10 as event_time,
                    format(format="MFTEntry:%v $STANDARD_INFORMATION (0x10) LastModified time",
                      args=EntryNumber) as message
                FROM common_fields
            },
            si_access = {
                SELECT *,
                    LastAccess0x10 as event_time,
                    format(format="MFTEntry:%v $STANDARD_INFORMATION (0x10) LastAccess time",
                      args=EntryNumber) as message
                FROM common_fields
            },
            si_created = {
                SELECT *,
                    LastRecordChange0x10 as event_time,
                    format(format="MFTEntry:%v $STANDARD_INFORMATION (0x10) LastRecordChange time",
                      args=EntryNumber) as message
                FROM common_fields
            },
            si_born = {
                SELECT *,
                    Created0x10 as event_time,
                    format(format="MFTEntry:%v $STANDARD_INFORMATION (0x10) Created time",
                      args=EntryNumber) as message
                FROM common_fields
            })
        LET file_name_rows = SELECT * FROM chain(
            fn_modified = {
                SELECT *,
                    LastModified0x30 as event_time,
                    format(format="MFTEntry:%v $FILE_NAME (0x30) LastModified time",
                      args=EntryNumber) as message
                FROM common_fields
            },
            fn_access = {
                SELECT *,
                    LastAccess0x30 as event_time,
                    format(format="MFTEntry:%v $FILE_NAME (0x30) LastAccess time",
                      args=EntryNumber) as message
                FROM common_fields
            },
            fn_created = {
                SELECT *,
                    LastRecordChange0x30 as event_time,
                    format(format="MFTEntry:%v $FILE_NAME (0x30) LastRecordChange time",
                      args=EntryNumber) as message
                FROM common_fields
            },
            fn_born = {
                SELECT *,
                    Created0x30 as event_time,
                      format(format="MFTEntry:%v $FILE_NAME (0x30) Created time",
                        args=EntryNumber) as message
                FROM common_fields
            })

        SELECT
            event_time,
            hostname.Fqdn[0] as hostname,
            "MFT" as parser,
            MFTFilename as source,
            message,
            OSPath as path,
            { SELECT EntryNumber,ParentEntryNumber,FileSize,
                     IsDir, InUse
              FROM scope() } as optional_1,

            { SELECT FNCreatedShift, USecZero, PossibleCopy,
                     VolumeCopy
              FROM scope() } as optional_2,

            { SELECT LastModified0x10,LastAccess0x10,
                     LastRecordChange0x10,Created0x10
              FROM scope() } as optional_3,

            { SELECT LastModified0x30,LastAccess0x30,
                     LastRecordChange0x30,Created0x30
              FROM scope() } as optional_4

          FROM foreach(
            row=records,
            query={
                SELECT * FROM chain(
                    standard_information={
                        SELECT * FROM if(
                            condition=TimeOutput="STANDARD_INFORMATION" OR TimeOutput="ALL",
                            then=standard_information_rows)
                    },
                    file_name={
                        SELECT * FROM if(
                            condition=TimeOutput="FILE_NAME" OR TimeOutput="ALL",
                            then=file_name_rows)
                    })
            })

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/server.internal.clientscheduled.md
======
---
title: Server.Internal.ClientScheduled
hidden: true
tags: [Internal Artifact]
---

This event will be fired when a client was sent flows to process.


<pre><code class="language-yaml">
name: Server.Internal.ClientScheduled
description: |
  This event will be fired when a client was sent flows to process.

type: INTERNAL
column_types:
  - name: ClientId
  - name: InFlightFlows
    description: New flows scheduled for the client
  - name: ClearFlows
    description: If this is set we clear all in flight flows.

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.applications.megasync.md
======
---
title: Windows.Applications.MegaSync
hidden: true
tags: [Client Artifact]
---

This artifact will parse MEGASync logs and enables using regex to search for
entries of interest.

With UploadLogs selected a copy of the logs are uploaded to the server.
SearchVSS enables search over VSS and dedup support.


<pre><code class="language-yaml">
name: Windows.Applications.MegaSync
description: |
  This artifact will parse MEGASync logs and enables using regex to search for
  entries of interest.

  With UploadLogs selected a copy of the logs are uploaded to the server.
  SearchVSS enables search over VSS and dedup support.

author: "Matt Green - @mgreen27"

reference:
  - https://attack.mitre.org/techniques/T1567/002/

precondition: SELECT OS From info() where OS = 'windows'

parameters:
  - name: LogFiles
    default: 'C:\Users\*\AppData\Local\Mega Limited\MEGAsync\logs\*.log'
  - name: SearchRegex
    description: "Regex of strings to search in line."
    default: 'Transfer\s\(UPLOAD\)|upload\squeue|local\sfile\saddition\sdetected|Sync\s-\ssending\sfile|\"user\"'
    type: regex
  - name: WhitelistRegex
    description: "Regex of strings to leave out of output."
    default:
    type: regex

  - name: VSSAnalysisAge
    type: int
    default: 0
    description: |
      If larger than zero we analyze VSS within this many days
      ago. (e.g 7 will analyze all VSS within the last week).  Note
      that when using VSS analysis we have to use the ntfs accessor
      for everything which will be much slower.

  - name: UploadLogs
    description: "Upload MEGASync logs."
    type: bool

sources:
  - query: |
      LET VSS_MAX_AGE_DAYS &lt;= VSSAnalysisAge
      LET Accessor = if(condition=VSSAnalysisAge &gt; 0, then="ntfs_vss", else="auto")

      -- Find target files
      LET files = SELECT *, OSPath as Source
        FROM glob(globs=LogFiles, accessor=Accessor)

      -- Collect all Lines in scope of regex search
      LET output = SELECT * FROM foreach(row=files,
          query={
              SELECT Line, OSPath,
                Mtime,
                Atime,
                Ctime,
                Size
              FROM parse_lines(filename=OSPath,accessor='file')
              WHERE TRUE
                AND Line =~ SearchRegex
                AND NOT if(condition= WhitelistRegex,
                    then= Line=~WhitelistRegex,
                    else = false)
          })
        GROUP BY Line

      SELECT
        Line as RawLine,
        OSPath
      FROM output


  - name: LogFiles
    query: |
        SELECT
            OSPath,
            if(condition=UploadLogs,
                then= upload(file=OSPath, accessor=Accessor)
                ) as Upload,
            'MEGAsync logfile' as Description,
            Mtime,
            Atime,
            Ctime,
            Size
        FROM output
        GROUP BY OSPath

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.forensics.jumplists.md
======
---
title: Windows.Forensics.JumpLists
hidden: true
tags: [Client Artifact]
---

The automaticdestinations jumplist is an OLE2 container containing LNK files
as individual streams


<pre><code class="language-yaml">
name: Windows.Forensics.JumpLists
description: |
  The automaticdestinations jumplist is an OLE2 container containing LNK files
  as individual streams

imports:
  - Windows.Forensics.Lnk

parameters:
  - name: Globs
    default: C:\Users\*\AppData\Roaming\Microsoft\Windows\Recent\AutomaticDestinations\*.automaticDestinations-ms

sources:
  - query: |
      // https://raw.githubusercontent.com/EricZimmerman/JumpList/a72a510b01922f60ce550c307e5f04131272448f/JumpList/Resources/AppIDs.txt
      LET AppIdTable &lt;= '''AppId|Description
      0006f647f9488d7a|AIM 7.5.11.9 (custom AppID + JL support)
      00098b0ef1c84088|fulDC 6.78
      012dc1ea8e34b5a6|Microsoft Paint 6.1
      01b29f0dc90366bb|AIM 5.9.3857
      b08971c77377bde3|Visual Studio Enterprise 2015 Version 14.0 Update 3
      c31b3d36438b5e2c|Visual Studio Enterprise 2017 Version 15.9.10
      03d877ec11607fe4|Thunderbird 6.0.2
      044a50e6c87bc012|Classic FTP Plus 2.15
      a2b95ca27b6c33d9|Windows Live Photo Gallery
      fdbd48d45512dffc|Photoshop 7
      e26f61afb0824f2e|Photoshop CC 2015
      050620fe75ee0093|VMware Player 3.1.4
      a55ed4fbb973aefb|Microsoft Teams version 1.3.0.4461
      05e01ecaf82f7d8e|Scour Exchange 0.0.0.228
      06059df4b02360af|Kadu 0.10.0 / 0.6.5.5
      070b52cf73249257|Sococo 1.5.0.2274
      0a1d19afe5a80f80|FileZilla 2.2.32
      0a79a7ce3c45d781|CuteFTP 7.1 (Build 06.06.2005.1)
      0b17d3d0c9ca7e29|Document ViewerPicasa 3.8.0 (Build 117.43, 0)
      0b3f13480c2785ae|Paint 6.1 (build 7601: SP1)
      0b48ce76eda60b97|Shareaza 8.0.0.112300
      0cfab0ec14b6f953|Express NewsPictures 2.41 (Build 08.05.07.0)
      0ef606b196796ebb|HP MediaSmart Photo
      10f5a20c21466e85|FTP Voyager 15.2.0.17
      1110d9896dceddb3|imgSeek 0.8.5
      12dc1ea8e34b5a6|Microsoft Paint (built-in Win7)
      12dc1ea8e34b5a6|Microsoft Paint 6.1
      134620458666ccb0|TeraCopy 2.3 64-bit
      135df2a440abe9bb|SoulSeek 156c
      13eb0e5d9a49eaef|Binjet 3.0.2
      1434d6d62d64857d|BitLord 1.2.0-66
      14354e216395983a|Remote Desktop Manager 2.1.0.0 FREE
      1461132e553e2e6c|Firefox 6.0
      169b3be0bc43d592|FastPictureViewer Professional 1.6 (Build 211)
      16d71406474462b5|Snagit Editor 12.4.1
      16ec093b8f51508f|Opera 8.54 build 7730 / 9.64 build 10487 / 11.50 build 1074
      174c2c811c286c58|InfraRecorder 0.53.0.0 64-bit
      177aeb41deb606ae|Adobe Photoshop CS6 (64 Bit)
      17d3eb086439f0d7|TrueCrypt 7.0a
      17d3eb086439f0d7|TrueCrypt 7.1a 64-bit
      18434d518c3a61eb|Minitab 17
      186b5ccada1d986b|NewsGrabber 3.0.36
      19ccee0274976da8|mIRC 4.72 / 5.61
      19e6043495a5b4da|Edit Pad Pro
      1a60b1067913516a|Psi 0.14
      1a89d1befe8e90e3|Adobe Acrobat Distiller Pro XI 32-bit 11.0.0779
      1b29f0dc90366bb|AIM 5.9.3857
      1b4dd67f29cb1962|Windows Explorer (Win7)
      1b4dd67f29cb1962|Windows Explorer Pinned and Recent.
      1bc392b8e104a00e|Remote Desktop
      1bc392b8e104a00e|Remote Desktop Connection 6.1.7600 (Win7)
      1bc9bbbe61f14501|OneNote
      1c30573bdfce4155|Zenmap GUI 6.49BETA4
      1cf97c38a5881255|MediaPortal 1.1.3
      1cffbe973a437c74|DSPlayer 0.889 Lite
      1da3c90a72bf5527|Safari 4.0.5 (531.22.7) / 5.1 (7534.50)
      1eb796d87c32eff9|Firefox 5.0
      20ef367747c22564|Bullet Proof FTP 2010.75.0.75
      223bf0f360c6fea5|I2P 0.8.8 (restartable)
      226400522157fe8b|FileZilla Server 0.9.39 beta
      22c4d315e96389e0|FastCopy 3.12
      22cefa022402327d|Meca Messenger 5.3.0.52
      22cefa022402327d|Meca Messenger 5.3.0.52 (CHANGED)
      236461219accfae0|This is new 1(NEW)
      23646679aaccfae0|Adobe Acrobat 9.4.0
      23646679aaccfae0|Adobe Reader 9 x64
      23646679aaccfae0|Adobe Reader 9.
      23646679aaccfae0|Adobe Reader 9.x
      23646679aaccfae0|Adobe Reader 9.x(CHANGED)
      23709f643539f03d|TGHIS IS NEW 2(NEW)
      23709f6439b9f03d|Hex Editor Neo 5.14
      23709f6439b9f03d|Hex Editor Neo 5.14(CHANGED)
      23ef200ca6364eff|Oracle VM VirtualBox 5.0.16
      23f08dab0f6aaf30|SoMud 1.3.3
      2417caa1f2a881d4|ICQ 7.6 (Build 5617)
      2437d4d14b056114|EiskaltDC++ 2.2.3
      2519133d6d830f7e|IMatch 3.6.0.113
      2544ff74641b639d|WiseFTP 6.1.5
      26717493b25aa6e1|Adobe Dreamweaver CS5 (32-bit)
      26753c97ea000ecd|LibreOffice 5.1.0.3 Math
      271e609288e1210a|Microsoft Office Access 2010 x86
      27da120d7e75cf1f|pbFTPClient 6.1
      27ececd8d89b6767|AIM 6.2.14.2 / 6.5.3.12 / 6.9.17.2
      28493d9d08e13aa6|UltraVNC Viewer 1.2.1.0
      28c8b86deab549a1|Internet Explorer 8 / 9
      28c8b86deab549a1|Internet Explorer 8 / 9 / 10 (32-bit)
      28c8b86deab549a1|Internet Explorer 8.0.7600.16385 / 9
      290532160612e071|WinRAR 2.90 / 3.60 / 4.01
      290532160612e071|WinRar x64
      292a746334889a7e|SQLiteSpy 1.9.13
      2a5a615382a84729|X-Chat 2 2.8.6-2
      2aa756186e21b320|RealTimeQuery 3.2
      2b164f512891ae37|NewsWolf NSListGen
      2b53c4ddf69195fc|Zune x64
      2b5841989b3857da|RealVNC Server 5.3.0 64-bit (Chat)
      2ca2a1a69dc5465f|UltraVNC 1.2.1.0 Server Property Page
      2d1658d5dc3cbe2d|MySpaceIM 1.0.823.0 Beta
      2d61cccb4338dfc8|BitTorrent 5.0.0 / 6.0.0 / 7.2.1 (Build 25548)
      2db8e25112ab4453|Deluge 1.3.12 / 1.3.3
      2db8e25112ab4453|Deluge 1.3.3
      2fa14c7753239e4c|Paint.NET 2.72 / 3.5.8.4081.24580
      2ff9dc8fb7e11f39|I2P 0.8.8 (no window)
      3094cdb43bf5e9c2|Microsoft Office OneNote 2010 x86
      30d23723bdd5d908|Digsby (Build 30140) (JL support)
      315e29a36e961336|Roboform 7.8
      3168cc975b354a01|Slypheed 3.1.2 (Build 1120)
      3198e37206f28dc7|CuteFTP 8.3 Professional (Build 8.3.4.0007)
      319f01bf9fe00f2d|Microsoft Access 2013 64-bit
      319f01bf9fe00f2d|Microsoft Access 2016 64-bit
      31e8ac6b0784ed7d|Foxit Reader 9.4.0.16811
      3353b940c074fd0c|Microsoft Built-in Snipping Tool
      337ed59af273c758|Sticky Notes
      337ed59af273c758|Sticky Notes (Windows 10)
      3461e4d1eb393c9c|WTW 0.8.18.2852 / 0.8.19.2940
      353e9052cccbec5d|Kindle for PC 1.21.0
      3594aab44bca414b|Windows Photo Viewer
      36801066f71b73c5|Binbot 2.0
      36c36598b08891bf|Vovox 2.5.3.4250
      36f6bc3efe1d99e0|Alt.Binz 0.25.0 (Build 27.09.2007)
      37392221756de927|RealPlayer SP 12
      3866ff352d7719e1|Paint.NET 4.0.9
      386a2f6aa7967f36|EyeBrowse 2.7
      387d72eb9c9aa960|UltraVNC 1.2.1.0 Launcher
      3917dd550d7df9a8|Konvertor 4.06 (Build 10)
      3a5148bf2288a434|Secure FTP 2.6.1 (Build 20101209.1254)
      3be7b307dfccb58f|NiouzeFire 0.8.7.0
      3c0022d9de573095|QuteCom 2.2
      3c309c17f7e8ffe1|GIMP 2.8.16
      3c93a049a30e25e6|J. River Media Center 16.0.149
      3cf13d83b0bd3867|RevConnect 0.674p (based on DC++)
      3d877ec11607fe4|Thunderbird 6.0.2
      3dc02b55e44d6697|7-Zip 3.13 / 4.20
      3df22b7648cec4c1|TeamViewer 11.0.55321
      3e9850346f375d41|Foxit Phantom PDF 7.2.2.929
      3ed70ef3495535f7|Gravity 3.0.4
      3edf100b207e2199|digiKam 1.7.0 (KDE 4.4.4)
      3f2cd46691bbee90|GOIM 1.1.0
      3f97341a65bac63a|Ozum 6.07 (Build 6070)
      409b67100697bcc0|Revo Uninstaller Pro 3.1.5
      40f2aca05d8a33f2|Minitab 16
      411447f7de177c68|Windows DVD Maker 64-bit (Win7)
      4278d3dc044fc88a|Gaim 1.5.0
      431a5b43435cc60b|Python (.pyc)
      43578521d78096c6|Windows Media Player Classic Home Cinema 1.3 (32-bit)
      435a2f986b404eb7|SmartFTP 4.0.1214.0
      435a2f986b404eb7|SmartFTP 4.0.1214.0 / 7.0.2200.0
      43886ba3395acdcc|Easy Post 3.0
      44a3621b32122d64|Microsoft Office Word 2010 x64
      44a398496acc926d|Adobe Premiere Pro CS5 (64-bit)
      44a50e6c87bc012|Classic FTP Plus 2.15
      454ef7dca3bb16b2|Exodus 0.10.0.0
      469e4a7982cea4d4|? (.job)
      469e4a7982cea4d4|Windows Wordpad
      46f433176bc0b3d2|WinRAR 5.30 beta 64-bit
      4700ff5ae80a6713|PDFCreator 2.2
      490c000889535727|WinMX 4.9.3.0
      4975d6798a8bdf66|7-Zip 4.65 / 9.20
      497b42680f564128|Zoner PhotoStudio 13 (Build 7)
      49b5edbd92d8cd58|FTP Commander 8.02
      49db7ed4f2703c22|LogMeIn Client 1.3.1835
      4a49906d074a3ad3|Media Go 1.8 (Build 121)
      4a7e4f6a181d3d08|broolzShare
      4aa2a5710da3efe0|DCSharpHub 2.0.0
      4acae695c73a28c7|VLC 0.3.0 / 0.4.6
      4b632cf2ceceac35|Robo-FTP Server 3.2.5
      4b6925efc53a3c08|BCWipe 5.02.2 Task Manager 3.02.3
      4b6925efc53a3c08|BCWipe Task Manager 3.02.3 / 3.06.5.5
      4b8a4727aa452343|Firefox 56.0.2
      4c58cf9096ef3efd|Kindle for PC 1.24.3
      4cdf7858c6673f4b|Bullet Proof FTP 1.26
      4d72cfa1d0a67418|Newsgroup Image Collector
      4d7bdaea55ad352|PeaZip 6.0.0
      4d8bdacf5265a04f|The KMPlayer 2.9.4.1434
      4dd48f858b1a6ba7|Free Download Manager 3.0 (Build 852)
      4e0ac37db19cba15|Xfire 1.138 (Build 44507)
      4e538fde985a3c01|Torch Browser 65.0.0.1614 (x86)
      4f24a7b84a7de5a6|Palringo 2.6.3 (r45983)
      4fceec8e021ac978|CoffeeCup Free FTP 3.5.0.0
      4fd44f9938892caa|CDBurnerXP
      500b8c1d5302fc9c|Python (.pyw)
      50620fe75ee0093|VMware Player 12 build-3272444
      50620fe75ee0093|VMware Player 3.1.4
      50c5e019818564e3|Microsoft Excel Viewer 12.0.6219.1000
      521a29e5d22c13b4|Skype 1.4.0.84 / 2.5.0.154 / 3.8.0.139 / 4.2.0.187 / Skype 5.3.0.120 / 5.5.0.115 / 5.5.32.117
      54c803dfc87b52ba|Nettalk 6.7.12
      550abc1cb58eb92c|VeraCrypt 1.16 / 1.19 64-bit
      550abc1cb58eb92c|VeraCrypt 1.16 64-bit
      558c5bd9f906860a|BearShare Lite 5.2.5.1
      560d789a6a42ad5a|DC++ 0.261 / 0.698 / 0.782 (r2402.1)
      56c5204009d2b915|uTorrent 3.5.5
      590aee7bdd69b59b|Powershell Windows 10
      590aee7bdd69b59b|Windows Powershell 5.0 64-bit
      59e86071b87ac1c3|CuteFTP 8.3 (Build 8.3.4.0007)
      59f56184c796cfd4|ACDSee Photo Manager 10 (Build 219)
      5b186fc4a0b40504|Dtella 1.2.5 (Purdue network only)
      5b72f67adcce9045|UltraVNC 1.2.1.0 Settings
      5b7f3287093c1623|Total Commander 8.52a 64-bit
      5bb830f67194431a|7-Zip 18.05 (x64)
      5c450709f7ae4396|Firefox 1.0 / 2.0 / 3.0
      5c450709f7ae4396|Firefox 3.6.13 (32-bit)
      5d696d521de238c3|Chrome 9.0.597.84 / 12.0.742.100 / 13.0.785.215
      5d696d521de238c3|Chrome 9.0.597.84 / 12.0.742.100 / 13.0.785.215 / 26
      5d696d521de238c3|Google Chrome 9.0.597.84 / 12.0.742.100 / 13.0.785.215 / 48.0.2564.116
      5d6f13ed567aa2da|Microsoft Office Outlook 2010 x64
      5d7b4175afdcc260|Shareaza 2.0.0.0
      5da8f997fd5f9428|Internet Explorer x64
      5df4765359170e26|Firefox 4.0.1
      5e01ecaf82f7d8e|Scour Exchange 0.0.0.228
      5ea2a50c7979fbdc|TrustyFiles 3.1.0.22
      5f6e7bc0fb699772|Microsoft Office PowerPoint 2010 x64
      5f7b5f1e01b83767|Quick Access
      5fb817cd5a8cad21|Google Drive
      5fd959f6fe6b8ae7|PuTTY 0.70 (x64)
      6059df4b02360af|Kadu 0.10.0 / 0.6.5.5
      606a33f5a27b57d4|Microsoft Built-in Computer Management 10.0.10011.16384 (Win10)
      6224453d9701a612|BinTube 3.7.1.0 (requires VLC 10.5!)
      62bff50b969c2575|"Quintessential Media Player 5.0 (Build 121) - also usage stats (times used, tracks played, total time used)"
      62bff50b969c2575|Quintessential Media Player 5.0 (Build 121)
      62dba7fb39bb0adc|Yahoo Messenger 7.5.0.647 / 8.1.0.421 / 9.0.0.2162 / 10.0.0.1270
      65009083bfa6a094|(app launched via XPMode)
      65f7dd884b016ab2|LimeChat 2.39
      669967f27afdebec|NirSoft PstPassword 1.20 (x86)
      6728dd69a3088f97|Command Prompt
      6728dd69a3088f97|Windows Command Processor - cmd.exe (64-bit)
      6824f4a902c78fbd|Firefox 64.0
      689319b6547cda85|emesene 2.11.7
      6a316aa67a46820b|Core FTP LE 1.3c (Build 1437) / 2.2 (Build 1689)
      6a8b377d0f5cb666|WinSCP 2.3.0 (Build 146)
      6aa18a60024620ae|GCN 2.9.1
      6b3a5ce7ad4af9e4|IceChat 9 RC2
      6bb54d82fa42128d|WinSCP 4.3.4 (Build 1428)
      6bb98fb8cdc26d69|Calculator (Windows built-in)
      6bc3383cb68a3e37|iTunes 7.6.0.29 / 8.0.0.35
      6d2bac8f1edf6668|Microsoft Office Outlook 365
      6d2bac8f1edf6668|Microsoft Outlook 2013 32-bit
      6d2bac8f1edf6668|Microsoft Outlook 2016 64-bit
      6e855c85de07bc6a|Microsoft Office Excel 2010 x64
      6e9a79992da9ea2|Nokia PC Suite 7.1
      6e9d40a4c63bb562|Real Player Alternative 1.25 (Media Player Classic 6.4.8.2 / 6.4.9.0)
      6f647f9488d7a|AIM 7.5.11.9 (custom AppID + JL support)
      6fee01bd55a634fe|Smuxi 0.8.0.0
      7010c278903c2b0f|Adobe Acrobat XI Pro 32-bit
      70b52cf73249257|Sococo 1.5.0.2274
      70d9ada92108d731|IrfanView 4.51 (x64)
      714b179e552596df|Bullet Proof FTP 2.4.0 (Build 31)
      7192f2de78fd9e96|TIFNY 5.0.3
      728008617bc3e34b|eM Client 3.0.10206.0
      73c6a317412687c2|Google Talk 1.0.0.104
      73ce3745a843c0a4|FrostWire 5.1.4
      7494a606a9eef18e|Crystal Player 1.98
      74d7f43c1561fc1e|Windows Media Player 12 (32-bit)
      74d7f43c1561fc1e|Windows Media Player 12.0.7600.16415 / 12.0.7601.17514
      74d7f43c1561fc1e|Windows Media Player 12.0.7601.17514
      74ea779831912e30|Skype 7.18.0.112
      74ea779831912e30|Skype 7.24.0.104
      7526de4a8b5914d9|Forte Agent 6.00 (Build 32.1186)
      7593af37134fd767|RealPlayer 6.0.6.99 / 7 / 8 / 10.5
      76689ff502a1fd9e|Imagine Image and Animation Viewer 1.0.7
      76f6f1bd18c19698|aMule 2.2.6
      776beb1fcfc6dfa5|Thunderbird 1.0.6 (20050716) / 3.0.2
      777483d3cdac1727|Gajim 0.14.4
      780732558f827a42|AutoPix 5.3.3
      784182360de0c5b6|Kazaa Lite 1.7.1
      78f0afb5bd4bb278|Microsoft Lync 2016 64-bit (Skype for Business)
      7904145af324576e|Total Commander 7.56a (Build 16.12.2010)
      7904145af324576e|Total Commander 7.56a (Build 16.12.2010) / 8.52a 32-bit
      792699a1373f1386|Piolet 3.1.1
      79370f660ab51725|UploadFTP 2.0.1.0
      7937df3c65790919|FTP Explorer 10.5.19 (Build 001)
      7a4ba998575ff2a4|FreeCommander XE 2016 Build 715 32-bit
      7a7c60efd66817a2|Spotnet 1.7.4
      7a8db574299c8568|Windows Movie Maker 2012 (build 16.4.3528.0331)
      7b2b4f995b54387d|News Reactor 20100224.16
      7b4d500e147e4391|Tor Browser 8.0.4 (x64)
      7b7f65aaeca20a8c|Dropbox App 5.4.24
      7c2916afd6f116a6|LibreOffice 5.1.0.3 Base
      7cb0735d45243070|CDisplay 1.8.1.0
      7dca40fd2a5a971f|LibreOffice 5.1.0.3
      7e4dca80246863e3|Control Panel
      7e4dca80246863e3|Control Panel (?)
      7e4dca80246863e3|Control Panel - Settings
      7fd04185af357bd5|UltraLeeacher 1.7.0.2969 / 1.8 Beta (Build 3490)
      8172865a9d5185cb|Binreader 1.0 (Beta 1)
      817bb211c92fd254|GOM Player 2.0.12.3375 / 2.1.28.5039
      817e5ad5be351574|Microsoft Built-in Services 10.0.10011.16384 (Win10)
      8211531a7918b389|Newsbin Pro 6.00 (Build 1019) (JL support)
      83b03b46dcd30a0e|iTunes 10
      83b03b46dcd30a0e|iTunes 9.0.0.70 / 9.2.1.5 / 10.4.1.10 (begin custom 'Tasks' JL capability)
      83b03b46dcd30a0e|iTunes 9.0.0.70 / 9.2.1.5 / 10.4.1.10 (begin custom 'Tasks' JL capability) / 12.3.2.35 64-bit
      83dd64e7fa560bd5|LibreOffice 5.1.0.3 Calc
      84f066768a22cc4f|Adobe Photoshop CS5 (64-bit)
      8628e76fd9020e81|Fling File Transfer Plus 2.24
      86781fe8437db23e|Messenger Pro 2.66.6.3353
      86b804f7a28a3c17|Miranda IM 0.6.8 / 0.7.6 / 0.8.27 / 0.9.9 / 0.9.29
      86b804f7a28a3c17|Miranda IM 0.6.8 / 0.7.6 / 0.8.27 / 0.9.9 / 0.9.29 (ANSI + Unicode)
      884fd37e05659f3a|VZOchat 6.3.5
      888f2fa044591eda|Twitter - Trusted Microsoft Store App (Win10)
      8904a5fd2d98b546|IceChat 7.70 20101031
      89b0d939f117f75c|Adobe Acrobat 9 Pro Extended (32-bit)
      8a1c1c7c389a5320|Safari 3.2.3 (525.29)
      8a461f82e9eb4102|Foxit Reader 7.2.0.722
      8bd5c6433ca967e9|ACDSee Photo Manager 2009 (v11.0 Build 113)
      8c816c711d66a6b5|MSN Messenger 6.2.0137 / 7.0.0820
      8dcca8b24a5e822e|CDBurnerXP 4.5.7.6623
      8deb27dfa31c5c2a|CoffeeCup Free FTP 4.4 (Build 1904)
      8eafbd04ec8631ce|VMware Workstation 11.0.0 build-2305329
      8eafbd04ec8631ce|VMware Workstation 9 x64
      8f3d7202aa5d4c01|ImgBurn 2.5.8.0
      8f852307189803b8|Far Manager 2.0.1807
      8fb5ce5e2b049ce|Windows Defender (Win10 built-in)
      8fd1364019dc2115|Calibre E-Book Manager 2.33
      8fdb062f1e486cac|Microsoft Powerpoint 2013 32-bit
      9027fe24326910d2|Thunderbird 38.6.0
      905c98e216107aa1|Microsoft Lync 2013 15.0.4753.1000
      9077b9c9cf187cc2|KeePass 1.36
      90e5e8b21d7e7924|Winamp 3.0d (Build 488)
      918e0ecb43d17e23|Notepad (32-bit)
      92f1d5db021cd876|NewsLeecher 4.0 / 5.0 Beta 6
      939c10c2c101c1b0|Stickies 9.0d
      93b18adf1d948fa3|qutIM 0.2
      954ea5f70258b502|Windows Script Host - wscript.exe (32-bit)
      9560577fd87cf573|LeechFTP 1.3 (Build 207)
      96252daff039437a|Lphant 7.0.0.112351
      966fa7c312d9b10|Eraser 6.2.0.2970
      969252ce11249fdd|Mozilla Firefox 40.0 / 44.0.2
      9749cea96d411f37|HexChat 2.10.2 64-bit
      977a5d147aa093f4|Lphant 3.51
      9839aec31243a928|Microsoft Office Excel 2010 x86
      989d7545c2b2e7b2|IMVU 465.8.0.0
      98b0ef1c84088|fulDC 6.78
      99c15cf3e6d52b61|mldonkey 3.1.0
      9a3bdae86d5576ee|WinSCP 3.2.1 (Build 174) / 3.8.0 (Build 312)
      9a464053cd82de6d|LINE Messenger
      9ad1ec169bf2da7f|FlylinkDC++ r405 (Build 7358)
      9ad84c52efeae190|1Password 4.6.0.604
      9b9cdc69c1c24e2b|Notepad (64-bit)
      9b9cdc69c1c24e2b|Notepad 64-bit
      9c08ad74ad8708df|Microsoft Publisher 2016 64-bit
      9c32e2313792e6e8|Microsoft Built-in Disk Cleanup (Win10)
      9c7cc110ff56d1bd|Microsoft Office PowerPoint 2010 x86
      9ce6555426f54b46|HxD 1.7.7.0
      9d1f905ce5044aee|Edge Browser
      9d78513a8998829c|Microsoft Built-in Run Dialog (Win7 + Win10)
      9d91276b0be3e46b|Windows Help and Support (Built-in) Win7
      9dacebaa9ac8ca4e|TLNews Newsreader 2.2.0 (Build 2430)
      9e0b3f677a26bbc4|BitKinex 3.2.3
      9edafe4ba4b22ce7|Eclipse IDE Oxygen (4.7.3a)
      9f03ae476ad461fa|GroupsAloud 1.0
      9f5c7755804b850a|Windows Script Host - wscript.exe (64-bit)
      9fda41b86ddcf1db|VLC 0.5.3 / 0.8.6i / 0.9.7 / 1.1.11
      9fda41b86ddcf1db|VLC Media Player 0.5.3 / 0.8.6i / 0.9.7 / 1.1.11 / 2.2.1
      9fdb10e18cdd0101|Cisco AnyConnect Secure Mobility Client 3.1.02040
      a028c9db28aa15a3|Piriform Defraggler 2.20.989 64-bit
      a0d6b1b874c6e9d2|TOR Browser 6.0.2
      a10b45adb36c1d27|PST Walker 5.54
      a18df73203b0340e|Microsoft Word 2016
      a1d19afe5a80f80|FileZilla 2.2.32
      a2c73c383525f1bb|RealVNC Viewer 5.3.0 64-bit
      a31ec95fdd5f350f|BitComet 0.49 / 0.59 / 0.69 / 0.79 / 0.89 / 0.99 / 1.07 / 1.28
      a3e0d98f5653b539|Instantbird 1.0 (20110623121653) (JL support)
      a4a5324453625195|Microsoft Office Word 2013 x86
      a4a5324453625195|Microsoft Word 2013 32-bit
      a4def57ee99d77e9|Nomad News 1.43
      a52b0784bd667468|Photos Microsoft 16.526.11220.0 (Windows 10)
      a581b8002a6eb671|WiseFTP 5.5.9
      a5db18f617e28a51|ICQ 6.5 (Build 2024)
      a6d4dfec09c69409|Microsoft Word Viewer 11.8169.8172
      a746f9625f7695e8|HeXHub 5.07
      a75b276f6e72cf2a|Kazaa Lite Tools K++ 2.7.0
      a75b276f6e72cf2a|Kazaa Lite Tools K++ 2.7.0 / WinMX 3.53
      a75b276f6e72cf2a|WinMX 3.53
      a777ad264b54abab|JetVideo 8.0.2.200 Basic
      a79a7ce3c45d781|CuteFTP 7.1 (Build 06.06.2005.1)
      a7bd71699cd38d1c|Microsoft Office Word 2010 x86
      a8c43ef36da523b1|Microsoft Office Word 2003 Pinned and Recent.
      a8df13a46d66f6b5|Kommute (Calypso) 0.24
      aa11f575087b3bdc|Unzbin 2.6.8
      ac3a63b839ac9d3a|Azureus Vuze Bittorrent Client 4.6.0.4 / 5.7.1.0
      ac3a63b839ac9d3a|Vuze 4.6.0.4
      ac8920ed05001800|@DMDirc 0.6.5 (Profile store: C:\Users\$user\AppData\Roaming\DMDirc\)
      ac8920ed05001800|DMDirc 0.6.5 (Profile store: C:\Users\$user\AppData\Roaming\DMDirc\)
      accca100973ef8dc|Azureus 2.0.8.4
      ace8715529916d31|40tude Dialog 2.0.15.1 (Beta 38)
      adecfb853d77462a|Microsoft Office Word 2007 Pinned and Recent.
      ae069d21df1c57df|mIRC 6.35 / 7.19
      ae3f2acd395b622e|QuickTime Player 6.5.1 / 7.0.3 / 7.5.5 (Build 249.13)
      aedd2de3901a77f4|Pidgin 2.0.0 / 2.10.0 / 2.7.3
      aedd2de3901a77f4|Pidgin 2.10.11
      b0236d03c0627ac4|ICQ 5.1 / ICQLite Build 1068
      b0459de4674aab56|(.vmcx)
      b0459de4674aab56|Windows Virtual PC - vmwindow.exe (32- and 64-bit)
      b06a975b62567622|Windows Live Messenger 8.5.1235.0517 BETA
      b08971c77377bde3|Microsoft Visual Studio Community 2015
      b17d3d0c9ca7e29|"Picasa 3.8.0 (build 117.43, 0) / 3.9.141 (build 259)"
      b17d3d0c9ca7e29|"Picasa 3.8.0 (Build 117.43, 0)"
      b223c3ffbc0a7a42|Bersirc 2.2.14
      b3016b8da2077262|eMule 0.50a
      b3965c840bf28ef4|AIM 4.8.2616
      b39bc6b590f53961|HexChat 2.10.2 32-bit
      b39c5f226977725d|ACDSee Pro 8.1.99
      b3f13480c2785ae|Paint 6.1 (build 7601: SP1)
      b48ce76eda60b97|Shareaza 8.0.0.112300
      b50ee40805bd280f|QuickTime Alternative 1.9.5 (Media Player Classic 6.4.9.1)
      b6267f3fcb700b60|WiseFTP 4.1.0
      b74736c2bd8cc8a5|WinZip
      b74736c2bd8cc8a5|WinZip 15.5 (9468)
      b77ef7f3fc946302|Pale Moon Browser 26.1.1 (32-bit)
      b7cb1d1c1991accf|FlashFXP 4.0.0 (Build 1548)
      b868d9201b866d96|Microsoft Lync 4.0.7577.0
      b8ab77100df80ab2|Microsoft Excel 2016 64-bit
      b8ab77100df80ab2|Microsoft Office Excel x64
      b8c13a5dd8c455a2|Titan FTP Server 8.40 (Build 1338)
      b8c29862d9f95832|Microsoft Office InfoPath 2010 x86
      b91050d8b077a4e8|Windows Media Center (Win7)
      b91050d8b077a4e8|Windows Media Center x64
      ba132e702c0147ef|KCeasy 0.19-rc1
      ba3a45f7fd2583e1|Blubster 3.1.1
      bac8a6b507360131|Remote Desktop Connection Manager 2.2
      baea31eacd87186b|BinaryBoy 1.97 (Build 55)
      bba8a4896f0d26f|Ares Chat Client (3.1.9.4045)
      bc03160ee1a59fc1|Foxit PDF Reader 5.4.5
      bc0c37e84e063727|Windows Command Processor - cmd.exe (32-bit)
      bc2f88eccd3461b4|Microsoft Built-in Event Viewer 1.0 (Win10)
      bcc705f705d8132b|Instan-t 5.2 (Build 2824)
      bcd7ba75303acbcf|BitLord 1.1
      bd249197a6faeff2|Windows Live Messenger 2011
      be4875bb3e0c158f|CrossFTP 1.75a
      be71009ff8bb02a2|Microsoft Office Outlook x86
      bec10d3aaf939ffa|Pale Moon Browser 26.1.1 (64-bit)
      bf483b423ebbd327|Binary Vortex 5.0
      bf9ae1f46bd9c491|Nimbuzz 2.0.0 (rev 6266)
      bfc1d76f16fa778f|Ares (Galaxy) 1.8.4 / 1.9.8 / 2.1.0 / 2.1.7.3041
      bfc1d76f16fa778f|Ares (Galaxy) 1.8.4 / 1.9.8 / 2.1.0 / 2.1.7.3041 / 3.1.9.4045
      bfe841f4d35c92b1|QuadSucker/News 5.0
      c01d68e40226892b|ClicksAndWhistles 2.7.146
      c02baf50d02056fc|FotoVac 1.0
      c04f69101c131440|CuteFTP 5.0 (Build 50.6.10.2)
      c1eece5026414c64|Recuva 1.52.1086 (64-bit)
      c2d349a0e756411b|Adobe Reader 8.1.2
      c312e260e424ae76|Mail.Ru Agent 5.8 (JL support)
      c5236fd5824c9545|PLAYXPERT 1.0.140.2822
      c54b96f328bdc28d|WiseFTP 7.3.0
      c5c24a503b1727df|XnView 1.98.2 Small / 1.98.2 Standard
      c5c24a503b1727df|XnView 1.98.2 Small / 1.98.2 Standard / 2.35
      c5ef839d8d1c76f4|LimeWire 5.2.13
      c634153e7f5fce9c|IrfanView 3.10 / 4.30
      c634153e7f5fce9c|IrfanView 3.10 / 4.30 / 4.41 32-bit
      c6f7b5bf1b9675e4|BitWise IM 1.7.3a
      c71ef2c372d322d7|PGP Desktop 10
      c765823d986857ba|Adobe Illustrator CS5 (32-bit)
      c7a4093872176c74|Paint Shop Pro Pinned and Recent.
      c8112ac53c5ed250|Jetico Log Viewer 1.1
      c845f3a6022d647c|Another File 2.Build 2/7/2004)
      c8aa3eaee3d4343d|Trillian 0.74 / 3.1 / 4.2.0.25 / 5.0.0.35 (JL support)
      c8e4c10e5460b00c|iMesh 6.5.0.16898
      c91d08dcfc39a506|SM Player 0.6.9 r3447
      c9374251edb4c1a8|BitTornado T-0.3.17
      c98ab5ccf25dda79|NewsShark 2.0
      c9950c443027c765|WinZip 9.0 SR-1 (6224) / 10.0 (6667)
      c997d2e1a0f0929|BCWipe 6.08.6
      c99ddde925d26df3|Robo-FTP 3.7.9 CronMaker
      ca1eb46544793057|RetroShare 0.5.2a (Build 4550)
      ca942805559495e9|aMSN 0.98.4
      caea34d2e74f5c8|uTorrent 3.4.7
      cb1d97aca3fb7e6b|Newz Crawler 1.9.0 (Build 4100)
      cb5250eaef7e3213|ApexDC++ 1.4.3.957
      cb984e3bc7faf234|NewsRover 17.0 (Rev.0)
      cb996a858d7f15c|PDF Architect 4.0.09.25450 64-bit
      cbbe886eca4bfc2d|ExoSee 1.0.0
      cbeb786f0132005d|VLC 0.7.2
      cc4b36fbfb69a757|gtk-gnutella 0.97
      cc76755e0f925ce6|AllPicturez 1.2
      cca6383a507bac64|Gadu-Gadu 10.5.2.13164
      ccb36ff8a8c03b4b|Azureus 2.5.0.4 / Vuze 3.0.5.0
      ccc0fa1b9f86f7b3|CCleaner 5.15.5513 64-bit
      cd2acd4089508507|AbsoluteTelnet 9.18 Lite
      cd40ead0b1eb15ab|NNTPGrab 0.6.2
      cd8cafb0fb6afdab|uTorrent 1.7.7 (Build 8179) / 1.8.5 / 2.0 / 2.21 (Build 25113) / 3.0 (Build 25583)
      cdb6f0c373f2da0f|stunnel 5.31
      cdf30b95c55fd785|Microsoft Office Excel 2007
      cf6379a9a987366e|Digibin 1.31
      cfab0ec14b6f953|Express NewsPictures 2.41 (Build 08.05.07.0)
      cfb56c56fa0f0a54|Mozilla 0.9.9
      d00655d2aa12ff6d|Microsoft Office PowerPoint x64
      d00655d2aa12ff6d|Microsoft PowerPoint 2016 64-bit
      d0261ed6e16b200b|News File Grabber 4.6.0.4
      d1fc019238236806|Newsgroup Commander Pro 9.05
      d22ad6d9d20e6857|ALLPlayer 4.7
      d28ee773b2cea9b2|3D-FTP 9.0 build 7
      d2d0fc95675fb2c8|Microsoft Built-in Print Management (Win10)
      d33ecf70f0b74a77|"Picasa 2.2.0 (Build 28.08, 0)"
      d33ecf70f0b74a77|Picasa 2.2.0 (Build 28.08, 0)
      d3530c5294441522|HydraIRC 0.3.165
      d38a3ea7ec79fbed|LibreOffice 5.1.0.3 Writer
      d38adec6953449ba|Microsoft Office OneNote 2010 x64
      d3c5cf21e86b28af|SeaMonkey 2.3.3
      d41746b133d17456|Tkabber 0.11.1
      d460280b17628695|Java Binary
      d4a589cab4f573f7|Microsoft Project 2010 x86
      d53b52fb65bde78c|Android Newsgroup Downloader 6.2
      d5c02fc7afbb3fd4|NNTPGrab 0.6.2 Server
      d5c3931caad5f793|Adobe Soundbooth CS5 (32-bit)
      d64d36b238c843a3|Microsoft Office InfoPath 2010 x86
      d7528034b5bd6f28|Windows Live Mail Pinned and Recent.
      d7666c416cba240c|NewsMan Pro 3.0.5.2
      d78150e0484a4e1d|Evernote 5.9.6.9494
      d7d647c92cd5d1e6|uTalk 2.6.4 r47692
      d7db75db9cdd7c5d|Xnews 5.04.25
      d8081f151f4bd8a5|CuteFTP 8.3 Lite (Build 8.3.4.0007)
      d838aac097abece7|ACDSee Photo Manager 12 (Build 344)
      d8671c1ed93c75c8|Tor Browser 5.5.2
      d93f411851d7c929|Windows Powershell 5.0 32-bit
      d97efdf3888fe7eb|KeePass 2.31
      da7e8de5b8273a0f|Yahoo Messenger 5.0.0.1226 / 6.0.0.1922
      db3b8d985f0668e|FreeFileSync 10.7
      dba909a61476ccec|NewsWolf 1.41
      dc64de6c91c18300|Brosix Communicator 3.1.3 (Build 110719 nid 1)
      dd658a07478b46c2|PIRCH98 1.0.1.1190
      de48a32edcbe79e4|Acrobat Reader 15.x
      de48a32edcbe79e4|Adobe Acrobat Reader DC 2015.010.20056
      de76415e0060ce13|Noworyta News Reader 2.9
      dee18f19c7e3a2ec|PopNote 5.21
      e0246018261a9ccc|qutIM 0.2.80.0
      e0532b20aa26a0c9|QQ International 1.1 (2042)
      e0f7a40340179171|imule 1.4.5 (rev. 749)
      e107946bb682ce47|FileZilla 3.5.1
      e107946bb682ce47|Filezilla 3.5.1 / 3.16
      e1d47cb031dafb9f|BearShare 6.0.0.22717 / 8.1.0.70928 / 10.0.0.112380
      e2a593822e01aed3|Adobe Flash CS5 (32-bit)
      e30bbea3e1642660|Neebly 1.0.4
      e31a6a8a7506f733|Image AXS Pro 4.1
      e36bfc8972e5ab1d|XPS Viewer
      e40cb5a291ad1a5b|Songbird 1.9.3 (Build 1959)
      e42a8e0f4d9b8dcf|Sysax FTP Automation 5.15
      e4bd2558bfab368d|UltraDefrag 7.0.0
      e57cfc995bdc1d98|Snagit 11
      e6ea77a1d4553872|Gnucleus 1.8.6.0
      e6ee34ac9913c0a9|VLC 0.6.2
      e6ef42224b845020|ALFTP 5.20.0.4
      e70d383b15687e37|Notepad++ 5.6.8 (32-bit)
      e70d383b15687e37|Notepad++ 6.6.7
      e73d9f534ed5618a|BitSpirit 1.2.0.228 / 2.0 / 2.6.3.168 / 2.7.2.239 / 2.8.0.072 / 3.1.0.077 / 3.6.0.550
      e76a4ef13fbf2bb1|Manolito 3.1.1
      e93dbdcede8623f2|Pandion 2.6.106
      e9a39dfba105ea23|FastStone Image Viewer 4.6
      e9a39dfba105ea23|Faststone Image Viewer 4.6 / 5.5
      ea83017cdd24374d|IrfanView Thumbnails
      eab25958dbddbaa4|Binary News Reaper 2 (Beta 0.14.7.448)
      eb3300e672136bc7|Stream Reactor 1.0 Beta 9 (uses VLC!)
      eb7e629258d326a1|WindowWasher 6.6.1.18
      ebd8c95d87f25154|Carrier 2.5.5
      ec3e36af0cdcb3e1|Steam build 2/4/2016
      ecd1a5e2c3af9c46|LibreOffice 5.1.0.3 Press
      ecd21b58c2f65a2f|StealthNet 0.8.7.9
      ecdd9154e84d5544|Wickr Top Secret Messenger Desktop 2.3.5
      ed49e1e6ccdba2f5|GNUnet 0.8.1a
      ed7a5cc3cca8d52a|CCleaner 1.32.345 / 1.41.544 / 2.36.1233 / 3.10.1525
      edc786643819316c|HoneyView3 #5834
      ee0c103672a7a2b9|ManyCam 6.7.0
      ee462c3b81abb6f6|Adobe Reader X 10.1.0
      ef473fab8120b354|uTorrent 3.5.5
      ef606b196796ebb|HP MediaSmart Photo
      efb08d4e11e21ece|Paltalk Messenger 10.0 (Build 409)
      efbb2bf3c1d06466|Auslogics Disk Defrag 6.2.1.0
      f001ea668c0aa916|Cabos 0.8.2
      f01b4d95cf55d32a|Windows Explorer (Win10) ??? TEST THIS
      f01b4d95cf55d32a|Windows Explorer Windows 8.1
      f0275e8685d95486|Microsoft Excel 2013 32-bit
      f0275e8685d95486|Microsoft Office Excel 2013 x86
      f0468ce1ae57883d|Adobe Reader 7.1.0
      f09b920bfb781142|Camfrog 4.0.47 / 5.5.0 / 6.1 (build 146) (JL support)
      f0c7bd3e0584a65a|InfraRecorder 0.53.0.0 32-bit
      f1a4c04eebef2906|[i2p] Robert 0.0.29 Preferences
      f214ca2dd40c59c1|FrostWire 4.20.9
      f2cb1c38ab948f58|X-Chat 1.8.10 / 2.6.9 / 2.8.9
      f5ac5390b9115fdb|Microsoft Office PowerPoint 2007
      f5e4e50707bcd215|Microsoft Message Analyzer 1.4
      f61b65550a84027e|iMesh 11.0.0.112351
      f64de962764b9b0f|FTPRush 1.1.3 / 2.15
      f674c3a77cfe39d0|Winamp 2.95 / 5.1 / 5.621
      f674c3a77cfe39d0|Winamp 2.95 / 5.1 / 5.621 / 5.666
      f6fd5d99e2b6e178|LibreOffice 5.1.0.3 Draw
      f784591ff7f60f76|Microsoft Built-in Defragment and Optimize Drives (Win10)
      f82607a219af2999|Cyberduck 4.1.2 (Build 8999)
      f91fd0c57c4fe449|ExpanDrive 2.1.0
      f920768fe275f7f4|Grabit 1.5.3 Beta (Build 909) / 1.6.2 (Build 940) / 1.7.2 Beta 4 (Build 997)
      f92e607f9de02413|RealPlayer 14.0.6.666
      fa02aa2c575837a6|Microsoft Built-in Task Scheduler 1.0 (Win10)
      fa496fe13dd62edf|KVIrc 3.4.2.1 / 4.0.4
      fa7144034d7d083d|Directory Opus 10.0.2.0.4269 (JL tasks supported)
      fac3aa4105c6c466|Microsoft Built-in System Restore (Win7)
      faef7def55a1d4b|VLC 2.2.6
      fb1f39d1f230480a|Bopup Messenger 5.6.2.9178 (all languages: en,du,fr,ger,rus,es)
      fb1f39d1f230480a|Bopup Messenger 5.6.2.9178 (all languages: en;du;fr;ger;rus;es)
      fb230a9fe81e71a8|Yahoo Messenger 11.0.0.2014-us
      fb3b0dbfee58fac8|Microsoft Office Word 365 x86
      fb3b0dbfee58fac8|Microsoft Word 2016 64-bit
      fb7ca8059b8f2123|ooVoo 3.0.7.21
      fc999f29bc5c3560|Robo-FTP 3.7.9
      fd1ad55e472f20e0|Google Earth Pro 7.3.2.5491
      fdbaca0a1fce6055|MozBackup 1.5.1
      fe57f5df17b45fe|Wireshark 2.6.3
      fe5e840511621941|JetAudio 5.1.9.3018 Basic / 6.2.5.8220 Basic / 7.0.0 Basic / 8.0.16.2000 Basic
      fe8bb4692de7b989|Smart Defrag 4.3.0.847
      fe9e0f7260000a12|RealVNC Server 5.3.0 64-bit (Connect+File Transfer)
      ff103e2cc310d0d|Adobe Reader XI
      ff224628f0e8103c|Morpheus 3.0.3.6
      4cb9c5750d51c07f|Microsoft Movies &amp; TV (Build 10.19031.11411.0)
      ae6df75df512bd06|Microsoft Groove Music (Build 10.19031.1141.0)
      959668a81d4f220e|Sublime Text 3.2.1 (Build 3207)
      9eff0b23d51fe003|XMind 201807140020
      70ffd305907c983b|7zip 18.05
      1c7a9be1b15a03ba|Microsoft ScreenSketch
      1ced32d74a95c7bc|Microsoft Visual Studio Code
      3c3871276e149215|PowerShell 7
      573770283dc3d854|Microsoft Window SecHealthUI
      9390ee5b658e96e|PuTTY 0.72 / 0.73
      a55ed4fbb973aefb|Microsoft Teams
      baacb5294867b833|Notepad++ 7.8.6
      d249d9ddd424b688|Google Chrome 81.0.4044.138
      ff99ba2fb2e34b73|Microsoft Windows Calculator
      4ac866364817f10c|Microsoft Edge (Chromium)
      ccba5a5986c77e43|Microsoft Edge (Chromium)
      188f5ec9d11ded56|Microsoft Edge (Chromium)
      69639df789022856|Google Chrome 86.0.4240.111
      352fd027c0e8f0e5|Zoom
      8bce06a9e923e1f9|Slack 4.10.3
      a55ed4fbb973aefb|Microsoft Teams
      1c7a9be1b15a03ba|Microsoft Snip &amp; Sketch
      466d339d8f21cfbf|Microsoft Snip &amp; Sketch
      9a165f62edbfa161|Microsoft Store
      573770283dc3d854|Windows Defender
      f18460fded109990|Windows Connected Devices
      dd7c3b1adb1c168b|Microsoft Game Bar
      447e6aa2bbdfbc8a|Slack 4.11.3
      3b94415067dd2c5d|GOG Galaxy
      58170c92fa4b91a1|MediaMonkey
      5f218922e0901ebf|MusicBee
      75fdacd8330bac18|AnyDesk
      8b87640a40ec9fc|Snagit 2020
      af0fdd562e3f275b|Snagit 2020
      b7173093b23b9a6a|Beyond Compare 4
      d356105fac5527ef|Steam 1/22/2021
      28efb5b6d2e28389|EA Origin
      20513cdf29d09c0e|Hex Editor Neo
      1d12f965b876dc87|Snagit 2021
      16f2f0042ddbe0e8|Windows Terminal
      352fd027c0e8f0e5|Zoom
      7111c0ce965b7246|Battle.net
      a7ba40025dac9a67|Microsoft Office Hub
      8e4e81d9adc545b8|Microsoft Your Phone
      c01827d56ff89056|Microsoft Sticky Notes
      bd050ac447f6cd65|Microsoft Xbox App
      ff99ba2fb2e34b73|Windows Calculator
      fc98c00f85d4ce77|EditPad Pro 8
      46e77b87767b92|Opera Browser 75
      ad57bd0f4825cce|WinRAR 6.01 Russian 64 bit
      '''

      LET AppIdLookup &lt;= memoize(key="AppId", query={
         SELECT *
         FROM parse_csv(accessor='data', separator="|",
                        filename=AppIdTable)
      })

      LET X = SELECT * FROM foreach(row={
        SELECT OSPath AS AutomaticDestinationsPath
        FROM glob(globs=Globs)
      }, query={
        SELECT AutomaticDestinationsPath, Name,
            parse_binary(filename=OSPath, accessor="mscfb",
                         profile=Profile, struct="ShellLinkHeader")  AS Parsed
        FROM glob(globs='*', accessor="mscfb",
            root=pathspec(DelegatePath=AutomaticDestinationsPath))
        WHERE Size &gt; 0 AND NOT IsDir AND Name =~ "^\\d+$"
      })

      LET Y = SELECT AutomaticDestinationsPath, Name AS Stream,
            split(sep_string=".", string=AutomaticDestinationsPath.Basename)[0] AS ApplicationId,
            ShowHeader(Parsed=Parsed) as _ShellLinkHeader,
            Parsed.LinkInfo as _LinkInfo,
            ShowLinkTarget(Parsed=Parsed) as _LinkTarget,
            Parsed.StringData as _StringData,
            ShowExtraData(Parsed=Parsed) as _ExtraData,
            property_store(data=Parsed) as _PropertyStore
      FROM X

      SELECT *, ApplicationId,
             get(item=AppIdLookup, field=ApplicationId).Description AS Application,
             _LinkTarget.LinkTarget || _LinkInfo.Target.Path AS LinkTarget,
             _ShellLinkHeader.FileSize AS FileSize,
             _ShellLinkHeader.CreationTime AS CreationTime,
             _ShellLinkHeader.AccessTime AS AccessTime,
             _ShellLinkHeader.WriteTime AS WriteTime
      FROM Y

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.detection.thumbdrives.officemacros.md
======
---
title: Windows.Detection.Thumbdrives.OfficeMacros
hidden: true
tags: [Client Event Artifact]
---

Users inserting Thumb drives or other Removable drive pose a
constant security risk. The external drive may contain malware or
other undesirable content. Additionally thumb drives are an easy way
for users to exfiltrate documents.

This artifact watches for any removable drives and scans any added
office documents for VBA macros.

We exclude very large removable drives since they might have too
many files.


<pre><code class="language-yaml">
name: Windows.Detection.Thumbdrives.OfficeMacros
description: |
  Users inserting Thumb drives or other Removable drive pose a
  constant security risk. The external drive may contain malware or
  other undesirable content. Additionally thumb drives are an easy way
  for users to exfiltrate documents.

  This artifact watches for any removable drives and scans any added
  office documents for VBA macros.

  We exclude very large removable drives since they might have too
  many files.

type: CLIENT_EVENT

parameters:
  - name: officeExtensions
    default: "\\.(xls|xlsm|doc|docx|ppt|pptm)$"
    type: regex

sources:
  - query: |
        SELECT * FROM foreach(
          row = {
            SELECT * FROM Artifact.Windows.Detection.Thumbdrives.List()
            WHERE OSPath =~ officeExtensions
          },
          query = {
            SELECT * from olevba(file=OSPath)
          })

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/macos.sys.pslist.md
======
---
title: MacOS.Sys.Pslist
hidden: true
tags: [Client Artifact]
---

List processes and their running binaries.


<pre><code class="language-yaml">
name: Linux.Sys.Pslist
description: |
  List processes and their running binaries.

aliases:
  - MacOS.Sys.Pslist

parameters:
  - name: processRegex
    default: .
    type: regex

precondition: |
  SELECT OS From info() where OS =~ 'linux|darwin'

sources:
  - query: |
        SELECT Pid, Ppid, Name, CommandLine, Exe,
               hash(path=Exe) as Hash,
               Username, timestamp(epoch=CreateTime/1000) AS CreatedTime,
               MemoryInfo.RSS AS RSS,
               Exe =~ "\\(deleted\\)$" AS Deleted
        FROM process_tracker_pslist()
        WHERE Name =~ processRegex

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/generic.client.profile.md
======
---
title: Generic.Client.Profile
hidden: true
tags: [Client Artifact]
---

This artifact collects profiling information about the running
client. This is useful when you notice a high CPU load in the client
and want to know why.

The following options are most useful:

1. Goroutines: This shows the backtraces of all currently running
   goroutines. It will generally show most of the code working in the
   current running set of queries.

2. Heap: This shows all allocations currently in use and where they
   are allocated from. This is useful if the client is taking too
   much memory.

3. Profile: This takes a CPU profile of the running process for the
   number of seconds specified in the Duration parameter. You can
   read profiles using:

```
go tool pprof -callgrind -output=profile.grind profile.bin
kcachegrind profile.grind
```

Note that this really only makes sense when another query is running
at the same time since this artifacts itself will not be doing very
much other than just measuring the state of the process.

NOTE: As of 0.7.0 release, this artifact will also collect
goroutines and heap profiles as distinct sources in a more readable
way.


<pre><code class="language-yaml">
name: Generic.Client.Profile
description: |
  This artifact collects profiling information about the running
  client. This is useful when you notice a high CPU load in the client
  and want to know why.

  The following options are most useful:

  1. Goroutines: This shows the backtraces of all currently running
     goroutines. It will generally show most of the code working in the
     current running set of queries.

  2. Heap: This shows all allocations currently in use and where they
     are allocated from. This is useful if the client is taking too
     much memory.

  3. Profile: This takes a CPU profile of the running process for the
     number of seconds specified in the Duration parameter. You can
     read profiles using:

  ```
  go tool pprof -callgrind -output=profile.grind profile.bin
  kcachegrind profile.grind
  ```

  Note that this really only makes sense when another query is running
  at the same time since this artifacts itself will not be doing very
  much other than just measuring the state of the process.

  NOTE: As of 0.7.0 release, this artifact will also collect
  goroutines and heap profiles as distinct sources in a more readable
  way.

parameters:
  - name: Allocs
    description: A sampling of all past memory allocations
    type: bool
    default: Y
  - name: Block
    description: Stack traces that led to blocking on synchronization primitives
    type: bool
  - name: Goroutine
    description: Stack traces of all current goroutines
    type: bool
    default: Y
  - name: Heap
    description: A sampling of memory allocations of live objects
    type: bool
  - name: Mutex
    description: Stack traces of holders of contended mutexes
    type: bool
  - name: Profile
    description: CPU profile
    type: bool
  - name: Trace
    description: CPU trace
    type: bool
  - name: Logs
    description: Get logs
    type: bool
  - name: QueryLogs
    description: Get recent queries logs
    type: bool
  - name: Metrics
    description: Get client metrics
    type: bool
  - name: Verbose
    description: Print more detail
    type: bool
  - name: Duration
    description: Duration of sampling for Profile and Trace.
    default: "30"

export: |
    LET CleanUp(Name) = regex_replace(
        re="www.velocidex.com/golang/velociraptor/",
        replace="", source=Name)

sources:
  - query: |
      SELECT Type,
             if(condition=get(field="OSPath"),
                then=upload(name=Type + ".bin", file=OSPath)) AS File,
             get(member="Line") AS Line
      FROM profile(allocs=Allocs, block=Block, goroutine=Goroutine,
                   heap=Heap, mutex=Mutex, profile=Profile, trace=Trace,
                   logs=Logs, queries=QueryLogs, metrics=Metrics,
                   debug=if(condition=Verbose, then=2, else=1),
                   duration=atoi(string=Duration))

  - name: Goroutines
    query: |
      -- Only show our own code. This removed unnecessary library
      -- calls and cleans up the output.
      SELECT *, {
         SELECT format(format="%v (%v:%v)",
             args=[CleanUp(Name=Name), basename(path=File), Line])
         FROM CallStack
         WHERE File =~ 'velociraptor|vfilter|go-ntfs'
         LIMIT 10
      } AS CallStack
      FROM profile_goroutines()
      WHERE CallStack

  - name: Memory
    query: |
      SELECT InUseBytes, InUseObjects, {
          SELECT format(format="%v (%v:%v)",
            args=[CleanUp(Name=Name), basename(path=File), Line])
          FROM CallStack
          WHERE File =~ 'velociraptor|vfilter|go-ntfs'
          LIMIT 10
      } AS CallStack
      FROM profile_memory()
      ORDER BY InUseBytes DESC

  - name: Logs
    query: |
      SELECT * FROM profile(logs=TRUE)

  - name: RunningQueries
    query: |
      SELECT Line.Start AS Timestamp, Line.Query AS Query
      FROM profile(queries=TRUE)
      WHERE NOT Line.Duration

  - name: AllQueries
    query: |
      SELECT Line.Start AS Timestamp, int(int = Line.Duration / 1000000) AS DurationSec, Line.Query AS Query
      FROM profile(queries=TRUE)

  - name: Metrics
    query: |
      SELECT Line.name AS Name, Line.value as value
      FROM profile(metrics=TRUE)

  - name: Everything
    query: SELECT * FROM profile(type='.+')

column_types:
  - name: InUseBytes
    type: mb

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/windows.network.packetcapture.md
======
---
title: Windows.Network.PacketCapture
hidden: true
tags: [Client Artifact]
---

Run this artifact twice, the first time, set the StartTrace flag to
True to start the PCAP collection, this will have the VQL return a
single row (the TraceFile generated) When you want to stop
collecting, and transform this TraceFile to a PCAP, re-run this
artifact with StartTrace as false, and put path of the .etl file
created in the previous step in the TraceFile. This will then
convert the .etl to a PCAP and upload it.


<pre><code class="language-yaml">
name: Windows.Network.PacketCapture
author: Cybereason &lt;omer.yampel@cybereason.com&gt;
description: |
  Run this artifact twice, the first time, set the StartTrace flag to
  True to start the PCAP collection, this will have the VQL return a
  single row (the TraceFile generated) When you want to stop
  collecting, and transform this TraceFile to a PCAP, re-run this
  artifact with StartTrace as false, and put path of the .etl file
  created in the previous step in the TraceFile. This will then
  convert the .etl to a PCAP and upload it.

precondition: SELECT OS From info() where OS = 'windows'

tools:
    - name: etl2pcapng
      url: https://github.com/microsoft/etl2pcapng/releases/download/v1.4.0/etl2pcapng.zip

parameters:
    - name: StartTrace
      type: bool
      default: Y
    - name: TraceFile
      type: string
      default:

sources:
    - query: |
        LET tool_zip = SELECT * FROM Artifact.Generic.Utils.FetchBinary(
            ToolName="etl2pcapng", IsExecutable=FALSE)

        LET ExePath &lt;= tempfile(extension='.exe')

        LET etl2pcapbin &lt;= SELECT
            copy(
              filename=pathspec(
                 DelegatePath=tool_zip[0].OSPath,
                 Path="etl2pcapng/x64/etl2pcapng.exe"),
              dest=ExePath,
              accessor='zip'
            ) AS file
        FROM scope()

        LET outfile &lt;= tempfile(extension=".pcapng")

        LET stop_trace = SELECT * FROM execve(
             argv=['netsh', 'trace', 'stop'])

        LET convert_pcap = SELECT * FROM execve(
             argv=[etl2pcapbin[0].file, TraceFile, outfile])

        LET end_trace = SELECT * FROM chain(
                a=stop_trace,
                b=convert_pcap,
                c={SELECT upload(file=outfile) AS Upload FROM scope()},
                d={SELECT upload(file=TraceFile) AS Upload FROM scope()}
            )

        LET launch_trace =
                SELECT
                    split(string=split(
                        string=Stdout,
                        sep="Trace File: ")[1],
                    sep="\r\nAppend:")[0] as etl_file
                FROM execve(argv=["netsh", "trace", "start", "capture=yes"])
                WHERE log(message="stderr: " + Stderr), log(message="stdout: " + Stdout)

        SELECT * FROM if(
                condition=StartTrace,
                then={ SELECT * FROM launch_trace},
                else={ SELECT * FROM end_trace }
        )

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/server.enrichment.geoipisp.md
======
---
title: Server.Enrichment.GeoIPISP
hidden: true
tags: [Client Artifact]
---

This artifact can use the MaxMind database to Geo resolve an IP
address using the GeoIP ISP Database. You will need to provide a valid GeoIP ISP database.

You can obtain a free to use (gratis but not libre) database from
https://www.maxmind.com/ or you can pay for a more accurate option.

After storing the database somewhere on your server, you should the
location in the server metadata screen to it under the key "GeoIPISPDB"
(for example `/usr/shared/GeoIP2-City_20210910/GeoIP2-ISP.mmdb`)

Alternatively you can import this artifact to gain access to the
utility functions (or just copy them into your own artifact).


<pre><code class="language-yaml">
name: Server.Enrichment.GeoIPISP
description: |
  This artifact can use the MaxMind database to Geo resolve an IP
  address using the GeoIP ISP Database. You will need to provide a valid GeoIP ISP database.

  You can obtain a free to use (gratis but not libre) database from
  https://www.maxmind.com/ or you can pay for a more accurate option.

  After storing the database somewhere on your server, you should the
  location in the server metadata screen to it under the key "GeoIPISPDB"
  (for example `/usr/shared/GeoIP2-City_20210910/GeoIP2-ISP.mmdb`)

  Alternatively you can import this artifact to gain access to the
  utility functions (or just copy them into your own artifact).

export: |
  LET ISPDB = server_metadata().GeoIPISPDB
  LET ISP(IP) = geoip(db=ISPDB, ip=IP).isp
  LET ORG(IP) = geoip(db=ISPDB, ip=IP).organization
  LET ASN(IP) = geoip(db=ISPDB, ip=IP).autonomous_system_number
  LET ASO(IP) = geoip(db=ISPDB, ip=IP).autonomous_system_organization

parameters:
  - name: IP
    description: An IP to lookup

sources:
  - query: |
      SELECT ISP(IP=_value) AS ISP,
             ORG(IP=_value) AS Organization,
             ASN(IP=_value) AS ASN,
             ASO(IP=_value) AS ASO
      FROM foreach(row=IP)

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/macos.system.dock.md
======
---
title: MacOS.System.Dock
hidden: true
tags: [Client Artifact]
---

This artifact examines the contents of the user's dock.  The
property list entry for each application represented within the dock
can be modified to point to a malcious application.

 By comparing the application name, CFURLString, and book, we can
 gather greater context to assist in determining if an adversary may
 have tampered with an entry, or if an entry has been added to
 emulate a legitimate application.


<pre><code class="language-yaml">
name: MacOS.System.Dock
description: |
  This artifact examines the contents of the user's dock.  The
  property list entry for each application represented within the dock
  can be modified to point to a malcious application.

   By comparing the application name, CFURLString, and book, we can
   gather greater context to assist in determining if an adversary may
   have tampered with an entry, or if an entry has been added to
   emulate a legitimate application.

reference:
  - https://specterops.io/so-con2020/event-758922
  - https://attack.mitre.org/techniques/T1547/009/
  - https://attack.mitre.org/techniques/T1647/

author: Wes Lambert - @therealwlambert

type: CLIENT

parameters:
   - name: DockGlob
     default: /Users/*/Library/Preferences/com.apple.dock.plist

sources:
  - query: |
       SELECT * FROM foreach(row={
          SELECT OSPath from glob(globs=DockGlob)
       }, query={
         SELECT OSPath, GUID,
           get(member="tile-data.file-label") AS FileLabel,
           get(member="tile-data.file-data._CFURLString") AS AppLocation,
           timestamp(mactime=get(member="tile-data.file-mod-date")) AS FileModDate,
           timestamp(mactime=get(member="tile-data.parent-mod-date")) AS ParentModDate,
           get(member="tile-data.bundle-identifier") AS BundleIdentifier,
           get(member="tile-data.dock-extra") AS DockExtra,
           base64encode(string=get(member="tile-data.book")) AS Book
         FROM foreach(row=plist(file=OSPath).`persistent-apps`)
       })

column_types:
  - name: Book
    type: base64hex

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/system.upload.completion.md
======
---
title: System.Upload.Completion
hidden: true
tags: [Client Event Artifact]
---

An internal artifact that produces events for every file that is
uploaded to the system.


<pre><code class="language-yaml">
name: System.Upload.Completion
description: |
  An internal artifact that produces events for every file that is
  uploaded to the system.

type: CLIENT_EVENT

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/server.utils.deleteevents.md
======
---
title: Server.Utils.DeleteEvents
hidden: true
tags: [Server Artifact]
---

This artifact permanently deletes Event files for client or
monitoring events.

NOTE: This action can not be undone! The event files are deleted
permanently. Since this is a sensitive operation, typically only
users with the administrator role can run it.


<pre><code class="language-yaml">
name: Server.Utils.DeleteEvents
description: |
  This artifact permanently deletes Event files for client or
  monitoring events.

  NOTE: This action can not be undone! The event files are deleted
  permanently. Since this is a sensitive operation, typically only
  users with the administrator role can run it.

type: SERVER

required_permissions:
  - MACHINE_STATE

parameters:
  - name: Artifact
    description: The artifact name to delete
    default:
  - name: ClientId
    description: The client id that the collection was done on
    default:
  - name: StartTime
    type: timestamp
    description: The begining time range to delete
  - name: EndTime
    type: timestamp
    description: The ending time range to delete
  - name: ReallyDoIt
    description: If you really want to delete the collection, check this.
    type: bool

sources:
  - query: |
       SELECT Type, Data.VFSPath AS VFSPath, Error
       FROM delete_events(
         artifact=Artifact, client_id=ClientId,
         start_time=StartTime, end_time=EndTime,
         really_do_it=ReallyDoIt)

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/generic.applications.chrome.sessionstorage.md
======
---
title: Generic.Applications.Chrome.SessionStorage
hidden: true
tags: [Client Artifact]
---

Session storage allows a web site to store permanent data in the
user's browser.

This artifact parses this data from the browser cache. Each website
has maintains a mapping between keys and values. The data is stored
per website and can vary.


<pre><code class="language-yaml">
name: Generic.Applications.Chrome.SessionStorage
description: |
  Session storage allows a web site to store permanent data in the
  user's browser.

  This artifact parses this data from the browser cache. Each website
  has maintains a mapping between keys and values. The data is stored
  per website and can vary.

parameters:
- name: SessionGlobs
  type: csv
  default: |
    Glob
    C:/Users/*/AppData/Local/Google/Chrome/User Data/*/Session Storage
    C:/Users/*/AppData/Local/BraveSoftware/Brave*/User Data/*/Session Storage
    C:/Users/*/AppData/Local/Microsoft/Edge/User Data/*/Session Storage
    /home/*/.config/google-chrome/*/Session Storage
    /home/*/.config/chrome-remote-desktop/chrome-profile/*/Session Storage
    /Users/*/Library/Application Support/BraveSoftware/Brave*/*/Session Storage
    /Users/*/Library/Application Support/Google/Chrome/*/Session Storage
    /Users/*/Library/Application Support/Microsoft Edge/*/Session Storage

- name: Accessor
- name: AlsoUpload
  type: bool
  description: If selected we also upload the Session Storage directory.

sources:
- query: |
    LET _ &lt;= log(message="Glob %v", args= [SessionGlobs.Glob, ])
    LET _GetMapping(Data, ID) = to_dict(item={
      SELECT _key AS RawKey,
             parse_string_with_regex(string=_key,
                 regex='map-([^-]+)-(?P&lt;Key&gt;.+)').Key AS _key,
             utf16(string=_value) AS _value
      FROM items(item=Data)
      WHERE RawKey =~ format(format="map-%v", args=ID)
    })

    LET DumpSessionStorate(Data) =
         SELECT parse_string_with_regex(string=_key,
                    regex='''namespace-(?P&lt;GUID&gt;[^-]+)-(?P&lt;URL&gt;.+)''') AS Parsed,
                _value, _GetMapping(Data=Data, ID=_value) AS Mapping
         FROM items(item=Data)
         WHERE Parsed.URL

    LET hits = SELECT OSPath, to_dict(item={

       -- Load the whole thing into memory since we need to make
       -- several passes on it.
       SELECT Key AS _key, Value  AS _value FROM leveldb(file=OSPath, accessor= Accessor)
    }) AS Data
    FROM glob(globs= SessionGlobs.Glob, accessor= Accessor)

    SELECT * FROM foreach(row={
       SELECT OSPath, Data, if(condition=AlsoUpload, then={
          SELECT upload(file=OSPath) AS Upload
          FROM glob(globs="*", root=OSPath, accessor= Accessor)
       }) AS Upload
       FROM hits
       WHERE log(message="Processing %v", args=OSPath)

    }, query={
       SELECT OSPath,
              Parsed.GUID AS GUID,
              Parsed.URL AS URL,
              Mapping
       FROM DumpSessionStorate(Data=Data)
    })

</code></pre>


---END OF FILE---

======
FILE: /content/artifact_references/pages/server.slack.clients.online.md
======
---
title: Server.Slack.Clients.Online
hidden: true
tags: [Server Event Artifact]
---

Send a message to slack when clients come online.

This artifact searches for all clients that carry the label "Slack"
by default, and if they have appeared online in the last 5 minutes,
sends a message to Slack and removed the label from the client.


<pre><code class="language-yaml">
name: Server.Slack.Clients.Online
description: |
   Send a message to slack when clients come online.

   This artifact searches for all clients that carry the label "Slack"
   by default, and if they have appeared online in the last 5 minutes,
   sends a message to Slack and removed the label from the client.

type: SERVER_EVENT

parameters:
  - name: LabelGroup
    default: Slack
  - name: SlackToken
    description: The token URL obtained from Slack. Leave blank to use server metadata. e.g. https://hooks.slack.com/services/XXXX/YYYY/ZZZZ

sources:
  - query: |
        LET token_url = if(
           condition=SlackToken,
           then=SlackToken,
           else=server_metadata().SlackToken)

        LET hits = SELECT client_id,
               os_info.fqdn as Hostname ,
               now() - last_seen_at / 1000000 AS LastSeen,
               label(client_id=client_id, labels=LabelGroup, op="remove")
        FROM clients(search="label:" + LabelGroup)
        WHERE LastSeen &lt; 300

        LET send_message = SELECT * FROM foreach(row=hits,
        query={
           SELECT client_id, Hostname, LastSeen, Content, Response
           FROM http_client(
                data=serialize(item=dict(
                text=format(format="Client %v (%v) has appeared online %v seconds ago",
                            args=[Hostname, client_id, LastSeen])),
                format="json"),
            headers=dict(`Content-Type`="application/json"),
            method="POST",
            url=token_url)
        })

        // Check every minute
        SELECT * FROM foreach(
           row={SELECT * FROM clock(period=60)},
           query=send_message)

</code></pre>


---END OF FILE---

